{"statistics":{"identical":746,"minorChanges":157,"relatedMeaning":0},"text":{"comparison":{"identical":{"source":{"chars":{"starts":[40213,40311,40420,40611,41068,41260,41329,41456,41669,41699,41963,42356,42442,42638,42674,42774,42850,43112,43142,43295,43389,43517,43581,43617,43713,43890,43926,44091,44189,44271,44443,44636,45266,45424,45537,45615,45715,45996,46264,46360,49931,50940,60937,63150,72828],"lengths":[35,29,27,23,37,23,23,45,29,27,27,23,23,35,25,23,37,29,23,35,29,31,35,25,25,35,23,43,35,43,53,43,23,37,35,31,27,35,31,27,49,21,35,59,62]},"words":{"starts":[5805,5835,5866,5907,5999,6050,6068,6096,6135,6150,6198,6258,6280,6311,6329,6353,6374,6436,6451,6489,6515,6537,6558,6576,6599,6623,6641,6684,6714,6740,6779,6829,6982,7028,7064,7088,7119,7188,7247,7274,8154,8430,10662,11106,13243],"lengths":[17,14,13,11,18,11,11,22,14,13,13,11,11,17,12,11,18,14,11,17,14,15,17,12,12,17,11,21,17,21,26,21,11,18,17,15,13,17,15,13,21,10,14,26,28]}},"suspected":{"chars":{"starts":[2025,2112,2255,2490,3545,4437,4612,4673,4860,4912,4948,4998,5257,5845,6203,6239,6284,6517,7009,7443,7583,7662,7751,7916,7999,8074,8159,8236,8307,8464,8801,9068,9554,9788,10481,10517,11217,13464,13824,14224,3739,9965,7823,4082,2394],"lengths":[35,29,27,23,37,23,23,45,29,27,27,23,23,35,25,23,37,29,23,35,29,31,35,25,25,35,23,43,35,43,53,43,23,37,35,31,27,35,31,27,49,21,35,59,62]},"words":{"starts":[292,328,375,465,801,1054,1108,1126,1181,1199,1217,1235,1314,1482,1589,1607,1625,1713,1898,2061,2110,2146,2181,2242,2272,2301,2332,2361,2389,2444,2549,2628,2781,2849,3003,3021,3154,3623,3711,3804,842,2902,2210,944,429],"lengths":[17,14,13,11,18,11,11,22,14,13,13,11,11,17,12,11,18,14,11,17,14,15,17,12,12,17,11,21,17,21,26,21,11,18,17,15,13,17,15,13,21,10,14,26,28]}}},"minorChanges":{"source":{"chars":{"starts":[45012,45105,45293,58156,60137],"lengths":[92,92,91,84,98]},"words":{"starts":[6908,6941,6995,10005,10426],"lengths":[32,33,27,27,33]}},"suspected":{"chars":{"starts":[9201,9282,9592,4468,5658],"lengths":[80,80,76,82,84]},"words":{"starts":[2675,2706,2800,1069,1430],"lengths":[30,28,26,28,34]}}},"relatedMeaning":{"source":{"chars":{"starts":[],"lengths":[]},"words":{"starts":[],"lengths":[]}},"suspected":{"chars":{"starts":[],"lengths":[]},"words":{"starts":[],"lengths":[]}}}},"value":"Lyapunov Arguments in\nOptimization\n\nby\nAshia Wilson\n\nA dissertation submitted in partial satisfaction of the\nrequirements for the degree of\nDoctor of Philosophy\nin\nStatistics\nin the\nGraduate Division\nof the\nUniversity of California, Berkeley\n\nCommittee in charge:\nProfessor Michael Jordan, Co-chair\nProfessor Benjamin Recht, Co-chair\nProfessor Martin Wainwright\nProfessor Craig Evans\n\nSpring 2018\n\nLyapunov Arguments in\nOptimization\n\nCopyright 2018\nby\nAshia Wilson\n\n1\nAbstract\n\nLyapunov Arguments in\nOptimization\nby\nAshia Wilson\nDoctor of Philosophy in Statistics\nUniversity of California, Berkeley\nProfessor Michael Jordan, Co-chair\nProfessor Benjamin Recht, Co-chair\nOptimization is among the richest modeling languages in science. In statistics and machine learning, for instance, inference is typically posed as an optimization problem. While\nthere are many algorithms designed to solve optimization problems, and a seemingly greater\nnumber of convergence proofs, essentially all proofs follow a classical approach from dynamical systems theory: they present a Lyapunov function and show it decreases. The primary\ngoal of this thesis is to demonstrate that making the Lyapunov argument explicit greatly\nsimplifies, clarifies, and to a certain extent, unifies, convergence theory for optimization.\nThe central contributions of this thesis are the following results: we\n• present several variational principles whereby we obtain continuous-time dynamical\nsystems useful for optimization;\n• introduce Lyapunov functions for both the continuous-time dynamical systems and\ndiscrete-time algorithms and demonstrate how to move between these Lyapunov functions;\n• utilize the Lyapunov framework as well as numerical analysis and integration techniques\nto obtain upper bounds for several novel discrete-time methods for optimization, a few\nof which have matching lower bounds.\n\ni\n\nFor my family\n\nii\n\nContents\nContents\n\nii\n\nList of Figures\n\nv\n\nList of Tables\n\nvi\n\n1 Introduction\n1.1 Preliminary Concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.1.1 Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.1.2 Algorithms and Upper Bounds . . . . . . . . . . . . . . . . . . . . . .\n1.1.3 Role of Convergence Theorems . . . . . . . . . . . . . . . . . . . . .\n1.1.4 Dynamical Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.1.5 Lyapunov’s Method . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.2 Goals and Organization . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n1\n1\n1\n2\n2\n3\n4\n6\n\n2 Deterministic Dynamical Systems\n2.1 Lyapunov Analysis of First-Order Dynamics . . . . . . . . . . . . . . . . . .\n2.1.1 Gradient Descent Dynamic . . . . . . . . . . . . . . . . . . . . . . . .\n2.1.1.1 Nonconvex Differentiable Functions . . . . . . . . . . . . . .\n2.1.2 Convex Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.1.3 Mirror Descent Dynamic . . . . . . . . . . . . . . . . . . . . . . . . .\n2.1.3.1 Convex Functions . . . . . . . . . . . . . . . . . . . . . . . .\n2.1.4 Subgradients and Time Reparameterization . . . . . . . . . . . . . .\n2.1.4.1 Convex Functions . . . . . . . . . . . . . . . . . . . . . . . .\n2.1.5 Dual Averaging Dynamic . . . . . . . . . . . . . . . . . . . . . . . . .\n2.1.6 Conditional Gradient Dynamic . . . . . . . . . . . . . . . . . . . . .\n2.2 Lyapunov Analysis of Second-Order Dynamics . . . . . . . . . . . . . . . . .\n2.2.1 A Lyapunov Analysis of Momentum Methods in Optimization . . . .\n2.2.1.1 The Bregman Lagrangian . . . . . . . . . . . . . . . . . . .\n2.2.1.2 Methods arising from the first Euler-Lagrange equation . . .\n2.2.1.3 Methods arising from the second Euler-Lagrange equation .\n2.2.2 Quasi-monotone methods . . . . . . . . . . . . . . . . . . . . . . . .\n\n7\n7\n7\n9\n10\n12\n12\n16\n18\n20\n22\n24\n25\n26\n28\n32\n35\n\niii\n\n2.3\n\n2.2.3 Equivalence between estimate sequences and Lyapunov functions . . .\n2.2.4 Dual averaging with momentum . . . . . . . . . . . . . . . . . . . . .\n2.2.5 Accelerated Proximal Gradient Dynamics . . . . . . . . . . . . . . . .\nSummary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.3.1 Additional Lyapunov Arguments . . . . . . . . . . . . . . . . . . . .\n\n38\n41\n44\n49\n49\n\n3 Stochastic Differential Equations\n53\n3.1 First-order Stochastic Differential Equations . . . . . . . . . . . . . . . . . . 53\n3.1.1 Stochastic Mirror Descent . . . . . . . . . . . . . . . . . . . . . . . . 56\n3.1.2 Strongly convex functions . . . . . . . . . . . . . . . . . . . . . . . . 57\n3.2 Second-order Stochastic Differential Equations . . . . . . . . . . . . . . . . . 59\n3.2.1 Strongly convex functions . . . . . . . . . . . . . . . . . . . . . . . . 61\n3.3 Lyapunov arguments for coordinate methods . . . . . . . . . . . . . . . . . . 64\n3.4 Breaking Locality Accelerates Block Gauss-Seidel . . . . . . . . . . . . . . . 66\n3.4.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\n3.4.2 Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68\n3.4.2.1 Existing rates for randomized block Gauss-Seidel . . . . . . 68\n3.4.2.2 Accelerated rates for fixed partition Gauss-Seidel . . . . . . 69\n3.4.3 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70\n3.4.3.1 Fixed partition vs random coordinate sampling . . . . . . . 70\n3.4.3.2 A Lyapunov analysis of accelerated Gauss-Seidel and Kaczmarz 71\n3.4.3.3 Specializing accelerated Gauss-Seidel to random coordinate\nsampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74\n3.4.4 Related Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\n3.4.5 Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76\n3.4.5.1 Fixed partitioning vs random coordinate sampling . . . . . 76\n3.4.5.2 Kernel ridge regression . . . . . . . . . . . . . . . . . . . . . 77\n3.4.5.3 Comparing Gauss-Seidel to Conjugate-Gradient . . . . . . . 78\n3.4.5.4 Kernel ridge regression on smaller datasets . . . . . . . . . . 79\n3.4.5.5 Effect of block size . . . . . . . . . . . . . . . . . . . . . . . 79\n3.4.5.6 Computing the μ and ν constants . . . . . . . . . . . . . . . 80\n3.4.6 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81\n3.5 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81\nA Chapter One\nA.1 Examples of Optimization Problems . . . . . . . . . . . . . . . . . . . . . . .\nA.2 Glossary of Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n82\n82\n83\n\nB Chapter Two\nB.1 Gradient Descent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nB.1.1 Polyak-Löjasiewicz Condition . . . . . . . . . . . . . . . . . . . . . .\nB.1.2 Strongly Convex Functions . . . . . . . . . . . . . . . . . . . . . . . .\n\n89\n89\n89\n90\n\niv\nB.1.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nB.1.4 Tighter Bound . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nMirror Desent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nB.2.1 Differentiable Function . . . . . . . . . . . . . . . . . . . . . . . . . .\nB.2.2 Convex Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nB.2.3 Strongly Convex Functions . . . . . . . . . . . . . . . . . . . . . . . .\nB.2.4 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nSubgradients and Time Reparameterization . . . . . . . . . . . . . . . . . .\nB.3.1 Strongly Convex Functions . . . . . . . . . . . . . . . . . . . . . . . .\nAccelerated Mirror Prox . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nDynamics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nB.5.1 Proof of Proposition . . . . . . . . . . . . . . . . . . . . . . . . . . .\nB.5.2 Hamiltonian Systems . . . . . . . . . . . . . . . . . . . . . . . . . . .\nAlgorithms derived from (2.38) . . . . . . . . . . . . . . . . . . . . . . . . .\nB.6.1 Proof of Proposition B.6.1 . . . . . . . . . . . . . . . . . . . . . . . .\nB.6.2 Proof of Lemma B.6.2 . . . . . . . . . . . . . . . . . . . . . . . . . .\nB.6.3 Proof of Proposition 2.2.4 . . . . . . . . . . . . . . . . . . . . . . . .\nB.6.4 Proof of Theorem 2.2.6 . . . . . . . . . . . . . . . . . . . . . . . . . .\nEstimate Sequences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nB.7.1 The Quasi-Montone Subgradient Method . . . . . . . . . . . . . . . .\nB.7.2 Frank-Wolfe . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nB.7.3 Accelerated Gradient Descent (Strong Convexity) . . . . . . . . . . .\nB.7.4 Adagrad with momentum . . . . . . . . . . . . . . . . . . . . . . . .\n\n93\n95\n95\n95\n96\n97\n98\n101\n101\n103\n104\n104\n105\n108\n109\n112\n113\n114\n116\n116\n117\n117\n118\n\nC Chapter Three\nC.1 Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nC.2 Proofs for Separation Results (Section 3.4.3.1) . . . . . . . . . . . . . . . . .\nC.2.1 Expectation calculations (Propositions 3.4.1 and 3.4.2) . . . . . . . .\nC.2.2 Proof of Proposition 3.4.3 . . . . . . . . . . . . . . . . . . . . . . . .\nC.3 Proofs for Convergence Results (Section 3.4.3.2) . . . . . . . . . . . . . . . .\nC.3.1 Proof of Theorem 3.4.5 . . . . . . . . . . . . . . . . . . . . . . . . . .\nC.3.2 Proof of Proposition 3.4.6 . . . . . . . . . . . . . . . . . . . . . . . .\nC.4 Recovering the ACDM Result from Nesterov and Stich [48] . . . . . . . . . .\nC.4.1 Proof of convergence of a simplified accelerated coordinate descent\nmethod . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nC.4.2 Relating Algorithm 2 to ACDM . . . . . . . . . . . . . . . . . . . . .\nC.4.3 Accelerated Gauss-Seidel for fixed partitions from ACDM . . . . . . .\nC.5 A Result for Randomized Block Kaczmarz . . . . . . . . . . . . . . . . . . .\nC.5.1 Computing ν and μ in the setting of [33] . . . . . . . . . . . . . . . .\nC.6 Proofs for Random Coordinate Sampling (Section 3.4.3.3) . . . . . . . . . . .\n\n120\n120\n121\n121\n124\n124\n129\n130\n133\n\nBibliography\n\n143\n\nB.2\n\nB.3\nB.4\nB.5\n\nB.6\n\nB.7\n\n133\n135\n137\n138\n139\n140\n\nv\n\nList of Figures\n3.1\n3.2\n\n3.3\n\n3.4\n\n3.5\n\n3.6\n\nExperiments comparing fixed partitions versus random coordinate sampling for\nthe example from Section 3.4.3.1 with n = 5000 coordinates, block size p = 500.\nThe effect of block size on the accelerated Gauss-Seidel method. For the MNIST\ndataset (pre-processed using random features) we see that block size of p = 500\nworks best. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nExperiments comparing fixed partitions versus uniform random sampling for\nCIFAR-10 augmented matrix while running kernel ridge regression. The matrix\nhas n = 250000 coordinates and we set block size to p = 10000. . . . . . . . . .\nComparing conjugate gradient with accelerated and un-accelerated Gauss-Seidel\nmethods for CIFAR-10 augmented matrix while running kernel ridge regression.\nThe matrix has n = 250000 coordinates and we set block size to p = 10000. . . .\nExperiments comparing fixed partitions versus uniform random sampling for\nMNIST while running kernel ridge regression. MNIST has n = 60000 coordinates and we set block size to p = 4000. . . . . . . . . . . . . . . . . . . . . . .\nComparison of the computed ν constant (solid lines) and ν bound from Theorem 3.4.5 (dotted lines) on random matrices with linearly spaced eigenvalues and\nrandom Wishart matrices. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\nB.1 The mirror map represents the duality relationship between MF and NGF. . . .\n\n77\n\n77\n\n77\n\n77\n\n79\n\n80\n99\n\nvi\n\nList of Tables\n2.1\n\n2.2\n\n2.3\n\n2.4\n\n2.5\n\nLyapunov functions for gradient flow (GF), gradient descent (GD), and the proximal method (PM); with discrete-time identification t = δk, the results in continuous time and discrete time match up to a constant factor of 2. . . . . . . .\nLyapunov functions for mirror flow (MF), mirror descent (MD), the Bregman\nproximal minimization (BPM), mirror prox method (MPM), natural gradient\nflow (NGF) and natural gradient descent (NGD); with discrete-time identification\nt = δk, in the limit δ → 0, the results in continuous time match the results in\ndiscrete time within a factor of 2. The smoothness condition for NGD is that\nDf (x, y) ≤ 1δ kx − yk2x , ∀x, y ∈ X , where kvkx = hv, ∇2 h(x)vi. . . . . . . . . . .\nLyapunov functions for the mirror descent dynamic with directional subgradients\n(MS Dynamic), mirror descent with subgradients (MS Method), and the proximal\nBregman minimization with subgradients (PS Method). When moving to discrete\ntime, there is a discretization error, and we choose parameters accordingly. When\nf is convex, τt = Ak , so that τ̇t ≈ (Ak+1 − Ak )/δ = αk . When f is μ-strongly\nconvex, eμτt = Ak , so that we have the approximation τ̇t = dtd eμτt /μeμτt ≈ (Ak+1 −\nAk )/δμAk+1 := αk . With these choices, the errors scale as ε1k = δαk2 G2 /2σ and\nα2k\n1\nε2k = δ 2σμ\nG2 , where k∂f (x)k2∗ ≤ G2 . In the limit δ → 0, the discrete-time\n2 A\nk+1\nand continuous-time statements match. . . . . . . . . . . . . . . . . . . . . . . .\nLyapunov functions for the dual averaging (DA) dynamic, dual averaging (DA)\nalgorithm , and the backward-Euler approximation of the dual averaging dynam2\n1 αk 2\nics (proximal DA); for the dual averaging algorithm, αk = Ak+1δ−Ak , ε1k = δ 2σ\nG\nγk\n2\n2\nwhere k∂f (x)k∗ ≤ G . In the limit δ → 0, the discrete-time and continuous-time\nstatements match. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nLyapunov functions for conditional gradient descent (CGD) dynamic and the\nd\n\neβt\n\nconditional gradient descent (CGD) algorithm. Here, dteβt\nA\n\n8\n\n13\n\n17\n\n21\n\n−Ak\n≈ Ak+1\n:= τk ,\nδAk+1\n\nτ2\n\nk\nεk+1 = δ k+1\nkzk − xk k2 . In the limit δ → 0, discrete-time and continuous-time\n2\u000f\nstatements match. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n23\n\nvii\n2.6\n\n2.7\n\nLyapunov functions for accelerated mirror descent (AMD) dynamic, accelerated\nmirror descent (AMD), accelerated mirror prox (AMP), and the backward Euler discretization.\nFor AMD1 and AMP, we take Ak+1 = σ\u000f(k+1)(k+2)\n, αk =\n4\n√\n√\n√ −(k+1)\nAk+1 −Ak\nσ\u000f(k+2)\n=\n, δ = \u000fσ and for AMD2, we take Ak+1 = (1 − μδ)\n,\nδ\n2\n√\n√\nAk+1 −Ak\nτk = δAk+1 = μ, δ = \u000f. . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nLyapunov functions for the quasi-monotone (QM) subgradient dynamics and\nquasi-monotone (QM) subgradient methods. There is a discretization error as\nwe move to discrete time, and we choose parameters accordingly. Here, eβt = Ak ,\nso that dtd eβt ≈ (Ak+1 − Ak )/δ = αk and τk = (Ak+1 − Ak )/δAk . The errors scales\nα2\n\n2.8\n2.9\n\n27\n\nα2\n\n1\nk\nG2 . In the limit δ → 0, the discrete-time and\nas ε1k = δ 2σk G2 and ε2k = δ 2σμ\nAk\ncontinuous-time statements match. . . . . . . . . . . . . . . . . . . . . . . . . .\nChoices of estimate sequences for various algorithms . . . . . . . . . . . . . . . .\nLyapunov functions for the dual averaging dynamic with momentum, dual averaging algorithm with momentum, and the backward-Euler approximation of the\ndual averaging dynamics with momentum; Here, g(x) ∈ ∂f (x), αk = Ak+1δ−Ak ,\n\n36\n40\n\nα2\n\n1 k 2\nand ε1k = δ 2σ\nG , where k∂f (x)k2∗ ≤ G2 . In the limit δ → 0, the discrete-time\nγk\nand continuous-time statements match. . . . . . . . . . . . . . . . . . . . . . . .\n2.10 Lyapunov functions for proximal accelerated mirror descent (AMD) dynamics,\nproximal accelerated mirror descent (AMD) algorithms .√ For proximal AMD\n√\n, αk = Ak+1δ−Ak = σ\u000f(k+2)\n, δ = \u000fσ and\nalgorithm 1 we take Ak+1 = σ\u000f(k+1)(k+2)\n4\n2\n√\n√\n−Ak\nfor proximal AMD algorithm 2, we take τk = Ak+1\n= μ, δ = \u000f. . . . . . .\nδAk+1\n2.11 List of Lyapunov Arguments in Optimization presented in this thesis (so far). .\n\n3.1\n\n42\n\n44\n50\n\nLyapunov functions for stochastic mirror descent dynamics and algorithm and\nstochastic dual averaging dynamics and algorithm. Assume σ \u0016 ∇2 h and E[σt ] ≤\nG, E[kg(x)k∗ ] ≤ G ∀x ∈ X and t ∈ R+ . When f is convex, αk = Ak+1δ−Ak and\n( d eμτt |\n\n)2\n\n1\n1\nk+1 −Ak\nwhen f is strongly convex αk = AδμA\n. Here, ε1s = 2σ\nG2 τ̇s2 , ε2s = 2σ\nG2 dt2μ2 eμτt=s\n,\ns\nk+1\n2\n\n3.2\n\n2\n\n2\n\n2\n\n−As )\n1\n1\n1\n1\ns)\ns+1 −As )\nε3s = δ 2σ\nG2 (As−1δ−A\n, ε4s = δ 2σ\nG2 (A\n, ε5s = 2σ\nG2 τ̇γss and ε6s = δ 2σ\nG2 (As+1\n.\n2\nδ 2 2μ2 As+1\nδ 2 γs\nThe scalings on the error and Ito correction terms match. . . . . . . . . . . . . 54\nLyapunov functions for the stochastic accelerated mirror descent (SAMD) dynamics and stochastic mirror descent (SAMD) algorithms. The error in continuous time comes from the Ito correction term. Assume σ \u0016 ∇2 h and E[σt ] ≤\n2\n−As )2\n1\n1\nG, E[kg(x)k∗ ] ≤ G ∀x ∈ X and t ∈ R+ . Here, ε1s = 2σ\nG2 τ̇γss , ε2s = 2σ\nG2 (As+1\nδ,\nδ 2 γs\n2\nd βt\n( e |t=s )\n−As )2\n1\n1\nε3s = 2σ\nG2 dt 2μeβs , and ε4s = 2σ\nG2 (As+1\nδ. The scalings on the error and\n2δ 2 μAs\nIto correction terms match. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\n\nviii\n\nAcknowledgments\nMom, Dad, Ayana and Jay, thank you for your unwavering love and support. You have been\nin the trenches with me and I certainly would not have made it to this point without you.\nYou have my eternal gratitude and love. We did it!\nTo my advisors, Mike and Ben, thank you, thank you, thank you for providing me with\ninvaluable encouragement, guidance, and support throughout the course of my PhD. Other\nacademic mentors to whom I owe special thanks are Cynthia Rudin, Eric Tchetgen Tchetgen,\nPamela Abshire, and Michael Brenner. Thank you for your kindness.\nThank you to my collaborators, Andre, Nick, Tamara, Becca, Shivaram, Mitchell, Stephen,\nMicheal B., Alex and Nati Srebro. I am so fortunate to have worked with and learned from\nsuch brilliant and kind people. I must single out Andre – you are a soulmate – and Nick –\nthank you for being such a patient and loving friend. Becca, girl, so grateful for your energy.\nI am honored and grateful to have many truly amazing and supportive relationships in\nmy life. While there are far too many to provide an exhaustive list, I would be remiss if I\ndid not mention some key friends. Henry, Brett, Velencia, Robert, Meron, Kene, Christine,\nMarianna, Nina, Dawn, Po-Ling, and Nick A. Velencia and Meron, you are sisters. Thank\nyou for showing up, and showing up, and showing up. Henry (and Lucy), Brett, and Robert,\nthank you for always being there. And to some new close friends, Jee, Elliot, Rocky, Jamal,\nMike. You inspire me and grow me. I hope to know you for a long time.\nI am also very grateful for the The Berkeley Chancellor’s Postdoctoral Fellowship Program and the National Science Foundation for providing me with financial support.\n\n1\n\nChapter 1\nIntroduction\nThe ubiquity of optimization problems in science and engineering has led to great interest\nin the design of algorithms meant to solve them. This thesis discusses the connection between continuous-time dynamical systems and discrete-time algorithms for machine learning\nand optimization. Examples of the algorithms we discuss include the stochastic, proximal,\ncoordinate, and deterministic variants of gradient descent, mirror descent, dual averaging,\naccelerated gradient descent, the conditional gradient method, dual averaging with momentum, and adaptive gradient methods. For each algorithm, we show that a single, simple\nLyapunov argument proves convergence. In this chapter, we present background material.\n\n1.1\n\nPreliminary Concepts\n\nWe begin by defining what an optimizatin problem is, what an algorithm is, and what it\nmeans to have an upper-bound for an algorithm. We also define continuous-time dynamical\nsystems and discuss Lyapunov’s method. We end by describing our strategy for moving\nbetween the Lyapunov arguments presented in continuous time and in discrete time; this\nwill provide a framework for obtaining upper bounds on the rate of convergence for most\nalgorithms in optimization.\n\n1.1.1\n\nOptimization\n\nThe field of optimization studies the following problem,\nmin f (x).\nx∈X\n\n(1.1)\n\nHere, x is the decision variable, X is the set of possible decisions, and f : X → R is the\nobjective function. Throughout, we refer to x∗ ∈ arg minx∈X f (x) as a solution to (1.1).\nMost decision and inference problems in engineering and science are modeled as (1.1). In\nAppendix A, we list several motivating examples.\n\nCHAPTER 1. INTRODUCTION\n\n1.1.2\n\n2\n\nAlgorithms and Upper Bounds\n\nAn optimization algorithm is a recipe for generating a sequence of points (xs )ks=0 to solve\nproblem (1.1). To generate the next point in the sequence, the algorithm uses the local\ninformation it receives from an oracle along with all the previous information it has received.\nAn oracle is a black-box function that provides the algorithm with information about (f , X )\nat a point x. As a specific example, if f is differentiable and X = Rd , a gradient oracle\nprovides the algorithm with the function value and the gradient (f (x), ∇f (x)) at any queried\npoint x; algorithms which have access to this oracle function use the information (xs )ks=0 ,\nk−1\n(f (xs ))k−1\ns=0 , (∇f (xs ))s=0 , and the pair (f (x), ∇f (x)) computed at any point x, to construct\nthe next point xk+1 .\nSuppose two algorithms A1 and A2 are proposed to solve an instance of problem (1.1).\nWhich algorithm should we choose? Is there another algorithm A3 which finds x∗ faster than\nA1 and A2 ? The goal of complexity theory for optimization is to address these questions.\nIdeally, we could partition the space of problems (f , X ) according to which algorithms are\nfastest for solving them (or vice versa). In addition, we might search for a framework that\ntakes into account potential computational constraints. Unfortunately, given the size of the\nspace of possible problems, creating such a comprehensive framework is probably impossible.\nInstead, the standard adopted widely in the theory community is to treat classes of problems, and evaluate algorithms according to the minimum number of oracle queries required\nto produce an approximate solution for any problem instance in the class. An approximate\nsolution is an iterate xk such that f (xk )−f (x∗ ) ≤ \u000f, d(xk , x∗ ) ≤ \u000f, or d∗ (∇f (xk ), ∇f (x∗ )) ≤ \u000f\nfor some distance measure d : X × X → R+ or d∗ : X ∗ × X ∗ → R+ and error threshold \u000f > 0.\nThe minimum number of oracle queries required to find an approximate solution for\nany function in a prespecified class of functions is called a lower bound for the oracle. For\nexample, consider f ∈ F, where F is the class of convex functions with smooth gradients\nover Rd . Any algorithm which\nhas access to the gradient oracle for this class of functions\n√\nrequires a minimum Ω(1/ \u000f) queries to find a solution such that f (xk ) − f (x∗ ) ≤ \u000f.\nLet xk be the output of the algorithm on the k-th iteration. An upper bound for\nan algorithm is a sequence \u000f(k), such that f (xk ) − f (x∗ ) ≤ \u000f(k), d(xk , x∗ ) ≤ \u000f(k), or\nd∗ (∇f (xk ), ∇f (x∗ )) ≤ \u000f(k). Generally speaking, upper bounds quantify how fast a solution to (1.1) is being found by the algorithm. An algorithm A is called provably optimal\nif there is an upper bound which matches the lower bound for the oracle function it has\naccess to. While this thesis does not discuss lower bounds or techniques for deriving them,\nwe mention when it has been established in the literature that an algorithm is provably\noptimal.\n\n1.1.3\n\nRole of Convergence Theorems\n\nOur goal in discussing how to obtain upper bounds for algorithms is to make explicit the\nconnection between continuous-time dynamical systems and discrete-time algorithms for\noptimization as well as the Lyapunov arguments used to analyze both. The observation that\n\nCHAPTER 1. INTRODUCTION\n\n3\n\nLyapunov arguments are important to convergence theory in optimization is not new; in his\nbook, Introduction to Optimization, for instance, Polyak makes this specific point [54]. A\nmain contribution of this thesis is to discuss the Lyapunov analysis of several methods that\nare not covered in Polyak’s early book, and to make the connection between continuous-time\ndynamical systems and discrete-time dynamical systems more concrete.\nIn the same book, Polyak encourages his reader to proceed with caution when studying\nconvergence theory for optimization. From the perspective of practitioners, he acknowledges,\nthe conditions under which the bound can be obtained are often hard to verify, unknown,\nor frequently violated. Furthermore, it is unclear whether worst-case performance over a\nfunction class is the criterion by which we should measure the performance of algorithms.\nNevertheless, convergence proofs provide useful information about the algorithm. Convergence guarantees determine a class of problems for which one can count on the applicability\nof the algorithm, as well as provide information on the qualitative behavior of convergence:\nwhether we should expect convergence for any initial approximation or only for a sufficiently\ngood one, and in what sense we should expect the converges to happen (the function converges, or the argument, non-asymptotic vs asymptotic, and so on).\n\n1.1.4\n\nDynamical Systems\n\nA dynamical system is a time varying vector field v : R × Rd → Rd . From an initial point\nX0 , a dynamical system generates a curve, called a trajectory, via the equation\nZ t\nXt = X 0 +\nvs (Xs )ds,\n(1.2)\n0\n\nwhere we adopt the shorthand vt (x) := v(t, x). We can interpret vt (x) as a velocity at\nposition x,\nd\nXt = vt (Xt ).\ndt\n\n(1.3)\n\nIn this thesis, we study how dynamical systems defined by ordinary differential equations (1.3)\ncan be used to generate discrete sequences of points. Notably, most algorithms in optimization are obtained from applying either the forward or backward Euler method to (1.3). We\nprovide a short explanation of these two techniques.\nSuppose we are given a dynamical system (1.3) and a starting position Xt ∈ Rd . The\ngoal is to use Xt and its velocity vt (Xt ) to tell us where to move next in time. To do so,\nwe adopt a scaling of time, δ > 0, (i.e. our notion of next) and approximate Xt+δ from Xt .\nUsing the integral curve formulation (1.2), we have,\nZ t+δ\nvs (Xs )ds.\n(1.4)\nXt+δ − Xt =\nt\n\nWe can form a discrete sequence of points as follows. For any initial point Xt , approximation of the integral (1.4) by its upper-limit, vt+δ (Xt+δ )δ, defines an operator called the\n\nCHAPTER 1. INTRODUCTION\n\n4\n\nBackward-Euler (BE) method. In particular, if we write xk+1 := Xδ(k+1) = Xt+δ and xk :=\nXδk = Xt and make the same identifications for the vector field, vk (xk ) := vk (Xδk ) = vt (Xt )\nand vk+1 (xk+1 ) := vk+1 (Xδ(k+1) ) = vt+δ (Xt+δ ), we can write the BE method as,\nxk+1 − xk\n= vk+1 (xk+1 ).\nδ\n\n(1.5)\n\nApproximation of the integral by its lower-limit, vt (Xt )δ, defines another operator called the\nForward-Euler (FE) method. Using the same identiifcations, we can write the FE method\nas,\nxk+1 − xk\n= vk (xk ).\nδ\n\n(1.6)\n\nBoth the BE method (1.5),\nxk+1 = (I − δvk+1 )−1 (xk ) := ABE\nδ,v (xk ),\nand FE method (1.6),\nxk+1 = (I + δvk )(xk ) := AFE\nδ,v (xk ),\napplied to dynamics (1.3) form discrete-time dynamical systems parameterized by the vector\nfield v and discretization scaling δ. These discrete-time dynamical systems are equivalent to\nFE\nalgorithms for oracle functions that allow the algorithm to compute ABE\nδ,v or Aδ,v evaluated\nat any point x ∈ X each time it is queried. As an example, suppose vk ≡ ∇f . The FE\noperator, is a popular algorithm called gradient descent, xk+1 = xk − δ∇f (xk ), and the BE\noperator is another algorithm called the proximal method. We elaborate on this example,\nas well as provide many more examples in Chapter 2.\n\n1.1.5\n\nLyapunov’s Method\n\nA popular way to describe dynamical systems is via conserved and dissipated quantities.\nThe general technique prescribes identifying a quantity E : X → R which is either constant\n(conserved),\nd\nE(Xt ) = h∇E(Xt ), vt (Xt )i = 0,\n(1.7a)\ndt\ndecreasing (dissipated),\nd\nE(Xt ) = h∇E(Xt ), vt (Xt )i ≤ 0,\n(1.7b)\ndt\nor strictly decreasing,\nd\nE(Xt ) = h∇E(Xt ), vt (Xt )i < 0,\n(1.7c)\ndt\nalong the trajectories of the dynamical system (1.3).\n\nCHAPTER 1. INTRODUCTION\n\n5\n\nThis thesis is primarily concerned with dissipated quantities for dynamical systems (1.7b)\nthat have explicit dependencies on time, which we refer to as Lyapunov functions. The idea of\nproviding the trajectories of dynamical systems with qualitative descriptions was formulated\nby Lyapunov in his fundamental work [36]; there exist many textbooks and monographs\nexpanding on this idea (see [27, 19] for example).\nFrom Lyapunov Functions to Convergence Theorems We demonstrte more explicitly how Lyapunov functions will be used to obtain upper bounds for most algorithms in\noptimization. Suppose we have generated a trajectory of the dynamical system Xt from an\narbritrary starting position X0 . To provide bounds for the rate at which E1 = f (Xt ) − f (x∗ ),\nE2 = d(Xt , x∗ ), or E3 = d∗ (∇f (Xt ), ∇f (x∗ )), converge to zero, we will consider E1 , E2 , and/or\nE3 , as well as combinations of them, scaled by some function of time. For example, if we\nshow the time-dependent function\nEt = eβt (f (Xt ) − f (x∗ )),\n\n(1.8)\n\nis a Lyapunov function, where βt : R → R is an arbitrary smooth, continuously differentiable,\nincreasing function of time, dtd βt > 0, then we will be able to conclude a non-asymptotic rate\nof convergence. Specifically, if (1.8) is decreasing, then dtd Et ≤ 0 (i.e (1.7b) holds); by\nintegrating we can conclude the property, Et ≤ E0 , which will allow us to obtain the upper\nbound,\nE0\neβ0 (f (X0 ) − f (x∗ ))\n=\n,\neβt\neβt\nand subsequently, an O(e−βt ) convergence rate.\nIn discrete time, we start by mapping the dynamical system to an algorithm, which\ngenerates a discrete sequence of points from any given starting point x0 . To provide bounds\nfor the rate at which E1 = f (xk ) − f (x∗ ), E2 = d(xk , x∗ ), and/or E3 = d∗ (∇f (xk ), ∇f (x∗ )),\nconverge to zero, the strategy will be same. Following the above example, we consider the\nLyapunov function,\nf (Xt ) − f (x∗ ) ≤\n\nEk = Ak (f (xk ) − f (x∗ )),\nwhere Ak : R → R+ is an increasing sequence in k. If we make the identifications eβt+δ = Ak+1\nand eβt = Ak , then the requirement dtd βt > 0 translates to the requirement dtd βt = dtd eβt /eβt ≈\n(Ak+1 − Ak )/δAk > 0. This, of course, is based on adopting an exponential scaling of\ntime eβt . If, instead, we choose to scale time linearly, Et = τt (f (Xt ) − f (x∗ )), so that\nτt = Ak and τt+δ = Ak+1 , then the requirment dtd τt > 0 translates to the requirement\nd\nτ ≈ (Ak+1 −Ak )/δ > 0. These two ways of scaling time appear throughout this framework.\ndt t\nFor either approximation, we check whether the Lyapunov property, Ek+1δ−Ek ≤ 0, can be\nshown for various discretizations of the dynamical system. If so, by summing we can show,\nEk ≤ E0 , which will allow us to obtain the upper bound,\nf (xk ) − f (x∗ ) ≤\n\nE0\nA0 (f (X0 ) − f (x∗ ))\n=\n,\nAk\nAk\n\nCHAPTER 1. INTRODUCTION\n\n6\n\nfor the algorithm, and subsequently, a matching O(1/Ak ) convergence rate.\nWe provide several specific examples of this technique in Chapters 2 and 3.\n\n1.2\n\nGoals and Organization\n\nThe primary contribution of this thesis is to present and discuss Lyapunov arguments commonly used in optimization. The Lyapunov framework we present demonstrates the centrality of dynamical systems to the field of optimization and machine learning. We organize this\nthesis as follows:\n• Chapter 2 summarizes several families of ordinary differential equations used in optimization. Section 2.1 focuses on algorithms in optimization that discretize first-order\ndifferential equations (i.e. ODEs with one time derivative). This includes gradient\ndescent, mirror descent, subgradient methods, dual averaging, and the condiitional\ngradient algorithms. For all these algorithms, we demonstrate how to move between\nthe Lyapunov arguments presented in continuous and discrete-time. This material\nwill mostly be presented in tables with more complete descriptions provided in the\nAppendices.\n• Section 2.2 focuses on algorithms in opimization that discretize second-order differential equations (i.e. ODEs with two time derivatives). This includes accelerated\ngradient descent, the accelerated proximal gradient method and the quasi-monotone\nsubgradient methods. Techniques for obtaining upper-bounds for these algorithms\nhave been famously considered esoteric. We demonstrate how many of these techniques, including the technique of estimate sequences, are equivalent to a Lyapunov\nargument. In addition, we introduce two Lagrangian/Hamiltonian functionals, we call\nBregman Lagrangians/Hamiltonians, which generate two large classes of accelerated\nmethods in continuous time. We then provide a systematic methodology for converting\nthe continuous-time dynamical systems obtained from these variational principles to\ndiscrete-time algorithms with matching convergence rates.\n• Chapter 3 extends the Lyapunov framework to stochastic differential equations and\nstochastic algorithms. This includes stochastic gradient descent, stochastic mirror\ndescent, stochastic dual averaging, stochastic accelerated gradient descent. We also\npresent an analogous description for coordinate-based methods. In particular, we show\nthe same Lyapunov functions presented in the previous chapter provide upper bounds\nfor the rate at which these algorithms find a solution to (1.1) in expectation.\nHow to read this thesis A good strategy for gleaming the content of this thesis is to\nreview the tables at the beginning of each subsection and to skim the summary section\npresented at the end of both chapters.\n\n7\n\nChapter 2\nDeterministic Dynamical Systems\nIn this chapter, we summarize several families of dynamics (1.3) which can be said to find\na solution to (1.1). For each dynamic, we exhibit a Lyapunov function which will ensure\nconvergence to a stationary point that is either a solution to (1.1) or a critical point of the\nobjective function. We also show how to move between the continuous and discrete-time\nanalyses using two standard discretization methods.\n\n2.1\n\nLyapunov Analysis of First-Order Dynamics\n\n2.1.1\n\nGradient Descent Dynamic\n\nLet X = Rd . The dynamic that gives rise to gradient descent can be analyzed in (at least)\nfour different settings:\n1. f is differentiable, but not necessarily convex;\n2. f is convex, so that Df (x, y) ≥ 0 ∀x, y ∈ X (see (A.2) for definition) ;\n3. f satisfies the Polyak-Löjasiewicz (PL) condition with parameter μ, so that\n1\n− k∇f (x)k2 ≤ −μ(f (x) − f (x∗ )), ∀x ∈ X .\n2\n\n(2.1)\n\n4. f is μ-strongly convex, so that Df (y, x) ≥ μ2 ky − xk2 .\nWe summarize the Lyapunov functions in Table 2.1 and provide a description of the first and\nsecond bullet points in the main text. The rest of the results can be found in Appendix B.1.\nThe gradient descent dynamic (GF),\n\u001a\n\u001b\nd\n1\n2\nXt = arg min h∇f (x), vi + kvk = −∇f (Xt ),\n(2.2)\ndt\n2\nv∈Rd\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n8\n\nGradient Flow:\n\nẊt = −∇f (Xt )\n\nFunction Class\n\nLyapunov Function\n\nConvergence Rate\n\nDifferentiable\n\nEt = f (Xt ) − f (x∗ )\n\nmin k∇f (Xs )k ≤ O(1/t 2 )\n\nConvex\n\nEt = 21 kx∗ − Xt k2 + t(f (Xt ) − f (x∗ ))\n\nf (Xt ) − f (x∗ ) ≤ O(1/t)\n\nPL Condition w.p μ\n\nEt = e2μt (f (Xt ) − f (x∗ ))\n\nf (Xt ) − f (x∗ ) ≤ O(e−2μt )\n\nμ-Strong Convexity\n\nEt = eμt 21 kx∗ − Xt k2\n\n1\nkx∗ − Xt k2 ≤ O(e−μt )\n2\n2μL\n1\nkx∗ − Xt k2 ≤ O(e− μ+L t )\n2\n\nf is L-smooth\n\nEt = e\n\n2μL\nt\nμ+L 1\n\n2\n\nkx∗ − Xt k2\n\n1\n\n0≤s≤t\n\n2μL\n\nf (Xt ) − f (x∗ ) ≤ O( L2 e− μ+L t )\nGradient Descent:\n\nxk+1 −xk\n= −∇f (xk )\nδ\n\nFunction Class\n\nLyapunov Function\n\nDifferentiable\n\nEk = f (xk ) − f (x∗ )\n\nf is (1/δ)-smooth\n\nConvergence Rate\n1\n\nmin 1 k∇f (xs )k ≤ O(1/(δk) 2 )\n\n0≤s≤k 2\n\nf is (1/δ)-smooth\n\nEk = 12 kx∗ − xk k2 + δk(f (xk ) − f (x∗ ))\n\nf (xk ) − f (x∗ ) ≤ O(1/δk)\n\nPL Condition w.p μ\n\nEk = (1 − μδ)−k (f (xk ) − f (x∗ ))\n\nf (xk ) − f (x∗ ) ≤ O(e−μδk )\n\nEk = (1 − μδ)−k 12 kx∗ − xk k2\n\u0010\n\u0011−k\n2μL\n1\nEk = 1 − μ+L\nδ\nkx∗ − xk k2\n2\n\n1\nkx∗ − xk k2 ≤ O(e−μδk )\n2\n\nConvex\nf is (1/δ)-smooth\n\nμ-Strong Convexity\nf is (1/δ)-smooth\nf is (L = 2−μδ\n)-smooth\nδ\n\n2μL\n1\nkx∗ − xk k2 ≤ O(e− μ+L δk )\n2\n2μL\n\nf (xk ) − f (x∗ ) ≤ O( L2 e− μ+L δk )\nProximal Method:\n\nxk+1 −xk\n= −∇f (xk+1 )\nδ\n\nFunction Class\n\nLyapunov Function\n\nDifferentiable\n\nEk = f (xk ) − f (x∗ )\n\nδ>0\n\nConvergence Rate\n1\n\nmin 1 k∇f (xs )k ≤ O(1/(δk) 2 )\n\n0≤s≤t 2\n\nConvex\nδ>0\n\nEk = 12 kx∗ − xk k2 + δk(f (xk ) − f (x∗ ))\n\nf (xk ) − f (x∗ ) ≤ O(1/δk)\n\nPL Condition w.p μ\n\nEk = (1 + μδ)k (f (xk ) − f (x∗ ))\n\nf (xk ) − f (x∗ ) ≤ O(e−μδk )\n\nEk = (1 + μδ)k 21 kx∗ − xk k2\n\u0010\n\u0011k\n2μL\nEk = 1 + μ+L\nδ 12 kx∗ − xk k2\n\n1\nkx∗ − xk k2 ≤ O(e−μδk )\n2\n\nδ>0\n\nμ-Strong Convexity\nδ>0\nf is L-smooth\n\n2μL\n1\nkx∗ − xk k2 ≤ O(e− μ+L δk )\n2\n2μL\n\nf (xk ) − f (x∗ ) ≤ O( L2 e− μ+L δk )\n\nTable 2.1: Lyapunov functions for gradient flow (GF), gradient descent (GD), and the proximal method (PM); with discrete-time identification t = δk, the results in continuous time\nand discrete time match up to a constant factor of 2.\n\nis a steepest descent flow. For any initial starting point X0 , GF moves with velocity vt (Xt ) =\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n9\n\n−∇f (Xt ), and stops only at a critical point of the function ( dtd Xt = 0 if and only if ∇f (Xt ) =\n0). Gradient descent (GD),\n\u001b\n\u001a\nxk+1 − xk\n1\n2\n(2.3)\n= arg min h∇f (x), vi + kvk = −∇f (xk ),\nδ\n2\nv∈Rd\nis the result of applying the forward-Euler method (1.6) to GF (2.2). GD similarly adds to\nits current position x, the gradient ∇f (x) computed at x, and stops only at a critical point\nof the function ( xk+1δ−xk = 0 if and only if ∇f (xk ) = 0). The backward-Euler method (1.5)\napplied to (2.2),\nxk+1 − xk\n= −∇f (xk+1 ),\nδ\n\n(2.4)\n\nis called the proximal method (PM). It is a stationary point of the following optimization\nproblem,\n\u001a\n\u001b\n1\n2\nxk+1 ∈ arg min f (x) + kx − xk k := Proxδf (xk ).\n(2.5)\nx∈X\n2δ\nGiven the nature of the update (2.5), the PM is used primarily when f is easy to optimize\nover (such as when f (x) = kxk1 is the `1 norm). See [53] for an excellent monograph on the\nproximal methods and the various ways to interpret them. Lyapunov analyses for all these\nmethods follow a similar structure.\n2.1.1.1\n\nNonconvex Differentiable Functions\n\nThe optimality gap,\nEt = f (Xt ) − f (x∗ )\nis a Lyapunov function for (2.2). We check,\nd\nd\n(2.2)\nEt = f (Xt ) = h∇f (Xt ), Ẋt i = −k∇f (Xt )k2 .\ndt\ndt\n\n(2.6)\n\nHere, the first equality follows because x∗ is constant with respect to time, and the second\nuses the chain rule. By rearranging and integrating (2.6), t min0≤s≤t k∇f (Xs )k2 ≤\nRequality\nt\nk∇f (Xs )k2 ds ≤ E0 − Et ≤ E0 , we conclude a O(1/t) convergence to a critical point of the\n0\nfunction,\nmin k∇f (Xs )k2 ≤\n\n0≤s≤t\n\nf (X0 ) − f (x∗ )\n.\nt\n\nGiven the description above, this result is intuitive – if we go down hill, we will only stop at\na critical point of the function, i.e. point x where ∇f (x) = 0. This corresponds to saddle\npoints and local/global minimizers of the function, if they exist. Similar statements can be\nmade for gradient descent and the proximal method.\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n10\n\nGradient Descent As long as the function is L-smooth (A.13) , where 0 ≤ δ < 2/L, the\noptimality gap,\nEk = f (xk ) − f (x∗ ),\n\n(2.7)\n\nremains a Lyapunov function for GD. We check,\n\n\nEk+1 − Ek\nf (xk+1 ) − f (xk )\n2 − δL\nxk+1 − xk (2.3) 2 − δL\n=\n≤\n∇f (xk ),\n= −\nk∇f (xk )k2 .\nδ\nδ\n2\nδ\n2\n(2.8)\nHere, the inequality follows from the smoothness condition (A.13). Take L\n1/δ. We can\nP=\nk\n1\n2\nsimilarly rearrange this statement to conclude, δk min0≤s≤t 2 k∇f (xs )k ≤ δ s=0 12 k∇f (xs )k2 ≤\nE0 − Et ≤ E0 . Therefore, as long as f is a (1/δ)-smooth function, we can guarantee O(1/δk)\nconvergence to a stationary point,\nf (x0 ) − f (x∗ )\n1\nk∇f (xs )k2 ≤\n.\n0≤s≤k 2\nδk\nmin\n\nProximal Method The discrete optimality gap (2.7) is a Lyapunov function for (2.5) as\nwell. We check,\n\n\nEk+1 − Ek\nf (xk+1 ) − f (xk )\n1\nxk+1 − xk (2.4) 1\n=\n≤\n∇f (xk+1 ),\n= − k∇f (xk+1 )k2 . (2.9)\nδ\nδ\n2\nδ\n2\nThe inequality follows from the optimality condition (2.5), which implies f (xk+1 )+ 2δ1 kxk+1 −\nxk k2 ≤ f (xk )+ 2δ1 kxk −xk k2 . By rearranging and summing, we obtain the analogous discretetime statement,\n1\nf (x0 ) − f (x∗ )\nk∇f (xs )k2 ≤\n.\n0≤s≤k 2\nδk\nmin\n\nWhen moving between upper bounds in continuous and discrete time, we lose a factor of\ntwo and an additional assumption (smoothness for GD) is needed.\n\n2.1.2\n\nConvex Functions\n\nWhen the objective function is convex, the Lyapunov function,\n1\nEt = kx∗ − Xt k2 + t(f (Xt ) − f (x∗ )),\n2\nallows us to conclude convergence to the minimizer. We check,\n\n\nd\nd\nd\n∗\nEt = −\nXt , x − Xt + f (Xt ) − f (x∗ ) + t f (Xt )\ndt\ndt\ndt\n(2.2)\n\n= −Df (x∗ , Xt ) − tk∇f (Xt )k2 ≤ 0.\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n11\n\nHere, the inequality follows from convexity of f , which ensures the Bregman\ndivergence (A.2)\nRt d\nis non-negative. By integrating, we obtain the statement Et −E0 = 0 ds Es ds ≤ 0, from which\nwe can conclude at O(1/t) convergence rate of the function value,\nf (Xt ) − f (x∗ ) ≤\n\nE0\n.\nt\n\nSimilar statements can be made about GF (2.2) and the PM (2.4).\nGradient Descent For GD, as long as the function is L-smooth, where δ ≤ 1/L, the\nfollowing function,\n1\nEk = kx∗ − xk k2 + δk(f (xk ) − f (x∗ )),\n2\n\n(2.10)\n\nis a Lyapunov function. For simplicity, take δ = 1/L. We check,\n\n\nEk+1 − Ek\nxk+1 − xk ∗\nf (xk+1 ) − f (xk )\n=−\n, x − xk + f (xk ) − f (x∗ ) + δk\n+ ε1k\nδ\nδ\nδ\n(2.3)\n(2.8)\n\n≤ −Df (x∗ , xk ) −\n\nδk\nk∇f (xk )k2 + ε2k ≤ 0,\n2\n\nwhere ε1k = f (xk+1 ) − f (xk ) − h xk+1δ−xk , xk − xk+1 i − 2δ k xk+1δ−xk k2 and ε2k = Df (xk+1 , xk ) −\n2\nδ\nk∇f (xk )k2 ≤ −( 2δ − δ 2L )k∇f (xk )k2 ≤ 0; the upper bound on the error follows from the\n2\nsmoothness assumption and the identification δ = 1/L. The first inequality plugs in the\nalgorithm (2.3)\nthe descent property (2.8). By summing, we obtain the statement\nPk and\nEi+1 −Ei\nδ ≤ 0, from which we can conclude a O(1/δk) convergence rate of\nEk − E0 = i=1\nδ\nthe function value,\nf (xk ) − f (x∗ ) ≤\n\nE0\n.\nδk\n\nProximal Method The function (2.10) is a Lyapunov function for the PM algorithm as\nwell. We check,\n\n\nEk+1 − Ek\nxk+1 − xk ∗\nf (xk+1 ) − f (xk )\n=−\n, x − xk+1 + f (xk+1 ) − f (x∗ ) + δ(k + 1)\n+ ε1k\nδ\nδ\nδ\n(2.4)\nδ(k + 1)\n≤ −Df (x∗ , xk+1 ) −\nk∇f (xk+1 )k2 ≤ 0,\n2\nwhere ε1k = − 2δ k xk+1δ−xk k2 . The first inequality uses (2.9) and the last inequality follows from\nP\nthe convexity of f . By summing, we obtain the statement Ek − E0 = ki=1 Ei+1δ−Ei δ ≤ 0,\nfrom which we can conclude a O(1/δk) convergence rate of the function value,\nf (xk ) − f (x∗ ) ≤\n\nE0\n.\nδk\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n2.1.3\n\n12\n\nMirror Descent Dynamic\n\nWe analyze the dynamic that gives rise to mirror descent/natural gradient descent in four\ndifferent settings:\n1. f is differentiable, but not necessarily convex;\n2. f is convex, so that Df (x, y) ≥ 0 ∀x, y ∈ X ;\n3. f satisfies the Polyak-Löjasiewicz (PL) condition with parameter μ, so that\n−k∇f (x)k2x∗ ≤ −2μ(f (x) − f (x∗ )), ∀x ∈ X .\n\n(2.11)\n\nHere, kvkx∗ = hv, ∇2 h(x)−1 vi. When h = 12 kxk2 , this is equivalent to condition (2.1)\n4. f is μ-strongly convex with respect to a strictly convex function h (A.7), so that\nDf (y, x) ≥ μDh (y, x) ∀x, y ∈ X .\nWe summarize the Lyapunov functions presented in this subsection in Table 2.2. The mirror descent dynamic is a natural generalization of the steepest descent dynamic to smooth\nmanifolds X̃ , where the metric on X̃ is given by the Hessian of a strictly convex function\nh : X̃ → R, and the objective function f : X → R, is defined on X ⊆ cl(X̃ ), where X ∩ X̃ 6= ∅.\nFor the remainder of this subsection, we will take X = X̃ = Rd and provide a description\nof the second bullet point only; a presenentation of the more general setting as well as the\nother bullet points are described in Appendix B.2.\n2.1.3.1\n\nConvex Functions\n\nLet f : Rd → R be a Lipschitz, continuously differentiable convex function. The mirror\ndescent dynamic (MF),\nd\n∇h(Xt ) = −∇f (Xt ),\ndt\n\n(2.12)\n\nis a steepest descent flow on with respect to the metric kvk2x (see definition (B.9) for more\ndetails). Furthermore, the function\nZ t\n∗\nEt = Dh (x , Xt ) +\n(f (Xs ) − f (x∗ ))ds,\n(2.13)\n0\n\nis a Lypaunov function for MF (2.12). We check,\n\n\nd\nd\n(2.12)\n∗\nEt = −\n∇h(Xt ), x − Xt + f (Xt ) − f (x∗ ) = −Df (x∗ , Xt ).\ndt\ndt\n\n(2.14)\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n13\n\nMirror Descent Dynamic:\n\nd\n∇h(Xt ) = −∇f (Xt )\ndt\n\nFunction Class\n\nLyapunov Function\nRt\nEt = Dh (x∗ , Xt ) + 0 f (Xs ) − f (x∗ )ds\n\nf (X̂t ) − f (x∗ ) ≤ O(1/t)\n\nEt = Dh (x∗ , Xt ) + t((Xs ) − f (x∗ ))\n\nf (Xt ) − f (x∗ ) ≤ O(1/t)\n\nμ-Strong Convexity\n\nEt = eμt Dh (x∗ , Xt )\n\nDh (x∗ , Xt ) ≤ O(e−μt )\n\nMirror Descent:\n\n∇h(xk+1 )−∇h(xk )\n= −∇f (xk )\nδ\n\nFunction Class\n\nLyapunov Function\nP\nEk = Dh (x∗ , xk ) + ks=0 (f (xs ) − f (x∗ ))δ\n\nf (x̂k ) − f (x∗ ) ≤ O(1/δk)\n\nEk = (1 − μδ)−k Dh (x∗ , xk )\n\nDh (x∗ , xk ) ≤ O(e−μδk )\n\nConvex\n\nConvex\nf is (1/δ)-smooth\n\nμ-Strong Convexity\n\nConvergence Rate\n\nConvergence Rate\n\nf is (1/δ)-smooth\n\nBreg Prox Minimization:\n\n∇h(xk+1 )−∇h(xk )\n= −∇f (xk+1 )\nδ\n\nFunction Class\n\nLyapunov Function\nP\nEk = Dh (x∗ , xk ) + ks=0 (f (xs ) − f (x∗ ))δ\n\nf (x̂k ) − f (x∗ ) ≤ O(1/δk)\n\nEk = Dh (x∗ , xk ) + δk(f (xk ) − f (x∗ ))\n\nf (xk ) − f (x∗ ) ≤ O(1/δk)\n\nEk = (1 + μδ)k Dh (x∗ , xk )\n\nDh (x∗ , xk ) ≤ O(e−μδk )\n\n∇h(x0k+1 )−∇h(xk )\n= −∇f (xk ), ∇h(xk+1 δ)−∇h(xk ) = −∇f (x0k+1 )\nδ\n\nkxk − x0k k = Θ(δ/σ)\n\nConvex\nδ>0\n\nμ-Strong Convexity\n\nConvergence Rate\n\nδ>0\n\nMirror Prox:\nFunction Class\nConvex\nf is (σ/δ)-smooth, h is σ-strongly convex\n\nLyapunov Function\nP\n∗\n0\nEk = Dh (x∗ , xk ) + k−1\ns=0 (f (xs ) − f (x ))δ\n\nConvergence Rate\nf (x̂k ) − f (x∗ ) ≤ O(1/δk)\n\nNatural Gradient Dynamic:\n\nd\nX = −∇2 h(Xt )−1 ∇f (Xt )\ndt t\n\nFunction Class\n\nLyapunov Function\n\nConvergence Rate\n\nDifferentiable\n\nEt = f (Xt ) − f (x∗ )\n\nk∇f (Xt )k2Xt∗ ≤ O(1/t)\n\nPL condition w.p μ\n\nEt = e2μt f (Xt ) − f (x∗ )\n\nf (Xt ) − f (x∗ ) ≤ O(e−2μt )\n\nNatural Gradient Descent:\n\nxk+1 −xk\n= −∇2 h(xk )−1 ∇f (xk )\nδ\n\nFunction Class\n\nLyapunov Function\n\nConvergence Rate\n\nDifferentiable\n\nEk = f (xk ) − f (x∗ )\n\nk∇f (xk )k2x∗k ≤ O(1/δk)\n\nEk = (1 − μδ)−k (f (xk ) − f (x∗ ))\n\nf (xk ) − f (x∗ ) ≤ O(e−μδk )\n\nf is (1/δ)-smooth\n\nPL condition w.p μ\nf is (1/δ)-smooth\n\nTable 2.2: Lyapunov functions for mirror flow (MF), mirror descent (MD), the Bregman\nproximal minimization (BPM), mirror prox method (MPM), natural gradient flow (NGF)\nand natural gradient descent (NGD); with discrete-time identification t = δk, in the limit\nδ → 0, the results in continuous time match the results in discrete time within a factor\nof 2. The smoothness condition for NGD is that Df (x, y) ≤ 1δ kx − yk2x , ∀x, y ∈ X , where\nkvkx = hv, ∇2 h(x)vi.\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n14\n\nRt\nDenote X̂t = 0 Xs ds/t as the time-average iterate. Using Jensen’s inequality (A.4), we\nRt\nconclude tf (X̂t ) ≤ 0 f (Xs )ds. By integrating (2.14) we obtain the statement, t(f (X̂t ) −\nf (x∗ )) ≤ Et ≤ E0 , from which we conclude an O(1/t) convergence rate,\nf (X̂t ) − f (x∗ ) ≤\n\nE0\n,\nt\n\nfor the optimality gap measured at the time-averaged iterate. Similar statements can be\nmade about mirror descent and the proximal Bregman method, which are the forward and\nbackward-Euler methods applied to (2.12), respectively.\nMirror Descent The forward-Euler method applied to MF,\n∇h(xk+1 ) − ∇h(xk )\n= −∇f (xk ),\nδ\nis a stationary point of the following optimization problem,\n\u001a\n\u001b\n1\nxk+1 = arg min h∇f (xk ), xi + Dh (x, xk ) .\nx∈X\nδ\n\n(2.15)\n\nAs long as f is L-smooth with respect to h (A.14), where δ < 1/L, then\n∗\n\nEk = Dh (x , xk ) +\n\nk\nX\n\n(f (xs ) − f (x∗ ))δ\n\n(2.16)\n\ns=0\n\nis a Lyapunov function for mirror descent (2.15). We check,\n\n\n(2.15)\nEk+1 − Ek\n∇h(xk+1 ) − ∇h(xk ) ∗\n=−\n, x − xk + f (xk ) − f (x∗ ) + ε1k ≤ −Df (x∗ , xk ),\nδ\nδ\nD\nE\nwhere the error term is ε1k = f (xk+1 )−f (xk )− ∇h(xk+1 δ)−∇h(xk ) , xk − xk+1 − 1δ Dh (xk+1 , xk ) =\nDf (xk+1 , xk ) − 1δ Dh (xk+1 , xk ). Take L = 1/δ. We ensure the non-negativity of the error,\nand subsequently the upper P\nbound, by using\nPkthe (1/δ)-smoothness condition with respect\nk\nto h (A.14). Denote x̂k = δ s=0 xs /δk = s=0 xs /k. Using Jensen’s inequality (A.4), we\nP\nconclude δkf (x̂k ) ≤ δ ks=0 f (xs ). By summing we obtain the statement δk(f (x̂k )−f (x∗ )) ≤\nEk ≤ E0 , from which we conclude an O(1/δk) convergence rate,\nf (x̂k ) − f (x∗ ) ≤\n\nE0\n,\nδk\n\nfor the optimality gap measured at the time-averaged iterate.\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n15\n\nBregman proximal minimization The Bregman proximal minimization (BPM),\n\u001a\n\u001b\n1\nxk+1 = arg min f (x) + Dh (x, xk ) := Proxhδf (xk ),\n(2.17)\nx∈X\nδ\nsatisfies the variational condition\n∇h(xk+1 ) − ∇h(xk )\n= −∇f (xk+1 ).\nδ\n\n(2.18)\n\nFurthermore, (2.16) is a Lyapunov function for the BPM. We check,\n\n\nEk+1 − Ek\n∇h(xk+1 ) − ∇h(xk ) ∗\n=−\n, x − xk+1 + f (xk+1 ) − f (x∗ ) + ε1k\nδ\nδ\n(2.18)\n\n≤ −Df (x∗ , xk+1 ),\n\nP\nwhere the error term ε1k = − 1δ Dh (xk+1 , xk ) is negative. Denote x̂k = δ ks=0 xs /δk =\nPk\nPk\ns=0 f (xs ). By summing we obs=0 xs /k. By Jensen’s inequality (A.4), δkf (x̂k ) ≤ δ\ntain the statement δk(f (x̂k ) − f (x∗ )) ≤ Ek ≤ E0 , from which we conclude an O(1/δk)\nconvergence rate,\nf (x̂k ) − f (x∗ ) ≤\n\nE0\n,\nδk\n\nfor the optimality gap measured at the time-averaged iterate.\nMirror Prox Method The update equations for the mirror prox method (MPM) algorithm can be written,\n\u001a\n\u001b\n1\n0\nxk+1 ∈ arg min h∇f (xk ), xi + Dh (x, xk ) ,\n(2.19a)\nx∈X\nδ\n\u001a\n\u001b\n1\n0\nxk+1 ∈ arg min h∇f (xk+1 ), xi + Dh (x, xk ) ;\n(2.19b)\nx∈X\nδ\nthe variational conditions satisfy,\n∇h(x0k+1 ) − ∇h(xk )\n= −∇f (xk )\nδ\n∇h(xk+1 ) − ∇h(xk )\n= −∇f (x0k+1 ).\nδ\nWe discuss how to solve the updates (2.19) using the projection operator in Appendix B.2.\nWe can think of this algorithm as mirror descent, where the update xk+1 has been replaced\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n16\n\nwith a sequence x0k+1 , which we use to take an additional step. To analyze MPM, we use\nthe following Lyapunov function,\nk\nX\nEk = Dh (x , xk ) +\n(f (x0s ) − f (x∗ ))δ.\n∗\n\n(2.20)\n\ns=0\n\nWe check,\nEk+1 − Ek\n=−\nδ\n\n\n∇h(xk+1 ) − ∇h(xk ) ∗\n, x − xk+1\nδ\n\n\n+ f (x0k+1 ) − f (x∗ ) + ε1k\n\n(2.19b)\n(2.19a)\n\n≤ −Df (x∗ , x0k+1 ) + ε2k ≤ −Df (x∗ , x0k+1 ).\n\nHere, ε1k = − 1δ Dh (xk+1 , xk ) = (∇h(x0k+1 ) − ∇h(xk ))/δ, x0k+1 − xk+1 − 1δ Dh (xk+1 , x0k+1 ) −\n1\nD (x0 , xk ) and the second error, ε2k = h∇f (x0k+1 )−∇f (xk ), x0k+1 −xk+1 i− 1δ Dh (xk+1 , x0k+1 )−\nδ h k+1\n1\nD (x0 , xk ). The last inequality, which upper bounds ε2k , assumes h is σ-strongly conδ h k+1\nvex and f is (σ/δ)-smooth; in which case, we can use Cauchy-Schwartz (A.26), smoothness (A.13), and Young’s inequality (A.25) to upper bound the inner product in ε2k as follows,\nσ\nσ\nh∇f (x0k+1 ) − ∇f (xk ), x0k+1 − xk+1 i ≤ 2δ\nkx0k+1 − xk k2 + 2δ\nkx0k+1 − xk+1 k2 ; the σ-strong convexity of h ensures this upper bound plus the remainder of the error is nonpositive. Similar\nto the analysis of MF, we can use Jensen’s (A.4) to conclude δk(f (x̂0k ) − f (x∗ )) ≤ Ek ≤ E0 ,\nP\nP\nwhere x̂0k = δ ks=0 x0s /δk = ks=0 x0s /k, and subsequently, an O(1/δk) convergence rate,\nf (x̂0k ) − f (x∗ ) ≤\n\nE0\n,\nδk\n\non the time-averaged iterate.\nThe introduction of an additional iterate might seem strange, but using the σ-strong\nconvexity of h, we can reason that kxk+1 − x0k+1 k ≤ (1/σ)k∇h(xk+1 ) − ∇h(x0k+1 )k ≤\n(δ/σ)k∇f (xk ) + ∇f (x0k+1 )k = Θ(δ/σ), where the second inequality uses (2.19); therefore\nin the limit δ → 0, the sequences xk+1 and x0k+1 are equivalent and we recover the mirror\ndescent dynamic (2.12).\n\n2.1.4\n\nSubgradients and Time Reparameterization\n\nWe analyze the dynamic that gives rise to mirror descent algorithm, where subgradients are\nused instead of full gradients, in three different settings:\n1. f is convex, so that Dfg (x, y) ≥ 0 ∀x, y ∈ X (see (A.17) for notation);\n2. f is μ-strongly convex with respect h (A.7), and h is σ-strongly convex function, so\nky − xk2 ∀x, y ∈ X .\nthat Dfg (y, x) ≥ μDh (y, x) ≥ μσ\n2\n3. f is differentiable but has (ν, L) Hölder-continuous gradients (A.15).\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n17\n\nMS Dynamics:\n\nd\n∇h(Yt ) = −τ̇t Gf (Yt , Ẏt )\ndt\n\nGf (Yt , Ẏt ) ∈ ∂f (Yt )\n\nFunction Class\n\nLyapunov Function\n\nConvergence Rate\n\nConvex\n\nRt\n\nEτt = Dh (x∗ , Yt ) + 0 (f (Ys ) − f (x∗ ))τ̇s ds\n\nf (Ŷt ) − f (x∗ ) ≤ ττt0\n\nμ-Strong Convexity\n\nEτt = eμτt Dh (x∗ , Yt )\nRt\nEτt = eμτt Dh (x∗ , Yt ) + μ1 0 (f (Ys ) − f (x∗ ))deμτs\n\nDh (x∗ , Yt ) ≤ eμττ0t\nf (Ŷt ) − f (x∗ ) ≤ eEμτ0t\n\nMS Method:\n\n∇h(yk+1 )−∇h(yk )\n= −αk g(yk )\nδ\n\ng(yk ) ∈ ∂f (yk )\n\nFunction Class\n\nLyapunov Function\n\nConvergence Rate\n\nConvex\n\nf is Lipschitz; h σ-strongly convex\n\nμ-Strong Convexity\nf is Lipschitz; h σ-strongly convex\n\nEAk = Dh (x∗ , yk ) +\n\n∗ As+1 −As\nδ\ns=0 (f (ys ) − f (x ))\nδ\n\nPk−1\n\nEAk = Ak Dh (x∗ , yk )\nEAk = Ak Dh (x∗ , yk ) + μ1\n\n∗ As+1 −As\nδ\ns=0 (f (ys ) − f (x ))\nδ\n\nPk−1\n\nE\n\nE\n\nf (ŷk ) − f (x∗ ) ≤\nDh (x∗ , yk ) ≤\n\nP\nEA0 +δ ks=0 ε1s\nAk\n\nP\nEA0 +δ ks=0 ε2s\nAk\n\nf (ŷk ) − f (x∗ ) ≤\n\nP\nEA0 +δ ks=0 ε2s\nAk\n\nPS Method\n\n∇h(yk+1 )−∇h(yk )\n= −αk g(yk+1 )\nδ\n\ng(yk+1 ) ∈ ∂f (yk+1 )\n\nFunction Class\n\nLyapunov Function\n\nConvergence Rate\n\nConvex\nδ>0\n\nμ-Strong Convexity\nδ>0\n\nEAk = Dh (x∗ , yk ) +\n\n∗ As+1 −As\nδ\ns=0 (f (ys ) − f (x ))\nδ\n\nPk\n\nE\n\nf (ŷk ) − f (x∗ ) ≤ AAk0\nE\n\nEAk = Dh (x∗ , yk ) + Ak (f (yk ) − f (x∗ ))\n\nf (yk ) − f (x∗ ) ≤ AAk0\n\nEAk = Ak Dh (x∗ , yk )\n\nDh (x∗ , yk ) ≤ AAk0\n\nEAk = Ak Dh (x∗ , yk ) + μ1\n\n∗ As+1 −As\nδ\ns=0 (f (ys ) − f (x ))\nδ\n\nPk\n\nE\n\nE\n\nf (ŷk ) − f (x∗ ) ≤ AAk0\n\nTable 2.3: Lyapunov functions for the mirror descent dynamic with directional subgradients\n(MS Dynamic), mirror descent with subgradients (MS Method), and the proximal Bregman\nminimization with subgradients (PS Method). When moving to discrete time, there is a\ndiscretization error, and we choose parameters accordingly. When f is convex, τt = Ak , so\nthat τ̇t ≈ (Ak+1 − Ak )/δ = αk . When f is μ-strongly convex, eμτt = Ak , so that we have\nthe approximation τ̇t = dtd eμτt /μeμτt ≈ (Ak+1 − Ak )/δμAk+1 := αk . With these choices, the\nα2\n\n1\nk\nG2 , where k∂f (x)k2∗ ≤ G2 . In the limit\nerrors scale as ε1k = δαk2 G2 /2σ and ε2k = δ 2σμ\n2 A\nk+1\nδ → 0, the discrete-time and continuous-time statements match.\n\nWhen f is not smooth, the function no longer necessarily has a uniquely defined gradient\nat each point. One natural way around this difficulty is to use the proximal update (2.4).\nHowever, for some non-smooth functions, the update (2.4) might be too expensive to solve\nevery iteration.\nAssume f is finite, convex, and absolutely continuous on X . Recall that the subdifferential of f at x, ∂f (x), contains the subgradient of f at x, and that the directional subgradient\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n18\n\nof f is a Borel measurable function Gf (x, v) : Rd × Rd → Rd . The subdifferential and\ndirectional derivative of a function share the following relationship in this setting [64],\nf (x + δv) − f (x)\n= sup hg(x), vi.\nδ→0\nδ\ng(x)∈∂f (x)\n\nf 0 (x; v) = lim\n\nGiven f is convex, the subdifferential is nonempty, convex and compact for any x.\nSimilar to Su, Boyd and Candes [70], we will consider dynamical systems defined by the\ndirectional subgradient of f , when f is not smooth, with the goal of implementing this curve\nas an algorithm.\nBefore doing so, however, we discuss how to choose an appropriate scaling of time. Concretely, let τ : R → R be a smooth (twice-continuously differentiable) increasing function\nτ̇ : R → R+ . Given a curve X : R → X , we consider a reparameterized curve Y = R → X\ndefined by,\nYt = Xτ t .\n\n(2.21)\n\nwhere we adopt the shorthand, τt = τ (t). That is, the new curve Y is obtained by traversing\nthe original curve X at a new speed of time determined by τ . If τt < t, we say that Y\nis the slowed-down version of X, because the curve Y at time t has the same value as the\noriginal curve X at the past time τt . We might expect that if the original curve obtained a\nconvergence rate f (Xt ) − f (x∗ ) ≤ O(1/t), the new curve Y might obtain a convergence rate\nf (Yt ) − f (x∗ ) ≤ O(1/τt ).\nWe study the family of curves,\nd\n∇h(Yt ) = −τ̇t Gf (Yt , Ẏt ),\ndt\n\n(2.22)\n\nobtained by an arbitrary reparameterization of the curve, dtd ∇h(Xt ) = −Gf (Xt , Ẋt ), by the\nscaling (2.21), where Gf (Xt , Ẋt ) ∈ ∂f (Xt ). If Gf (Xt , Ẋt ) = ∇f (Xt ) and τt = t, then (2.22)\nis equivalent to the mirror descent dynamic (2.15). Let X = Rn . We provide a description\nof the first bullet point in the main text and provide details on the other bullet points in\nAppendix B.3.\n2.1.4.1\n\nConvex Functions\n\nWe analyze the family of curves (2.22) when f is convex. To do so, we apply the same\ntime-reparameterization to the Lyapunov function (2.13),\nZ t\n∗\nEτt = Dh (x , Yt ) +\n(f (Ys ) − f (x∗ ))dτs ,\n(2.23)\n0\n\nwhere dτs = τ̇s ds. The absolute continuity of f ensures Eτt is differentiable. We check,\n\n\nd\nd\n(2.22)\n∗\nEτ t = −\n∇h(Yt ), x − Yt + (f (Yt ) − f (x∗ ))τ̇t = −DfG (x∗ , Yt )τ̇t ≤ 0.\ndt\ndt\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n19\n\nRt\nR\nDenote Ŷt = 0 Ys dτs /τt as the time-average point. The inequality τt f (Ŷt ) ≤ f (Ys )dτs\nfollows from applying Jensen’s inequality (A.4). By integrating the Lyapunov function, we\nobtain the statement τt (f (Ŷt ) − f (x∗ )) ≤ Eτt ≤ Eτ0 for the curve. Therefore we can conclude\na O(1/τt ) convergence rate for (2.22) on the time-averaged iterate:\nf (Ŷt ) − f (x∗ ) ≤\n\nEτ 0\n.\nτt\n\nWe apply a similar argument to the discretizations of (2.22) using a discretization of the\nLyapunov function (2.23). Make the identifications Ak := τt and αk = Ak−1δ−Ak := τ̇t .\nDifferent scalings produce errors with differing scales in discrete time. At the end of the\ndiscrete-time analysis, the scaling which maximizes the upper-bound is chosen.\nMirror subgradient method The forward-Euler discretization of (2.22),\n\u001b\n\u001a\n1\nyk+1 = arg min αk hg(yk ), xi + Dh (x, yk ) ,\nδ\nx∈Rd\n\n(2.24)\n\nchooses an element of the subdifferential at every iteration g(yk ) ∈ ∂f (yk ). It satisfies the\nvariational condition ∇h(yk+1 δ)−∇h(yk ) = −αk g(yk ). We analyze (2.24) using the Lyapunov\nfunction,\nEAk = Dh (x∗ , yk ) +\n\nk−1\nX\nAs+1 − As\n(f (ys ) − f (x∗ ))\nδ.\nδ\ns=0\n\n(2.25)\n\nWe check,\nEAk+1 − EAk\n=−\nδ\n\n\n∇h(yk+1 ) − ∇h(yk ) ∗\n, x − yk\nδ\n\n\n+ (f (yk ) − f (x∗ ))αk + ε1k\n\n(2.24)\n\n= −Dfg (x∗ , yk )αk + ε1k\n\nwhere the error scales as ε1k = αk hg(yk ), yk − yk+1 i − 1δ Dh (yk+1 , yk ). Define the time-averaged\nP\niterate ŷk = δ ks=0 ys αs /Ak . By summing, we obtain the statement Ak (f (ŷk ) − f (x∗ )) ≤\nP\nEAk ≤ EA0 + δ ks=0 ε1s , as well as the bound,\nP\nEA0 + δ ks=0 ε1s\n∗\n.\n(2.26)\nf (ŷk ) − f (x ) ≤\nAk\nP\nThe bound provides us with a rate of convergence as long as ks=0 ε1s /Ak → 0 as k → ∞. To\nobtain an upper bound on the error, we typically assume that h is σ-strongly convex (A.6);\nwith this assumption, Young’s inequality (A.25) can be used to obtain the following upper\nα2\nbound ε1k ≤ δ 2σk kg(yk )k2∗ . Assume f is Lipschitz on X , so that for all y ∈ X , k∂f (y)k2∗ ≤ G2 ,\nP\n2\nfor some finite constant G2 (see (A.17) for notation). Maximizing the bound, δ ks=0 α2σs G2 /Ak\n√\nover √\nthe sequence Ak leads to the choice αK = Dh (x∗ , X0 )/G2 K, and convergence rate\nO(1/ K). There is a matching lower bound for the subgradient oracle function.\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\nProximal Bregman method The backward-Euler discretization of (2.22)\n\u001a\n\u001b\n1\nyk+1 = arg min αk f (x) + Dh (x, yk ) ,\nδ\nx∈Rd\n\n20\n\n(2.27)\n\nsatisfies variational inequality we can write as ∇h(yk+1 δ)−∇h(yk ) = −αk g(yk+1 ), where g(yk+1 ) ∈\n∂f (yk+1 ). We can similarly be analyzed using Lyapunov function (2.25), as well as the\nLyapunov function\nEAk = Dh (x∗ , yk ) + Ak (f (yk ) − f (x∗ )).\n\n(2.28)\n\nWe check,\nEAk+1 − EAk\n=−\nδ\n\n\n∇h(yk+1 ) − ∇h(yk ) ∗\n, x − yk+1 + αk f (yk+1 ) − f (x∗ )\nδ\nf (yk+1 ) − f (yk )\n+ ε1k ≤ −Dfg (x∗ , yk+1 )αk + ε2k\n+ Ak\nδ\n\nwhere the errors ε1k = − 1δ Dh (yk+1 , yk ) and ε2k = ε1k + Ak f (yk+1 δ)−f (yk ) are negative. The nonnegativity of the second error follows from the descent property of the proximal method (2.27),\ni.e. Ak f (yk+1 δ)−f (yk ) ≤ − Aαkk δ12 Dh (yk+1 , yk ).\n\n2.1.5\n\nDual Averaging Dynamic\n\nWe analyze the dynamic that gives rise to the dual averaging algorithm in the setting when\nf is convex.\nLet X = Rd and f : Rd → R be an absolutely continuous convex function. Take\nγ̇t , γt , τ̇t , τt > 0. The dual averaging dynamic is given by the system of equations,\nd\nYt = −τ̇t G(Xt , Ẋt )\ndt\nYt = γt ∇h(Xt ).\n\n(2.29a)\n(2.29b)\n\nHere, Gf (Xt , Ẋt ) ∈ ∂f (Xt ) is a directional subgradient of f at Xt and we choose h : X → R\nto be a σ-storngly convex function with a well-defined prox-center [44]; specifically, the\nprox-center y is defined as the solution to the optimization problem,\ny = arg min h(x).\nx∈X\n\n(2.30)\n\nIt is usually taken without loss of generality that h(y) = 0 so that h(x) = Dh (x, y) ≥ 0, ∀x ∈\nX . In particular, when h(x) = 21 kxk2 , then the point y = 0 is the prox-center. If we choose\nour initial position X0 to be the prox-center (2.30), the function,\nZ t\n∗\nEt = γt Dh (x , Xt ) +\n(f (Xs ) − f (x∗ ))dτs ,\n0\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n21\n\nDA Dynamic:\n\nd\nY = −τ̇t Gf (Xt , Ẋt ), Yt = γt ∇h(Xt )\ndt t\n\nGf (Xt , Ẋt ) ∈ ∂f (Xt )\n\nFunction Class\n\nConvergence Rate\n\nConvex\n\nLyapunov Function\nRt\nEτt = γt Dh (x∗ , Xt ) + 0 (f (Xs ) − f (x∗ ))τ̇s ds\n\n,X0 )\nf (X̂t ) − f (x∗ ) ≤ γt Dh (x\nτt\n\nDA Algorithm:\n\nyk+1 −yk\n= −αk g(xk ), yk = γk ∇h(xk )\nδ\n\ng(xk ) ∈ ∂f (xk )\n\nFunction Class\n\nConvergence Rate\n\nConvex\n\nLyapunov Function\nP\n∗\nEk = γk Dh (x∗ , xk ) + k−1\ns=0 (f (xs ) − f (x ))αs δ\n\nProximal DA:\n\nyk+1 −yk\n= −αk g(xk+1 ), yk = γk ∇h(xk )\nδ\n\ng(xk+1 ) ∈ ∂f (xk+1 )\n\nFunction Class\n\nLyapunov Function\nP\nEk = γk Dh (x∗ , xk ) + ks=0 (f (xs ) − f (x∗ ))αs δ\n\nConvergence Rate\n\nf is Lipschitz; h σ-strongly convex\n\nConvex\nδ>0\n\n∗\n\nf (x̂k ) − f (x∗ ) ≤\n\nγk Dh (x∗ ,x0 )+δ\nAk\n\nPk\n\n1\ns=0 εs\n\n∗\n\nf (x̂k ) − f (x∗ ) ≤ γk DhA(xk ,x0 )\n\nTable 2.4: Lyapunov functions for the dual averaging (DA) dynamic, dual averaging (DA)\nalgorithm , and the backward-Euler approximation of the dual averaging dynamics (proximal\n2\n1 αk 2\nDA); for the dual averaging algorithm, αk = Ak+1δ−Ak , ε1k = δ 2σ\nG where k∂f (x)k2∗ ≤ G2 .\nγk\nIn the limit δ → 0, the discrete-time and continuous-time statements match.\n\nprovides a rate of convergence for (2.29). We check,\n\n\nd\nd\nd\n∗\n∗\nEt = Dh (x , Xt ) γt − γt\n∇h(Xt ), x − Xt + τ̇t (f (Xt ) − f (x∗ ))\ndt\ndt\ndt\n\n\nd\nd\n(2.29b)\n∗\n∗\nYt , x − Xt + τ̇t (f (Xt ) − f (x∗ ))\n= (h(x ) − h(Xt )) γt −\ndt\ndt\n(2.29a)\n\n= −τ̇t DfG (x∗ , Xt ) + γ̇t (h(x∗ ) − h(Xt )) ≤ γ̇t Dh (x∗ , X0 ).\n\nThe last inequality uses the fact that h(x) = Dh (x, X0 ) ≥R0, ∀x ∈ X as well as the defit\nnition of a prox-center h(x∗ ) = Dh (x∗ , X0 ). Denote X̂t = 0 Xs dτs /τt as the time-average\nRt\niterate and note that the inequality τt f (X̂t ) ≤ 0 f (Xs )dτs follows from Jensen’s (A.4).\nBy integrating the Lyapunov argument dtd Et ≤ γ̇t Dh (x∗ , X0 ), we obtain the statement,\nτt (f (X̂t ) − f (x∗ )) ≤ Et ≤ E0 + γt Dh (x∗ , X0 ) − γ0 Dh (x∗ , X0 ), from which we conclude an\nO(γt /τt ) convergence rate,\nf (X̂t ) − f (x∗ ) ≤\n\nE0 + γt Dh (x∗ , X0 )\n.\nτt\n\nDual Averaging The dual averaging algorithm,\n( k\n)\nX\nxk+1 = arg min δ\nαs hg(xs ), xi + γk Dh (x, x0 ) ,\nx∈X\n\ns=0\n\n(2.31)\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n22\n\nsatisfies the variational condition γk+1 ∇h(xk+1δ )−γk ∇h(xk ) = −αk g(xk ), where x0 is the proxcenter (2.30), αk = Ak+1δ−Ak and g(xk ) ∈ ∂f (xk ). Denote yk = γk ∇h(xk ). The variational\ncondition can be written, yk+1δ−yk = −αk g(xk ). Using the discrete-time function,\n∗\n\nEk = γk Dh (x , xk ) +\n\nk−1\nX\n\n(f (xs ) − f (x∗ ))\n\ns=0\n\nAs+1 − As\nδ,\nδ\n\nwe check,\n\n\nEk+1 − Ek\nγk+1 − γk\n∇h(xk+1 ) − ∇h(xk ) ∗\n∗\n= Dh (x , xk+1 )\n− γk\n, x − xk\nδ\nδ\nδ\n+ αk (f (xk ) − f (x∗ )) + ε1k\n\n\nyk+1 − yk ∗\nγk+1 − γk\n∗\n−\n, x − xk + αk (f (xk ) − f (x∗ )) + ε1k\n= (h(x ) − h(xk+1 ))\nδ\nδ\nγk+1 − γk\nγk+1 − γk\n(2.31)\n= −αk Dfg (x∗ , xk ) +\n(h(x∗ ) − h(xk+1 )) + ε2k ≤\nDh (x∗ , x0 ) + ε1k .\nδ\nδ\nHere, the error scales as ε1k = αk hg(xk ), xk − xk+1 i − γδk Dh (xk+1 , xk ). The final upper bound\nfollows from noting −Dfg (x∗ , xk ) ≤ 0 and using the definition of the prox-center. Assume\nk∂f (yk )k2∗ ≤ G2 for all yk ∈ X and some constant G. Using the σ-strong convexity of\nα2k δ\nG := ε3k . Denote\nh, we can use Young’s inequality to upper bound the error ε2k ≤ 2σγ\nk\nPk\nx̂k = δ s=0 xs αs /Ak as the time-average iterate and note that the inequality Ak f (x̂k ) ≤\nP\nδ ks=0 f (xs )αs follows from Jensen’s (A.4). By summing the Lyapunov function we obtain\nP\nthe statement, Ak (f (x̂k ) − f (x∗ )) ≤ Ek ≤ E0 + γk Dh (x∗ , x0 ) − γ0 Dh (x∗ , x0 ) + δ ks=0 ε3i , from\nwhich we obtain the convergence bound,\n∗\n\nf (x̂k ) − f (x ) ≤\n\n1\nE0 + γk Dh (x∗ , x0 ) + δ 2 2σ\n\nAk\n\nα2s 2\ns=0 γs G\n\nPk\n\n.\n\nIf we assume\nwith out loss of generality\nσ = 1, and choose Ak = k, δ = 1 and γk =\n√\n√\nG2\nk + 1, we obtain O(1/ k) convergence rate [44]. This bound matches the oracle\nDh (x∗ ,x0 )\nfunction lower bound for algorithms designed using only subgradients of convex functions\n(i.e. is provably optimal). Furthermore, as δ → 0, the error ε3k → 0 and we recover the result\nfor the continuous time dynamics.\n\n2.1.6\n\nConditional Gradient Dynamic\n\nWe analyze the dynamical systems that gives rise to the conditional gradient method (FrankWolfe algorithm) in two different settings:\n1. X is a convex, compact set, f is Lipschitz on X and has (1/\u000f)-smooth gradients (A.13).\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n23\n\n2. X is a convex, compact set, f is Lipschitz on X and has (ν, 1/\u000f) Hölder-continuous\ngradients (A.15).\n\nConditional Gradient Dynamic:\n\nh∇f (Xt ), x − Zt i,\n\nd\n\n∀x ∈ X ,\n\neβt\n\nẊt = dteβt (Zt − Xt )\n\nFunction Class\n\nLyapunov Function\n\nConvergence Rate\n\nConvex\n\nEt = eβt (f (Xt ) − f (x∗ ))\n\nf (Xt ) − f (x∗ ) ≤ eEβ0t\n\nX is compact and convex, f is Lipschitz on X\n\nConditional Gradient Algorithm\n\nh∇f (xk ), x − zk i,\n\nFunction Class\n\nLyapunov Function\n\nConvex\n\nEk = Ak (f (xk ) − f (x∗ ))\n\nX is compact and convex, f is (1/δ)-smooth\n\nxk+1 −xk\n= τk (zk − xk )\nδ\n\n∀x ∈ X ,\n\nConvergence Rate\nf (xk ) − f (x∗ ) ≤\n\nE0 +δ\n\nPk\n\n1\ns=0 εs\n\nAk\n\nTable 2.5: Lyapunov functions for conditional gradient descent (CGD) dynamic and the\nconditional gradient descent (CGD) algorithm.\n\nHere,\n\nd βt\ne\ndt\neβt\n\n≈\n\nAk+1 −Ak\nδAk+1\n\n:= τk , εk+1 =\n\nA\nτk2\nkzk − xk k2 . In the limit δ → 0, discrete-time and continuous-time statements match.\nδ k+1\n2\u000f\n\nThe conditional gradient dynamic,\nd βt\ne\nd\ndt\nXt = βt (Zt − Xt ),\ndt\ne\nZt ∈ arg minh∇f (Xt ), vi\n\n(2.32a)\n(2.32b)\n\nv∈X\n\nis defined on convex, compact sets X . The update (2.32b) satisfies the variational condition\n0 ≤ h∇f (Xt ), x−Zt i, ∀x ∈ X . This dynamical system is remarkably similar to the dynamical\nsystem (2.38), where instead of using the Bregman divergence to ensure nonnegativity of the\nvariational inequality 0 ≤ h∇f (Xt ), x − Zt i dtd eβt , we simply assume (2.32b) holds on the\ndomain X . The following function,\nEt = eβt (f (Xt ) − f (x)),\n\n(2.33)\n\nis a Lyapunov function for (2.32). We check,\nd\nd\nd\nEt = eβt f (Xt ) + (f (Xt ) − f (x∗ )) eβt\ndt\ndt\ndt\n≤ eβt h∇f (Xt ), Ẋt i + h∇f (Xt ), x∗ − Xt i\n(2.32a)\n\n= h∇f (Xt ), x∗ − Zt i\n\nd βt (2.32b)\ne\n≤ 0\ndt\n\nd βt\ne\ndt\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n24\n\nApplying the backward-Euler scheme to (2.32a) and (2.32b), with the same approximations,\n−Ak\nd\nX = xk+1δ−xk , dtd eβt = Ak+1δ−Ak , and denoting τk = Ak+1\n, we obtain the variational\ndt t\nδAk+1\nconditions for the following algorithm:\nzk = arg min h∇f (xk ), zi,\nz∈X\n\nxk+1 − xk\n= τk (zk − xk ).\nδ\n\n(2.34a)\n(2.34b)\n\nWe can write update (2.34b) as xk+1 = δτk zk + (1 − δτk )xk Update (2.34a) requires the\nassumptions that X be convex and compact; under this assumption, (2.34a) satisfies\n0 ≤ h∇f (xk ), x − zk i, ∀x ∈ X ,\nconsistent with (2.32b). The following proposition describes how a discretization of (2.33)\ncan be used to analyze the behavior of algorithm (2.34). Assume f is convex and X is convex\nand compact. If f is (1/\u000f)-smooth, using the Lyapunov function,\nEk = Ak (f (xk ) − f (x∗ )),\n\n(2.35)\n\nwe obtain the error bound,\nf (xk+1 ) − f (xk )\nAk+1 − Ak\nEk+1 − Ek\n= Ak+1\n+ (f (xk ) − f (x∗ ))\nδ\nδ\nδ\n\n\nAk+1 − Ak\nxk+1 − xk\n≤ Ak+1 ∇f (xk ),\n+ h∇f (xk ), x∗ − xk )\n+ εk+1\nδ\nδ\n(2.34a)\nAk+1 − Ak\n(2.34b)\n+ εk+1 ≤ ε1k .\n= h∇f (xk ), x∗ − zk i\nδ\nThe second inequality uses the convexity and (1/\u000f)-smoothness of f . The error scales as\nA\nτk2\nk+1 xk+1 −xk 2\nεk+1 = δ A2\u000f\nk δ k = δ k+1\nkzk − xk k2 . If instead we assume f has (\u000f, ν)-Hölder2\u000f\nk+1 xk+1 −xk 1+ν\ncontinuous gradients (A.15), the error in algorithm (2.34) now scales as εk+1 = δ A2\u000f\nk δ k\nA\n\nτ 1+ν\n\nk\nkzk − xk k1+ν . Taking Ak = (k+1)(k+2)\nwe infer the convergence rates O(1/\u000fk)\n= δ ν k+1\n(1+ν)\u000f\n2\nν\nand O(1/\u000fk ), respectively.\n\n2.2\n\nLyapunov Analysis of Second-Order Dynamics\n\nThis section is based on the work A Lyapunov analysis of momentum methods in optimization. A. Wilson, B. Recht and M. I. Jordan. Submitted to Mathematics of Operations\nResearch (MOOR), 2016.\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n2.2.1\n\n25\n\nA Lyapunov Analysis of Momentum Methods in\nOptimization\n\nMomentum is a powerful heuristic for accelerating the convergence of optimization methods.\nOne can intuitively “add momentum” to a method by adding to the current step a weighted\nversion of the previous step, encouraging the method to move along search directions that had\nbeen previously seen to be fruitful. Such methods were first studied formally by Polyak [54],\nand have been employed in many practical optimization solvers. As an example, since the\n1980s, momentum methods have been popular in neural networks as a way to accelerate the\nbackpropagation algorithm. The conventional intuition is that momentum allows local search\nto avoid “long ravines” and “sharp curvatures” in the sublevel sets of cost functions [66].\nPolyak motivated momentum methods by an analogy to a “heavy ball” moving in a\npotential well defined by the cost function. However, Polyak’s physical intuition was difficult to make rigorous mathematically. For quadratic costs, Polyak was able to provide\nan eigenvalue argument that showed that his Heavy Ball Method required no more iterations than the method of conjugate gradients [54].1 Despite its intuitive elegance, however,\nPolyak’s eigenvalue analysis does not apply globally for general convex cost functions. In\nfact, Lessard et al. derived a simple one-dimensional counterexample where the standard\nHeavy Ball Method does not converge [30].\nIn order to make momentum methods rigorous, a different approach was required. In\ncelebrated work, Nesterov devised a general scheme to accelerate convex optimization methods, achieving optimal running times under oracle models in convex programming [43]. To\nachieve such general applicability, Nesterov’s proof techniques abandoned the physical intuition of Polyak [43]; in lieu of differential equations and Lyapunov functions, Nesterov devised\nthe method of estimate sequences to verify the correctness of these momentum-based methods. Researchers have struggled to understand the foundations and scope of the estimate\nsequence methodology since Nesterov’s initial papers. The associated proof techniques are\noften viewed as an “algebraic trick.”\nTo overcome the lack of fundamental understanding of the estimate sequence technique,\nseveral authors have recently proposed schemes to achieve acceleration without appealing to\nit [15, 9, 30, 14]. One promising general approach to the analysis of acceleration has been\nto analyze the continuous-time limit of accelerated methods [70, 76, 25], or to derive these\nlimiting ODEs directly via an underlying Lagrangian [76], and to prove that the ODEs are\nstable via a Lyapunov function argument. However, these methods stop short of providing\nprinciples for deriving a discrete-time optimization algorithm from a continuous-time ODE.\nThere are many ways to discretize ODEs, but not all of them give rise to convergent methods or to acceleration. Indeed, for unconstrained optimization on Euclidean spaces in the\nsetting where the objective is strongly convex, Polyak’s Heavy Ball method and Nesterov’s\naccelerated gradient descent have the same continuous-time limit. One recent line of attack\non the discretization problem is via the use of a time-varying Hamiltonian and symplectic\n1\nIndeed, when applied to positive-definite quadratic cost functions, Polyak’s Heavy Ball Method is equivalent to Chebyshev’s Iterative Method [10].\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n26\n\nintegrators [52]. In this chapter, we present a different approach, one based on a fuller development of Lyapunov theory. In particular, we present Lyapunov functions for both the\ncontinuous and discrete settings, and we show how to move between these Lyapunov functions. Our Lyapunov functions are time-varying and they thus allow us to establish rates\nof convergence. They allow us to dispense with estimate sequences altogether, in favor of a\ndynamical-systems perspective that encompasses both continuous time and discrete time.\n2.2.1.1\n\nThe Bregman Lagrangian\n\nWe [4] introduced the following function on curves,\n\u0001\n\u0001\nL(x, v, t) = eαt +γt Dh x, x + e−αt v − eβt f (x) ,\n\n(2.36)\n\nwhere x ∈ X , v ∈ Rd , and t ∈ R represent position, velocity and time, respectively [76]. They\ncalled (2.36) the Bregman Lagrangian. The functions α, β, γ : R → R are arbitrary smooth\nincreasing functions of time that determine the overall damping of the Lagrangian functional,\nas well as the weighting on the velocity and potential function. We also introduced the\nfollowing “ideal scaling conditions,” which are needed to obtain optimal rates of convergence:\nγ̇t = eαt\n\n(2.37a)\n\nβ̇t ≤ eαt .\n\n(2.37b)\n\nGiven L(x, v, t), we can define a functional\non curves {Xt : t ∈ R} called the action via\nR\nintegration of the Lagrangian: A(X) = R L(Xt , Ẋt , t)dt. Calculation of the Euler-Lagrange\n(Xt , Ẋt , t) = dtd ∂L\n(Xt , Ẋt , t), allows us to obtain a stationary point for the\nequation, ∂L\n∂x\n∂v\nproblem of finding the curve which minimizes the action. We showed [76, (2.7)] that under\nthe first scaling condition (2.37a), the Euler-Lagrange equation for the Bregman Lagrangian\nreduces to the following ODE:\nd\n∇h(Xt + e−αt Ẋt ) = −eαt +βt ∇f (Xt ).\ndt\nSecond Bregman Lagrangian. We [4] introduced a second function on curves,\n\u0001\n\u0001\nL(x, v, t) = eαt +γt +βt μDh x, x + e−αt v − f (x) ,\n\n(2.38)\n\n(2.39)\n\nusing the same definitions and scaling conditions. The Lagrangian (2.39) places a different\ndamping on the kinetic energy than in the original Bregman Lagrangian (2.36).\nProposition 2.2.1. Under the same scaling condition (2.37a), the Euler-Lagrange equation\nfor the second Bregman Lagrangian (2.39) reduces to:\nd\ne αt\n−αt\n−αt\n∇h(Xt + e Ẋt ) = β̇t ∇h(Xt ) − β̇t ∇h(Xt + e Ẋt ) −\n∇f (Xt ).\ndt\nμ\nWe provide a proof of Proposition 2.2.1 in Appendix B.5.1.\n\n(2.40)\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n27\n\nSummary We summarize the results presented in this subsection in Table 2.6.\nAccelerated Dynamic 1\n\nd\n∇h(Zt ) = −\ndt\n\nd βt\ne\ndt\n\n\u0001\n\n∇f (Xt )\n\nd\nX =\ndt t\n\nd βt\ne\ndt\neβt\n\n(Zt − Xt )\n\nFunction Class\n\nLyapunov Function\n\nConvergence Rate\n\nConvex\n\nEt = Dh (x∗ , Zt ) + eβt (f (Xt ) − f (x∗ ))\n\nf (Xt ) − f (x∗ ) ≤ O(1/eβt )\n\nAccelerated Algorithm 1\n\n∇h(zk+1 )−∇h(zk )\n= −αk ∇f (xk+1 )\nδ\n\nxk+1 −yk\n= τk (zk − yk )\nδ\n\nkyk − xk k = O(δ), δ =\n\n√\n\u000fσ\n\nyk = xk − δ∇f (xk )\n\nFunction Class\n\nLyapunov Function\n\nConvergence Rate\n\nConvex\n\nEk = Dh (x∗ , zk ) + Ak (f (yk ) − f (x∗ ))\n\nf (yk ) − f (x∗ ) ≤ O(1/Ak )\n\n0\n√\n∇h(zk+1\n)−∇h(zk )\n= −αk ∇f (x0k+1 ), δ = \u000fσ\nδ\n\nxk+1 −xk\n0\n= τk (zk+1\n− xk )\nδ\n\n∇h(zk+1 )−∇h(zk )\n= −αk ∇f (xk+1 ), kx0k − xk k = O(δ),\nδ\n\nxk+1 −xk\n= τk (zk − xk )\nδ\n\nFunction Class\n\nLyapunov Function\n\nConvergence Rate\n\nConvex\n\nf (yk ) − f (x∗ ) ≤ O(1/Ak )\n\nAccelerated Dynamic 2\n\nEk = Dh (x∗ , zk ) + Ak (f (yk ) − f (x∗ ))\n\u0011\n\u0010\nd βt\ne\nd\n∇h(Zt ) = dteβt ∇h(Xt ) − ∇h(Zt ) − μ1 ∇f (Xt )\ndt\n\nFunction Class\n\nLyapunov Function\n\nConvergence Rate\n\nf is μ-uniformly convex w.r.t h\n\nEt = eβt (μDh (x∗ , Zt ) + f (Xt ) − f (x∗ ))\n\u0010\n\u0011\n∇h(zk+1 )−∇h(zk )\n= τk ∇h(xk ) − ∇h(zk ) − μ1 ∇f (xk )\nδ\n\nf (Xt ) − f (x∗ ) ≤ O(1/eβt )\n\nf is (1/\u000f)-smooth, h is σ-strongly convex\n\nAccelerated Mirror Prox\n\nf is (1/\u000f)-smooth, h is σ-strongly convex\n\nAccelerated Algorithm 2\n\nkyk+1 − xk k = O(δ) , δ =\n\n√\n\n\u000f\n\nd\n\neβt\n\nẊt = dteβt (Zt − Xt )\n\nxk+1 −yk+1\n= τk (zk+1 − xk+1 )\nδ\n\nyk+1 = xk − δ∇f (xk )\n\nFunction Class\n\nLyapunov Function\n\nConvergence Rate\n\nμ-Strongly Convex\n\nEk = Ak (Dh (x∗ , zk ) + f (yk ) − f (x∗ ))\n\nf (yk ) − f (x∗ ) ≤ O(1/Ak )\n\nf is (1/\u000f)-smooth, h is Euclidean\n\nTable 2.6: Lyapunov functions for accelerated mirror descent (AMD) dynamic, accelerated\nmirror descent (AMD), accelerated mirror prox (AMP), and the backward√Euler discretiza√\ntion. For AMD1 and AMP, we take Ak+1 = σ\u000f(k+1)(k+2)\n, αk = Ak+1δ−Ak = σ\u000f(k+2)\n, δ = \u000fσ\n4\n2\n√\n√\n√\n−Ak\nand for AMD2, we take Ak+1 = (1 − μδ)−(k+1) , τk = Ak+1\n= μ, δ = \u000f.\nδAk+1\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n2.2.1.2\n\n28\n\nMethods arising from the first Euler-Lagrange equation\n\nAssume f is convex, h is strictly convex, and the second ideal scaling condition (2.37b) holds\nwith equality. We write the Euler Lagrange equation (2.38) as,\nd βt\ne\nd\nXt = dt βt (Zt − Xt ),\ndt\ne\nd\nd\n∇h(Zt ) = −∇f (Xt ) eβt .\ndt\ndt\n\n(2.41a)\n(2.41b)\n\nFor this continuous-time dynamical system,\nEt = Dh (x∗ , Zt ) + eβt (f (Xt ) − f (x∗ ))\nis a Lyapunov function. We check,\n\n\nd\nd\nd\nd\n∗\nEt = −\n∇h(Zt ), x − Zt + eβt f (Xt ) + (f (Xt ) − f (x∗ )) eβt .\ndt\ndt\ndt\ndt\nd\nd\n(2.41b)\n= (h∇f (Xt ), x∗ − Zt i + f (Xt ) − f (x∗ )) eβt + eβt f (Xt )\ndt\ndt\nd\n(2.41a)\n= −Df (x∗ , Xt ) eβt ≤ 0\ndt\n\n(2.42)\n\n(2.43)\n\nThis argument allows us to conclude a O(e−βt ) convergence rate.\nBackward-Backward-Euler. Written as an algorithm, the backward Euler method applied to (2.41a) and (2.41b) has the following update equations:\n\u001a\n\u001b\n1\nzk+1 =\narg min\nAk f (x) +\nDh (z, zk ) ,\n(2.44a)\nδτk\nz∈X\nδτ\n\n1\nk z+\nx= 1+δτ\nxk\n1+δτ\nk\n\nk\n\n1\nδτk\nxk+1 =\nzk+1 +\nxk ;\n1 + δτk\n1 + δτk\n\n(2.44b)\n\nthese updates satisfy the variational conditions ∇h(zk+1 δ)−∇h(zk ) = −∇f (xk+1 ) Ak+1δ−Ak and\nxk+1 −xk\n−Ak\n= τk (zk+1 − xk+1 ) where τk = Ak+1\n, respectively. Let αk = Ak+1δ−Ak . We now\nδ\nδAk\nstate our main proposition for the discrete-time dynamics.\nProposition 2.2.2. Using the discrete-time Lyapunov function,\nEk = Dh (x∗ , zk ) + Ak (f (xk ) − f (x∗ )),\nthe bound Ek+1δ−Ek ≤ 0 holds for algorithm (2.44).\n\n(2.45)\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n29\n\nThis allows us to conclude a general O(1/Ak ) convergence rate for the implicit method (2.44).\nUsing these identities, we have the following derivation:\n\n\n∇h(zk+1 ) − ∇h(zk ) ∗\nf (xk+1 ) − f (xk )\nEk+1 − Ek\n=−\n, x − zk+1 + Ak\nδ\nδ\nδ\n∗\n1\n+ (f (xk+1 ) − f (x ))αk + εk\nf (xk+1 ) − f (xk )\n(2.44a)\n= (h∇f (xk+1 ), x∗ − zk+1 i + f (xk+1 ) − f (x∗ ))αk + Ak\n+ ε1k\nδ\n(2.44b)\n\n= −Df (x∗ , xk+1 )αk + ε2k\n\nThe inequality on the last line follows from the convexity of f and the strict convexity of h.\nBoth errors, ε1k = − 1δ Dh (zk+1 , zk ) and ε2k = − Aδk Df (xk , xk+1 ) − 1δ Dh (zk+1 , zk ) are negative.\nThis argument allows us to conclude a O(1/Ak ) convergence rate.\nAccelerated gradient family. We study families of algorithms which give rise to a family\nof accelerated methods. These methods can be thought of variations of the explicit Euler\nscheme applied to (2.41a) and the implicit Euler scheme applied to (2.41b). Take, τk =\n(Ak+1 − Ak )/δAk+1 := αk /Ak+1 . The variational conditions for the first family of methods\ncan be written as the following:\nxk+1 − yk\n= τk (zk − yk )\nδ\n∇h(zk+1 ) − ∇h(zk )\nAk+1 − Ak\n=−\n∇f (xk+1 )\nδ\nδ\nyk+1 = G(x),\n\n(2.46a)\n(2.46b)\n(2.46c)\n\nwhere G : X → X is an arbitrary map whose domain is the previous state, x = (xk+1 , zk+1 , yk ).\nThe variational conditions for second family can be written:\nxk+1 − yk\n= τk (zk − yk )\nδ\nyk+1 = G(x)\n∇h(zk+1 ) − ∇h(zk )\nAk+1 − Ak\n=−\n∇f (yk+1 ),\nδ\nδ\n\n(2.47a)\n(2.47b)\n(2.47c)\n\nwhere G : X → X is an arbitrary map whose domain is the previous state, x = (xk+1 , zk , yk ).\nWhen G(x) = xk+1 for either algorithm, we recover a classical explicit discretization applied\nto (2.41a) and implicit discretization applied to (2.41b). We will show that the additional\nsequence yk allows us to obtain better error bounds in our Lyapunov analysis. Indeed,\naccelerated gradient descent [43, 45], accelerated mirror prox [13] accelerated higher-order\nmethods [40, 6], accelerated universal methods [21], all involve particular choices for the\nmap G and for the smoothness assumptions on f and h. We demonstrate how the analyses contained in all of these papers implicitly show the following discrete-time Lyapunov\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n30\n\nfunction,\nEk = Dh (x∗ , zk ) + Ak (f (yk ) − f (x∗ )),\n\n(2.48)\n\nis decreasing for each iteration k. We present the proposition for gradient descent in the\nmain text, and leave the fully general case to the appendix.\nProposition 2.2.3. Assume that the distance-generating function h is σ-strongly convex\nand the objective function f is convex. Using only the updates (2.46a) and (2.46b), and\nusing the Lyapunov function (2.48), we have the following bound:\nEk+1 − Ek\n≤ −Df (x∗ , xk+1 )αk + εk+1 ,\nδ\n\n(2.49)\n\nwhere the error term scales as\nεk+1 = δ\n\nαk2\nf (yk+1 ) − f (xk+1 )\nk∇f (yk+1 )k2 + Ak+1\n.\n2σ\nδ\n\nIf we use the updates (2.47a) and (2.47c) instead, the error term scales as\n\n\nαk2\nyk+1 − xk+1\n2\nεk+1 = δ k∇f (yk+1 )k + Ak+1 ∇f (yk+1 ),\n.\n2σ\nδ\n\n(2.50a)\n\n(2.50b)\n\nIn particular, accelerated mirror decent uses the following family of operators G ≡ G\u000f ,\nparameterized by a scaling constant \u000f > 0:\n\u001a\n\u001b\n1\n2\nG\u000f (x) = arg min f (x) + h∇f (x), y − xi + ky − xk .\n(2.51)\ny∈X\n2\u000f\nNesterov assumed the use of full gradients ∇f which are (1/\u000f)-smooth; thus, the gradient map\nis scaled according to the Lipschitz parameter. Using the gradient update, yk+1 = G\u000f (xk+1 ),\nfor updates (2.46c) and (2.47b), where G\u000f is defined in (2.51), the error for algorithm (2.46)\ncan be written as follows:\nεk+1 = δ\n\nAk+1 \u000f\nαk2\nk∇f (xk+1 )k2 −\nk∇f (xk+1 )k2 ,\n2σ\n2δ\n\n(2.52a)\n\nand for algorithm (2.47), we have:\nεk+1 = δ\n\nαk2\nAk+1 \u000f\nk∇f (yk+1 )k2 −\nk∇f (yk+1 )k2 .\n2σ\n2δ\n\n(2.52b)\n\nIn particular, observe that the optimality condition for the gradient update (2.51) is\n1\n∇f (x) = (x − G\u000f (x)).\n\u000f\n\n(2.53)\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n31\n\nThe bound (2.52a) follows from smoothness of the objective function f ,\n\u000f\n\u000f\n(2.53)\nf (G\u000f (x)) ≤ f (x) + h∇f (x), G\u000f (x) − xi + kG\u000f (x) − xk2 = f (x) − k∇f (x)k2 .\n2\n2\nFor the second bound (2.52b), we use the L-smoothness of the gradient,\n1\nk∇f (G\u000f (x)) − ∇f (x)k ≤ kG\u000f (x) − xk;\n\u000f\n\n(2.54)\n\nsubstituting (2.53) into (2.54), squaring both sides, and expanding the square on the lefthand side, yields the desired bound:\n\u000f\nh∇f (G\u000f (x)), x − G\u000f (x))i ≤ − k∇f (G\u000f (x))k2 .\n2\nThe error bounds we have just obtained depend explicitly on the scaling \u000f. This restricts\nα2k\n≤ 1, for the error\nour choice of sequences Ak ; they must satisfy the following inequality, Ak+1\n√\n\nto be bounded. For example, Ak+1 = σ\u000f(k+1)(k+2)\nand αk = σ\u000f(k+1)\nsatisfies the bound;\n4\n2\n∗\n2\nfrom this we can conclude f (yk ) − f (x ) ≤ O(1/\u000fσk ), which matches the lower bound\nfor algorithms which only use full gradients of the objective function. Furthermore,\nif we\n√\n\u000fσ,\nthen\nboth\ntake the discretization\nstep\nto\nscale\naccording\nto\nthe\nsmoothness\nas\nδ\n=\n√\n√\n√\nxk√\n−yk\nk \u000f k = O( \u000f) and εk = O( \u000f); therefore, as δ = \u000fσ → 0, for a fixed σ, we recover the\ndynamics (2.41) and the statement dtd Et ≤ 0 for Lyapunov function (2.38) in the limit.\nAccelerated Mirror Prox Accelerated mirror-prox, which was introduced by Diakonikolas and Orecchia [13], also fits into the Lyapunov framework. Let f be (1/\u000f)-smooth. Take,\nτk = (Ak+1 − Ak )/δAk+1 := αk /Ak+1 . The variational conditions for the first family of\nmethods can be written as the following:\nx0k+1 − xk\n= τk (zk − xk )\nδ\n0\n∇h(zk+1\n) − ∇h(zk )\nAk+1 − Ak\n=−\n∇f (x0k+1 )\nδ\nδ\nxk+1 − xk\n0\n= τk (zk+1\n− xk )\nδ\n∇h(zk+1 ) − ∇h(zk )\nAk+1 − Ak\n=−\n∇f (xk+1 )\nδ\nδ\n\n(2.55a)\n(2.55b)\n(2.55c)\n(2.55d)\n\nAs an algorithm, we can write it as, x0k+1 = δτk zk + (1 − δτk )xk ((2.55a)); yk+1 = ∇h(zk ) −\n0\n0\nαk ∇f (x0k+1 ), zk+1\n= ΠX ∩X 0 (∇h∗ (yk+1 )) ((2.55b)); xk+1 = δτk zk+1\n+ (1 − δτk )xk ((2.55c));\n0\n0\nyk+1\n= ∇h(zk ) − αk ∇f (xk+1 ), zk+1 = ΠX ∩X 0 (∇h∗ (yk+1\n)), where Π is the Bregman projection\noperator (B.18) . The function (2.45) is a Lyapunov function for (2.55). In particular, the\nfollowing upper bound,\nEk+1 − Ek\n≤ −Df (x∗ , xk+1 )αk + εk+1 ,\nδ\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n32\n\nfollows using a few simple arguments, where the error scales as,\nαk2\nσ 0\nσ 0\n0\n0\nεk+1 = δ\nkzk+1\n− zk kkzk+1\n− zk+1 k − kzk+1\n− zk k2 − kzk+1\n− zk+1 k2 .\n(2.56)\nAk+1 \u000f\n2δ\n2δ\n√\nThe proof of this result can be found in Appendix B.4. Taking δ = \u000fσ, the\nerror is\n√\nα2k\nσ\u000f(k+1)\nσ\u000f(k+1)(k+2)\nnonpositive if Ak+1 ≤ 1. The same choices, Ak+1 =\nand αk =\nen4\n2\n∗\n2\nsures the error is nonpositive; from this we can conclude f (xk ) − f (x ) ≤ O(1/\u000fσk ), which\nmatches the lower bound for algorithms which only use full gradients of the objective func0\n0\n0\n) − ∇h(zk+1 )k =\nk ≤ σ −1 k∇h(zk+1\n− zk+1\ntion. Similar to the mirror prox algorithm, kzk+1\nδσ −1 kαk (∇f (x0k+1 ) − ∇f (xk+1 ))k = O(δ/σ), so that in the limit δ → 0, we recover the\ncontinuous-time dynamic (2.41).\n2.2.1.3\n\nMethods arising from the second Euler-Lagrange equation\n\nAssume f is μ-strongly convex with respect to h (A.7), h is strictly convex, and the second\nideal scaling condition (2.37b) holds with equality. We write the Euler Lagrange equation (2.40) as,\nd βt\ne\nd\nXt = dt βt (Zt − Xt ),\ndt\ne\n\u0013\nd βt \u0012\ne\nd\n1\ndt\n∇h(Zt ) = βt ∇h(Xt ) − ∇h(Zt ) − ∇f (Xt ) .\ndt\ne\nμ\n\n(2.57a)\n(2.57b)\n\nFor this dynamical system,\nEt = eβt (μDh (x∗ , Zt ) + f (Xt ) − f (x∗ ))\n\n(2.58)\n\nis a Lyapunov function. We check,\n\n\nd\nd βt\nd\n∗\n∗\nβt d\nβt\n∗\nEt = (μDh (x , Zt ) + f (Xt ) − f (x )) e + e\nf (Xt ) − e μ\n∇h(Zt ), x − Zt\ndt\ndt\ndt\ndt\nd\n(2.57b)\n= (μDh (x∗ , Zt ) + f (Xt ) − f (x∗ ) + h∇f (Xt ), x∗ − Zt )) eβt\ndt\nd\nd\n+ eβt f (Xt ) + μ h∇h(Xt ) − ∇h(Zt ), x∗ − Zt i eβt\ndt\ndt\n(2.57a)\nd\n(2.59)\n≤ (−Df (x∗ , Xt ) + μDh (x∗ , Xt )) eβt ≤ 0.\ndt\nIn third line, we use the Bregman three point identity (A.27) and the inequality follows from\nthe μ-strong convexity of f with respect to h (A.7).\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n33\n\nBackward-Backward-Euler Written as an algorithm, the implicit Euler scheme applied\nto (2.57a) and (2.57b) results in the following updates:\n\u001a\n\u001b\nμ\nf (x) + μDh (z, x) +\nDh (z, zk ) ,\n(2.60a)\nzk+1 =\narg min\nδτk\nz∈X\nδτ\n\n1\nk z+\nx= 1+δτ\nxk\n1+δτ\nk\n\nk\n\nδτk\n1\nxk+1 =\nzk+1 +\nxk .\n1 + δτk\n1 + δτk\n\n(2.60b)\n\nUsing the following discrete-time Lyapunov function:\nEk = Ak (μDh (x∗ , zk ) + f (xk ) − f (x∗ )),\n\n(2.61)\n\nwe obtain the bound Ek+1δ−Ek ≤ 0 for algorithm (2.44). This allows us to conclude a general\nO(1/Ak ) convergence rate for the implicit scheme (2.44). Indeed, the backward-Euler (1.5)\ndiscretization applied to dynamics (2.60) satisfies the variational conditions\n\u0010\n\u0011\n1\n∇h(zk+1 ) − ∇h(zk )\n= τk ∇h(xk+1 ) − ∇h(zk+1 ) − ∇f (xk+1 ) ,\nδ\nμ\nand\n\nxk+1 − xk\n= τk (zk+1 − xk+1 ),\nδ\n\n−Ak\nwhere τk = Ak+1\n. Using these variational inequalities, we have the following argument:\nδAk\n\nEk+1 − Ek\nf (xk+1 ) − f (xk )\n= (μDh (x∗ , zk+1 ) + f (xk+1 ) − f (x∗ ))αk + Ak\nδ\nδ\n\n\n∇h(zk+1 ) − ∇h(zk ) ∗\n, x − zk+1 + ε1k\n− Ak μ\nδ\n(2.60a)\n\n= (μDh (x∗ , zk+1 ) + f (xk+1 ) − f (x∗ ) + h∇f (xk+1 ), x∗ − zk+1 i)αk\n\n\n∇h(xk+1 ) − ∇h(zk+1 ) ∗\nf (xk+1 ) − f (xk )\n+μ\n, x − zk+1 αk + ε1k\n+ Ak\nδ\nδ\n(2.60b)\n\n= (−Df (x∗ , xk+1 ) + μDh (x∗ , xk+1 ))αk + ε2k ≤ 0.\n\nThe third line follows from the Bregman three-point identity (A.27) and the last line follows from the μ-strong convexity of f with respect to h (A.7). The first error scales as\nε1k = − Aδk μ Dh (zk+1 , zk ) and ε2k = − Aδk Df (xk , xk+1 ) − αk μDh (xk+1 , zk+1 ) + ε1k . We now focus\non analyzing the accelerated gradient family, which can be viewed as a discretization that\ncontains easier subproblems.\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n34\n\nAccelerated gradient descent We study a family of algorithms which can be thought\nof as slight variations of the implicit Euler scheme applied to (2.57a) and the explicit Euler\nscheme applied to (2.57b)\nxk − yk\n= τk (zk − yk )\nδ\n\u0012\n\u0013\n∇h(zk+1 ) − ∇h(zk )\n1\n= τk ∇h(xk ) − ∇h(zk ) − ∇f (xk )\nδ\nμ\nyk+1 = G(x),\n\n(2.62a)\n(2.62b)\n(2.62c)\n\n−Ak\nk\nwhere x = (xk , zk+1 , yk ) is the previous state and τk = Ak+1\n:= Aαk+1\n. (2.62a) written as\nδAk+1\nδτk\n1\nan update, is simply, xk = 1+δτ\nzk + 1+δτ\nyk . Note that when G(x) = xk , we recover classical\nk\nk\ndiscretizations. The additional sequence yk+1 = G(x), however, allows us to obtain better\nerror bounds using the Lyapunov analysis. To analyze the general algorithm (2.62), we use\nthe following Lyapunov function:\n\nEk = Ak (μDh (x∗ , zk ) + f (yk ) − f (x∗ )).\n\n(2.63)\n\nWe begin with the following proposition, which provides an initial error bound for algorithm (2.62) using the general update (2.62c).\nProposition 2.2.4. Assume the objective function f is μ-uniformly convex with respect\nto h (A.5) and h is σ-strongly convex. In addition, assume f is (1/\u000f)-smooth. Using the\nsequences (2.62a) and (2.62b), the following bound holds:\nEk+1 − Ek\n≤ (−Df (x∗ , xk ) + μDh (x∗ , xk ))αk + εk ,\nδ\n\n(2.64)\n\nwhere the error term has the following form:\nf (yk+1 ) − f (xk )\nσμ\nσμ\n+ Ak+1 k∇h(zk+1 ) − ∇h(zk )k2 − Ak+1 kxk − yk k2\nδ\n2δ\n2δ\nαk (h∇f (xk ), yk − xk i + (1/\u000f)Dh (yk , xk ) − μDh (xk , zk ))\n\nεk = Ak+1\n\nWhen h is Euclidean, the error simplifies to the following form\nεk+1 = Ak+1\n\nτ2\nf (yk+1 ) − f (xk )\n+ δ k k∇f (xk )k2 + δ\nδ\n2μ\n\n\u0012\n\nτk\nμ\n−\n2\u000f 2τk\n\n\u0013\n\nxk − yk\nδ\n\n2\n\n!\n.\n\nWe present a proof of Proposition 2.2.4 in Appendix B.6.3. The result for accelerated\ngradient descent can be summed up in the following corollary, which is a consequence of\nProposition 2.2.4.\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n35\n\nCorollary 2.2.5. Using the gradient step,\nG(x) = xk − \u000f∇f (xk ),\nfor update (2.62c) results in an error which scales as\n\u0012 2\n\u0013\n\u0012\n\u0013\nδτk\n\u000f\nτk\nμ\nxk − yk\n2\nεk+1 = Ak+1\n−\nk∇f (xk )k + δAk+1\n−\n2μ\n2δ\n2\u000f 2τk\nδ\n\n2\n\n,\n\nwhen h is Euclidean.\n√\n√\n√\nThe parameter choice τk = μ, δ = \u000f so that√ δτk = 1/ κ ensures the error is non√\n−k/ κ\n− μδk\n)\n=\nO(e\n) convergence rate. In\npositive. With this choice,\nwe\nobtain\na\nlinear\nO(e\n√\n√\nk\naddition, k xk√−y\nk\n=\nO(\nδ)\nand\nε\n=\nO(\nδ),\nso\nwe\nrecover\nthe\ndynamical\nsystem (2.57) in\nk\nδ\n√\nthe Euclidean setting and the continuous Lyapunov argument Ėt ≤ 0 in the limit \u000f = δ → 0.\nIn Appendix B.6, we provide an analysis of the algorithms that arise from dynamics (2.38)\nand (2.40) for the following additional two settings:\n• f has (\u000f, ν)-Hölder continuous gradients (A.15)\n• accelerated higher order gradient methods, such as the accelerated cubic-regularized\nNewton method [40].\n\n2.2.2\n\nQuasi-monotone methods\n\nFor both dynamics (2.41) and (2.57), the full gradients ∇f (Xt ) can be replaced by directional\nsubgradients Gf (Xt , Ẋt ), and the same functions (2.42) and (2.58) are Lyapunov functions.\nHowever, these Lyapunov functions are not necessarily differentiable in this setting. To adapt\nthe analysis, we follow the technique of Su, Boyd and Candes [70] and summarize with the\nfollowing theorem:\nTheorem 2.2.6. Take X(0) = x0 , Ẋ(0) = 0 and βt = p log t for p > 0. Given a convex\nfunction f with directional subgradient Gf (x, v), assume that\nd βt\ne\n(2.65a)\nẊt = dt βt (Zt − Xt )\ne\nd\nd\n∇h(Zt ) = Gf (Xt , Ẋt ) eβt ,\n(2.65b)\ndt\ndt\nadmits a solution X(t) on [0, α) for some α > 0. Then for any 0 < t < α, Et given by (2.42)\nis a Lyapunov function on [0, α). Given a μ-strongly convex function f with directional\nsubgradients, assume that\n\nẊt =\n\nd βt\ne\ndt\n(Zt − Xt )\neβt\n\n\u0013\nd βt \u0012\ne\nd\n1\ndt\n∇h(Zt ) = βt ∇h(Xt ) − ∇h(Zt ) − Gf (Xt , Ẋt )\ndt\ne\nμ\n\n(2.66a)\n(2.66b)\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\nd\n∇h(Zt ) = −Gf (Xt , Ẋt ) dtd eβt ,\ndt\n\nQM Dynamics 1:\n\n36\nd\nX =\ndt t\n\nd βt\ne\ndt\neβt\n\n(Zt − Xt )\n\nGf (Xt , Ẋt ) ∈ ∂f (Xt )\nFunction Class\n\nLyapunov Function\n\nConvergence Rate\n\nConvex\n\nEt = Dh (x∗ , Xt ) + eβt (f (Xt ) − f (x∗ ))\n\nf (Xt ) − f (x∗ ) ≤ eβt0t\n\nQM Method 1:\n\n∇h(zk+1 )−∇h(zk )\n= −αk g(xk+1 ),\nδ\n\nxk+1 −xk\n= τk (zk − xk+1 )\nδ\n\nE\n\ng(xk+1 ) ∈ ∂f (xk+1 )\nFunction Class\n\nLyapunov Function\n\nConvex\n\nEk = Dh (x∗ , zk ) + Ak (f (xk ) − f (x∗ ))\n\nQM Dynamics 2:\n\nd βt\ne\nd\n∇h(Zt ) = (∇h(Xt ) − ∇h(Zt ) − μ1 Gf (Xt , Ẋt )) dteβt ,\ndt\n\nf is Lipschitz; h σ-strongly convex\n\nConvergence Rate\nf (xk ) − f (x∗ ) ≤\nd\nX =\ndt t\n\nd βt\ne\ndt\neβt\n\nE0 +δ\n\nPk\n\n1\ns=0 εs\n\nAk\n\n(Zt − Xt )\n\nGf (Xt , Ẋt ) ∈ ∂f (Xt )\nFunction Class\n\nLyapunov Function\n\nConvergence Rate\n\nf is μ-uniformly convex w.r.t h\n\nEt = eβt (μDh (x∗ , Zt ) + f (Xt ) − f (x∗ ))\n\nf (Xt ) − f (x∗ ) ≤ O(1/eβt )\n\nQM Method 2:\n\n∇h(zk+1 )−∇h(zk )\n= −τk (∇h(xk+1 ) − ∇h(zk+1 ) − μ1 g(xk+1 ))\nδ\n\nxk+1 −xk\n= τk (zk − xk+1 )\nδ\n\ng(xk+1 ) ∈ ∂f (xk+1 )\nFunction Class\n\nLyapunov Function\n\nμ-Strongly Convex\n\nEk = Ak (Dh (x∗ , zk ) + f (xk ) − f (x∗ ))\n\nConvergence Rate\nf (xk ) − f (x∗ ) ≤\n\nE0 +δ\n\nPk\n\n2\ns=0 εs\n\nAk\n\nf is Lipschitz;, h σ-strongly convex\n\nTable 2.7: Lyapunov functions for the quasi-monotone (QM) subgradient dynamics and\nquasi-monotone (QM) subgradient methods. There is a discretization error as we move\nto discrete time, and we choose parameters accordingly. Here, eβt = Ak , so that dtd eβt ≈\nα2\n\n(Ak+1 − Ak )/δ = αk and τk = (Ak+1 − Ak )/δAk . The errors scales as ε1k = δ 2σk G2 and\nα2\n\n1\nk\nε2k = δ 2σμ\nG2 . In the limit δ → 0, the discrete-time and continuous-time statements\nAk\nmatch.\n\nadmits a solution X(t) on [0, α) for some α > 0. Then for any 0 < t < α, Et given by (2.58)\nis a Lyapunov function on [0, α).\nThe proof can be found in Appendix B.6.4. Notice, this theorem does not guarantee the\n−Ak\n:= Aαkk and g(x) ∈ ∂f (x). We\nexistence of solutions for (2.65) and (2.66). Let τk = Ak+1\nδAk\nanalyze the following discretizations\nxk+1 − xk\n= τk (zk − xk+1 )\nδ\n∇h(zk+1 ) − ∇h(zk )\nAk+1 − Ak\n=−\ng(xk+1 ),\nδ\nδ\n\n(2.67a)\n(2.67b)\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n37\n\nand,\nxk+1 − xk\n= τk (zk − xk+1 )\nδ\n\u0012\n\u0013\n∇h(zk+1 ) − ∇h(zk )\n1\n= τk ∇h(xk+1 ) − ∇h(zk+1 ) − g(xk+1 ) ,\nδ\nμ\n\n(2.68a)\n(2.68b)\n\nusing Lyapunov functions (2.45) and (2.61), respectively. When h is Euclidean, we can\nwrite (2.68b) as the following update:\n\u001a\n\u001b\nμ\n2\nzk+1 = arg min hg(xk+1 ), zi +\nkz − z̃k+1 k .\nz∈X\n2δτk\nk xk+1\nwhere z̃k+1 = zk +δτ\n. The update (2.68b) involves optimizing a linear approximation\n1+δτk\nto the function regularized by a weighted combination of Bregman divergences. The Lyapunov arguments resemble the continuous-time arguments (2.43) and (2.59), respectively.\nFor algorithm (2.67), we use Lyapunov function (2.45) to check,\n\n\n∇h(zk+1 ) − ∇h(zk )\nEk+1 − Ek\nf (xk+1 ) − f (xk )\n∗\n=\n, zk − x + (f (xk+1 ) − f (x∗ ))αk + Ak\n+ ε1k\nδ\nδ\nδ\nf (xk+1 ) − f (xk )\n(2.67b)\n+ ε1k\n= (hg(xk+1 ), x∗ − zk i + f (xk+1 ) − f (x∗ ))αk + Ak\nδ\n\n(2.67a)\n\n= −Dfg (x∗ , xk+1 )αk + ε2k .\n\nHere, the first error scales as ε1k = αk hg(xk+1 ), zk − zk+1 i − 1δ Dh (zk+1 , zk ), and the second\nas ε2k = ε1k − Ak /δDfg (xk , xk+1 ). The σ-strong convexity of h, Young’s inequality, and the\nα2\n\nα2\n\nLipschitz property of f ensures the upper bound ε2k ≤ δ 2σk kg(xk )k2 ≤ δ 2σk G2 := εk+1 . This\nallows us to conclude the upper bound\n∗\n\nf (xk ) − f (x ) ≤\n\nE0 + δ 2\n\nα2s 2\ns=0 2σ G\n\nPk\nAk\n\n;\n\nthis bound is the same as the bound obtained for subgradient descent (2.26), but it is\non the iterate xk , and√not the time-averaged iterate\n√ x̂k . It is maximized with the choice\n∗\n2\nαK = Dh (x , X0 )/G / K which results in an O(1/ K) rate of convergence.\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n38\n\nFor algorithm (2.68), we check\nEk+1 − Ek\nf (xk+1 ) − f (xk )\n= αk (μDh (x∗ , zk+1 ) + f (xk+1 ) − f (x∗ )) + Ak\nδ\nδ\n\n\n∇h(zk+1 ) − ∇h(zk ) ∗\n, x − zk+1 + ε1k\n− Ak μ\nδ\n(2.60a)\n\n= (μDh (x∗ , zk+1 ) + f (xk+1 ) − f (x∗ ) + hg(xk+1 ), x∗ − zk i)αk\nf (xk+1 ) − f (xk )\n+ μ h∇h(xk+1 ) − ∇h(zk+1 ), x∗ − zk+1 i αk + ε2k\n+ Ak\nδ\n(A.27)\n(2.60b)\n\n= (−Dfg (x∗ , xk+1 ) + μDh (x∗ , xk+1 ))αk + ε3k ≤ 0.\n\nHere, the first error scales as ε1k = − Aδk μ Dh (zk+1 , zk ), the second scales as ε2k = αk hg(xk+1 ), zk −\nzk+1 i + ε1k and the third as ε3k = ε2k − Aδk Dfg (xk , xk+1 ) ≤ ε2k . The σ-strong convexity\nof h, Young’s inequality, and the Lipschitz property of f ensures the upper bound ε2k ≤\nα2\nα2\nδ 2μAkk σ kg(xk )k2 ≤ δ 2μAkk σ G2 . This allows us to conclude the upper bound\n∗\n\nf (xk ) − f (x ) ≤\n\nE0 + δ 2\n\nα2s\n2\ns=0 2μσAs G\n\nPk\n\nAk\n\n;\n\nthis bound is the same as the bound obtained for the mirror subgradient method (2.24) (it\nis optimal), but here the convergence rate is on the iterate xk , and not the time-averaged\niterate x̂k . It is maximized by the sequence Ak = (k + 1)k, which results in the convergence\nrate O(1/k) convergence rate.\n\n2.2.3\n\nEquivalence between estimate sequences and Lyapunov\nfunctions\n\nIn this section, we connect our Lyapunov framework directly to estimate sequences. We\nderive continuous-time estimate sequences directly from our Lyapunov function and demonstrate how these two techniques are equivalent.\nEstimate sequences We provide a brief review of the technique of estimate sequences [43].\nWe begin with the following definition.\n∞\nDefinition 2.2.7. [43, p. 2.2.1] A pair of sequences {φk (x)}∞\nk=1 and {Ak }k=0 Ak ≥ 1 is\ncalled an estimate sequence of function f (x) if\n\nA−1\nk → 0,\nand, for any x ∈ Rn and for all k ≥ 0, we have\n\u0010\n\u0011\nφk (x) ≤ 1 − A−1\nf (x) + A−1\nk\nk φ0 (x).\n\n(2.69)\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n39\n\nThe following lemma, due to Nesterov, explains why estimate sequences are useful.\nLemma 2.2.8. [43, p. 2.2.1] If for some sequence {xk }k≥0 we have\nf (xk ) ≤ φ∗k ≡ min φk (x),\n\n(2.70)\n\nx∈X\n\n∗\n∗\nthen f (xk ) − f (x∗ ) ≤ A−1\nk [φ0 (x ) − f (x )].\n\nThe proof is straightforward:\n(2.70)\n\n(2.69)\n\nf (xk ) ≤ φ∗k ≡ min φk (x) ≤ min\nx∈X\n\nx∈X\n\nh\u0010\n\n\u0011\ni \u0010\n\u0011\n−1\n−1\n∗\n1 − A−1\nf\n(x)\n+\nA\nφ\n(x)\n≤\n1\n−\nA\nf (x∗ ) + A−1\n0\nk\nk\nk\nk φ0 (x ).\n\nRearranging gives the desired inequality. Notice that this definition is not constructive.\nFinding sequences which satisfy these conditions is a non-trivial task. The next proposition,\nformalized by Baes in [6] as an extension of Nesterov’s Lemma 2.2.2 [43], provides guidance\nfor constructing estimate sequences. This construction is used in [43, 45, 40, 6, 47, 41],\nand is, to the best of our knowledge, the only known formal way to construct an estimate\nsequence. We will see below that this particular class of estimate sequences can be turned\ninto our Lyapunov functions with a few algebraic manipulations (and vice versa).\nProposition 2.2.9. [6, p. 2.2] Let φ0 : X → R be a convex function such that minx∈X φ0 (x) ≥\nf ∗ . Suppose also that we have a sequence {fk }k≥0 of functions from X to R that underestimates f :\nfk (x) ≤ f (x)\n\nfor all x ∈ X and all k ≥ 0.\n\n(2.71)\n\n−Ak\n:= Aαkk , and\nDefine recursively A0 = 1, τk = Ak+1\nAk+1\n\nφk+1 (x) := (1 − τk )φk (x) + τk fk (x) = A−1\nk+1 A0 φ0 (x) +\n\nk\nX\n\n!\nas fs (x) ,\n\n(2.72)\n\nαs fs (x) + A0 φ0 (x),\n\n(2.73)\n\ns=0\n\nfor all k ≥ 0. Then ({φk }k≥0 , {Ak }k≥0 ) is an estimate sequence.\nFrom (2.70) and (2.72), we observe that the following invariant:\nAk+1 f (xk+1 ) ≤ min Ak+1 φk+1 (x) = min\nx\n\nx\n\nk\nX\ns=0\n\nis maintained. In [47, 41], this technique was extended to incorporate an error term {ε̃k }∞\nk=1 ,\n\u0010\n\nφk+1 (x) − A−1\nk+1 ε̃k+1 := (1 − τk )\n\nφk (x) − A−1\nk ε̃k\n\n\u0011\n\n+ τk fk (x) = A−1\nk+1\n\n\u0010\n\nA0 (φ0 (x) − ε̃0 ) +\n\nk\nX\ns=0\n\n\u0011\nas fs (x) ,\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n40\n\nwhere εk ≥ 0, ∀k. Rearranging, we have the following bound:\nAk+1 f (xk+1 ) ≤ min Ak+1 φk+1 (x) = min\nx\n\nx\n\nk\nX\n\n\u0010\n\nαs fs (x) + A0 φ0 (x) − A−1\n0 ε̃0\n\n\u0011\n\n+ ε̃k+1 .\n\ns=0\n\nNotice that an argument analogous to that of Lemma 2.2.8 holds:\nAk+1 f (xk+1 ) ≤\n\nk\nX\n\n∗\n\nk\n(2.71) X\n\n∗\n\nαs fs (x ) + A0 (φ0 (x ) − ε̃0 ) + ε̃k+1 ≤\n\ns=0\n\nαs f (x∗ ) + A0 φ0 (x∗ ) + ε̃k+1\n\ns=0\n\n= Ak+1 f (x∗ ) + A0 φ0 (x∗ ) + ε̃k+1 .\nRearranging, we obtain the desired bound,\nf (xk+1 ) − f (x∗ ) ≤\n\nA0 φ0 (x∗ ) + ε̃k+1\n.\nAk+1\n\nThus, we simply need to choose our sequences {Ak , φk , ε̃k }∞\nk=1 to ensure ε̃k+1 /Ak+1 → 0. The\nfollowing table illustrates the choices of φk (x) and ε̃k for the four methods discussed earlier.\nAlgorithm\nQuasi-Monotone Subgradient Method\nAccelerated Gradient Method\n(Weakly Convex)\nAccelerated Gradient Method\n(Strongly Convex)\nConditional Gradient Method\n\nfs (x)\nlinear\nlinear\nquadratic\nlinear\n\nφk (x)\n1\nD (x, zk ) + f (xk )\nAk h\n1\nD (x, zk ) + f (xk )\nAk h\nf (xk ) + μ2 kx − zk k2\nf (xk )\n\n1\n2\n\nε̃k+1\n(As+1 −As )2 2\nG\ns=0\n2\n\nPk\n\n0\n0\n1\n2\u000f\n\nPk\n\ns=0\n\n(As+1 −As )2\ndiam(X )2\nAs+1\n\nTable 2.8: Choices of estimate sequences for various algorithms\nIn Table 2.8 “linear” is defined as fs (x) = f (xs ) + h∇f (xs ), x − xs i, and “quadratic” is\ndefined as fs (x) = f (xs ) + h∇f (xs ), x − xs i + μ2 kx − xs k2 . The estimate-sequence argument is\ninductive; one must know the three sequences {εk , Ak , φk (x)} a priori in order to check the\ninvariants hold. This aspect of the estimate-sequence technique has made it hard to discern\nits structure and scope.\nEquivalence to Lyapunov functions We now demonstrate an equivalence between these\ntwo frameworks. The continuous-time view shows that the errors in both the Lyapunov\nfunction and estimate sequences are due to discretization errors. We demonstrate how this\nworks for accelerated methods, and defer the proofs for the other algorithms discussed earlier\nin the chapter to Appendix B.7.\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n41\n\nEquivalence in discrete time. The discrete-time estimate sequence (2.72) for accelerated\ngradient descent can be written:\nφk+1 (x) := f (xk+1 ) + A−1\nk+1 Dh (x, zk+1 )\n(2.72)\n\n= (1 − τk )φk (x) + τk fk (x)\n\u0010\n\u0011\u0010\n\u0011\nTable 2.8\n−1\n=\n1 − A−1\nα\nf\n(x\n)\n+\nA\nD\n(x,\nz\n)\n+ A−1\nk\nk\nh\nk\nk+1\nk\nk+1 αk fk (x).\n\nMultiplying through by Ak+1 , we have the following argument, which follows directly from\nour definitions:\n\u0010\n\u0011\nAk+1 f (xk+1 ) + Dh (x, zk+1 ) = (Ak+1 − αk ) f (xk ) + A−1\nD\n(x,\nz\n)\n+ αk fk (x)\nh\nk\nk\n\u0010\n\u0011\n= Ak f (xk ) + A−1\nk Dh (x, zk ) + (Ak+1 − Ak )fk (x)\n≤ Ak f (xk ) + Dh (x, zk ) + (Ak+1 − Ak )f (x).\nThe last inequality follows from definition (2.71). Rearranging, we obtain the inequality\nEk+1 ≤ Ek for our Lyapunov function (2.48). Going the other direction, from our Lyapunov\nanalysis we can derive the following bound:\nEk ≤ E0\nAk (f (xk ) − f (x)) + Dh (x, zk ) ≤ A0 (f (x0 ) − f (x)) + Dh (x, z0 )\n\u0010\n\u0011\n\u0010\n\u0011\n−1\n∗\nAk f (xk ) − A−1\nD\n(x,\nz\n)\n≤\n(A\n−\nA\n)f\n(x)\n+\nA\nf\n(x\n)\n+\nA\nD\n(x\n,\nz\n)\nh\nk\nk\n0\n0\n0\nh\n0\n0\nk\nAk φk (x) ≤ (Ak − A0 )f (x) + A0 φ0 (x).\n\n(2.74)\n\nRearranging, we obtain the estimate sequence (2.69), with A0 = 1:\n\u0010\n\u0011\n\u0010\n\u0011\n−1\n−1\nφk (x) ≤ 1 − A−1\nA\nf\n(x)\n+\nA\nA\nφ\n(x)\n=\n1\n−\nA\nf (x) + A−1\n0\n0\n0\nk\nk\nk\nk φ0 (x).\nWriting Et ≤ E0 , one can simply rearrange terms to extract an estimate sequence:\n\u0010\n\u0011\n\u0010\n\u0011\nf (Xt ) + e−βt Dh (x, Zt ) ≤ 1 − e−βt eβ0 f (x∗ ) + e−βt eβ0 f (X0 ) + e−β0 Dh (x, Z0 ) .\nComparing this to (2.74), matching terms allows us to extract the continuous-time estimate\nsequence {φt (x), eβt }, where φt (x) = f (Xt ) + e−βt Dh (x, Zt ).\n\n2.2.4\n\nDual averaging with momentum\n\nWe summarize the results presented in this section in Table 2.9;\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n42\n\nDA Dynamic with momentum:\n\nd\nY = −τ̇t ∇f (Xt ), Yt = γt ∇h(Zt )\ndt t\n\nd\nX = τ̇τtt (Zt − Xt )\ndt t\n\nFunction Class\n\nLyapunov Function\n\nConvergence Rate\n\nConvex\n\nEt = γt Dh (x∗ , Zt ) + τt (f (Xs ) − f (x∗ ))\n\n,X0 )\nf (Xt ) − f (x∗ ) ≤ γt Dh (x\nτt\n\nDA Algorithm with momentum:\n\nyk+1 −yk\n= −αk g(xk ), yk = γk ∇h(zk )\nδ\n\nxk+1 −xk\n−Ak\n= Ak+1\n(zk − xk+1 )\nδ\nAk δ\n\nFunction Class\n\nLyapunov Function\n\nConvergence Rate\n\nConvex\n\nEk = γk Dh (x∗ , zk ) + Ak (f (xk ) − f (x∗ ))\n\nProximal DA Algorithm:\n\nyk+1 −yk\n= −αk g(xk+1 ), yk = γk ∇h(zk )\nδ\n\n−Ak\nxk+1 −xk\n= Ak+1\n(zk+1 − xk+1 )\nδ\nAk δ\n\nFunction Class\n\nLyapunov Function\n\nConvergence Rate\n\nConvex\n\nEk = γk Dh (x∗ , xk ) + Ak (f (xk ) − f (x∗ ))\n\nf (xk ) − f (x∗ ) ≤ γk DhA(xk ,x0 )\n\nf is Lipschitz\n\nδ>0\n\n∗\n\nf (xk ) − f (x∗ ) ≤\n\nγk Dh (x∗ ,z0 )+δ\nAk\n\nPk\n\n1\ns=0 εs\n\n∗\n\nTable 2.9: Lyapunov functions for the dual averaging dynamic with momentum, dual averaging algorithm with momentum, and the backward-Euler approximation of the dual averaging\n2\n1 αk 2\nG , where\ndynamics with momentum; Here, g(x) ∈ ∂f (x), αk = Ak+1δ−Ak , and ε1k = δ 2σ\nγk\n2\n2\nk∂f (x)k∗ ≤ G . In the limit δ → 0, the discrete-time and continuous-time statements match.\n\nWe adopt the setting of dual averaging, where we have a pre-establish prox function h\nwith prox-center X0 . When momentum is added to the dual averaging dynamic,\nd\nd\nYt = −∇f (Xt ) τt\ndt\ndt\nYt = γt ∇h (Zt )\nτ̇t\nd\nXt = (Zt − Xt ),\ndt\nτt\n\n(2.75b)\n\nEt = γt Dh (x∗ , Zt ) + τt (f (Xt ) + f (x∗ )),\n\n(2.76)\n\n(2.75a)\n\n(2.75c)\n\nthe following function,\n\nis a natural candidate for a Lyapunov function. We check,\n\n\nd\nd\nd\nd\n∗\n∗\nEt = Dh (x , Zt ) γt − γt\n∇h(Zt ), x − Zt + τ̇t (f (Xt ) − f (x∗ )) + τt f (Xt )\ndt\ndt\ndt\ndt\n\n\nd\nd\nd\n(2.75a)\n∗\n∗\n∗\nYt , x − Zt + τ̇t (f (Xt ) − f (x )) + τt ∇f (Xt ), Xt\n= (h(x ) − h(Zt )) γt −\ndt\ndt\ndt\n(2.75b)\n(2.75c)\n\n= −τ̇t Df (x∗ , Xt ) + γ̇t (h(x∗ ) − h(Zt )) ≤ γ̇t Dh (x∗ , Z0 ).\n\nThe last inequality uses the fact that h(x) = Dh (x, Z0 ) ≥ 0, ∀x ∈ X as well as the definition\nof a prox-center h(x∗ ) = Dh (x∗ , Z0 ). From the bound Et ≤ E0 + γt Dh (x∗ , Z0 ) − γ0 Dh (x∗ , Z0 ),\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n43\n\nwe obtain the convergence rate2\nf (Xt ) − f (x∗ ) ≤\n\nE0 + γt Dh (x∗ , Z0 )\nτt\n\nA similar guarantee can be obtained by the algorithm obtained from discretizing the dynamics (2.75).\nDual Averaging subgradient method with momentum Make the identifications τt =\n−Ak\nAk , τ̇t = αk = Ak+1δ−Ak and let τk = Ak+1\n. The forward-Euler method (1.6) applied to\nAk δ\nthe updates (2.75a) and the backward-Euler method (1.5) to (2.75c) results in the quasimonotone method,\nxk+1 − xk\n= τk (zk − xk+1 )\nδ\n( k\n)\nX\n1\nzk+1 ∈ arg min\nαs hg(xs+1 ), zi +\nDh (z, zk ) ,\nz∈X\nγk δ\ns=0\n\n(2.77a)\n(2.77b)\n\nwhere g(xk+1 ) ∈ ∂f (xk+1 ). The variational condition for (2.77b) is given by\nγk+1 ∇h(zk+1 ) − γk ∇h(zk )\n= −αk g(xk+1 ).\nδ\nThe following function,\nEk = γk Dh (x∗ , zk ) + Ak (f (xk ) − f (x∗ )),\nis a Lyapunov function. We check,\n\n∇h(zk+1 ) − ∇h(zk ) ∗\n, x − zk+1\nδ\nf (xk+1 ) − f (xk )\n+ αk (f (xk+1 ) − f (x∗ )) + Ak\n+ ε1k\nδ\nγk+1 − γk\nγk+1 − γk\n(2.77b)\n= −αk Dfg (x∗ , xk ) +\n(h(x∗ ) − h(xk+1 )) + ε3k ≤\nDh (x∗ , z0 ) + ε3k .\nδ\nδ\n\nEk+1 − Ek\nγk+1 − γk\n= Dh (x∗ , xk )\n− γk\nδ\nδ\n\n\nwhere the first error scales as ε1k = − γδk Dh (zk+1 , zk ), the second as ε2k = αk hg(xk+1 ), xk+1 −\nzk+1 i + ε1k and ε2k = Ak f (xk+1 δ)−f (xk ) + ε3k . Using the convexity of f , we can bound the error\nas follows ε3k ≤ Ak hg(xk+1 ), xk+1δ−xk i + ε1k = αk hg(xk+1 ), zk − zk+1 i − γδk Dh (zk+1 , zk ). Using\nthe σ-strong convexity of h and Young’s inequality and the assumption that f is Lipschitz,\nα2k δ\nk∂f (x)k2∗ ≤ G2 , we obtain the upper bounds ε3k ≤ 2σγ\nG2 . By summing the Lyapunov\nk\nwe can also write the numerator of the convergence bound as the smaller quantity, τ0 (f (X0 ) − f (x∗ )) +\nγt Dh (x∗ , Z0 )\n2\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n44\n\nfunction we obtain the statement, Ek ≤ E0 + (γk − γ0 )Dh (x∗ , z0 ) + δ\nobtain the convergence bound,\n∗\n\nf (xk ) − f (x ) ≤\n\n1\nE0 + γk Dh (x∗ , z0 ) + δ 2 2σ\n\nPk\n\n3\ns=0 εs , from which we\n\nα2s 2\ns=0 γs G\n\nPk\n\nAk\n\n.\n\nIf we assume\nwith out loss of generality\nσ = 1, and choose Ak = k, δ = 1 and γk =\n√\n√\nG2\nk + 1, we obtain O(1/ k) convergence rate [47]. This bound matches the oracle\nDh (x∗ ,x0 )\nfunction lower bound for algorithms designed using only subgradients of convex functions\n(i.e. is provably optimal). Furthermore, as δ → 0, the error ε2k → 0 and we recover the result\nfor the continuous time dynamics.\n\n2.2.5\n\nAccelerated Proximal Gradient Dynamics\n\nWe summarize several of the results presented in this section in Table 2.10.\nd\n∇h(Zt ) = −(∇f2 (Xt ) + ∇f1 (Zt )) dtd eβt\ndt\n\nFunction Class\n\nLyapunov Function\n\nConvergence Rate\n\nConvex\n\nEt = Dh (x∗ , Zt ) + eβt (f (Xt ) − f (x∗ ))\n\nf (Xt ) − f (x∗ ) ≤ O(1/eβt )\n\nProx AMD Algorithm 1\n\n∇h(zk+1 )−∇h(zk )\n= −(∇f2 (xk+1 ) − g(zk+1 ))αk\nδ\n\nxk+1 −yk\n= τk (zk − yk )\nδ\n\ng(z) ∈ ∂f1 (z), kyk − xk k = O(δ), δ =\n\n√\n\n\u000fσ\n\nd\nX =\ndt t\n\nd βt\ne\ndt\neβt\n\nProx AMD Dynamic 1\n\n(Zt − Xt )\n\nyk+1 = yk + δτk (zk+1 − yk )\n\nFunction Class\n\nLyapunov Function\n\nConvergence Rate\n\nConvex\n\nf (yk ) − f (x∗ ) ≤ O(1/Ak )\n\nProx AMD Dynamic 2\n\nEk = Dh (x∗ , zk ) + Ak (f (yk ) − f (x∗ ))\n\u0010\n\u0011\nd βt\ne\nd\n∇h(Zt ) = dteβt ∇h(Xt ) − ∇h(Zt ) − μ1 (∇f2 (Xt ) + ∇f1 (Zt ))\ndt\n\nFunction Class\n\nLyapunov Function\n\nConvergence Rate\n\nf is μ-uniformly convex w.r.t h\n\nEt = eβt (μDh (x∗ , Zt ) + f (Xt ) − f (x∗ ))\n\u0010\n\u0011\n∇h(zk+1 )−∇h(zk )\n= τk ∇h(xk ) − ∇h(zk ) − μ1 (∇f (xk ) + g(zk+1 ))\nδ\n√\ng(z) ∈ ∂f1 (z), kyk+1 − xk k = O(δ) , δ = \u000f\n\nf (Xt ) − f (x∗ ) ≤ O(1/eβt )\n\nyk+1 = yk + δτk (zk+1 − yk )\n\nFunction Class\n\nLyapunov Function\n\nConvergence Rate\n\nf is μ-uniformly convex w.r.t h\n\nEk = Ak (Dh (x∗ , zk ) + f (yk ) − f (x∗ ))\n\nf (yk ) − f (x∗ ) ≤ O(1/Ak )\n\nf is (1/\u000f)-smooth, h is σ-strongly convex\n\nProx AMD Algorithm 2\n\nd\nX =\ndt t\n\nd βt\ne\ndt\neβt\n\n(Zt − Xt )\n\nxk −yk\n= τk (zk − xk )\nδ\n\nf is (1/\u000f)-smooth, h is Euclidean\n\nTable 2.10: Lyapunov functions for proximal accelerated mirror descent (AMD) dynamics,\nproximal accelerated mirror descent (AMD) algorithms\n. For proximal AMD algorithm 1\n√\n√\nAk+1 −Ak\nσ\u000f(k+1)(k+2)\nσ\u000f(k+2)\nwe take Ak+1 =\n, αk =\n=\n, δ = \u000fσ and for proximal AMD\n4\nδ\n2\n√\n√\n−Ak\nalgorithm 2, we take τk = Ak+1\n= μ, δ = \u000f.\nδAk+1\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n45\n\nConvex Functions Define f = f1 + f2 and assume f1 , f2 are convex. For the following\ndynamics,\nd βt\ne\nd\nXt = dt βt (Zt − Xt )\ndt\ne\n\n(2.78a)\n\nd\nd\n∇h(Zt ) = −(∇f2 (Xt ) + ∇f1 (Zt )) eβt ,\ndt\ndt\n\n(2.78b)\n\nthe same function (2.42),\nEt = Dh (x∗ , Zt ) + eβt (f (Xt ) − f (x∗ )),\nis a Lyapunov function for (2.78).\nWe check,\n\n\nd\nd\nd\nd\n∗\nEt = −\n∇h (Zt ) , x − Zt + (f (Xt ) − f (x∗ )) eβt + eβt f (Xt )\ndt\ndt\ndt\ndt\n(2.78b)\n\n= (−Df2 (x∗ , Xt ) − Df1 (x∗ , Zt ) + f1 (Xt ) − f1 (Zt ) + h∇f2 (Xt ), Xt − Zt i)\n+ eβt\n\nd βt\ne\ndt\n\n(2.78a)\nd\nd\nf (Xt ) ≤ −(Df2 (x∗ , Xt ) + Df1 (x∗ , Zt )) eβt ≤ 0\ndt\ndt\n\nwhere the second line follows from the dynamical system (2.78a) and (2.78b), and the\n(2.78a)\n\ninequalities follows from the convexity of f1 and f2 , where we plug in eβt dtd f (Xt ) =\nh∇f (Xt ), Zt − Xt i dtd eβt . This allows us to conclude an O(e−βt ) convergence rate for the\nfunction value\nf (Xt ) − f (x∗ ) ≤\n\nE0\n.\neβt\n\nProximal AGD The backward-Euler discretization of (2.78b) provides us with a forwardbackward mapping (B.8)\n\u001a\n\u001b\n1\nzk+1 = arg min f1 (z) + h∇f2 (xk+1 ), zi + Dh (z, zk ) .\n(2.79)\nz∈X\nαk\nIts variational condition is given by\n∇h(zk+1 ) − ∇h(zk )\nAk+1 − Ak\n=−\n(g(zk+1 ) + ∇f2 (xk+1 )),\nδ\nδ\nwhere g(zk+1 ) ∈ ∂f1 (zk+1 ) is an element of the subgradient. We combine this with the\nforward-Euler method applied to (2.78a), where we have replaced the xk with an iterate yk ,\nwhere yk+1 = G(x), just as in the general AGD setting,\nxk+1 − yk\n= τk (zk − yk ).\nδ\n\n(2.80)\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n46\n\n−Ak\nk\n= Aαk+1\n. We consider maps such that kxk − yk k = O(δ) and x =\nHere, τk = Ak+1\nδAk+1\n(xk+1 , zk+1 , yk ) is the previous state. In particular, we choose\n\nyk+1 − yk\n= τk (zk+1 − yk ).\nδ\n\n(2.81)\n\nFor this analysis we will need to assume φ is (1/\u000f)-smooth. Using the same Lyapunov\nfunction (2.48) as the one used for AGD,\nEk = Dh (x∗ , zk ) + Ak (f (yk ) − f (x∗ )),\nwe check,\n\n\n∇h(zk+1 ) − ∇h(zk ) ∗\nAk+1 − Ak\n, x − zk+1 +\n(f (yk+1 ) − f (x∗ ))\nδ\nδ\nf (yk+1 ) − f (yk )\n+ Ak\n+ ε1k\nδ\n= (−Df1 (x∗ , xk+1 ) − Dfg2 (x∗ , zk+1 ) + f1 (yk ) − f1 (zk+1 ) + h∇f2 (xk+1 ), xk+1 − zk i)αk\nf (yk+1 ) − f (yk )\n+ ε2k\n+ Ak\nδ\n= −(Df1 (x∗ , xk+1 ) + Dfg2 (x∗ , zk+1 ))αk + ε3k ≤ ε3k .\n\nEk+1 − Ek\n=−\nδ\n\nk+1\n= τk (zk − zk+1 ) and\nWe can combine (2.81) and (2.80) to obtain the identity xk+1 −y\nδ\nαk (xk+1 − zk ) = Ak yk −xδ k+1 . These identities will be used to simplify the discretization\nerrors.\nHere, the error ε1k = 1δ Dh (zk+1 , zk ), and εk2 = εk1 +αk h∇f2 (xk+1 ), zk −zk+1 i+αk (f2 (yk+1 )−\nk+1\nf2 (xk+1 )) = εk1 + Ak+1 h∇f2 (xk+1 ), xk+1 −y\ni + αk (f2 (yk+1 ) − f2 (xk+1 )) using the identity. For\nδ\n3\n2\nthe last error, we have εk = εk + Ak ∇f2 (xk+1 ), yk −xδ k+1 + Ak f2 (yk+1 δ)−f2 (yk ) + Ak+1 f1 (yk+1 ) −\n2 (xk+1 )\nAk f1 (yk ) − αk f1 (zk+1 ) ≤ ε2k + Ak f2 (yk+1 )−f\n+ Ak+1 f1 (yk+1 ) − Ak f1 (yk ) − αk f1 (zk+1 ),\nδ\nwhere the upper bounded follows using convexity. First, we notice the convexity of f1 gives\nthe identity Ak+1 f1 ((1 − δτk )yk + δτk zk+1 ) ≤ Ak+1 (1 − δτk )f1 (yk ) + Ak+1 τk f1 (zk+1 ) using\n2 (xk+1 )\nJensen’s (A.4). Therefore ε3k ≤ ε2k + Ak f2 (yk+1 )−f\n. Next, we use the σ-strong convexity\nδ\nf\n(y\n)−f\n2\nto upper bound the error as follows, ε3k ≤ Ak k+1 δ 2 (xk+1 ) + αk (f2 (yk+1 ) − f2 (xk+1 )) −\nσ\nk+1\nkzk+1 −zk k2 +Ak+1 h∇f2 (xk+1 ), xk+1 −y\ni. Using the (1/\u000f)-smoothness of f2 , we obtain the\n2δ\nδ\n\u0001\nσ\nσ\nk+1 2\n2\n2 1\n3\nkzk+1 −zk k2 .\nupper bound εk ≤ − 2δ kzk+1 −zk k +δAk+1 2\u000f1 k yk+1 −x\nk\n=\n−\n−\nδA\nτ\nk+1\nk\nδ\n2δ\n2\u000f\n√\n√\nMaking the same parameter as AGD δ = σ\u000f and Ak = σ\u000f(k+1)(k+2)\nαk = σ\u000f(k+2)\n, we can\n4\n2\n3\nensure the error εk is nonpositive.\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n47\n\nStrongly Convex Functions Define f = f1 + f2 and assume f2 is μ-strongly convex and\nf1 is convex. For the dynamics\nd βt\ne\nd\ndt\nXt = βt (Zt − Xt )\ndt\ne\nd βt\ne\nd\n∇h(Zt ) = dt βt (∇h(Xt ) − ∇h(Zt ) − (1/μ)(∇f2 (Xt ) + ∇f1 (Zt ))) ,\ndt\ne\n\n(2.82a)\n(2.82b)\n\nthe same function (2.16),\nEt = eβt (μDh (x∗ , Zt ) + f (Xt ) − f (x∗ )),\nis a Lyapunov function.\nWe check,\nd\nd\nEt = (μDh (x∗ , Zt ) + f (Xt ) − f (x∗ )) eβt − μeβt\ndt\ndt\n\n\nd\n∇h(Zt ), x∗ − Zt\ndt\n\n\n+ e βt\n\nd\nf (Xt )\ndt\n\n(2.82b)\n\n= (−Df1 (x∗ , Zt ) − Df2 (x∗ , Xt ) + μDh (x∗ , Zt ) − μh∇h(Xt ) − ∇h(Zt ), x∗ − Zt i)\n\nd βt\ne\ndt\n\nd βt\ne + eβt h∇f (Xt ), Ẋi\ndt\nd\n(A.27)\n= (−Df1 (x∗ , Zt ) − Df2 (x∗ , Xt ) + μDh (x∗ , Xt ) − μDh (Zt , Xt )) eβt\ndt\nd βt\n(h∇f2 (Xt ), Xt − Zt i + f1 (Xt ) − f1 (Zt )) e + eβt h∇f (Xt ), Ẋi\ndt\n(2.82a)\nd\n≤ (−Df2 (x∗ , Zt ) − Df1 (x∗ , Xt ) + μDh (x∗ , Xt )) eβt ≤ 0.\ndt\n+ (h∇f2 (Xt ), Xt − Zt i + f1 (Xt ) − f1 (Zt ))\n\nHere, the first equality uses the Bregman three-point identity (A.27). The first inequality\nfollows from the convexity of f1 . The last inequality follows from using the strong convexity\nof f2 .\nAccelerated Proximal Gradient Descent We analyze the setting h(x) = 12 kxk2 . To\ndiscretize the dynamics (2.82b), we split the vector field (2.82b) into two components –\nd\n\nd\n\neβt\n\neβt\n\nv1 (x, z, t) = dteβt (∇h(Xt ) − ∇h(Zt ) − (1/μ)∇f2 (Xt )) and v2 (x, z, t) = − dtμeβt ∇f1 (Zt ) and\napply the forward-Euler scheme to v2 (x, z, t) and the backward-Euler scheme to v1 (x, z, t),\nd\n\neβt\n\n−Ak\nwith the same identification, dteβt = Ak+1\n= τk for both vector fields.3 This results in the\nδAk+1\n3\n\nWhile using the same identification of β̇t for both vector fields is problematic – since one is being\nevaluated forward in time and the other backward in time – the error bounds only scale sensibly in the\n√\nsetting where β̇t ≤ μ is a constant.\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n48\n\nalgorithm,\n\u001a\n\n\u001b\nμ\n2\nzk+1 = arg min f1 (z) + h∇f2 (xk ), zi +\n(2.83a)\nkz − (1 − δτk )zk − δτk xk k\nz\n2δτk\nyk+1 = G(x)\n(2.83b)\nxk+1 − yk+1\n= τk+1 (zk+1 − xk+1 ),\n(2.83c)\nδ\n\u0010\n\u0011\nwhich satisfies the variational condition zk+1δ−zk = τk xk − zk − μ1 ∇f2 (xk ) − μ1 g(zk+1 ) , where\ng(x) ∈ ∂f1 (x). We can combine this update with the backward-Euler method applied\nto (2.82a), where we have replaced the iterate xk with an iterate yk+1 , just as in the AGD\nsetting. Using the Lyapunov function\n\u0010μ\n\u0011\n∗\n2\n∗\nkx − zk k + f (yk ) − f (x )\nEk+1 = Ak\n2\nwe check,\n\n\n\u0011A\nEk+1 − Ek \u0010 μ ∗\nzk+1 − zk ∗\nk+1 − Ak\n2\n∗\n=\nkx − zk k + f (xk ) − f (x )\n− μAk+1\n, x − zk+1\nδ\n2\nδ\nδ\nf (yk+1 ) − f (yk )\n+ Ak+1\n+ ε1k\nδ\nAk+1 − Ak\nμ\n= (−DfG1 (x∗ , zk+1 ) − Df2 (x∗ , xk ) + kx∗ − zk k2 − μhxk − zk , x∗ − zk i)\n2\nδ\nAk+1 − Ak\n+ (h∇f2 (xk ), xk − zk+1 i + f1 (yk ) − f1 (zk+1 )) + f2 (yk ) − f2 (xk ))\nδ\nf (yk+1 ) − f (yk )\n+ Ak+1\n+ ε2k\nδ\n\u0010\n\u0011\nμ ∗\nμ\n(A.27)\nG\n∗\n∗\n2\n2 Ak+1 − Ak\n= −Df1 (x , zk+1 ) − Df2 (x , xk ) + kx − xk k − kxk − zk k\n2\n2\nδ\nAk+1 − Ak\n+ (h∇f2 (xk ), xk − zk i + f1 (yk ) − f1 (zk+1 )) + f2 (yk ) − f2 (xk ))\nδ\nf (yk+1 ) − f (yk )\n+ Ak+1\n+ ε2k\nδ\nμ\nAk+1 − Ak\n= (−Df2 (x∗ , zk+1 ) − Df1 (x∗ , xk ) + kx∗ − xk k2 )\n+ ε3k .\n2\nδ\nHere, the errors scale as ε1k = −δAk+1 μ2 k zk+1δ−zk k2 , ε2k = ε1k + μαk hxk − zk , zk − zk+1 i, and ε3k =\nε2k +αk (h∇f2 (xk ), xk −zk+1 i+f1 (yk )−f1 (zk+1 )+f2 (yk )−f2 (xk ))+Ak+1 f (yk+1 δ)−f (yk ) . Using the\nconvexity of f1 , we conclude Ak+1 f1 (yk+1 )−Ak f1 (yk )+αk f1 (zk+1 ) ≤ 0. Using the strong convexity and smoothness of f2 , we upper-bound the error by ε3k ≤ ε2k +αk (h∇f2 (xk ), xk −zk+1 i+\nμ\nk+1 1\nf2 (yk )−f2 (xk ))+Ak+1 h∇f2 (xk ), yk −yδ k+1 i+ A2\u000f\nkxk −yk+1 k2 − Ak+1\nkxk −yk k2 . Take yk+1 =\nδ\n2δ\nG(x) = δτk zk+1 + (1 − δτk )yk . With this choice, Ak+1 h∇f2 (xk ), yk −yδ k+1 i = αk h∇f2 (xk ), zk+1 −\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n49\n\nyk i. Plugging this in the error, we have ε3k ≤ ε2k + αk (f2 (yk ) − f2 (xk ) + h∇f2 (xk ), xk − yk i) +\nδAk+1 xk −yk+1 2\nμ xk −yk 2\nk δ k − δ Ak+1\nk δ k . Using convexity, of f2 , we have the final error bound\n2\u000f\n2\nμ xk −yk 2\nμ zk+1 −zk 2\nk+1 xk −yk+1 2\n3\nεk ≤ −δAk+1 2 k δ k + μαk hxk − zk , zk − zk+1 i + δ A2\u000f\nk δ k − δ Ak+1\nk δ k . The\n2\nzk −zk+1\nfinal step involves using the identity xk − yk+1 = δτk (τk (xk − zk ) − ( δ )). This allows\nus to upper bound the error by ε3k ≤ −δ(Ak+1 μ2 k zk+1δ−zk k2 + μAk+1 hτk (xk − zk ), zk −zδ k+1 i +\n√\n√\nAk+1 τk2 δ 2\nμ\nkτk (xk − zk ) − (zk − zk+1 )k2 − Ak+1\nkτk (xk − zk )k2 ). Taking δ = \u000f and τk = μ,\n2\u000f\n2\nwe can check the error ε3k is non-positive by completing the square.\n\n2.3\n\nSummary\n\nThe connection between algorithms and dynamical systems bring immense structure to the\ntechniques used to obtain upper bound in optimization; indeed, it has been the primary\ninspiration to a growing number of works in optimization [13, 74, 52] which propose new\ntechniques. We provide a few examples of other places where we think it can be used below,\nas well as summarize the Lyapunov functions we have presented in Table 2.11.\n\n2.3.1\n\nAdditional Lyapunov Arguments\n\nThere are several other methods which fit into this framework that we did not discuss. We\nprovide a high-level summary of some examples, leaving details to the Appendix, or as future\nwork.\n• Conjugate Gradient Method: In [24], Karimi and Vavasis showed that the Lyapunov function (2.63) can be used to analyze the conjugate gradient method (CG). In\nfuture work, if possible, it would be interesting to develop a dynamcial perspective for\nCG.\n• Adagrad with Momentum: The Lyapunov framework described in this thesis can\nbe applied to obtain new analyses of adaptive methods, such as Adagrad [16]. Let\nαk = Ak+1δ−Ak and g(x) ∈ ∂f (x) be an element of the subdifferential of f at x. Adagrad,\nxk+1 − xk\n= −αk Hk−1 g(xk ),\nδ\ncan be analyzed using the Lyapunov function,\nk−1\nX\n1 ∗\nAs+1 − As\n2\nEk = kx − xk kHk +\n(f (xs ) − f (x∗ ))\nδ.\n2\nδ\ns=0\n\nHere, kxk2Hk = hx, Hk xi, 0 ≺ H0 , and 0 \u0016 Hk+1δ−Hk .4 From the Lyapunov property, we\n√\nobtain the upper bound f (x̂k ) − f (x∗ ) ≤ O(1/ k). A natural way to add momentum\n4\n\nTypically, we choose Hk =\n\n\u0010P\n\n\u00111/2\n\nk\ni=1 g(xi ) ◦ g(xi )\n\ndenotes the entrywise Hadamard product.\n\nor Hk = diag\n\n\u0012\u0010\nP\n\n\u00111/2 \u0013\n, where “◦”\n\nk\ni=1 g(xi ) ◦ g(xi )\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n50\n\nEt = τt (f (Xt ) − f (x∗ ))\n\nEk = Ak (f (xk ) − f (x∗ ))\n\nDynamic\n\nAlgorithm\n\nProblem Class\n\nGradient Flow\n\nGradient Descent\n\nf is differentiable, (1/δ)-smooth, τt = e2μt\nf satisfies PL condition with parameter μ\n\nFrank Wolfe\n\nFrank Wolfe\n\nf is (1/δ)-smooth\nX ⊆ Rd is a convex and compact\n\nEt = τt Dh (x∗ , Xt )\n\nEk = Ak Dh (x∗ , xk )\n\nDynamic\n\nAlgorithm\n\nProblem Class\n\nMirror Descent Dynamic\n\nMirror Descent\n\nf is (1/δ)-smooth\n\nGradient Descent Dynamic\n∗\n\nGradient Descent\n∗\n\n∗\n\nf is (1/δ)-smooth\n∗\n\nEt = Dh (x , Xt ) + τt (f (Xk ) − f (x ))\n\nEk = Dh (x , xk ) + Ak (f (xk ) − f (x ))\n\nDynamic\n\nAlgorithm\n\nProblem Class\n\nMirror Descent Dynamic\nRt\nEt = γt Dh (x∗ , Xt ) + c 0 (f (Xs ) − f (x∗ ))dτs\n\nMirror Descent\nP\n∗ As+1 −As\n∗\nδ\nEk = γk Dh (x , xk ) + c k−1\ns=0 (f (xs ) − f (x ))\nδ\n\nf is (1/δ)-smooth\nτt = t, Ak = δk\n\nDynamic\n\nAlgorithm\n\nProblem Class\n\nMirror Descent Dynamic\n\nMirror Descent ,Mirror Prox\n\nf is Lipschitz, γt ≡ γk ≡ 1, c = 1\n\nMirror Descent Dynamic\n\nMirror Descent\n\nf is Lipschitz, μ-strongly convex\n1\nγt ≡ τt , γk = Ak , c = μ\n\nDual Averaging Dynamic\n\nDual Averaging Algorithm\n\nf is Lipschitz, c = 1\n\nEt = γt Dh (x∗ , Zt ) + τt (f (Xt ) − f (x∗ ))\n\nEk = γk Dh (x∗ , zk ) + Ak (f (xk ) − f (x∗ ))\n\nDynamic\n\nAlgorithm\n\nProblem Class\n\nAccelerated Gradient Descent Dynamic\n\nAccelerated Gradient descent/Mirror Prox\n\nf is (1/δ)-smooth, γt ≡ γk ≡ 1\n\nQuasi-monotone Subgradient Dynamic\n\nQuasi-monotone subgradient descent\n\nf is Lipschitz, γt ≡ γk ≡ 1\n\nDual Averaging with Momentum Dynamic\n\nDual Averaging with Momentum Dynamic\n\nf is Lipschitz\n\nEt = τt (μDh (x∗ , Zt ) + f (Xt ) − f (x∗ ))\n\nEk = Ak (μDh (x∗ , zk ) + f (xk ) − f (x∗ ))\n\nDynamic\n\nAlgorithm\n\nProblem Class\n\nAccelerated Gradient Descent Dynamic\n\nAccelerated Gradient descent\n\nf is (1/δ)-smooth\nf is μ-strongly convex\n\nAccelerated Proximal Dynamic\n\nAccelerated Proximal descent\n\nf is (1/δ)-smooth\nf is μ-strongly convex\n\nTable 2.11: List of Lyapunov Arguments in Optimization presented in this thesis (so far).\n\nto Adagrad is via the following averaging step\nxk+1 − xk\n= τk (zk − xk+1 )\nδ\nzk+1 − zk\n= −αk Hk−1 g(xk+1 ),\nδ\n\n(2.84a)\n(2.84b)\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n51\n\n−Ak\n. Using the Lyapunov framework, we can analyze algowhere τk = Aαkk = Ak+1\nδAk\nrithm (2.84) using the function\n\n1\nEk = kx∗ − zk k2Hk + Ak (f (xk ) − f (x∗ )).\n(2.85)\n2\nA demonstration of this result can be found√Appendix B.7.4. This analysis allows us to\nconclude the bound f (xk ) − f (x∗ ) ≤ O(1/ k) for (2.84), which has a matching lower\nbound. Such a algorithm might be useful if we do not care about the regret, but the.\n• Geodesically Convex Functions Geodesic spaces are metric spaces (X , d) where\nthere is a path, called a geodesic, connecting every two points x, y ∈ X . Geodesic\n(strong) convexity generalizes the idea of (strong) convexity to functions defined on\nthese more general spaces. The length of the paths between two points x, y is equivalent\nto the geodesic distance between them d(x, y) up to a small precision parameter \u000f.\nZhang and Sra [79] showed that if X is an Alexandrov space (has sectional curvature\nbounded from below), then there is a natural generalization of the Bregman three-point\nidentity (A.27) to geodesic spaces. In particular, for any xk+1 , xk , x ∈ X , we have\n\n\nζ(κ, d(xk , x))\n1\nd(x, xk+1 ) − d(x, xk )\n=\nlogxk (xk+1 ), logxs (x) +\nk logxk (xk+1 )k2\nδ\nδ\n2δ\nwhere log = exp−1 : X → Tx X is the inverse of the exponential map and ζ(κ, d(xk , x)) >\n0 is a curvature dependent quantity [79, Cor. 8]. Subsequently, it is easy to check that\nEk = d(x∗ , xk ) + δk(f (xk ) − f (x∗ ))\nis a Lyapunov function for gradient descent 1δ logxk (xk+1 ) = −gk when f is a (1/δ)geodesically smooth function and gk is the gradient of f at xk . In fact, the results\ncontained in Tables 2.1 and 2.3 can be adapted to this more general setting. Recently,\nthere has been some work extending the idea of averaging to geodesic spaces [34]. We\nbelieve the Lyapunov framework provides a systematic way to extend several families\nof second-order algorithms to this more general setting.\n• Higher-order gradient methods In [76], a Lyapunov analysis of higher-order gradient methods,\n\u001b\n\u001a\nN\np̃\n(2.86)\nxk+1 = G\u000f,p,ν,N (xk ) = arg min fp−1 (xk ; y) + kxk − yk ,\ny∈X\n\u000fp̃\nwas also presented, where p̃ = p − 1 + ν, N > 1, p ≥ 3 and fp−1 (x; y) is given by (A.1).\n, ν)-Hölder smooth (A.15), the function\nIf the p-th order derivatives of (2.86) are ( (p−1)\nδ\n1\n∗ − p̃−1\np̃−1\nEk = (f (xk ) − f (x ))\nprovides a O(1/δk ). Its continuous time limit,\n\u001a\n\u001b\n1\n∇f (Xt )\np̃\nẊt = arg min h∇f (Xt ), vi + kvk = −\n(2.87)\np̃−2\nv\np̃\np̃−1\nk∇f (Xt )k∗\n\nCHAPTER 2. DETERMINISTIC DYNAMICAL SYSTEMS\n\n52\n1\n\ncan be analyzed using the same function Et = (f (Xt )−f (x∗ ))− p̃−1 , to obtain a matching\nconvergence rate O(tp̃−1 ). It would be interesting to analyze the rescaled gradient\nflow (2.87) in other settings as well.\n• Newton’s method Newton’s method is one of the most widely used and studied\nalgorithms in optimization. It would be interesting , if possible, to develop a dynamical\nperspective on the analysis of this family of algorithms as well. For example, it is wellknown that the function\n1\nEt = k∇f (Xt )k2\n2\nis a Lypaunov function for the Newton dynamics Ẋt = −∇2 f (Xt )−1 ∇f (Xt ). Developing a dynamical perspective of the analysis of Newton’s method, if possible, would be\na potentially interesting avenue of future work.\nNext, we demonstrate how this Lyapunov framework for dynamical perspective can be extended to stochastic differential equations and stochastic algorithms, including stochastic\ngradient descent, stochastic gradient descent with momentum, stochastic dual averaging,\nand stochastic dual averaging with momentum.\n\n53\n\nChapter 3\nStochastic Differential Equations\nIn this chapter, we focus on optimization problems (1.1) where the objective function is of\nthe form, f (x)+σ(x). Here σ(x) ∼ P represents some zero mean noise process EP [σ(x)] = 0.\nMany machine learning and statistical problems are posed as stochastic optimization problems. The algorithms we discuss to solve these problems have access to oracle functions that\nprovide it with stochastic gradients or stochastic subgradients. All of them are simple, and\nscale well, requiring little memory. In Section 3.1 we focus on algorithms that discretize firstorder stochastic differential equations. In Section 3.2, we turn our attention to algorithms\nthat discretize second-order stochastic differential equations. We end the chapter with a discussion of coordinate methods, demonstrating in the work Breaking locality accelerates Block\nGauss-Seidal [73] how the Lyapunov framework can be helpful for deriving novel algorithms.\n\n3.1\n\nFirst-order Stochastic Differential Equations\n\nThe first-order stochastic differential equations that model mirror descent have been studied\nby many [59] and [37]. In this section we summarize and add to these works. In particular,\nwe emphasize the Lyapunov analysis of several families of stochastic differential equations\nand several stochastic discrete time algorithms, and demonstrate how to move between these\narguments.\nStochastic Dual Averaging Dynamics The stochastic dual averaging dynamics (2.29)\nis given by the following Ito stochastic differential equations (SDE) [51]\ndYt = −(∇f (Xt )dt + σt dBt )τ̇t ,\nXt = ∇h∗ (Yt /γt ),\n\n(3.1a)\n(3.1b)\n\nwhere the diffusion term σt := σ(x, t) is bounded, kσt k2F ≤ G2 , ∀x ∈ X , t ≥ 0, and Bt ∈ Rd\nis a standard Brownian motion. In particular, [37, Lemma A.4] implicitly showed that (2.23)\nZ t\n∗\nEt = γt Dh∗ (Yt /γt , ∇h(x )) +\n(f (Xs ) − f (x∗ ))dτs .\n(3.2)\n0\n\nCHAPTER 3. STOCHASTIC DIFFERENTIAL EQUATIONS\n\n54\n\nStochastic MD Dynamics:\n\ndYt = −τ̇t (∇f (Xt )dt + σ(Xt , t)dBt )\n\nXt = ∇h∗ (Yt )\n\nFunction Class\n\nLyapunov Function\nRt\nEt = Dh (x∗ , Xt ) + 0 (f (Xs ) − f (x∗ ))dτs\n\nConvergence Rate\n\nμ-Strong Convexity\n\nEt = eμτt Dh (x∗ , Xt )\nRt\nEt = eμτt Dh (x∗ , Xt ) + μ1 0 (f (Xs ) − f (x∗ ))deμτs\n\nR\nE0 + 0t ε1s ds\nτt\nR\nE0 + 0t εs2 ds\n∗\nE[Dh (x , Xt )] ≤ eμτt\nR\nμE +μ t ε2\nE[f (X̂t )] − f (x∗ ) ≤ 0 eμτt 0 s\n\nMirror Subgradient Method:\n\nyk+1 −yk\n= −αk (∇f (xk ) + σ(xk ))\nδ\n\nxk = ∇h∗ (yk ), g(xk ) ∈ ∂f (xk )\n\nFunction Class\n\nConvergence Rate\n\nf is Lipschitz; h σ-strongly convex\n\nConvex\n\nLyapunov Function\nP\n∗ As+1 −As\nEk = Dh (x , xk ) + k−1\nδ\ns=0 (f (xs ) − f (x ))\nδ\n\nE[f (x̂k )] − f (x∗ ) ≤\n\nμ-Strong Convexity\n\nEk = Ak Dh (x∗ , xk )\n\nE[Dh (x∗ , xk )] ≤\n\nConvex\n\nE[f (X̂t )] − f (x∗ ) ≤\n\n∗\n\nf is Lipschitz; h σ-strongly convex\n\nEk = Ak Dh (x∗ xk ) + μ1\n\n∗ As+1 −As\nδ\ns=0 (f (xs ) − f (x ))\nδ\n\nPk−1\n\nE[f (x̂k )] − f (x∗ ) ≤\n\nE0 +δ\n\nPk\n\n3\ns=0 εs\n\nAk\n\nE0 +δ\n\nPk\n\n4\ns=0 εs\n\nAk\nP\nμE0 +μδ ks=0 ε4s\nAk\n\nStochastic DA Dynamics:\n\ndYt = −τ̇t (∇f (Xt )dt + σ(Xt , t)dBt )\n\nXt = ∇h∗ (Yt /γt )\n\nFunction Class\n\nConvergence Rate\n\nConvex\n\nLyapunov Function\nRt\nEt = γt Dh (x∗ , Xt ) + 0 (f (Xs ) − f (x∗ ))dτs\n\nStochastic DA Algorithm:\n\nyk+1 −yk\n= − Ak+1δ−Ak (∇f (xk ) + σ(xk ))\nδ\n\nxk = ∇h∗ (yk /γk )\n\nFunction Class\n\nLyapunov Function\nP\n∗ As+1 −As\nEk = γk Dh (x , xk ) + k−1\nδ\ns=0 (f (xs ) − f (x ))\nδ\n\nConvergence Rate\n\nE[f (X̂t )] − f (x∗ ) ≤\n\n∗\n\nConvex\n\nE[f (X̂t )] − f (x∗ ) ≤\n\nR\nE0 +γt Dh (x∗ ,X0 )+ 0t ε5s ds\nτt\n\nE0 +γk Dh (x∗ ,x0 )+δ\nAk\n\nPk−1\n\n6\ns=0 εs\n\nTable 3.1: Lyapunov functions for stochastic mirror descent dynamics and algorithm\nand stochastic dual averaging dynamics and algorithm. Assume σ \u0016 ∇2 h and E[σt ] ≤\nG, E[kg(x)k∗ ] ≤ G ∀x ∈ X and t ∈ R+ . When f is convex, αk = Ak+1δ−Ak and\n( d eμτt |\n\n)2\n\n1\n1\nk+1 −Ak\nwhen f is strongly convex αk = AδμA\n,\n. Here, ε1s = 2σ\nG2 τ̇s2 , ε2s = 2σ\nG2 dt2μ2 eμτt=s\ns\nk+1\n2\n\n2\n\n2\n\n2\n\n−As )\n1\n1\n1\n1\ns)\ns+1 −As )\nε3s = δ 2σ\nG2 (As−1δ−A\n, ε4s = δ 2σ\nG2 (A\nG2 τ̇γss and ε6s = δ 2σ\nG2 (As+1\n, ε5s = 2σ\n. The\n2\nδ 2 2μ2 As+1\nδ 2 γs\nscalings on the error and Ito correction terms match.\n\nis a Lyapunov function, where dτt = τ̇t dt. Take X0 to be the prox center of h. Denote Z̃t = Yt /γt so that Xt = ∇h∗ (Z̃t ). Using Ito’s formula, on the first component\nẼt = γt Dh∗ (Z̃t , ∇h(x∗ )) we check,\ndẼt =\n\n∂ Ẽt\nτ̇ 2\n∂ Ẽt\ndt +\ndZ̃t + t tr(σt> ∇2 h∗ (Z̃t )σt )dt,\n∂t\n2γt\n∂ Z̃t\n\nτ̇t2\n= γ̇t D (Z̃t , ∇h(x )) + γt h∇h (Z̃t ) − x , dZ̃t i +\ntr(σt> ∇2 h∗ (Z̃t )σt )dt\n2γt\nτ̇t2\n∗\n∗\n∗\n∗\n= γ̇t Dh (x , ∇h (Z̃t )) + γt h∇h (Z̃t ) − x , dZ̃t i +\ntr(σt> ∇2 h∗ (Z̃t )σt )dt.\n2γt\nh∗\n\n∗\n\n∗\n\n∗\n\nCHAPTER 3. STOCHASTIC DIFFERENTIAL EQUATIONS\n\n55\n\nWith the identity γt dZ̃t = dYt − γ̇t Z̃t dt, we proceed,\nτ̇t2\ndẼt = γ̇t (h(x ) − h(∇h (Z̃t )))dt + h∇h (Z̃t ) − x , dYt i +\ntr(σt> ∇2 h∗ (Z̃t )σt )dt,\n2γt\n∗\n\n∗\n\n∗\n\n∗\n\n(3.1b)\n(3.1a)\n\n= γ̇t (h(x∗ ) − h(∇h∗ (Z̃t ))dt + τ̇t hx∗ − Xt , ∇f (Xt )dt + σt dBt i\nτ̇t2\n+\ntr(σt> ∇2 h∗ (Z̃t )σt )dt,\n2γt\n\n≤ −τ̇t (f (Xt ) − f (x∗ ))dt + τ̇t hσt dBt , x∗ − Xt i + γ̇t Dh (x∗ , X0 )dt +\n\nτ̇t2\ntr(σt> ∇2 h∗ (Z̃t )σt )dt.\n2γt\n\nHere, the inequality follows using the convexity of f and non-negativity of h. The last\nline uses the prox-center identity γ̇t h(xR∗ ) = γ̇t Dh (x∗ , X0 ). Integrating, we obtainRthe bound,\ns\nt\nDefine the time averaged iterate X̂t = 0 Xs dτs /τt . Applying Jensen’s τt f (X̂t ) ≤ 0 f (Xs )dτs\nTaking the expectation and integrating the last line, we obtain the following convergence\nbound,\n∗\n\nE[f (X̂t )] − f (x ) ≤\n\nR t τ̇s2\ntr(σs> ∇2 h∗ (Z̃t )σs )ds]\nẼ0 + γt Dh (x∗ , X0 ) + E[ 0 2γ\ns\nτt\n\n,\n\n(3.3)\n\non the time averaged iterate. Assume\n∇2 h∗ \u0016 σ −1 I, or equivalently σI \u0016 ∇h2 and kσt kF ≤\n√\n1\nq\nGt ∀x ∈ X , t ∈ R. Take γt = t and τt = t. Then the bound (3.3) implies an O(t− 2 +2q )\n1\nconvergence rate. In particular, if q = 0 (i.e. the noise is not growing), we obtain a O(t− 2 )\nconvergence rate.\nStochastic Dual Averaging The variational condition for the stochastic variant of the\ndual averaging algorithm (2.31) is given by,\nyk+1 − yk\nAk+1 − Ak\n=−\n(∇f (xk ) + σ(xk )),\nδ\nδ\nyk = γk ∇h(xk ),\n\n(3.4a)\n(3.4b)\n\nwhere E[σ(x)] = 0. Typically, we write g(x) = ∇f (x) + σ(x), so that E[g(x)] = ∇f (x). We\ncan analyze this algorithm using the Lyapunov function\nEk = γk Dh (x∗ , xk ) +\n\nk−1\nX\ns=0\n\n(f (xs ) − f (x∗ ))\n\nAs+1 − As\nδ.\nδ\n\nCHAPTER 3. STOCHASTIC DIFFERENTIAL EQUATIONS\n\n56\n\nNote the identity Dh (x∗ , xk ) = Dh∗ (∇h(xk ), ∇h(x∗ )), which follows from (A.29). We check,\n\n\nEk+1 − Ek\nγk+1 − γk\n∇h(xk+1 ) − ∇h(xk ) ∗\n∗\n= Dh (x , xk+1 )\n− γk\n, x − xk\nδ\nδ\nδ\n+ αk (f (xk ) − f (x∗ )) + ε1k\n\n\nyk+1 − yk ∗\nγk+1 − γk\n∗\n−\n, x − xk + αk (f (xk ) − f (x∗ )) + ε2k\n= (h(x ) − h(xk+1 ))\nδ\nδ\nγk+1 − γk\n(3.4a)\n= −αk Df (x∗ , xk ) +\n(h(x∗ ) − h(xk+1 )) + αk hσ(xk ), x∗ − xk i + ε2k\nδ\nγk+1 − γk\n≤\nDh (x∗ , x0 ) + αk hσ(xk ), x∗ − xk i + ε2k .\nδ\nHere, the errors scale as ε1k = − γδk Dh (xk+1 , xk ), and ε2k = αk h∇f (xk ) + σ(xk ), xk − xk+1 i −\nγk\nDh (xk+1 , xk ). The final upper bound follows from noting −Df (x∗ , xk ) ≤ 0 and using the\nδ\ndefinition of the prox-center. Denote g(x) = ∇f (x) + σ(x) and assume E[kg(x)k2∗ ] ≤ G2 for\nall x ∈ X and some constant G. Using the σ-strong convexity of h, we can use Young’s\nPk\nα2k δ\n3\ninequality to upper bound the error E[ε2k ] ≤ 2σγ\nG\n:=\nε\n.\nDenote\nx̂\n=\nδ\nk\nk\ns=0 xs αs /Ak\nk\nPk\nas the time-average iterate and note that the inequality Ak f (x̂k ) ≤ δ s=0 f (xs )αs follows\nfrom Jensen’s (A.4). By summing the Lyapunov function and taking the expectation, we\n∗\n∗\n∗\nobtain\nPk the 3statement, Ak (E[f (x̂k )] − f (x )) ≤ E[Ek ] ≤ E0 + γk Dh (x , x0 ) − γ0 Dh (x , x0 ) +\nδ s=0 E[εi ], from which we obtain the convergence bound,\n∗\n\nE[f (x̂k )] − f (x ) ≤\n\n1\nE0 + γk Dh (x∗ , x0 ) + δ 2 2σ\n\nAk\n\nα2s 2\ns=0 γs G\n\nPk\n\n.\n\nIf we take If √\nwe assume with out loss\n√ of generality σ = δ = 1, and choose Ak = k and\nG2\nγk = Dh (x∗ ,x0 ) k + 1, we obtain O(1/ k) convergence rate [44, (2.15)].\n\n3.1.1\n\nStochastic Mirror Descent\n\nThe mirror descent dynamics is given by the following Ito stochastic differential equations\n(SDE) [51] ,\ndYt = −τ̇t (∇f (Xt )dt + σt dBt ),\nXt = ∇h∗ (Yt ).\n\n(3.5a)\n(3.5b)\n\nWe recognize\nit as the dual averaging dynamics with γt ≡ 1. In the bound (3.3), if we take\n√\n1\nτt = t, we obtain a matching O(t 2 −2q ) convergence rate in the setting when f is convex.\nNow, we will study the dynamics (3.5) in the setting when f is μ-strongly convex.\n\nCHAPTER 3. STOCHASTIC DIFFERENTIAL EQUATIONS\n\n3.1.2\n\n57\n\nStrongly convex functions\n\nWhen f is μ-strongly convex with respect to h (A.7), [37] implicitly showed that the Lyapunov function,\nEt = eμτt Dh∗ (Yt , ∇h(x∗ )),\ncan be used to provide a convergence rate for (3.5). Using Ito’s formula, we check,\n∂Et\nτ̇ 2 eμτt\n∂Et\ndt +\ndYt + t\ntr(σt> ∇2 h∗ (Yt )σt )dt,\n∂t\n∂Yt\n2\n= τ̇t eμτt (μDh∗ (Yt , ∇h(x∗ ))dt − h∇h∗ (Yt ) − x∗ , ∇f (Xt )dt + σt dBt i)\nτ̇t2 eμτt\n+\ntr(σt> ∇2 h∗ (Yt )σt )dt\n2\n= τ̇t eμτt (μDh (x∗ , Xt )dt + h∇f (Xt ), x∗ − Xt idt + hσt dBt , x∗ − Xt i)\nτ̇t2 eμτt\n+\ntr(σt> ∇2 h∗ (Yt )σt )dt\n2\nτ̇ 2 eμτt\ntr(σt> ∇2 h∗ (Yt )σt )dt.\n≤ −τ̇t eμτt ((f (Xt ) − f (x∗ ))dt + hσt dBt , x∗ − Xt i) + t\n2\n\ndEt =\n\nThe last line follows from the strong convexity assumption. By integrating and taking the\nexpectation, we have the bound,\nR t 2 μτs\nE0 + E[ 0 τ̇s e2 tr(σs> ∇2 h∗ (Ys )σs )ds]\nE[Dh∗ (Yt , ∇h(x ))] ≤\neμτt\n∗\n\nWe can also infer the inequality,\n\u0014Z t\n\u0015\n\u0014Z t 2 μτs\n\u0015\n1\nτ̇s e\n∗\nμτs\n> 2 ∗\n(f (Xs ) − f (x ))de\nE\n+ E[Et ] − E0 − E\ntr(σs ∇ h (Ys )σs )ds ≤ 0, (3.6)\nμ\n2\n0\n0\nRt\nfrom the argument. Define the average iterate X̂t = 0 Xs deμτs /eμτt . Using Jensen’s, we\nRt\nhave the inequality eμτt f (X̂t ) ≤ 0 f (Xs )deμτs . Taking the expectation of (3.6), we obtain a\nconvergence bound on the expectation of the optimality gap,\nR t ( dtd eμτt |t=s )2\n\n∗\n\nE[f (X̂t )] − f (x ) ≤\n\nμE0 + 0\n\n2eμτt μ\n\ntr(σs> ∇2 h∗ (Ys )σs )ds\n\neμτt\n\n,\n\n(3.7)\n\nevaluated at the time averaged iterate. Assume ∇2 h∗ \u0016 σ −1 I (i.e that h is σ-strongly\nconvex), and E[kσt k2F ] ≤ Gt2q . Take τt = tp . Then the bound (3.7) implies an O(tp−3+2q )\nrate of convergence. In particular, if p = 2, and q = 0, we obtain a O(t−1 ) rate of convergence.\n\nCHAPTER 3. STOCHASTIC DIFFERENTIAL EQUATIONS\n\n58\nd\n\neμτt\n\nk+1 −Ak\n≈ dtμeμτt . The variational\nStochastic Mirror Descent Algorithm Let τ̇t ≈ αk = AδμA\nk+1\ncondition for the stochastic mirror descent algorithm given by\n\n∇h(xk+1 ) − ∇h(xk )\n= −αk (∇f (xk ) + σ(xk )),\nδ\n\n(3.8)\n\nwhere E[σ(x)] = 0. We can analyze (3.8) using the Lyapunov function,\nEk = Ak Dh (x∗ , xk ).\nWe check,\nEk+1 − Ek\nAk+1 − Ak\nDh (x∗ , xk+1 ) − Dh (x∗ , xk )\n= Dh (x∗ , xk )\n+ Ak+1\nδ\nδ\nδ\n\n\n∇h(x\n)\n−\n∇h(xk ) ∗\nk+1\n∗\n, x − xk + ε1k\n= Ak+1 αk μDh (x , xk ) − Ak+1\nδ\n(3.8)\n\n= Ak+1 αk (μDh (x∗ , xk ) + h∇f (xk ) + σ(xk ), x∗ − xk i) + ε1k\n≤ −Ak+1 αk (f (xk ) − f (x∗ )) + Ak+1 αk hx∗ − xk , σ(xk )i + ε1k ≤ ε1k\nwhere the first error scales as εk = Ak+1 (αk h∇f (xk ) + σ(xk ), xk − xk+1 i − 1δ Dh (xk+1 , xk ).\nThe upper bound follows from using the strong convexity of f with respect to h. Denote\ng(x) = ∇f (x). − σ(x). We can upper bound the final error using the σ strong convexity of\n2\nk+1 −Ak )\nkg(x)k2∗ . If we assume E[kg(x)k2∗ ] ≤\nh as well as Young’s inequality (A.25): εk ≤ (A\n2μ2 σδAk+1\nG2 ∀x ∈ X , then by summing and taking the expectation, we obtain the convergence bound\nPk (As+1 −As )2 2\n1\nE0 + δ 2σ\ns=0 μ2 δAs+1 G\n∗\nE[Dh (x , xk )] ≤\n.\nAk\nWe can also infer,\n\" k−1\n#\n\" k\n#\nX\nX (As+1 − As )2\n1\nA\n−\nA\n1\ns+1\ns\nE\n(f (xs ) − f (x∗ ))\nδ + E[Ek ] − E0 − δ E\nG2 ≤ 0.\n2 δA\nμ\nδ\n2σ\nμ\nk+1\ns=0\ns=0\n(3.9)\nP\nDefine the time-average iterate xk = δ ks=0 xs (As+1 − As )/Ak δ. Using Jensen’s we have\nP\nthe inequality Ak f (x̂k ) ≤ ts=0 f (xs ) As+1δ−As δ. Taking the expectation of (3.9), we obtain a\nconvergence bound on the expectation of the optimality gap,\nPk (As+1 −As )2 2\n1\nμE\nG\n0 + δ 2σ\ns=0\nμδAs+1\nE[f (x̂k )] − f (x∗ ) ≤\n,\nAk\nevaluated at the time aver iterate. The same parameter choices, Ak = (k + 1)k so that\n2\nαk = δμ(k+2)\nresults in an O(1/k) convergence rate.\n\nCHAPTER 3. STOCHASTIC DIFFERENTIAL EQUATIONS\ndXt = τ̇τtt (∇h∗ (Yt /γt ) − Xt )dt\n\ndYt = −τ̇t (∇f (Xt )dt + σ(Xt , t)dBt )\n\nSAMD Dynamic 1:\n\n59\n\nYt /γt = ∇h(Zt )\nFunction Class\n\nLyapunov Function\n\nConvex\n\nEt = Dh∗ (Yt /γt , ∇h(x∗ )) + τt (f (Xt ) − f (x∗ ))\n\nSAMD Algorithm 1:\n\nyk+1 −yk\n= −αk (∇f (xk ) + σ(xk ))\nδ\n\nConvergence Rate\nE[f (X̂t )] − f (x∗ ) ≤\n\nR\nE0 +γt Dh (x∗ ,Z0 ) 0t ε1s ds\nτt\n\nxk+1 −xk\n−Ak\n= Ak+1\n(∇h∗ (yk /γk ) − xk )\nδ\nδAk\n\nyk /γk = ∇h(zk )\nFunction Class\n\nLyapunov Function\n\nConvex\n\nEk = Dh∗ (yk /γk , ∇h(x∗ )) + Ak (f (xk ) − f (x∗ ))\n\nSAMD Dynamic 2:\n\ndYt = dteβt ((∇h(Xt ) − Yt )dt − μ1 (∇f (Xt )dt + σ(Xt , t)dBt ))\n\nd\n\nConvergence Rate\nE[f (x̂k )] − f (x∗ ) ≤\n\neβt\n\nd\n\nE0 +γk Dh (x∗ ,z0 )+δ\nAk\n\nPk\n\n3\ns=0 εs\n\neβt\n\ndXt = dteβt (∇h∗ (Yt ) − Xt )dt\n\nYt = ∇h(Zt )\nFunction Class\n\nLyapunov Function\n\nμ-Strongly Convex\n\nEt = eβt (μDh∗ (Yt , ∇h(x∗ )) + f (Xt ) − f (x∗ ))\n\nSAMD Algorithm 2:\n\nyk+1 −yk\n−Ak\n= Ak+1\n((∇h(xk ) − yk ) − μ1 (∇f (xk ) + σ(xk )))\nδ\nδAk\n\nConvergence Rate\nE[f (X̂t )] − f (x∗ ) ≤\n\nR\nE0 + 0t ε2s ds\neβt\n\nxk+1 −xk\n−Ak\n= Ak+1\n(∇h∗ (yk ) − xk )\nδ\nδAk\n\nyk = ∇h(zk )\nFunction Class\n\nLyapunov Function\n\nμ-Strongly Convex\n\nEk = Ak (μDh∗ (yk , ∇h(x∗ )) + f (xk ) − f (x∗ ))\n\nConvergence Rate\nE[f (x̂k )] − f (x∗ ) ≤\n\nE0 +δ\n\nPk\n\n4\ns=0 εs ds\n\nAk\n\nTable 3.2: Lyapunov functions for the stochastic accelerated mirror descent (SAMD) dynamics and stochastic mirror descent (SAMD) algorithms. The error in continuous time\ncomes from the Ito correction term. Assume σ \u0016 ∇2 h and E[σt ] ≤ G, E[kg(x)k∗ ] ≤ G\n2\nd βt\n2\n−As )2\n1\n1\n1\n3\n2 ( dt e |t=s )\n=\nδ,\nε\nG2 τ̇γss , ε2s = 2σ\nG2 (As+1\nG\n∀x ∈ X and t ∈ R+ . Here, ε1s = 2σ\n, and\n2\nβ\ns\nδ γs\n2σ\n2μe s\n2\n\n−As )\n1\nG2 (As+1\nδ. The scalings on the error and Ito correction terms match.\nε4s = 2σ\n2δ 2 μAs\n\n3.2\n\nSecond-order Stochastic Differential Equations\n\nKrichene and Bartlett [26] showed the stochastic dual averaging dynamic with momentum (2.75),\ndYt = −τ̇t (∇f (Xt )dt + σ(Xt , t)dBt )\nτ̇t\ndXt = (∇h∗ (Yt /γt ) − Xt )dt\nτt\n\n(3.10a)\n(3.10b)\n\ncan be analyzed using the same Lyapunov function (2.76)\nEt = γt Dh∗ (Yt /γt , ∇h(x∗ )) + τt (f (Xt ) − f (x∗ )).\n\n(3.11)\n\nCHAPTER 3. STOCHASTIC DIFFERENTIAL EQUATIONS\n\n60\n\nHere, we take γ̇t , γt , τ̇t , τt > 0, Yt /γt = ∇h(Zt ) and using (A.29), we note Dh (x∗ , Zt ) =\nDh∗ (Yt /γt , ∇h(x∗ )). Krichene and Bartlett use Ito’s formula\ndEt =\n\n∂Et\n∂Et\nτ̇ 2\n∂Et\ndt +\ndXt +\ndYt + t tr(σt> ∇2 h∗ (Zs )σt )dt,\n∂t\n∂Xt\n∂Yt\n2γt\n\nto show the bound [26, Thm 2],\nE[Et ] =\n\nR t τ̇s2\nE0 + γt Dh (x∗ , Z0 ) + E[ 0 2γ\ntr(σs> ∇2 h∗ (Zs )σt )ds]\ns\nτt\n\nIn particular, if we assume ∇2 h∗ \u0016 σ −1 I (i.e that h is σ-strongly convex), and Ekσt kF ≤ G,\nthen obtain the convergence bound\nE[f (Xt )] − f (x∗ ) ≤\n\nRt 2\n1\nG2 0 τ̇γss ds\nE0 + γt Dh (x∗ , Z0 ) + 2σ\nτt\n\n(3.12)\n\nMore generally, [26] note that if kσt kF ≤ Gtq and τt = tp , then we can infer the upper bound\nO(tp−1+2q ) from convergence rate bound (3.12). If we take p = 1/2, then q < 1/4 for the\nbound (3.12)√to provide a rate of convergence. If q = 0, this bound is also optimized by the\nchoices γt = t and τt = t, which results in an O(t−1/2 ) convergence rate.\nStochastic Dual Averaging with Momentum We can analyze dual averaging with\nmomentum (2.31) where we replace gradients ∇f (x) with stochastic estimates of the gradients ∇f (x) + σ(x) = g(x), where E[σ(x)] = 0. The variational condition for this algorithm\ncan be written,\nxk+1 − xk\n= τk (zk − xk+1 )\nδ\nyk+1 − yk\nAk+1 − Ak\n=−\n(∇f (xk+1 ) + σ(xk+1 )),\nδ\nδ\n−Ak\nwhere yk = γk ∇h(zk ) and τk = Ak+1\n. Using the Lyapunov function\nδAk\n\nEk = γk Dh (x∗ , zk ) + Ak (f (xk ) − f (x∗ )),\nwhich we can also write as\nEk = γk Dh∗ (yk /γk , ∇h(x∗ )) + Ak (f (xk ) − f (x∗ )),\nsimilar to (3.11).\n\n(3.13a)\n(3.13b)\n\nCHAPTER 3. STOCHASTIC DIFFERENTIAL EQUATIONS\n\n61\n\nWe check,\n\n∇h(zk+1 ) − ∇h(zk ) ∗\n, x − zk+1\nδ\nf (xk+1 ) − f (xk )\n+ ε1k\n+ αk (f (xk+1 ) − f (x∗ )) + Ak\nδ\nγk+1 − γk\n(3.13b)\n∗\n= (h(x ) − h(xk+1 ))\n+ αk h∇f (xk+1 ) + σ(xk+1 ), x∗ − xk+1 i\nδ\nf (xk+1 ) − f (xk )\n+ αk (f (xk+1 ) − f (x∗ )) + Ak\n+ ε2k\nδ\nγk+1 − γk\n∗\n∗\n(h(x ) − h(xk+1 )) + hσ(xk+1 ), x∗ − zk i + ε3k\n= −αk Df (x , xk ) +\nδ\nγk+1 − γk\n∗\n≤\nDh (x , x0 ) + hσ(xk+1 ), x∗ − zk i + ε3k .\nδ\n\nEk+1 − Ek\nγk+1 − γk\n= Dh (x∗ , xk )\n− γk\nδ\nδ\n\n\nwhere the first error scales as ε1k = − γδk Dh (zk+1 , zk ), the second as ε2k = αk h∇f (xk+1 ) +\nσ(xk+1 ), xk+1 − zk+1 i + ε1k and ε2k = Ak f (xk+1 δ)−f (xk ) + ε3k . Denote g(x) = ∇f (x) + σ(x).\nUsing the convexity of f , we can bound the error as follows ε3k ≤ αk hg(xk+1 ), zk − zk+1 i −\nγk\nDh (zk+1 , zk ). Using the σ-strong convexity of h and Young’s inequality and the assumption,\nδ\nα2 δ\n\nk\nE[kg(x)k2∗ ≤ G2 ∀x ∈ X , we obtain the upper bounds ε3k ≤ 2σγ\nG2 . By summing the\nk\nP\nLyapunov function we obtain the statement, EAk ≤ EA0 + (γk − γ0 )Dh (x∗ , z0 ) + δ ks=0 ε3s +\nδh(σ(xs+1 ), x∗ − zs i. Taking the expectation, we obtain the convergence bound,\n\nE[f (xk )] − f (x∗ ) ≤\n\n1\nE0 + γk Dh (x∗ , z0 ) + δ 2 2σ\n\nα2s 2\ns=0 γs G\n\nPk\n\nAk\n\n.\n\nIf we assume\nwith out loss of √\ngenerality σ = 1, and choose Ak = k, δ = 1 and γk =\n√\nG2\nk\n+\n1,\nwe\nobtain\nO(1/\nk) convergence rate.\nDh (x∗ ,x0 )\n\n3.2.1\n\nStrongly convex functions\n\nIn [4], we proposed the dynamics,\ndXt = β̇t (∇h∗ (Yt ) − Xt )dt\n\u0012\n\u0013\n1\ndYt = β̇t (∇h(Xt ) − Yt )dt − (∇f (Xt )dt + σt dBt )\nμ\n\n(3.14a)\n(3.14b)\n\nWe recognize (3.14) as (2.57) with the addition of a stochastic term, using the identification\n∇h∗ (Yt ) = Zt . To analyze the dynamics (3.14), we use the Lyapunov function (2.58)\nEt = eβt (μDh∗ (Yt , ∇h(x∗ )) + f (Xt ) − f (x∗ ))\n\n(3.15)\n\nCHAPTER 3. STOCHASTIC DIFFERENTIAL EQUATIONS\n\n62\n\nWe use Ito’s formula\ndEt =\n\n∂Et\n∂Et\n∂Et\neβt τ̇t2\ndt +\ndXt +\ndYt +\ntr(σt> ∇2 h∗ (Ys )σt )dt,\n∂t\n∂Xt\n∂Yt\n2μ\n\nwhere we compute the components,\n\n\n∂Et\ndt = β̇t eβt (μDh∗ (Yt , ∇h(x∗ )) + f (Xt ) − f (x∗ )) dt\n∂t\n\n∂Et\n, dXt = β̇t eβt h∇f (Xt ), ∇h∗ (Yt ) − Xt idt\n∂X\nt\n\n∂Et\n1\n, dYt = μβ̇t eβt h∇h∗ (Yt ) − x∗ , (∇h(Xt ) − Yt )dt − (∇f (Xt )dt + σt dBt )i.\n∂Yt\nμ\n\nSubsequently,\ndEt = β̇t eβt (−Df (x∗ , Xt )dt + μ (Dh∗ (Yt , ∇h(x∗ ))dt + h∇h∗ (Yt ) − x∗ , ∇h(Xt ) − Yt i) dt)\n− β̇t eβt h∇h∗ (Yt ) − x∗ , σt dBt i +\n\neβt β̇t2\ntr(σt> ∇2 h∗ (Ys )σt )dt\n2μ\n\n(A.29)\n(B.15)\n\n= β̇t eβt (−Df (x∗ , Xt )dt + μ (Dh (x∗ , ∇h∗ (Yt ))dt + h∇h(∇h∗ (Yt )) − ∇h(Xt ), x∗ − ∇h∗ (Yt )i)dt))\n\neβt β̇t2\ntr(σt> ∇2 h∗ (Ys )σt )dt\n2μ\n= β̇t eβt (−Df (x∗ , Xt )dt + μDh (x∗ , Xt )dt − Dh (∇h∗ (Yt ), Xt )dt − h∇h∗ (Yt ) − x∗ , σt dBt i)\n− β̇t eβt h∇h∗ (Yt ) − x∗ , σt dBt i +\n\n+\n\neβt β̇t2\ntr(σt> ∇2 h∗ (Ys )σt )dt\n2μ\n\n≤ β̇t eβt h∇h∗ (Yt ) − x∗ , σt dBt i +\n\neβt β̇t2\ntr(σt> ∇2 h∗ (Ys )σt )dt.\n2μ\n\nThe inequality follows from teh strong conveixy to f with respect to h and non-negativity\nof the bregman divergence for convex functions. Taking the integral of both sides, we have\nZ t\neβs β̇s2\nEt ≤ E0 +\nβ̇s eβs μh∇h∗ (Ys ) − x∗ , σs dBs i +\ntr(σs> ∇2 h∗ (Ys )σs )ds.\n2μ\n0\nFinally, taking the expectation, we have\n\"Z\n#\n\u00012\nt d βt\ne |t=s\n> 2 ∗\ndt\nE[Et ] ≤ E0 + E\ntr(σs ∇ h (Ys )σs )ds ,\n2μeβs\n0\nfrom which we can conclude the convergence bound\nhR βs 2\ni\nt\nE0 + E 0 e 2μβ̇s tr(σs> ∇2 h∗ (Ys )σs )ds\nE[f (Xt )] − f (x∗ ) ≤\n.\neβt\n\n(3.16)\n\nCHAPTER 3. STOCHASTIC DIFFERENTIAL EQUATIONS\n\n63\n\nAssume ∇2 h∗ = [∇2 h]−1 \u0016 σ −1 I and kσt kF ≤ Gtq . Take βt = p log t or eβt = tp . Then we\ncan infer the upper bound O(tp−3+2q ) from (3.16). Take p = 2. Then q < 1/2 for the upper\nbound to provide a rate of convergence, otherwise, if q = 0, we can infer a O(t−1 ) rate of\nconvergence.\nStochastic Gradient Descent with Momentum When f is μ-strongly convex with respect to h, and h is σ-strongly convex, the algorithm which satisfies the variational condition\nxk+1 − xk\n= τk (zk − xk+1 )\nδ\n\u0012\n\u0013\n∇h(zk+1 ) − ∇h(zk )\n1\n= τk ∇h(xk+1 ) − zk − (∇f (xk+1 ) + σ(xk+1 ))\nδ\nμ\n\n(3.17a)\n(3.17b)\n\ncan be analyzed using the following Lyapunov function.\nEk = Ak (μDh (x∗ , zk ) + f (xk ) − f (x∗ )).\n−Ak\nHere, σ(x) = g(x) − ∇f (x), E[σ(x)] = 0 and τk = Ak+1\n:= Aαkk . Update (3.17b) involves\nδAk\noptimizing a linear approximation to the function regularized by a weighted combination of\nBregman divergences. When h is Euclidean, we can write (3.17b) as,\n\u001a\n\u001b\nμ\n2\nzk+1 = arg min hg(xk+1 ), zi +\nkz − z̃k+1 k .\nz∈X\n2τk\n\nWith the identification ∇h(Yt ) = Zt , is similar to the analysis of the SDE (3.14). We check,\nAk+1 − Ak\nf (xk+1 ) − f (xk )\nEk+1 − Ek\n=\n(μDh (x∗ , zk+1 ) + f (xk+1 ) − f (x∗ )) + Ak\nδ\nδ\nδ\n\n∇h(zk+1 ) − ∇h(zk ) ∗\n− Ak μ\n, x − zk+1 + ε1k\nδ\n(3.17a)\n\n= (μDh (x∗ , zk+1 ) + f (xk+1 ) − f (x∗ ) + h∇f (xk+1 ) + σ(xk+1 ), x∗ − zk i)αk\nf (xk+1 ) − f (xk )\n+ Ak\n+ μ h∇h(xk+1 ) − ∇h(zk+1 ), x∗ − zk+1 i αk + ε2k\nδ\n(A.27)\n(3.17b)\n\n= (−Dfg (x∗ , xk+1 ) + μDh (x∗ , xk+1 ) + hσ(xk+1 ), x∗ − zk i)αk + ε3k ≤ 0.\n\nHere, the first error scales as ε1k = − Aδk μ Dh (zk+1 , zk ), the second scales as ε2k = αk h∇f (xk+1 )+\nσ(xk+1 ), zk −zk+1 i+ε1k and the third as ε3k = ε2k − Aδk Df (xk , xk+1 ) ≤ ε2k . The σ-strong convexity\nα2\n\nof h, Young’s inequality, and the assumption E[kg(x)k] ≤ G, ensures ε2k ≤ δ 2μAkk σ kg(xk )k2 ≤\nα2\n\nδ 2μAkk σ G2 . This allows us to conclude the upper bound\nPk\nα2s\n2\nE\n+\nδ\nG2\n0\ns=0\n2μσA\ns\n∗\nE[f (xk )] − f (x ) ≤\n.\nAk\n\nCHAPTER 3. STOCHASTIC DIFFERENTIAL EQUATIONS\n\n64\n\nNotice, for all the methods analyzed in this section, the Ito correction term scales in the\nsame way as the term we refer to as the discrete-time error.\n\n3.3\n\nLyapunov arguments for coordinate methods\n\nCoordinate methods are another class of iterative methods in which only a few components\nof the state x are updated at any given time. For example, the coordinate version of gradient\ndescent has as its update,\nxk+1 − xk\n= −∇i f (xk )\nδ\nwhere ∇i is the gradient of f along its i-th coordinate, which is sampled randomly i ∈ [d], so\nthat E[∇i f (x)] = ∇f (x). The Lyapunov framework can be extended to analyze coordinate\nversion of the algorithms discussed in the previous chapter. As a preview, we a present\na Lyapunov argument for the coordinate version of accelerated mirror prox (2.55), as that\ndoes not have appeared to be done yet. We end by presenting our work Breaking Locality\nAccelerates Block Gauss Seidel, where we demonstrate how the Lyapunov framework can be\nused to analyze coordinate algorithms with very general sampling schemes.\nCoordinate Accelerated Mirror Prox\nSample coordinate i ∈ [d] at random. We\nassume f is convex along its i-th coordinate (A.20) and (1/\u000fi ) smooth along its i-th coordinate (A.21). The block coordinate mirror prox method can be written as the sequence of\nupdates,\nx0k+1 − xk\n= τk (zk − xk )\nδ\n\b\n0(i)\nzk+1 = arg min h∇i f (x0k+1 ), xi + Dh (x, zk )\n\n(3.18a)\n(3.18b)\n\nx∈X\n\n(i)\n\nxk+1 − xk\n0(i)\n= τk (zk+1 − xk )\nδ\nn\no\n(i)\n(i)\nzk+1 = arg min h∇i f (xk+1 ), xi + Dh (x, zk )\n\n(3.18c)\n(3.18d)\n\nx∈X\n\n0(i)\n\n(i)\n\n(i)\n\nWe use the superscript (i) on zk+1 , xk+1 and zk+1 to denote that its value depends on the choice\nof coordinate i. That is, we perform the update x0k+1 and treat x0k+1 , zk and xk as fixed. We\nthen sample the i-th coordinate along which we compute the relevant gradients and update\n0(i)\n\n∇h(zk+1 )−∇h(zk )\n=\nδ\n(i)\n∇h(z\n)−∇h(z\n)\nk\nk+1\n− Ak+1δ−Ak ∇i f (x0k+1 ) , and update (3.18b) satisfies the variational condition,\n=\nδ\n0\nzk+1\n, xk+1 and zk+1 . Update (3.18b) satisfies the variational condition,\n\nCHAPTER 3. STOCHASTIC DIFFERENTIAL EQUATIONS\n\n65\n\n− Ak+1δ−Ak ∇i f (xk+1 ). We use the Lyapunov function (2.45) to analyze (3.18). We check,\n*\n+\n(i)\n∇h(zk+1 ) − ∇h(zk ) ∗\nEk+1 − Ek\n(i)\n=−\n, x − xk+1 + αk (f (xk+1 ) − f (x∗ )) + ε1k\nδ\nδ\n(i)\n\n(2.55d)\n\n(i)\n\n= −Df i (x∗ , xk+1 )αk + ε1k\n\nwhere we use the notation Df i (x, y) is given by (A.19). Here, the error scales as,\n*\n+\n(i)\n(i)\nf\n(x\n)\n−\nf\n(x\n)\n∇h(z\n)\n−\n∇h(z\n)\n1\nk\nk\n(i)\n(i)\nk+1\nk+1\nε1k = Ak\n−\n, xk+1 − zk+1 − Dh (zk+1 , zk )\nδ\nδ\nδ\n(3.18d)\n(A.27)\n\n(i)\n\nf (xk+1 ) − f (xk )\n1\n(i)\n(i)\n(i)\n(i)\n0(i)\n= Ak\n+ αk h∇i f (xk+1 ), xk+1 − zk+1 i − Dh (zk+1 , zk+1 )\nδ\n*\n+ δ\n0(i)\n∇h(zk+1 ) − ∇h(zk ) (i)\n1\n0(i)\n0(i)\n− Dh (zk+1 , zk ) −\n, zk+1 − zk+1\nδ\nδ\n\nUsing convexity along the i-th coordinate, we can further upper-bound the error as follows,\n*\n+\n(i)\n(3.18b)\nx\n−\nx\n1\nk\n(i)\n(i)\n(i)\n(i)\n0(i)\nε1k ≤ Ak+1 ∇i f (xk+1 ), k+1\n+ αk h∇i f (xk+1 ), xk − zk+1 i − Dh (zk+1 , zk+1 )\nδ\nδ\n1\n0(i)\n0(i)\n(i)\n0(i)\n− Dh (zk+1 , zk ) + αk h∇i f (xk+1 ), zk+1 − zk+1 i\nδ\n1\n1\n(i)\n0(i)\n(i)\n(i)\n0(i)\n0\n= αk h∇i f (xk+1 ) − ∇i f (x0k+1 ), zk+1 − zk+1 i − Dh (zk+1 , zk+1 ) − Dh (zk+1\n, zk )\nδ\nδ\n\n(3.18c)\n\nx\n\n(i)\n\n−x0\n\nUsing the (1/\u000fi )-smoothness of ∇i f , Cauchy-Schwartz (A.26) and the identity k+1 δ k+1 =\n0(i)\n(i)\n0(i)\n(i)\n(i)\nτk (zk+1 − zk ), the inequality αk h∇i f (xk+1 ) − ∇i f (x0k+1 ), zk+1 − zk+1 i ≤ αk k∇i f (xk+1 ) −\n(3.18a)\n(3.18c)\nα2\n0(i)\n(i)\n0(i)\n(i)\n0(i)\n0\n∇i f (xk+1 )kkzk+1 − zk+1 k = δ Ak+1k \u000fi kzk+1 − zk+1 kkzk+1 − zk k and the σ-strong convexity\n\nof h gives the upper bound\nEk+1 − Ek\n(i)\n≤ −Df i (x∗ , xk+1 ) + ε1k\nδ\nwhere\nαk2\n\nσ 0(i)\nσ 0(i)\n(i)\nkzk+1 − zk k2 − kzk+1 − zk+1 k2 .\nAk+1 \u000fi\n2δ\n2δ\n√\nTaking the expectation of of both sides ensures E[Ek+1δ ]−Ek ≤ E[ε1k ]. Taking δ = \u000fσ, the\nε1k = δ\n\n0(i)\n\n0(i)\n\n(i)\n\nkzk+1 − zk kkzk+1 − zk+1 k −\n\nα2\n\nk\nexpected error is nonpositive if Ak+1\n≤ 1. The same choices as mirror prox/agd, Ak+1 =\n\nσ\u000f(k+1)(k+2)\n4\n\n√\n\nand αk = σ\u000f(k+1)\nensures the error is nonpositive; from this we can conclude\n2\nE[f (xk )] − f (x∗ ) ≤ O(1/\u000fσk 2 ).\n\nCHAPTER 3. STOCHASTIC DIFFERENTIAL EQUATIONS\n\n66\n\nSummary From this example, it is clear that how the aforementioned Lyapunov framework\ncan be applied to the coordinate versions of all the methods previously discussed. We now\nshow how we can use this framework can be extended to analyze coordinate methods which\nperform random coordinate block updates at every iteration.\n\n3.4\n\nBreaking Locality Accelerates Block Gauss-Seidel\n\nThis section is based on the work Breaking locality accelerates block Gauss-Seidel. S. Tu, S.\nVenkataraman, A. Wilson, A. Gittens, M. I. Jordan, and B. Recht. In D. Precup and Y. W.\nTeh (Eds), Proceedings of the 34th International Conference on Machine Learning (ICML),\nSydney, Australia, NY, 2017.\nRecent work by Nesterov and Stich [48] showed that momentum can be used to accelerate\nthe rate of convergence for block Gauss-Seidel in the setting where a fixed partitioning\nof the coordinates is chosen ahead of time. We show that this setting is too restrictive,\nconstructing instances where breaking locality by running non-accelerated Gauss-Seidel with\nrandomly sampled coordinates substantially outperforms accelerated Gauss-Seidel with any\nfixed partitioning. Motivated by this finding, we analyze the accelerated block Gauss-Seidel\nalgorithm in the random coordinate sampling setting. Our Lyapunov framework captures\nthe benefit of acceleration with a new data-dependent parameter which is well behaved when\nthe matrix sub-blocks are well-conditioned. Empirically, we show that accelerated GaussSeidel with random coordinate sampling provides speedups for large scale machine learning\ntasks when compared to non-accelerated Gauss-Seidel and the classical conjugate-gradient\n\n3.4.1\n\nIntroduction\n\nThe randomized Gauss-Seidel method is a commonly used iterative algorithm to compute\nthe solution of an n × n linear system Ax = b by updating a single coordinate at a time in\na randomized order. While this approach is known to converge linearly to the true solution\nwhen A is positive definite (see e.g. [31]), in practice it is often more efficient to update a\nsmall block of coordinates at a time due to the effects of cache locality.\nIn extending randomized Gauss-Seidel to the block setting, a natural question that arises\nis how one should sample the next block. At one extreme a fixed partition of the coordinates\nis chosen ahead of time. The algorithm is restricted to randomly selecting blocks from this\nfixed partitioning, thus favoring data locality. At the other extreme we break locality by\nsampling a new set of random coordinates to form a block at every iteration.\nTheoretically, the fixed partition case is well understood both for Gauss-Seidel [58, 20] and\nits Nesterov accelerated variant [48]. More specifically, at most O(μ−1\npart log(1/ε)) iterations\nof Gauss-Seidel are sufficient to reach a solution with at most ε error, where μpart is a\nquantity which measures how well the A matrix is preconditioned by the block diagonal\nmatrix containing the sub-blocks corresponding to the fixed partitioning. When acceleration\n\nCHAPTER 3. STOCHASTIC DIFFERENTIAL EQUATIONS\n\n67\n\n\u0010q\n\u0011\nn −1\nis used, Nesterov and Stich [48] show that the rate improves to O\nμ\nlog(1/ε)\n, where\np part\np is the partition size.\nFor the random coordinate selection model, the existing literature is less complete.\nWhile it is known [58, 20] that the iteration complexity with random coordinate section\nis O(μ−1\nrand log(1/ε)) for an ε error solution, μrand is another instance dependent quantity\nwhich is not directly comparable to μpart . Hence it is not obvious how much better, if at all,\none expects random coordinate selection to perform compared to fixed partitioning.\nOur first contribution in this paper is to show that, when compared to the random\ncoordinate selection model, the fixed partition model can perform very poorly in terms\nof iteration complexity to reach a pre-specified error. Specifically, we present a family of\ninstances (similar to the matrices recently studied by Lee and Wright [28]) where nonaccelerated Gauss-Seidel with random coordinate selection performs arbitrarily faster than\nboth non-accelerated and even accelerated Gauss-Seidel, using any fixed partition. Our\nresult thus shows the importance of the sampling strategy and that acceleration cannot\nmake up for a poor choice of sampling distribution.\nThis finding motivates us to further study the benefits of acceleration under the random\ncoordinate selection model. Interestingly, the benefits are more nuanced\nunder this model.\n\u0013\n\u0012q\n−1\n−1\nνμrand log(1/ε) ,\nWe show that acceleration improves the rate from O(μrand log(1/ε)) to O\nwhere ν is a new instance dependent quantity that satisfies ν ≤ μ−1\nrand . We derive a bound\non ν which suggests that if the sub-blocks of A are all well conditioned, then acceleration\ncan provide substantial speedups. We note that this is merely a sufficient condition, and our\nexperiments suggest that our bound is conservative.\nIn the process of deriving our results, we also develop a general proof framework for\nrandomized accelerated methods based on Wilson et al. [77] which avoids the use of estimate\nsequences in favor of an explicit Lyapunov function. Using our proof framework we are\nable to recover recent results [48, 1] on accelerated coordinate descent. Furthermore, our\nproof framework allows us to immediately transfer our results on Gauss-Seidel over to the\nrandomized accelerated Kaczmarz algorithm, extending a recent result by Liu and Wright [33]\non updating a single constraint at a time to the block case.\nFinally, we empirically demonstrate that despite its theoretical nuances, accelerated\nGauss-Seidel using random coordinate selection can provide significant speedups in practical applications over Gauss-Seidel with fixed partition sampling, as well as the classical\nconjugate-gradient (CG) algorithm. As an example, for a kernel ridge regression (KRR)\ntask in machine learning on the augmented CIFAR-10 dataset (n = 250, 000), acceleration\nwith random coordinate sampling performs up to 1.5× faster than acceleration with a fixed\npartitioning to reach an error tolerance of 10−2 , with the gap substantially widening for\nsmaller error tolerances. Furthermore, it performs over 3.5× faster than conjugate-gradient\non the same task.\n\nCHAPTER 3. STOCHASTIC DIFFERENTIAL EQUATIONS\n\n3.4.2\n\n68\n\nBackground\n\nWe assume that we are given an n × n matrix A which is positive definite, and an n dimensional response vector b. We also fix an integer p which denotes a block size. Under\nthe assumption of A being positive definite, the function f (x) = 21 x> Ax − x> b is strongly\nconvex and smooth. Recent analysis of Gauss-Seidel [20] proceeds by noting the connection\nbetween Gauss-Seidel and (block) coordinate descent on f . This is the point of view we will\ntake in this paper.\n3.4.2.1\n\nExisting rates for randomized block Gauss-Seidel\n\nWe first describe the sketching framework of [58, 20] and show how it yields rates on GaussSeidel when blocks are chosen via a fixed partition or randomly at every iteration. While we\nwill only focus on the special case when the sketch matrix represents column sampling, the\nsketching framework allows us to provide a unified analysis of both cases.\nTo be more precise, let D be a distribution over Rn×p , and let Sk ∼ D be drawn iid from\nD. If we perform block coordinate descent by minimizing f along the range of Sk , then the\nrandomized block Gauss-Seidel update is given by\nxk+1 = xk − Sk (SkT ASk )† SkT (Axk − b) .\n\n(3.19)\n\nColumn sampling. Every index set J ⊆ 2[n] with |J| = p induces a sketching matrix S(J) = (eJ(1) , ..., eJ(p) ) where ei denotes the i-th standard basis vector in Rn , and\nJ(1), ..., J(p) is any ordering of the elements of J. By equipping different probability measures on 2[n] , one can easily describe fixed partition sampling as well as random coordinate\nsampling (and many other sampling schemes). The former puts\u0001uniform mass on the index\nsets J1 , ..., Jn/p , whereas the latter puts uniform mass on all np index sets of size p. Furthermore, in the sketching framework there is no limitation to use a uniform distribution,\nnor is there any limitation to use a fixed p for every iteration. For this paper, however, we\nwill restrict our attention to these cases.\nExisting rates. Under the assumptions stated above, [58, 20] show that for every k ≥ 0,\nthe sequence (3.19) satisfies\nE[kxk − x∗ kA ] ≤ (1 − μ)k/2 kx0 − x∗ kA ,\n\n(3.20)\n\nwhere μ = λmin (E[PA1/2 S ]). The expectation in (3.20) is taken with respect to the randomness\nof S0 , S1 , ..., and the expectation in the definition of μ is taken with respect to S ∼ D. Under\nboth fixed partitioning and random coordinate selection, μ > 0 is guaranteed (see e.g. [20],\nLemma 4.3). Thus, (3.19) achieves a linear rate of convergence to the true solution, with\nthe rate governed by the μ quantity shown above.\nWe now specialize (3.20) to fixed partitioning and random coordinate sampling, and\nprovide some intuition for why we expect the latter to outperform the former in terms of\n\nCHAPTER 3. STOCHASTIC DIFFERENTIAL EQUATIONS\n\n69\n\niteration complexity. We first consider the case when the sampling distribution corresponds\nto fixed partitioning. Assume for notational convenience that the fixed partitioning corresponds to placing the first p coordinates in the first partition J1 , the next p coordinates in\nthe second partition J2 , and so on. Here, μ = μpart corresponds to a measure of how close\nthe product of A with the inverse of the block diagonal is to the identity matrix, defined as\n\u0010\n\u0010\n\u0011\u0011\np\n−1\nμpart = λmin A · blkdiag A−1\n,\n...,\nA\n.\n(3.21)\nJ1\nJn/p\nn\nAbove, AJi denotes the p × p matrix corresponding to the sub-matrix of A indexed by the\ni-th partition. A loose lower bound on μpart is\nμpart ≥\n\nλmin (A)\np\n.\nn max1≤i≤n/p λmax (AJi )\n\n(3.22)\n\nOn the other hand, in the random coordinate case, Qu et al. [58] derive a lower bound on\nμ = μrand as\n\u0012\n\u0013−1\np\nmax1≤i≤n Aii\nμrand ≥\n,\n(3.23)\nβ + (1 − β)\nn\nλmin (A)\nwhere β = (p − 1)/(n − 1). Using the lower bounds (3.22) and (3.23),\nwe can upper bound \u0011\n\u0010\nn max1≤i≤n/p λmax (AJi )\nthe iteration complexity of fixed partition Gauss-Seidel Npart by O p\nlog(1/ε)\n\u0010\n\u0011λmin (A)\nmax\nAii\nand random coordinate Gauss-Seidel Nrand as O np λ1≤i≤n\nlog(1/ε) . Comparing the\nmin (A)\nbound on Npart to the bound on Nrand , it is not unreasonable to expect that random coordinate sampling has better iteration complexity than fixed partition sampling in certain cases.\nIn Section 3.4.3, we verify this by constructing instances A such that fixed partition GaussSeidel takes arbitrarily more iterations to reach a pre-specified error tolerance compared with\nrandom coordinate Gauss-Seidel.\n3.4.2.2\n\nAccelerated rates for fixed partition Gauss-Seidel\n\nBased on the interpretation of Gauss-Seidel as block coordinate descent on the function f ,\nwe can use Theorem 1 of Nesterov and Stich [48] to recover a procedure and a rate for accelerating (3.19) in the fixed partition case; the specific details are discussed in Section C.4.2\nof the appendix. We will refer to this procedure as ACDM.\nThe convergence guarantee of the ACDM procedure is that for all k ≥ 0,\n!\nr\n\u0013k/2\n\u0012\np\nE[kxk − x∗ kA ] ≤ O\nμpart\nkx0 − x∗ kA .\n(3.24)\n1−\nn\nAbove, μpart is the same quantity defined in (3.21). Comparing (3.24) to the non-accelerated\nGauss-Seidel rate given in (3.20), we see that acceleration improves\nthe iteration\n\u0010q\n\u0011 complexity\nto reach a solution with ε error from O(μ−1\npart log(1/ε)) to O\nin Section 3.4.1.\n\nn −1\nμ\nlog(1/ε)\np part\n\n, as discussed\n\nCHAPTER 3. STOCHASTIC DIFFERENTIAL EQUATIONS\n\n3.4.3\n\n70\n\nResults\n\nWe now present the main results. All proofs are deferred to the appendix.\n3.4.3.1\n\nFixed partition vs random coordinate sampling\n\nOur first result is to construct instances where Gauss-Seidel with fixed partition sampling\nruns arbitrarily slower than random coordinate sampling, even if acceleration is used.\nConsider the family of n×n positive definite matrices A given by A = {Aα,β : α > 0, α+\nβ > 0} with Aα,β defined as Aα,β = αI + βn 1n 1Tn . The family A exhibits a crucial property\nthat ΠT Aα,β Π = Aα,β for every n × n permutation matrix Π. Lee and Wright [28] recently\nexploited this invariance to illustrate the behavior of cyclic versus randomized permutations\nin coordinate descent.\nWe explore the behavior of Gauss-Seidel as the matrices Aα,β become ill-conditioned.\nTo do this, we consider a particular parameterization which holds the minimum eigenvalue\nequal to one and sends the maximum eigenvalue to infinity via the sub-family {A1,β }β>0 .\nOur first proposition characterizes the behavior of Gauss-Seidel with fixed partitions on this\nsub-family.\nProposition 3.4.1. Fix β > 0 and positive integers n, p, k such that n = pk. Let {Ji }ki=1\nbe any partition of {1, ..., n} with |Ji | = p, and denote Si ∈ Rn×p as the column selector for\npartition Ji . Suppose S ∈ Rn×p takes on value Si with probability 1/k. For every A1,β ∈ A\nwe have that\np\n.\n(3.25)\nμpart =\nn + βp\nNext, we perform a similar calculation under the random column sampling model.\nProposition 3.4.2. Fix β > 0 and integers n, p such that 1 < p < n. Suppose each column\nof S ∈ Rn×p is chosen uniformly at random from {e1 , ..., en } without replacement. For every\nA1,β ∈ A we have that\nμrand =\n\np\n(p − 1)βp\n+\n.\nn + βp (n − 1)(n + βp)\n\n(3.26)\n\nThe differences between (3.25) and (3.26) are striking. Let us assume that β is much\np−1\nlarger than n. Then, we have that μpart ≈ 1/β for (3.25), whereas μrand ≈ n−1\nfor (3.26).\nThat is, μpart can be made arbitrarily smaller than μrand as β grows.\nOur next proposition states that the rate of Gauss-Seidel from (3.20) is tight order-wise\nin that for any instance there always exists a starting point which saturates the bound.\nProposition 3.4.3. Let A be an n×n positive definite matrix, and let S be a random matrix\nsuch that μ = λmin (E[PA1/2 S ]) > 0. Let x∗ denote the solution to Ax = b. There exists a\nstarting point x0 ∈ Rn such that the sequence (3.19) satisfies for all k ≥ 0,\nE[kxk − x∗ kA ] ≥ (1 − μ)k kx0 − x∗ kA .\n\n(3.27)\n\nCHAPTER 3. STOCHASTIC DIFFERENTIAL EQUATIONS\n\n71\n\nFrom (3.20) we see that Gauss-Seidel using random coordinates computes a solution\nxk satisfying E[kxk − x∗ kA1,β ] ≤ ε in at most k = O( np log(1/ε)) iterations. On the other\nhand, Proposition 3.4.3 states that for any fixed partition, there exists an input x0 such that\nk = Ω(β log(1/ε)) iterations are required to reach the same ε error tolerance. Furthermore,\nthe situation does not improve even if use ACDM from [48]. Proposition 3.4.6, which we\ndescribe\nthat for any fixed partition there exists an input x0 such that k =\n\u0011\n\u0010q later, implies\nn\nβ log(1/ε) iterations are required for ACDM to reach ε error. Hence as β −→ ∞,\nΩ\np\nthe gap between random coordinate and fixed partitioning can be made arbitrarily large.\nThese findings are numerically verified in Section 3.4.5.1.\n3.4.3.2\n\nA Lyapunov analysis of accelerated Gauss-Seidel and Kaczmarz\n\nMotivated by our findings, our goal is to understand the behavior of accelerated GaussSeidel under random coordinate sampling. In order to do this, we establish a general framework from which the behavior of accelerated Gauss-Seidel with random coordinate sampling\nfollows immediately, along with rates for accelerated randomized Kaczmarz [33] and the\naccelerated coordinate descent methods of [48] and [1].\nFor conciseness, we describe a simpler version of our framework which is still able to\ncapture both the Gauss-Seidel and Kaczmarz results, deferring the general version to the\nfull version of the paper. Our general result requires a bit more notation, but follows the\nsame line of reasoning.\nLet H be a random n × n positive semi-definite matrix. Put G = E[H], and suppose\nthat G exists and is positive definite. Furthermore, let f : Rn −→ R be strongly convex and\nsmooth, and let μ denote the strong convexity constant of f w.r.t. the k·kG−1 norm.\nConsider the following sequence {(xk , yk , zk )}k≥0 defined by the recurrence\nτ\n1\nyk +\nzk ,\n1+τ\n1+τ\nyk+1 = xk+1 − Hk ∇f (xk+1 ) ,\nτ\nzk+1 = zk + τ (xk+1 − zk ) − Hk ∇f (xk+1 ) ,\nμ\n\nxk+1 =\n\n(3.28a)\n(3.28b)\n(3.28c)\n\nwhere H0 , H1 , ... are independent realizations of H and τ is a parameter to be chosen. Following [77], we construct a candidate Lyapunov function Ek for the sequence (3.28) defined\nas\nμ\nEk = f (yk ) − f∗ + kzk − x∗ k2G−1 .\n(3.29)\n2\nThe following theorem demonstrates that Ek is indeed a Lyapunov function for (xk , yk , zk ).\nTheorem 3.4.4. Let f , G, H be as defined above. Suppose further that f has 1-Lipschitz\ngradients w.r.t. the k·kG−1 norm, and for every fixed x ∈ Rn ,\n1\nf (Φ(x; H)) ≤ f (x) − k∇f (x)k2H ,\n2\n\n(3.30)\n\nCHAPTER 3. STOCHASTIC DIFFERENTIAL EQUATIONS\nholds for a.e. H, where Φ(x; H) = x − H∇f (x). Set τ in (3.28) as τ =\n\u0003\u0001\n\u0002\nν = λmax E (G−1/2 HG−1/2 )2 .\n\n72\np\nμ/ν, with\n\nThen for every k ≥ 0, we have\nE[Ek ] ≤ (1 − τ )k E0 .\nWe now proceed to specialize Theorem 3.4.4 to both the Gauss-Seidel and Kaczmarz\nsettings.\nAccelerated Gauss-Seidel Let S ∈ Rn×p denote a random sketching matrix. As suggested in Section 3.4.2, we set f (x) = 21 xT Ax − xT b and put H = S(S T AS)† S T . Note that\nG = E[S(S T AS)† S T ] is positive definite iff λmin (E[PA1/2 S ]) > 0, and is hence satisfied for\nboth fixed partition and random coordinate sampling (c.f. Section 3.4.2). Next, the fact that\nf is 1-Lipschitz w.r.t. the k·kG−1 norm and the condition (3.30) are standard calculations.\nAll the hypotheses of Theorem 3.4.4 are thus satisfied, and the conclusion is Theorem 3.4.5,\nwhich characterizes the rate of convergence for accelerated Gauss-Seidel (Algorithm 1).\nAlgorithm 1 Accelerated randomized block Gauss-Seidel.\n−1\nRequire: A ∈ Rn×n , A \u001f 0, b ∈ Rn , sketching matrices {Sk }Tk=0\n⊆ Rn×p , x0 ∈ Rn ,\nμ ∈ (0, 1),\np ν ≥ 1.\n1: Set τ =\nμ/ν.\n2: Set y0 = z0 = x0 .\n3: for k = 0, ..., T − 1 do\nτ\n1\nyk + 1+τ\nzk .\n4:\nxk+1 = 1+τ\nT\n† T\n5:\nHk = Sk (Sk ASk ) Sk .\n6:\nyk+1 = xk+1 − Hk (Axk+1 − b).\n7:\nzk+1 = zk + τ (xk+1 − zk ) − μτ Hk (Axk+1 − b).\n8: end for\n9: Return yT .\n\nTheorem 3.4.5. Let A be an n × n positive definite matrix and b ∈ Rn . Let x∗ ∈ Rn denote\nthe unique vector satisfying Ax∗ = b. Suppose each Sk , k = 0, 1, 2, ... is an independent copy\nof a random matrix S ∈ Rn×p . Put μ = λmin (E[PA1/2 S ]), and suppose the distribution of S\nsatisfies μ > 0. Invoke Algorithm 1 with μ and ν, where\n\u0002\n\u0003\u0001\nν = λmax E (G−1/2 HG−1/2 )2 ,\n(3.31)\np\nwith H = S(S T AS)† S T and G = E[H]. Then with τ = μ/ν, for all k ≥ 0,\n√\nE[kyk − x∗ kA ] ≤ 2(1 − τ )k/2 kx0 − x∗ kA .\n(3.32)\n\nCHAPTER 3. STOCHASTIC DIFFERENTIAL EQUATIONS\n\n73\n\nNote that in the setting of Theorem 3.4.5, by the definition of ν and μ, it is always the\ncase that ν ≤ 1/μ. Therefore, the iteration complexity of acceleration is at least as good as\nthe iteration complexity without acceleration.\nWe conclude our discussion of Gauss-Seidel by describing the analogue of Proposition 3.4.3\nfor Algorithm 1, which shows that our analysis in Theorem 3.4.5 is tight order-wise. The\nfollowing proposition applies to ACDM as well; we show in the full version of the paper how\nACDM can be viewed as a special case of Algorithm 1.\nProposition 3.4.6. Under the setting of Theorem 3.4.5, there exists starting positions\ny0 , z0 ∈ Rn such that the iterates {(yk , zk )}k≥0 produced by Algorithm 1 satisfy\nE[kyk − x∗ kA + kzk − x∗ kA ] ≥ (1 − τ )k ky0 − x∗ kA .\nAccelerated Kaczmarz The argument for Theorem 3.4.5 can be slightly modified to\nyield a result for randomized accelerated Kaczmarz in the sketching framework, for the case\nof a consistent overdetermined linear system.\nSpecifically, suppose we are given an m × n matrix A which has full column rank, and\nb ∈ R(A). Our goal is to recover the unique x∗ satisfying Ax∗ = b. To do this, we apply a\nsimilar line of reasoning as [29]. We set f (x) = 21 kx−x∗ k22 and H = PAT S , where S again is our\nrandom sketching matrix. At first, it appears our choice of f is problematic since we do not\nhave access to f and ∇f , but a quick calculation shows that H∇f (x) = (S T A)† S T (Ax − b).\nHence, with rk = Axk − b, the sequence (3.28) simplifies to\nτ\n1\nyk +\nzk ,\n1+τ\n1+τ\nyk+1 = xk+1 − (SkT A)† SkT rk+1 ,\nτ\nzk+1 = zk + τ (xk+1 − zk ) − (SkT A)† SkT rk+1 .\nμ\n\nxk+1 =\n\n(3.33a)\n(3.33b)\n(3.33c)\n\nThe remainder of the argument proceeds nearly identically, and leads to the following theorem.\nTheorem 3.4.7. Let A be an m × n matrix with full column rank, and b = Ax∗ . Suppose each Sk , k = 0, 1, 2, ... is an independent copy of a random sketching matrix S ∈\nRm×p . Put \u0002H = PAT S and \u0003\u0001\nG = E[H].p The sequence (3.33) with μ = λmin (E[PAT S ]),\n−1/2\n−1/2 2\nν = λmax E (G\nHG\n) , and τ = μ/ν satisfies for all k ≥ 0,\n√\nE[kyk − x∗ k2 ] ≤ 2(1 − τ )k/2 kx0 − x∗ k2 .\n(3.34)\nSpecialized to the setting of [33] where each row of A has unit norm and is sampled uniformly at every iteration, it can be shown (Section C.5.1) that ν ≤ m and μ =\n1\nλ (AT A).\nm min\n\u0012 Hence, the above\n\u0013 theorem states that the iteration complexity to reach ε\nerror is O\n\n√\n\nm\nlog(1/ε)\nλmin (AT A)\n\n, which matches Theorem 5.1 of [33] order-wise. However,\n\nTheorem 3.4.7 applies in general for any sketching matrix.\n\nCHAPTER 3. STOCHASTIC DIFFERENTIAL EQUATIONS\n3.4.3.3\n\n74\n\nSpecializing accelerated Gauss-Seidel to random coordinate sampling\n\nWe now instantiate Theorem 3.4.5 to random coordinate sampling. The μ quantity which\nappears in Theorem 3.4.5 is identical to the quantity appearing in the rate (3.20) of nonaccelerated Gauss-Seidel. That is, the iteration complexity to reach tolerance ε is\n\u0013\n\u0012q\n−1\nνμrand log(1/ε) ,\nO\nand the only new term here is ν. In order to provide a more intuitive interpretation of the\nν quantity, we present an upper bound on ν in terms of an effective block condition number\ndefined as follows. Given an index set J ⊆ 2[n] , define the effective block condition number\ni∈J Aii\nof a matrix A as κeff,J (A) = max\n. Note that κeff,J (A) ≤ κ(AJ ) always. The following\nλmin (AJ )\nlemma gives upper and lower bounds on the ν quantity.\nLemma 3.4.8. Let A be an n × n positive definite matrix and let p satisfy 1 < p < n. We\nhave that\n\u0012\n\u0012\n\u0013\n\u0013\nn p−1\np−1\nn\n≤ν≤\n+ 1−\nκeff,p (A) ,\np\np n−1\nn−1\nwhere κeff,p (A) = maxJ⊆2[n] :|J|=p κeff,J (A), ν is defined in (3.31), and the distribution of S\ncorresponds to uniformly selecting p coordinates without replacement.\nLemma 3.4.8 states that if the p×p sub-blocks of A are well-conditioned as defined by the\neffective block condition number κeff,J (A), then the speed-up of accelerated Gauss-Seidel with\nrandom coordinate selection over its non-accelerate counterpart parallels the case of fixed\npartitioning sampling (i.e. the rate described in (3.24) versus the rate in (3.20)). This is a\nreasonable condition, since very ill-conditioned sub-blocks will lead to numerical instabilities\nin solving the sub-problems when implementing Gauss-Seidel. On the other hand, we note\nthat Lemma 3.4.8 provides merely a sufficient condition for speed-ups from acceleration, and\nis conservative. Our numerically experiments in Section 3.4.5.6 suggest that in many cases\nthe ν parameter behaves closer to the lower bound n/p than Lemma 3.4.8 suggests. We\nleave a more thorough theoretical analysis of this parameter to future work.\nWe can now combine Theorem 3.4.5 with (3.23) to derive the following upper bound on\nthe iteration complexity of accelerated Gauss-Seidel with random coordinates as\ns\n!\nn max1≤i≤n Aii\nκeff,p (A) log(1/ε) .\nNrand,acc ≤ O\np\nλmin (A)\nIllustrative example. We conclude our results by illustrating our bounds on a simple\nexample. Consider the sub-family {Aδ }δ>0 ⊆ A , with\nAδ = An+δ,−n , δ > 0 .\n\n(3.35)\n\nCHAPTER 3. STOCHASTIC DIFFERENTIAL EQUATIONS\n\n75\n\nn−1+δ\nA simple calculation yields that κeff,p (Aδ ) = n−p+δ\n, and hence Lemma 3.4.8 states that\n\u0001\np−1\nn\nν(Aδ ) ≤ p 1 + n−1 . Furthermore, by a similar calculation to Proposition 3.4.2, μrand =\npδ\n. Assuming for simplicity that p = o(n) and δ ∈ (0, 1), Theorem 3.4.5 states that\nn(n−p+δ)\n3/2\n\nat most O( np√δ log(1/ε)) iterations are sufficient for an ε-accurate solution. On the other\n2\n\nhand, without acceleration (3.20) states that O( npδ log(1/ε)) iterations are sufficient and\nProposition 3.4.3 shows there exists a starting position for which it is necessary. Hence, as\neither n grows large or δ tends to zero, the benefits of acceleration become more pronounced.\n\n3.4.4\n\nRelated Work\n\nWe split the related work into two broad categories of interest: (a) work related to coordinate\ndescent (CD) methods on convex functions and (b) randomized solvers designed for solving\nconsistent linear systems.\nWhen A is positive definite, Gauss-Seidel can be interpreted as an instance of coordinate descent on a strongly convex quadratic function. We therefore review related work\non both non-accelerated and accelerated coordinate descent, focusing on the randomized\nsetting instead of the more classical cyclic order or Gauss-Southwell rule for selecting the\nnext coordinate. See [71] for a discussion on non-random selection rules, [49] for a comparison of random selection versus Gauss-Southwell, and [50] for efficient implementations of\nGauss-Southwell.\nNesterov’s original paper in [42] first considered randomized CD on convex functions,\nassuming a partitioning of coordinates fixed ahead of time. The analysis included both nonaccelerated and accelerated variants for convex functions. This work sparked a resurgence of\ninterest in CD methods for large problems. Most relevant to our paper are extensions to the\nblock setting [63], handling arbitrary sampling distributions [55, 56, 18], and second order\nupdates for quadratic functions [57].\nFor accelerated CD, Lee and Sidford [29] generalize the analysis of Nesterov [42]. While\nthe analysis of [29] was limited to selecting a single coordinate at a time, several follow on\nworks [55, 32, 35, 17] generalize to block and non-smooth settings. More recently, both\nAllen-Zhu et al. [1] and Nesterov and Stich [48] independently improve the results of [29]\nby using a different non-uniform sampling distribution. One of the most notable aspects of\nthe analysis in [1] is a departure from the (probabilistic) estimate sequence framework of\nNesterov. Instead, the authors construct a valid Lyapunov function for coordinate descent,\nalthough they do not explicitly mention this. In our work, we make this Lyapunov point of\nview explicit. The constants in our acceleration updates arise from a particular discretization\nand Lyapunov function outlined from Wilson et al. [77]. Using this framework makes our\nproof particularly transparent, and allows us to recover results for strongly convex functions\nfrom [1] and [48] as a special case.\nFrom the numerical analysis side both the Gauss-Seidel and Kaczmarz algorithm are\nclassical methods. Strohmer and Vershynin [69] were the first to prove a linear rate of\nconvergence for randomized Kaczmarz, and Leventhal and Lewis [31] provide a similar kind of\n\nCHAPTER 3. STOCHASTIC DIFFERENTIAL EQUATIONS\n\n76\n\nanalysis for randomized Gauss-Seidel. Both of these were in the single constraint/coordinate\nsetting. The block setting was later analyzed by Needell and Tropp [38]. More recently,\nGower and Richtárik [20] provide a unified analysis for both randomized block Gauss-Seidel\nand Kaczmarz in the sketching framework. We adopt this framework in this paper. Finally,\nLiu and Wright [33] provide an accelerated analysis of randomized Kaczmarz once again in\nthe single constraint setting and we extend this to the block setting.\n\n3.4.5\n\nExperiments\n\nIn this section we experimentally validate our theoretical results on how our accelerated\nalgorithms can improve convergence rates. Our experiments use a combination of synthetic\nmatrices and matrices from large scale machine learning tasks.\nSetup. We run all our experiments on a 4 socket Intel Xeon CPU E7-8870 machine with\n18 cores per socket and 1TB of DRAM. We implement all our algorithms in Python using\nnumpy, and use the Intel MKL library with 72 OpenMP threads for numerical operations.\nWe report errors as relative errors, i.e. kxk − x∗ k2A /kx∗ k2A . Finally, we use the best values of\nμ and ν found by tuning each experiment.\nWe implement fixed partitioning by creating random blocks of coordinates at the beginning of the experiment and cache the corresponding matrix blocks to improve performance.\nFor random coordinate sampling, we select a new block of coordinates at each iteration.\nFor our fixed partition experiments, we restrict our attention to uniform sampling. While\nGower and Richtárik [20] propose a non-uniform scheme based on Tr(S T AS), for translationinvariant kernels this reduces to uniform sampling. Furthermore, as the kernel block Lipschitz\nconstants were also roughly the same, other non-uniform schemes [1] also reduce to nearly\nuniform sampling.\n3.4.5.1\n\nFixed partitioning vs random coordinate sampling\n\nOur first set of experiments numerically verify the separation between fixed partitioning\nsampling versus random coordinate sampling.\nFigure 3.1 shows the progress per iteration on solving A1,β x = b, with the A1,β defined in\nSection 3.4.3.1. Here we set n = 5000, p = 500, β = 1000, and b ∼ N (0, I). Figure 3.1 verifies\nour analytical findings in Section 3.4.3.1, that the fixed partition scheme is substantially\nworse than uniform sampling on this instance. It also shows that in this case, acceleration\nprovides little benefit in the case of random coordinate sampling. This is because both μ and\n1/ν are order-wise p/n, and hence the rate for accelerated and non-accelerated coordinate\ndescent coincide. However we note that this only applies for matrices where μ is as large\nas it can be (i.e. p/n), that is instances for which Gauss-Seidel is already converging at the\noptimal rate (see [20], Lemma 4.2).\n\nCHAPTER 3. STOCHASTIC DIFFERENTIAL EQUATIONS\nMNIST Random Features, n=5000\n\nId+RankOne, n=5000, p=500\n\n100\n\n77\n\np = 1000\np = 800\n\n10−6\n10−9\n\nBlock Size\n\nkxk − x∗k2A/kx∗k2A\n\n10−3\n\n10−12\n10−15\n\nGS Fixed Partition\nGS-Acc Fixed Partition\nGS Random Coordinates\nGS-Acc Random Coordinates\n\n10−18\n10−21\n10−24\n10−27\n10−30\n\n0\n\n100\n\n200\n\n300\n\nIteration\n\n400\n\np = 500\np = 200\np = 100\np = 50\n0.0\n\n500\n\nFigure 3.1: Experiments comparing fixed\npartitions versus random coordinate sampling for the example from Section 3.4.3.1\nwith n = 5000 coordinates, block size\np = 500.\n\n1.0\n\n1.5\n\n2.0\n\n2.5\n\n3.0\n\n3.5\n\n4.0\n\n4.5\n\nTime (s) to 10−5 error\n\nFigure 3.2: The effect of block size on the\naccelerated Gauss-Seidel method. For the\nMNIST dataset (pre-processed using random features) we see that block size of\np = 500 works best.\n\nCIFAR-10 KRR, n=250k, p=10k\n\n100\n\n0.5\n\nCIFAR-10 KRR, n=250k, p=10k\n\n100\n10−1\n10−2\n\n10−2\n\n10−4\n10−5\n10−6\n\n0\n\n100\n\n200\n\n300\n\nIteration\n\n400\n\n500\n\nFigure 3.3: Experiments comparing fixed\npartitions versus uniform random sampling for CIFAR-10 augmented matrix\nwhile running kernel ridge regression.\nThe matrix has n = 250000 coordinates\nand we set block size to p = 10000.\n\n3.4.5.2\n\nGS Fixed Partition\nGS-Acc Fixed Partition\nGS Random Coordinates\nGS-Acc Random Coordinates\nConjugate Gradient\n\n10−3\n\nGS Fixed Partition\nGS-Acc Fixed Partition\nGS Random Coordinates\nGS-Acc Random Coordinates\n\n10−3\n\n10−4\n\nkxk − x∗k2A/kx∗k2A\n\nkxk − x∗k2A/kx∗k2A\n\n10−1\n\n0\n\n1000\n\n2000\n\n3000\n\n4000\n\nTime (s)\n\n5000\n\n6000\n\n7000\n\nFigure 3.4: Comparing conjugate gradient with accelerated and un-accelerated\nGauss-Seidel methods for CIFAR-10 augmented matrix while running kernel ridge\nregression. The matrix has n = 250000\ncoordinates and we set block size to p =\n10000.\n\nKernel ridge regression\n\nWe next evaluate how fixed partitioning and random coordinate sampling affects the performance of Gauss-Seidel on large scale machine learning tasks. We use the popular image\n\nCHAPTER 3. STOCHASTIC DIFFERENTIAL EQUATIONS\n\n78\n\nclassification dataset CIFAR-10 and evaluate a kernel ridge regression (KRR) task with a\nGaussian kernel. Specifically, given a labeled dataset {(xi , yi )}ni=1 , we solve the linear system\n(K + λI)α = Y with Kij = exp(−γkxi − xj k22 ), where λ, γ > 0 are tunable parameters (see\ne.g. [67] for background on KRR). The key property of KRR is that the kernel matrix K is\npositive semi-definite, and hence Algorithm 1 applies.\nFor the CIFAR-10 dataset, we augment the dataset1 to include five reflections, translations per-image and then apply standard pre-processing steps used in image classification [12,\n68]. We finally apply a Gaussian kernel on our pre-processed images and the resulting kernel\nmatrix has n = 250000 coordinates.\nResults from running 500 iterations of random coordinate sampling and fixed partitioning\nalgorithms are shown in Figure 3.3. Comparing convergence across iterations, similar to\nprevious section, we see that un-accelerated Gauss-Seidel with random coordinate sampling is\nbetter than accelerated Gauss-Seidel with fixed partitioning. However we also see that using\nacceleration with random sampling can further improve the convergence rates, especially to\nachieve errors of 10−3 or lower.\nWe also compare the convergence with respect to running time in Figure 3.4. Fixed\npartitioning has better performance in practice random access is expensive in multi-core\nsystems. However, we see that this speedup in implementation comes at a substantial cost\nin terms of convergence rate. For example in the case of CIFAR-10, using fixed partitions\nleads to an error of 1.2 × 10−2 after around 7000 seconds. In comparison we see that random\ncoordinate sampling achieves a similar error in around 4500 seconds and is thus 1.5× faster.\nWe also note that this speedup increases for lower error tolerances.\n3.4.5.3\n\nComparing Gauss-Seidel to Conjugate-Gradient\n\nWe also compared Gauss-Seidel with random coordinate sampling to the classical conjugategradient (CG) algorithm. CG is an important baseline to compare with, as it is the de-facto\nstandard iterative algorithm for solving linear systems in the numerical analysis community.\nWhile we report the results of CG without preconditioning, we remark that the performance\nusing a standard banded preconditioner was not any better. However, for KRR specifically,\nthere have been recent efforts [5, 65] to develop better preconditioners, and we leave a\nmore thorough comparison for future work. The results of our experiment are shown in\nFigure 3.4. We note that Gauss-Seidel both with and without acceleration outperform CG.\nAs an example, we note that to reach error 10−1 on CIFAR-10, CG takes roughly 7000\nseconds, compared to less than 2000 seconds for accelerated Gauss-Seidel, which is a 3.5×\nimprovement.\nTo understand this performance difference, we recall that our matrices A are fully dense,\nand hence each iteration of CG takes O(n2 ). On the other hand, each iteration of both\nnon-accelerated and accelerated Gauss-Seidel takes O(np2 + p3 ). Hence, as long as p =\nO(n2/3 ), the time per iteration of Gauss-Seidel is order-wise no worse than CG. In terms of\n1\n\nSimilar to https://github.com/akrizhevsky/cuda-convnet2.\n\nCHAPTER 3. STOCHASTIC DIFFERENTIAL EQUATIONS\n\n79\n\n√\niteration complexity, standard results state that CG takes at most O( κ log(1/ε)) iterations\nto reach an ε error solution, where κ denotes the condition number of A. On the other\nmax\nAii\n. In the case\nhand, Gauss-Seidel takes at most O( np κeff log(1/ε)), where κeff = λ1≤i≤n\nmin (A)\nof any (normalized) kernel matrix associated with a translation-invariant kernel such as the\nGaussian kernel, we have max1≤i≤n Aii = 1, and hence generally speaking κeff is much lower\nthan κ.\n3.4.5.4\n\nKernel ridge regression on smaller datasets\n\nIn addition to using the large CIFAR-10 augmented dataset, we also tested our algorithms\non the smaller MNIST2 dataset. To generate a kernel matrix, we applied the Gaussian kernel\non the raw MNIST pixels to generate a matrix K with n = 60000 rows and columns.\nResults from running 500 iterations of random coordinate sampling and fixed partitioning\nalgorithms are shown in Figure 3.5. We plot the convergence rates both across time and\nacross iterations. Comparing convergence across iterations we see that random coordinate\nsampling is essential to achieve errors of 10−4 or lower. In terms of running time, similar\nto the CIFAR-10 experiment, we see that the benefits in fixed partitioning of accessing\ncoordinates faster comes at a cost in terms of convergence rate, especially to achieve errors\nof 10−4 or lower.\nMNIST KRR, n=60000, p=4000\n\n100\n\n10−1\n\nkxk − x∗k2A/kx∗k2A\n\nkxk − x∗k2A/kx∗k2A\n\n10−1\n\n10−2\n\n10−2\n10−3\n\n10−3\n\nGS Fixed Partition\nGS-Acc Fixed Partition\nGS Random Coordinates\nGS-Acc Random Coordinates\n\n10−4\n10−5\n10−6\n\nMNIST KRR, n=60000, p=4000\n\n100\n\n10−5\n10−6\n\n0\n\n100\n\n200\n\n300\n\nIteration\n\n400\n\nGS Fixed Partition\nGS-Acc Fixed Partition\nGS Random Coordinates\nGS-Acc Random Coordinates\n\n10−4\n\n500\n\n0\n\n200\n\n400\n\n600\n\nTime (s)\n\n800\n\n1000\n\n1200\n\nFigure 3.5: Experiments comparing fixed partitions versus uniform random sampling for\nMNIST while running kernel ridge regression. MNIST has n = 60000 coordinates and we\nset block size to p = 4000.\n\n3.4.5.5\n\nEffect of block size\n\nWe next analyze the importance of the block size p for the accelerated Gauss-Seidel method.\nAs the values of μ and ν change for each setting of p, we use a smaller MNIST matrix for\nthis experiment. We apply a random feature transformation [60] to generate an n × d matrix\n2\n\nhttp://yann.lecun.com/exdb/mnist/\n\nCHAPTER 3. STOCHASTIC DIFFERENTIAL EQUATIONS\nLinearly Spaced Eigenvalues\n\n102\n\nRandom Wishart\n\n102\n\n80\nDeterministic Structured Matrices\n\n103\n\nSobolev\nCirculant\nTridiag\n\n101\n\nν\n\n101\n\nν\n\nν\n\n102\n\n101\nκ = 10\nκ = 100\nκ = 1000\n100\n\n0\n\n2\n\n4\n\nm = 18\nm = 20\nm = 22\n6\n\n8\n\n10\n\nBlock size (p)\n\n12\n\n14\n\n16\n\n100\n\n0\n\n2\n\n4\n\n6\n\n8\n\n10\n\nBlock size (p)\n\n12\n\n14\n\n16\n\n100\n\n0\n\n2\n\n4\n\n6\n\n8\n\n10\n\nBlock size (p)\n\n12\n\n14\n\n16\n\nFigure 3.6: Comparison of the computed ν constant (solid lines) and ν bound from Theorem 3.4.5 (dotted lines) on random matrices with linearly spaced eigenvalues and random\nWishart matrices.\nF with d = 5000 features. We then use A = F T F and b = F T Y as inputs to the algorithm.\nFigure 3.2 shows the wall clock time to converge to 10−5 error as we vary the block size from\np = 50 to p = 1000.\nIncreasing the block-size improves the amount of progress that is made per iteration\nbut the time taken per iteration increases as O(p3 ) (Line 5, Algorithm 1). However, using\nefficient BLAS-3 primitives usually affords a speedup from systems techniques like cache\nblocking. We see the effects of this in Figure 3.2 where using p = 500 performs better than\nusing p = 50. We also see that these benefits reduce for much larger block sizes and thus\np = 1000 is slower.\n3.4.5.6\n\nComputing the μ and ν constants\n\nIn our last experiment, we explicitly compute the μ and ν constants from Theorem 3.4.5 for\na few 16 × 16 positive definite matrices constructed as follows.\nLinearly spaced eigenvalues. We first draw Q uniformly at random from n×n orthogonal\nmatrices. We then construct Ai = QΣi QT for i = 1, 2, 3, where Σ1 is diag(linspace(1,\n10, 16)), Σ2 is diag(linspace(1, 100, 16)), and Σ3 is diag(linspace(1, 1000, 16)).\nRandom Wishart. We first draw Bi with iid N (0, 1) entries, where Bi ∈ Rmi ×16 with\nm1 = 18, m2 = 20, and m3 = 22. We then set Ai = BiT Bi .\nSobolev kernel. We form the matrix Aij = min(i, j) with 1 ≤ i, j ≤ n. This corresponds\nto the gram matrix for the set of points x1 , ..., xn ∈ R with xi = i under the Sobolev kernel\nmin(x, y).\nCirculant matrix. We let A be a 16 × 16 instance of the family of circulant matrices\nAn = Fn diag(cn )Fn∗ where Fn is the n × n unitary DFT matrix and cn = (1, 1/2, ..., 1/(n/2 +\n1), ..., 1/2, 1). By construction this yields a real valued circulant matrix which is positive\ndefinite.\nTridiagonal matrix. We let A be a tridiagonal matrix with the diagonal value equal to\none, and the off diagonal value equal to (δ − a)/(2 cos(πn/(n + 1))) for δ = 1/10. The matrix\n\nCHAPTER 3. STOCHASTIC DIFFERENTIAL EQUATIONS\n\n81\n\nhas a minimum eigenvalue of δ.\nFigure 3.6 shows the results of our computation for the linearly spaced eigenvalues ensemble, the random Wishart ensemble and the other deterministic structured matrices. Alongside with the actual ν values, we plot the bound given for each instance by Lemma 3.4.8.\nFrom the figures we see that our bound is quite close to the computed value of ν for circulant\nmatrices and for random matrices with linearly spaced eigenvalues with small κ. We plan to\nextend our analysis to derive a tighter bound in the future.\n\n3.4.6\n\nConclusion\n\nIn this paper, we extended the accelerated block Gauss-Seidel algorithm beyond fixed partition sampling. Our analysis introduced a new data-dependent parameter ν which governs\nthe speed-up of acceleration. Specializing our theory to random coordinate sampling, we\nderived an upper bound on ν which shows that well conditioned blocks are a sufficient condition to ensure speedup. Experimentally, we showed that random coordinate sampling is\nreadily accelerated beyond what our bound suggests.\nThe most obvious question remains to derive a sharper bound on the ν constant from\nTheorem 3.4.5. Another interesting question is whether or not the iteration complexity of\nrandom coordinate sampling is always bounded above by the iteration complexity with fixed\ncoordinate sampling.\nWe also plan to study an implementation of accelerated Gauss-Seidel in a distributed\nsetting [72]. The main challenges here are in determining how to sample coordinates without\nsignificant communication overheads, and to efficiently estimate μ and ν. To do this, we\nwish to explore other sampling schemes such as shuffling the coordinates at the end of every\nepoch [62].\n\n3.5\n\nSummary\n\nThe Lyapunov framework we have discussed in this thesis is an especially nice way of viewing\nconvergence theory in optimization. Many algorithms in optimization are significantly less\nmysterious when viewed through the lens of dynamical systems. The Lyapunov framework\nalso makes the introduction of new analyses seamless. As a simple example, most of the nonasymptotic results for coordinate methods can be extended to geodesic spaces, for geodesic\n(smooth/strong)-convex functions, using the Lyapunov framework. There are many other\nexamples as well.\n\n82\n\nAppendix A\nChapter One\nA.1\n\nExamples of Optimization Problems\n\nExample A.1.1 (Planning). The decision variable is an action, the set X represents all the\nactions under consideration, and the objective function f : X → R assigns a cost to each\naction. The optimization problem is to find an action with minimal cost.\nAs a specific example, consider the problem of reasoning about choosing a path to reach\na destination. In this instance, X is the set of easible paths from our starting position to\nthe desired location and the functions f (x) measures the cost to travel on path x. Solving\nthe optimization problem finds the path with minimal cost. Another example is choosing\na project from a set of proposals X . In this example, the function maps each proposal to\nan estimate of its negative profit. Solving the optimization problem finds the project that\nmaximizes the profit, x∗ ∈ arg minx∈X f (x).\nExample A.1.2 (Empricial Risk Minimization). The decision variable x is a function, the\nset X imposes assumptions on the function class, and the objective function is the prediction\nerror when evaluated on an observe dataset. The optimization problem is to find the function\nx with minimal prediction error on the observed data.\nAs a specific example, consider the goal of providing images with short descriptions, or\nlabels. In machine learning, the task is posed as finding a function x∗ ∈ arg minx∈X f (x) that\nminimizes a functional, where each function x ∈ X maps images to labels. The functional\nto be minimized, called the empirical risk, measures the error of each function x ∈ X when\nevaluated on some observed data z. Thus, the problem is posed as finding the function which\nperforms best on the observed dataset, with the hope that the classifier will perform well\nmore generally.\nExample A.1.3 (Maximum likelihood). The decision variable x is a vector of parameters\nof a probabilistic model, the X is the set of possible parameters, and the objective function\nf is the negative log-likelihood of the observed data. The optimization problem is to find the\nparameters x which maximizes the likelihood of the observed data\n\nAPPENDIX A. CHAPTER ONE\n\n83\n\nAs a specific example, consider the inverse problem in scientific measurement. In this\nexample, the negative log-likelihood f (x) = − log p(z; x) encodes the probability of observing\nthe noisy measurement z when the ground-truth object is x. The maximum likelihood\nproblem is to find the ground-truth object x, from some restricted set X , that maximizes\nthe likelihood of observing z.\nExample A.1.4 (Robust/worst-case Planning). The decision variable x is an action being\ntaken by some adversarial entity, the set X are the actions the adversary can make, and\nthe objective function f is the gain or loss received due to the adversary’s actions. The\noptimization problem is to find the worst-case loss due to an adversary’s actions.\n\nA.2\n\nGlossary of Definitions\n\nIn this section we discuss several basic concepts from calculus and geometry that will be\nused repeatedly in proofs of convergence. For many readers, most of this material will be\nfamiliar and can be referred to only when necessary.\nCalculus In this section we take X = Rd , but many of the definitions we discuss can\nextended to convex, compact sets X ⊆ Rd in a natural way. Let f : Rd → R be continuously\ndifferentiable as many times as necessary. Recall that the Taylor series is a representation of\na function as an infinite sum of terms, calculated from the values of the function’s derivatives\nat a single point. In particular, for an integer p ≥ 2, the (p−1)-st order Taylor approximation\nof f centered at x ∈ Rd is the (p − 1)-st degree polynomial\nfp−1 (y; x) =\n\np−1\nX\n1\ni=0\n\ni!\n\n∇i f (x)(y − x)i = f (x) + h∇f (x), y − xi + · · · +\n\n1\n∇p−1 f (x)(y − x)p−1 .\n(p − 1)!\n(A.1)\n\nThe Taylor series provides a way to approximate any function using a finite number of\npolynomial terms. We call the difference between the function f at a point y and its firstorder Taylor series approximation at a point x the Bregman divergence of f ,\nDf (y, x) = f (y) − f (x) − h∇f (x), y − xi.\n\n(A.2)\n\nNote, Df (y, x) ≈ hy − x, ∇2 f (x)(y − x)i. If f is convex its Bregman divergence (A.2) is\nnon-negative,\nDf (y, x) ≥ 0.\n\n(A.3)\n\n(A.3) is equivalent to the condition that ∀x, y ∈ X , any intermediate value is at most the\naverage value (Jensen’s inequality)\nf (λx + (1 − λ)y) ≤ λf (x) + (1 − λ)f (y)\n\n(A.4)\n\nAPPENDIX A. CHAPTER ONE\n\n84\n\nTo elaborate, when X = Rd , convexity is the condition that the first-order Taylor approximation, f (x) + h∇f (x), y − xi, is a global underestimator of the function. If ∇f (x) = 0\nin (A.2), this implies the property f (x) ≤ f (y), ∀x ∈ Rd , and subsequently that x is a global\nminimizer of the function. Therefore, if f is convex, the local condition ∇f (x) = 0, implies\nthat x is a solution to (1.1). A function f is strictly convex if the inequality in (A.4) and\n(A.3) is strict (> and not ≥) ∀x 6= y. For strictly convex functions, the local condition,\n∇f (x) = 0, implies the global property, x is the unique solution to (1.1).\nWe say f is μ-uniformly convex (p ≥ 2) if\nDf (y, x) ≥\n\nμ\nky − xkp .\np\n\n(A.5)\n\nWhen p = 2, the condition (A.5) is called strong convexity,\nDf (y, x) ≥\n\nμ\nky − xk2 .\n2\n\n(A.6)\n\nLet h : Rd → R be a strictly convex, differentiable function. We say f is μ-strongly convex\nwith respect to a strictly convex function h, if for ∀x, y ∈ X it satisfies,\nDf (y, x) ≥ μDh (y, x).\n\n(A.7)\n\nIf h(x) = 21 kxk2 then (A.6) and (A.7) are equivalent. Furthermore, if h(x) = p1 kxkp , h\nsatisfies (A.5) with μ = 2−p+2 . Therefore if f is strongly convex with respect to the Bregman\ndivergence generated by h(x) = p1 kxkp (A.7), it is satisfies (A.5).\nDefinition A.2.1 (Geodesic). We can think of a geodesic as a generalization of the straightline distance to curved metric spaces X . More precisely, we define the length of a path\nγ : [0, 1] → X as\nDefinition A.2.2 (Geodesic Space). If for every pair points x, y ∈ X there is a geodesic in\nX connecting them, X is called a geodesic space.\nDefinition A.2.3 (Geodesic Convexity). A function is geodesically convex if for any x, y ∈\nX , a geodesic γ such that γ(0) = x and γ(1) = y, and t ∈ [0, 1], it holds that\nf (y) − f (x) ≥ h∇f (x), logx (y)ix ,\n\n(A.8)\n\nwhere ∇f (x) is the gradient of f at x. It is geodesically convex along its i-th component if\nit satisfies\nDfi (y, x) := f (y) − f (x) − h∇i f (x), logx (y)ix ≤ 0,\n\n(A.9)\n\nDefinition A.2.4 (Geodesically Smooth). A function is geodesically L-smooth if for any\nx, y ∈ X , a geodesic γ such that γ(0) = x and γ(1) = y, and t ∈ [0, 1], it holds that,\nf (y) − f (x) ≤ h∇f (x), logx (y)ix +\n\nL 2\nd (x, y)\n2\n\n(A.10)\n\nAPPENDIX A. CHAPTER ONE\n\n85\n\nwhere ∇f (x) is the gradient of f at x. It is geodesically Li - smooth along its i-th component\nif it satisfies\nf (y) − f (x) ≤ h∇i f (x), logx (y)ix +\n\nLi 2\nd (x, y)\n2\n\n(A.11)\n\nSmoothness Smoothness is a property which measures the number of continuous derivatives a function has. In particular, we say say that f is L-smooth of order p, where p is\na positive integer, if f is p-times continuously differentiable and ∇p f is L-Lipschitz, which\nmeans for all x, y ∈ Rd ,\nk∇p f (y) − ∇p f (x)k∗ ≤ Lky − xk.\n\n(A.12)\n\nNotable cases are when p = 0, in which case the function is Lipschitz, and when p = 1, in\nwhich case the function has Lipschitz gradients. If f satisfies (A.12) with p = 1, we call the\nfunction smooth. If f is smooth we can also write,\nDf (y, x) ≤\n\nL\nky − xk2 .\n2\n\n(A.13)\n\nA natural generalization of (A.13) is the condition that f be L-smooth with respect to a\nstrictly convex function h,\nDf (y, x) ≤ LDh (y, x).\n\n(A.14)\n\nA natural generalization of (A.12), is that f have (ν, L)-Hölder continuous gradients of order\np,\nk∇p f (y) − ∇p f (x)k∗ ≤ Lky − xkν .\n\n(A.15)\n\nwhere ν ∈ [0, 1]. If f has (ν, L)-Hölder continuous gradients of order p = 2, we can write\nDf (x, y) ≤\n\nL\nkx − yk1+ν\n1+ν\n\n(A.16)\n\nFor convex functions on a vector space, the subgradient generalizes the notion of a\nderivative to functions which are not differentiable. The subdifferential of f at a point x is\nthe set of subgradients,\n∂f (x) := {g(x) ∈ Rd : f (y) ≥ f (x) + hg(x), y − xi\n\n∀y ∈ Rd }.\n\n(A.17)\n\nWe also write k∂f (x)k∗ := supg(x)∈∂f (x) kg(x)k∗ . For any element of the subdifferential\ng(x) ∈ ∂f (x), we define the short-hand,\nDfg (y, x) := f (y) − f (x) − hg(x), y − xi.\n\n(A.18)\n\nAPPENDIX A. CHAPTER ONE\n\n86\n\nIf f is convex, then (A.18) is non-negative Dfg (y, x) ≥ 0, ∀g ∈ ∂f (x). Given convex\nfunctions are locally Lipschitz, ∂f (x) is compact for any x. Therefore, there always exists a\ndirectional subgradient for a convex function.\nWe use an analogous notation to (A.18) to define the Bregman divergence defined for the\ngradient along the i-th coordinate of x ∈ X :\nDfi (y, x) := f (y) − f (x) − h∇i f (x), y − xi.\n\n(A.19)\n\nWe say that a function f is convex along its ith-coordinate if,\nDfi (y, x) ≥ 0.\n\n(A.20)\n\nWe say a function f is Li -smooth along its i-th coordinate if,\nDfi (y, x) ≤\n\nLi\nky − xk2 .\n2\n\n(A.21)\n\nNotation We denote a discrete-time sequence in lower case, e.g., xk with k ≥ 0 an integer.\nWe denote a continuous-time curve in upper case, e.g., Xt with t ∈ R. An over-dot means\nderivative with respect to time, i.e., Ẋt = dtd Xt .\nRiemannian Manifolds For many applications, it is important to be able to optimize\nover spaces that are more general than Rn . One family of spaces we consider in this thesis\nare spaces that locally look like Rn , but not globally. A typical example is the sphere, which\nonly locally looks flat. In order to define the notion of continuity of the functions on X , it\nis important that X be topological space; this way a notion of “nearby” can be well-defined\nusing open sets. We also require X have enough structure so that it is easy to tell when\nf : X → R is smooth. Technically speaking, we assume there exists smooth charts covering\nX (i.e. an atlas) in addition to the collection of open sets. Such spaces are called smooth\nmanifolds.\nThe last requirement involves the existence of what is called a vector field, which is a space\nof vectors tangent to each x ∈ X ; this requirement provides us with the notion of a directional\nderivative for any f : X → R, which will be a requirement for the existence of various families\nof dynamical systems that find a solution to (1.1). We call the subspace of vectors tangent to\nx the tangent space, Tx X . Finally, we require the existence of a symmetric, positive definite,\nbilinear form, gx : Tx X × Tx X → R, which measures the distance between any two vectors\nin Tx X , and which varies smoothly as a function of x. Together, (X , gX ) is called a smooth\nRiemannian manifold.\nFinally, we mention the cotangent space T∗x X , which is the dual vector space to Tx X\n(i.e. the space of linear functionals on Tx X ). The gradient, for example, is an element of\nthe cotangent space, which defines the directional derivative of f :\nf (x + δv) − f (x)\nδ→0\nδ\n\nh∇f (x), vi ≡ f 0 (x, v) := lim\n\n(A.22)\n\nAPPENDIX A. CHAPTER ONE\n\n87\n\nThe metric gx can be viewed as a mapping between the dual spaces Tx X and Tx X ∗ ,\ngx : Tx X → Tx X ∗\nv 7→ gx (v, ·).\nGiven gx is positive definite ∀x ∈ X and dim(Tx X ) = dim(Tx X ∗ ), it has a well-defined\ninverse g−1 : Tx X ∗ → Tx X . The inverse metric will be useful for defining vector fields in\nTx X using elements of the cotangent space Tx X ∗ .\nWe can extend the notion of directional derivatives to non-differentiable functions as well.\nIn particular, the directional subgradient of f , for ∀x, v ∈ Rd is a Borel measurable function\n∂f (x; v) given by,\nf (x + δv) − f (x)\n= sup hg, vi\nδ→0\nδ\ng∈∂f (x)\n\nh∂f (x), vi ≡ ∂f (x; v) := lim\n\n(A.23)\n\nIf f : X → R and X ⊂ Rn is convex, then the subgradient is guaranteed to exist, ∂f (x) 6= ∅,\nfor every x ∈ int(X ) [64].\nDuality As suggested by the previous paragraph, the dual correspondence between a function f and its convex dual (or conjugate) function f ∗ , given by the Legendre-Fenchel transform, plays an important role in mathematics and optimization. Formally, if X is a vector\nspace, its dual vector space X ∗ is the space of linear functionals, which itself forms a vector\nspace under point-wise addition and scalar multiplication.\nLet f : X → R. The Legendre-Fenchel transform of f is the function f ∗ : X → R given\nby,\nf ∗ (g) = sup{hg, xi − f (x)}.\n\n(A.24)\n\nx∈X\n\nAs f ∗ is the supremum of linear functions, it is convex and (f ∗ )∗ = f . If g ∈ X ∗ is of the\nform g = ∇f (x) for some x ∈ X , then the supremum in (A.24) is achieved, and we obtain\nthe identity, f ∗ (∇f (x)) = h∇f (x), xi − f (x). By differentiating this identity, we are able to\nconclude that ∇f : X ∗ → X is the inverse of ∇f : X → X ∗ , i.e. that ∇f ∗ (∇f (x)) = x. As\na specific example of duality, consider the standard inner product h·, ·i on Rd which defines\na norm k · k on Rd . Its dual k · k∗ is defined as, kgk∗ = supx∈Rd {hx, gi : kxk ≤ 1}. More\ngenerally, Young’s inequality,\np\np−1\n1\nkgk∗p−1 ,\nhg, xi + kxkp ≥ −\np\np\n\n(A.25)\n\ndemonstrates another special case of the duality relation hg, xi ≤ f ∗ (g) + f (x), where f (x) =\nxp /p, f ∗ (g) = g q /q and 1/p + 1/q = 1. A final dual relationship that will be used in several\nproofs is Cauchy-Schwartz’s inequality on a Hilbert space X ,\n|hx, yi| ≤ kxk2 kyk2 , ∀x, y ∈ X\n\n(A.26)\n\nAPPENDIX A. CHAPTER ONE\n\n88\n\nProperties of Bregman Divergences The Bregman three-point identity,\nh∇h(z) − ∇h(x), x∗ − zi + Dh (x∗ , z) = Dh (x∗ , x) − Dh (z, x),\n\n(A.27)\n\nwhich holds for all x∗ , z, x ∈ X , will be used many times througout the text. We also need\nto make use of the Bregman projection onto a set X . Formally, let X ⊆ Rn and Xt =\narg minx∈X Dh (x, Yt ) be the Bregman projection of Yt onto X . For all x ∈ X , it follows\nDh (x, Xt ) ≤ Dh (x, Yt ) − Dh (Xt , Yt )\n\n(A.28)\n\nFurthermore, the Bregman projection is unique.\nAnother property of Bregman divergence that will make use of is the following dual relationship\nDh∗ (x, y) = Dh (∇h∗ (y), ∇h∗ (x))\nfor all x, y ∈ X , where h∗ is the fenchel conjugate (A.24) to h.\n\n(A.29)\n\n89\n\nAppendix B\nChapter Two\nB.1\n\nGradient Descent\n\nB.1.1\n\nPolyak-Löjasiewicz Condition\n\nIf the objective function satisfies the Polyak-Löjasiewicz (PL) condition with parameter μ,\nwe can conclude the following for the optimality gap Ẽt = f (Xt ) − f (x∗ ),\n(2.1)\nd (2.6)\nẼt = −k∇f (Xt )k2 ≤ −2μ(f (Xt ) − f (x∗ )) ≤ −2μẼt .\ndt\n\n(B.1)\n\nEt = e2μt (f (Xt ) − f (x∗ )),\n\n(B.2)\n\nTherefore\n\nis a Lyapunov function for any function which satisfies the PL-condition with parameter μ.\n(B.1)\nRt d\nOne can check, dtd Et = 2μe2μt Ẽt + e2μt dtd Ẽt = e2μt (2μẼt + dtd Ẽt ≤ 0. Integrating 0 ds\nEs ds =\n−μt\nEt − E0 ≤ 0 allows us to conclude a O(e ) convergence rate,\nf (Xt ) − f (x∗ ) ≤ e−2μt E0 .\nWe can obtain similar statement for GD and PM.\nGradient Descent For GD, as long as the function is L-smooth, where 1/δ ≤ L, and the\nPL inequality holds, we can conclude the following for the optimality gap, Ẽk = f (xk )−f (x∗ ).\nWe check,\n(2.1)\nẼk+1 − Ẽk (2.8) 2 − δL\n≤ −\nk∇f (xk )k2 ≤ −μ(2 − δL)(f (xk ) − f (x∗ )) ≤ −μ(2 − δL)Ẽk\nδ\n2\nTaking 1/δ = L and denoting the inverse coniditon number, κ−1 = μ/L = μδ, we obtain the\nbound Ẽk+1δ−Ẽk ≤ −μẼk from which we can conclude\n\nEk = (1 − (μδ))−k (f (xk ) − f (x∗ )),\n\nAPPENDIX B. CHAPTER TWO\n\n90\n\nis a Lyapunov function.1 Summing allows us to conclude an O(e−μδk ) ≈ O((e−μδ )k ) ≈\nO((1 − μδ)k ) convergence rate,\nf (xk ) − f (x∗ ) ≤ (1 − κ−1 )k E0 .\nProximal Method For the PM, similar arguments can be made assuming the PolyakLöjasiewicz condition by using the discrete optimality gap Ẽk = f (xk ) − f (x∗ ),\n(2.1)\nẼk+1 − Ẽk (2.9) 1\n≤ − k∇f (xk+1 )k2 ≤ −μ(f (xk+1 ) − f (x∗ )) = −μẼk+1 .\nδ\n2\n\nThus, the recurrence, Ẽk+1 − Ẽk ≤ −κ−1 Ẽk+1 shows that\nEk = (1 + κ−1 )k (f (xk ) − f (x∗ )),\nis a Lyapunov function, where κ−1 = μδ.2 By summing, we can conclude a O(e−μδk ) ≈\nO((eμδ )−k ) ≈ O((1 + μδ)−k ) convergence rate\nf (xk ) − f (x∗ ) ≤ (1 + κ−1 )−k E0 .\nIn moving from continuous to discrete-time, we lose a factor of two on the bound.\n\nB.1.2\n\nStrongly Convex Functions\n\nWhen the objective function is μ-strongly convex (A.6), it satisfies the PL inequality; thus,\nthe analysis from the previous section applies. Another Lyapunov function is the scaled\ndistance function on Euclidean space,\n1\nEt = eμt kx∗ − Xt k2 .\n2\n\n(B.3)\n\nTo see this, we define Ẽt = 12 kx∗ − Xt k2 , and note\nd\n(2.2)\nẼt = −hẊt , x∗ − Xt i = h∇f (Xt ), x∗ − Xt i\ndt\n(A.6)\n1\n≤ −μ kx∗ − Xt k2 = −μẼt ;\n2\ntherefore the Lyapunov property is easy to check: dtd Et = eμt ( dtd Ẽt + μẼt ) ≤ 0. The Lyapunov\nproperty, Et ≤ E0 , for (B.3) allows us to conclude\n1 ∗\nkx − Xt k2 ≤ e−μt E0 .\n2\nWe can obtain a similar statement for GD and GF.\n1\n\nOne can check, Ek+1δ−Ek = (1−μδ)−(k+1) Ẽk+1 /δ−(1−μδ)−k Ẽk /δ = (1−μδ)−(k+1) (μẼk + Ẽk+1δ−Ẽk ) ≤ 0\n\n2\n\nOne can check, Ek+1δ−Ek = (1 + μδ)(k+1) Ẽk+1 − (1 + μδ)k Ẽk /δ = (1 + μδ)k (μẼk+1 + Ẽk+1δ−Ẽk ) ≤ 0\n\nAPPENDIX B. CHAPTER TWO\n\n91\n\nGradient Descent For GD, a similarly scaled distance function,\n1\nEk = (1 − μδ)−k kx∗ − xk k2 ,\n2\nis a Lyapunov function when f is (1/δ)-smooth and μ strongly convex. We similarly use\nẼk = 12 kx∗ − xk k2 , and check,\nẼk+1 − Ẽk\n=−\nδ\n\n\nxk+1 − xk ∗\n, x − xk\nδ\n\n\n(2.3)\n\n+ ε1k = h∇f (xk ), x∗ − xk i + ε1k\n(A.6)\n\n1\n≤ −μ kx∗ − xk k2 + ε2k ≤ −μẼk ,\n2\n\nwhere ε1k = h∇f (xk ), xk − xk+1 i − 2δ1 kxk+1 − xk k2 and ε2k = f (x∗ ) − f (xk ) + ε1k . The last\nupper bound ε2k ≤ 0 follows from the (1/δ)-smoothness assumption on f (A.13). Therefore,\nthe recurrence Ẽk+1 − Ẽk = −δμẼk allows us to conclude a O(e−μδk ) ≈ O((1 − (μδ))k ) =\nO((1 − κ−1 )k ) convergence rate,\n1 ∗\nkx − xk k2 ≤ (1 − κ−1 )k E0 .\n2\nProximal Method For PM, the scaled distance function,\n1\nEk = (1 + μδ)k kx∗ − xk k2 ,\n2\nis a Lyapunov function. We check,\n\n\nxk+1 − xk ∗\nẼk+1 − Ẽk\n(2.4)\n=−\n, x − xk+1 + ε1k = h∇f (xk+1 ), x∗ − xk+1 i + ε1k\nδ\nδ\n(A.6)\n1\n≤ −μ kx∗ − xk+1 k2 = −μẼk+1 ,\n2\nwhere ε1k = − 2δ1 kxk+1 − xk k2 is negative. Therefore, the recurrence Ẽk+1 − Ẽk ≤ −μδ Ẽk+1\nallows us to conclude a O(e−μδk ) ≈ O((1 + μδ)−k ) convergence rate,\nf (xk ) − f (x∗ ) ≤ (1 + μδ)−k E0 .\nTighter Bound: If we assume the f is L-smooth in continuous time, we obtain a tighter\nbound for GF when f is μ-strongly convex using the bound (μ ≤ L),\nh∇f (Xt ), x∗ − Xt i ≤ −\n\n1\nμL\nkx∗ − Xt k2 −\nk∇f (Xt )k2 .\nμ+L\nμ+L\n\n(B.4)\n\nAPPENDIX B. CHAPTER TWO\n\n92\n\nWe provide a proof of this bound in the Appendix B.1.4. Using (B.4), it follows that,\nd\n(2.2)\nẼt = −hẊt , x∗ − Xt i = h∇f (Xt ), x∗ − Xt i\ndt\n(B.4)\n2μL\nẼt\n≤ −\nμ+L\nfor Ẽt = 21 kx∗ − Xt k2 . Thus,\n2μL 1\nEt = e μ+L t kx∗ − Xt k2 ,\n2\nis a Lyapunov function; we can subsequently conclude the upper bound,\n2μL\n1 ∗\nkx − Xt k2 ≤ e− μ+L t E0 ,\n2\n2μL\n\nand an O(e− μ+L t ) convergence rate. In addition, smoothness can be used to conclude a tighter\nbound on the convergence of the optimality gap using this tighter bound,\n2μL L\nL ∗\nkx − Xt k2 ≤ e− μ+L t kx∗ − X0 k2 .\n2\n2\nSimilar improved bounds can be obtained for GD and PM under the same conditions.\n\nf (Xt ) − f (x∗ ) ≤\n\nGradient Descent Define Ẽk = 12 kx∗ − xk k2 . The following bound holds for GD,\n\n\nxk+1 − xk ∗\nẼk+1 − Ẽk\n(2.3)\n=−\n, x − xk + ε1k = h∇f (xk ), x∗ − xk i + ε1k\nδ\nδ\n2μL\n(B.4)\nẼk + ε2k ,\n= −\nμ+L\n\u0010\n\u0011\n1\n2\nwhere ε1k = 2δ k∇f (xk )k2 and ε2k = − μ+L\n− 2δ k∇f (xk )k2 . If we take 0 < δ < μ+L\n, then\n\u0010\n\u0011\n2μL\nε2k ≤ 0, and we obtain the recursion Ẽk+1 ≤ 1 − μ+L\nδ Ẽk . Let δ = 2/(μ + L). Then,\n\u0012\n\u0013−k\n\u0012\n\u0013−2k\nκ−1\n2μL\n1 ∗\n1 ∗\n2\nEk = 1 −\nδ\nkx − xk k =\nkx − xk k2\nμ+L\n2\nκ+1\n2\nis a Lyapunov function, from which we conclude,\n\u0012\n\u00132k\n1 ∗\nκ−1\n2\nkx − xk k ≤\nE0 .\n2\nκ+1\nUsing the Lyapunov argument as well as the smoothness condition (A.13), we can also conclude a stronger bound on the optimality gap,\nf (xk ) − f (x∗ ) ≤\n\n2μL\nL\nL ∗\nkx − xk k2 ≤ e− μ+L δk kx∗ − x0 k2 .\n2\n2\n\nAPPENDIX B. CHAPTER TWO\n\n93\n\nProximal Method Define Ẽk = 12 kx∗ − xk k2 . The following bound holds for the PM,\n\n\nẼk+1 − Ẽk\nxk+1 − xk ∗\n(2.4)\n=−\n, x − xk+1 + ε1k = h∇f (xk+1 ), x∗ − xk+1 i + ε1k\nδ\nδ\n2μL\n(B.4)\n= −\nẼk+1 + ε2k\nμ+L\n\u0010\n\u0011\n1\nk∇f (xk+1 )k2 are negwhere both of the errors ε1k = − 2δ k∇f (xk+1 )k2 and ε2k = − 2δ + μ+L\n\u0011−1\n\u0010\n2μL\nẼk for any δ > 0, and\native. This allows us to obtain the recursion Ẽk+1 ≤ 1 + μ+L δ\nthat\n\u0013k\n\u0012\n1 ∗\n2μL\nδ\nkx − xk k2 ,\nEk = 1 +\nμ+L\n2\nis a Lyapunov function. Smoothness gives an improved upper bound on the function,\nf (xk ) − f (x∗ ) ≤\n\n2μL\nL ∗\nL\nkx − xk k2 ≤ e− μ+L δk kx∗ − x0 k2 ,\n2\n2\n\nfor the proximal method.\n\nB.1.3\n\nSummary\n\nTo summarize, we have presented several Lyapunov functions for the gradient flow equation (2.2), which provides a tool to conclude a non-asymptotic rate of convergence. When\nthe objective function is differentiable, Lipschitz and X = Rd , we can expect the function to\nconverge to a critical point at the rate O(1/t). If in addition f is convex, so that all local\nminima are global minimum and there are no saddle points, we can guarantee convergence of\nthe optimality gap defined by a minimizer of f . If f is μ-strongly convex, i.e. the optimality\n1\ngap is bounded below by O(− 2μ\nk∇f (Xt )k2 ), we can expect a much faster convergence rate of\nO(e−μt ). However, in discrete-time if μδ := κ−1 is too small, δ is the discretization set and\na measure of the smoothness of f (f is (1/δ)-smooth), then the difference between these two\nsettings diminishes.\nFor the proximal method we can think of the step-size δ as a regularizer, which determines\nthe trade off between minimizing the function f (x) and keeping the point close to the current\niterate 2δ1 kx − xk k2 . The larger the step-size, the smaller the distance function, and the more\nwe prioritize minimizing the function. This intuitively leads to a faster rate of convergence.\nHowever, unless f is somehow simple, it may be hard to solve the subproblem, and so using\nthis method is often impractical. This accounts for why gradient descent is one of the most\nwidely used algorithms in optimization.\nWe now end by giving a brief description of what changes when X is a compact, convex\nset, how to analyze proximal gradient descent, and the Lyapunov property is used to pick the\nstep-size.\n\nAPPENDIX B. CHAPTER TWO\n\n94\n\nProjections Suppose X ⊆ Rd is a convex, compact set. We can instead write the GF\nupdate (2.2) as\nd\nYt = −∇f (Xt )\ndt\nXt = ΠX (Yt )\n\n(B.5)\n\nwhere ΠX (x) = arg miny∈X 12 ky − xk2 is the projection operator onto the set X .\nWe can similarly write the GD update (2.3) as\nyk+1 = xk − δ∇f (xk )\nxk+1 = ΠX (yk+1 )\n\n(B.6)\n\nusing the same projection operator. Furthermore, nearly the same arguments presented in\nthis section follow from using the same Lyapunov functions; the only modification in each\nanalysis involves using the property\n\n\nxk+1 − x xk+1 − yk+1\n−\n,\n≤ 0, ∀x ∈ X\n(B.7)\nδ\nδ\nfor the Lyapunov arguments which entail showing the descent property, and the property\nkx∗ − xk+1 k2 ≤ kx∗ − yk+1 k2 ,\nfor Lyapunov arguments involving the metric, at the beginning of each analysis. Both inequalities follow from properties of the projection operator (A.28). Each analysis then proceeds\naccordingly with the same Lyapunov arguments. To provide an explicit example, for argument (2.8), we have the simple modification,\n\n\nf (yk+1 ) − f (xk )\n2 − δL\nyk+1 − xk\n2 − δL\nf (xk+1 ) − f (xk )\n≤\n≤\n∇f (xk ),\n=−\nk∇f (xk )k2\nδ\nδ\n2\nδ\n2\nwhere the first inequality uses the convexity of f and property (B.7) with x = yk+2 to upper(yk+1 )\nbound f (xk+1 )−f\n≤ 0.\nδ\nProximal gradient descent Suppose we can decompose the objective function into two\ncomponents, f = f1 + f2 , where one of them is easy to optimize over. The forward-backward\nsplitting method (also called the proximal gradient method), is obtained by applying the\nforward-Euler (1.6) discretization to f1 and the backward-Euler (1.5) discretization to f2 ,\nthe part that is easy to optimize,\nyk+1 = xk − δ∇f2 (xk )\nxk+1 = Proxf1 (yk+1 ).\n\n(B.8a)\n(B.8b)\n\nAPPENDIX B. CHAPTER TWO\n\n95\n\n\b\nRecall, Proxδf1 (x) = arg minx∈X f1 (x) + 2δ1 kx − yk2 . We can write the variational condition for the combined update (B.8) as,\nxk+1 − xk\n= −∇f1 (xk+1 ) − ∇f2 (xk ).\nδ\nLyapunov arguments for the FB-splitting method can be obtained by combining Lyapunov\nfunctions for the proximal method and gradient descent appropriately. This follows from the\nfact that (1) the two vector fields are additive, and (2) both discretizations use the same\nLyapunov functions. For an excellent monograph on proximal algorithms, see [53]\nChoosing δ using Lypaunov functions We showed that choosing the optimal step-size\nδ for gradient descent required knowing the smoothness of the function, and sometimes the\nstrong convexity parameter μ. Often we know neither of these. Most ways of searching\nfor good step-sizes for GD are constructed around the idea of making the function value\nEt = f (Xt ) (i.e. the Lyapunov function Et = f (Xt ) − f (x∗ ) shifted by a constant f (x∗ )) go\ndown, given we know that it should be decreasing as function of time for any smooth function.\nFor instance, exact line search is a technique which solves the subproblem,\n1\nf (xk+1 ) − f (xk )\n= min (f (xk − δ∇f (xk )) − f (xk ))\nδ>0 δ\nδ>0\nδ\n\nmin\nor more simply,\n\nmin f (xk+1 ) − f (xk ) = min f (xk − δ∇f (xk )).\nδ>0\n\nδ>0\n\nOften, however, this subproblem is too expensive to solve for practical applications. Other\ntechniques for choosing step-sizes, such as the weak Wolfe conditions and backtracking line\nsearch also use criterion formulated around the idea of making the function value go down.\n\nB.1.4\n\nTighter Bound\n\nThis proof follows [43, p. 2.1.12]. Define φ(x) = f (x) − μ2 kxk2 and note ∇x φ(x) = ∇f (x) −\nμx. The smoothness of f , i.e. h∇f (x) − ∇f (y), x − yi ≤ Lkx − yk2 implies hφ(x) −\nφ(y), x − yi ≤ (L − μ)kx − yk2 (i.e. that φ is L − μ-smooth.) This, in turn, implies\n1\nh∇f (x)−∇f (y), x−yii ≤ L−μ\nk∇φ(x)−φ(y)k2 , which when expanded, is our condition (B.4)\n\nB.2\n\nMirror Desent\n\nB.2.1\n\nDifferentiable Function\n\nThe steepest descent dynamic is called natural gradient flow (NGF),\n\u001a\n\u001b\n1\n2\nẊt = arg min h∇f (Xt ), vi + kvk∇2 h(Xt ) = −∇2 h(Xt )−1 ∇f (Xt ).\n2\nv∈Rd\n\n(B.9a)\n\nAPPENDIX B. CHAPTER TWO\n\n96\n\nThe optimality gap, Et = f (Xt ) − f (x∗ ) is a Lyapunov function for (B.9),\nd\n(B.9)\nEt = h∇f (Xt ), Ẋt i = −k∇f (Xt )k2Xt∗ ≤ 0.\ndt\n\n(B.10)\n\nIf in addition, f satisfies the PL condition (2.11),\n(2.11)\nd\n(B.9)\nEt = h∇f (Xt ), Ẋt i = −k∇f (Xt )k2Xt∗ ≤ −2μ(f (Xt ) − f (x∗ )),\ndt\n\nwe conclude\nEt = e2μt (f (Xt ) − f (x∗ ))\nis a Lyapunov function and an O(e−μt ) convergence rate. A similar statement can be made\nfor natural gradient descent (NGD), the forward-Euler (1.6) discretization of natural gradient\nflow.\nNatural Gradient Descent Natural gradient descent [3],\nxk+1 − xk\n= −∇2 h(xk )−1 ∇f (xk ),\nδ\nis also a steepest descent flow as long as f is L = (1/δ)-smooth with respect the Hessian\nmetric: Df (x, y) ≤ 1δ kx − ykx . If so, the discrete optimality gap, Ek = f (xk ) − f (x∗ ), is a\nLyapunov function for NGD:\n\n\n2 − δL\nEk+1 − Ek\nxk+1 − xk\n2 − δL\n≤\nk∇f (xk )k2x∗k ≤ 0.\n(B.11)\n∇f (xk ),\n=−\nδ\n2\nδ\n2\nIf in addition, f satisfies the PL-condition (2.11),\n(2.11)\nEk+1 − Ek (B.11) 1\n≤ − k∇f (xk )k2x∗k ≤ −μ(f (xk ) − f (x∗ )),\nδ\n2\n\nthen Ek = (1 − μδ)−k (f (xk ) − f (x∗ ) is a Lyapunov function, and we can conclude a matching\nO(e−μδk ) convergence rate.\n\nB.2.2\n\nConvex Functions\n\nDescent Property MF and NGF are equivalent dynamics. Therefore, we can combine\nthe descent property (B.10) and Lyapunov function (2.16) to conclude\nEt = Dh (x∗ , Xt ) + t(f (Xt ) − f (x∗ ))\n\n(B.12)\n\nAPPENDIX B. CHAPTER TWO\n\n97\n\nis a Lyapunov function for MF/NGF. We check,\n(B.10)\nd (B.12)\nd (2.13)\nd\nEt\n= Et\n+ t (f (Xt ) − f (x∗ )) ≤ −tkẊt k2Xt ≤ 0.\ndt\ndt\ndt\n(2.13)\n\nHere, Et\nrepresents the Lyapunov function defined by (2.13) and the second inequality uses\nthe fact that we have shown this Lyapunov function is decreasing for MF (2.12). Therefore, if\nin addition, we can show our discretizations are descent methods, we can conclude a slightly\nstronger result. We now remark that the descent property can be shown for the BPM (2.17);\nsubsequently, we can establish\nEk = Dh (x∗ , xk ) + δk(f (xk ) − f (x∗ ))\n\n(B.13)\n\nis a Lyapunov function. We check,\n(B.13)\n\n(B.13)\n\nEk+1 − Ek\nδ\n\n(2.16)\n\n(2.16)\n\nE\n− Ek\n≤ k+1\nδ\n\n+ δk\n\nf (xk+1 ) − f (xk )\n1\n≤ −δk 2 Dh (xk+1 , xk ) ≤ 0,\nδ\nδ\n\nwhere the second inequality follows because xk+1 satisfies f (xk+1 ) + 1δ Dh (xk+1 , xk ) ≤ f (xk ) +\n1\nD (x , xk ); we can therefore obtain the tighter convergence bound f (xk ) − f (x∗ ) ≤ E0 /δk.\nδ h k\nUnfortunately, it is unclear whether the descent property holds for mirror descent without\nstronger conditions on the geometry h.\n\nB.2.3\n\nStrongly Convex Functions\n\nThe distance function, Ẽt = Dh (x∗ , Xt ), is a Lyapunov function for NGF/MF, when f is\nμ-strongly convex with respect to h (A.7), Df (x∗ , Xt ) ≤ −μDh (x∗ , Xt ). We check,\n\n\nd\nd\n(2.12)\n∗\nẼt = −\n∇h(Xt ), x − Xt\n= h∇f (Xt ), x∗ − Xt i\ndt\ndt\n(A.7)\n\n≤ −μDh (x∗ , Xt ) = −μẼt .\n\nNotice that if f is just convex, the distance function Ẽt = Dh (x∗ , Xt ) is a Lyapunov function.\nThe addition of the strong convexity condition allows us to conclude a rate of convergence;\nin particular, from the recurrence dtd Ẽt ≤ −μẼt , we can conclude\nEt = eμt Dh (x∗ , Xt )\nis also a Lyapunov function, as well as the convergence bound Dh (x∗ , Xt ) ≤ O(e−μt ).\nA similar statement can be made for mirror descent and the BPM.\n\n(B.14)\n\nAPPENDIX B. CHAPTER TWO\n\n98\n\nMirror Descent When f is μ-strongly convex and (1/δ)-smooth with respect to h (A.7),\nẼk = Dh (x∗ , xk ), is a Lyapunov function for mirror descent,\n\n\n∇h(xk+1 ) − ∇h(xk ) ∗\nẼk+1 − Ẽk\n(2.12)\n=−\n, x − xk + ε1k = − h∇f (xk ), x∗ − xk i + ε1k\nδ\nδ\n≤ −μDh (x∗ , xk ) + ε2k ≤ −μẼk .\nHere, ε1k = h∇f (xk ), xk − xk+1 i − 1δ Dh (xk+1 , xk ) and ε2k = f (x∗ ) − f (xk+1 ) + Df (xk+1 , xk ) −\n1\nD (x , xk ). The first inequality uses strong convexity and the second uses smoothness to\nδ h k+1\nupper bound the final error. From the recursion Ẽk+1 ≤ (1 − μδ)Ẽk ≤ (1 − μδ)k Ẽ0 , we can\nconclude\nEk = (1 − μδ)−k Dh (x∗ , xk ),\nis a Lyapunov function, as well as the convergence bound, Dh (x∗ , xk ) ≤ O(e−μδk ).\nBregman Proximal Minimization When f is μ-strongly convex with respect to h (A.7),\nẼk = Dh (x∗ , xk ), is a Lyapunov function for BPM,\n\n\n∇h(xk+1 ) − ∇h(xk ) ∗\nẼk+1 − Ẽk\n(2.17)\n=−\n, x − xk+1 + ε1k = − h∇f (xk+1 ), x∗ − xk+1 i + ε1k\nδ\nδ\n≤ −μDh (x∗ , xk+1 ) ≤ −μEk+1 .\nwhere the error ε1k = − 1δ Dh (xk+1 , xk ). From the recursion Ẽk+1 ≤ (1 + μδ)−1 Ẽk ≤ (1 +\nμδ)−k Ẽ0 , we can conclude\nEk = (1 + μδ)k Dh (x∗ , xk ),\nis a Lyapunov function, as well as the convergence bound, Dh (x∗ , xk ) ≤ O(e−μδk ).\n\nB.2.4\n\nSummary\n\nWe end this section by giving brief descriptions of the relationship between NGF and MF,\nwhat changes when X is a compact, convex set, how to analyze proximal mirror descent, and\nconnections between mirror descent and information geometry.\nMirror Maps To summarize, on a Hessian Riemannian manifold, MF is the push-forward\nof natural gradient flow NGF under the mapping φ = ∇h, and both are gradient flows. Furthermore, this property, that flows on both spaces are gradient flows, is unique to Riemannian\nmanifolds with a Hessian metric structure (see Theorem 3.1 of [2]). To illustrate this property, we demonstrate how the gradient flow changes as we map between these two spaces.\nConsider a function f : X̃ → R defined on the set X̃ and a smooth bijective map φ : X̃ →\nỸ. The push-forward of f function under the map leads to a new objective function f ̃ : Ỹ → R\n\nAPPENDIX B. CHAPTER TWO\n\n99\n\ndefined on Ỹ, given by f ̃ = f ◦ φ−1 . We compute the gradient of f ̃ at a point y = φ(x) as\n∇f ̃(y) = ∂z f ̃(z)|z=y = ∂z (f ◦ φ−1 )(z)|z=y = Jφ−1 (y)∂z f (φ−1 (z))|z=y = Jφ−1 (y)∇f (φ−1 (y)),\nwhere Jφ−1 (y) is the Jacobian (partial derivatives) of φ−1 (z) at z = y, represented as a matrix.\nWe compute how the general metric g(x) on X changes at a point, where we eventually make\nthe choice g = ∇2 h. The pullback metric of g, which we denote g̃ = φ−1 g at a point y = φ(x),\nis given by g̃(y) = Jφ−1 (y)> (g ◦ φ−1 )(y)Jφ−1 (y). Putting the pieces together, we can calculate\nnatural gradient flow on Ỹ as Ẏt = −g̃(Yt )−1 ∇f ̃(Yt ) = −Jφ−1 (Yt )−1 g(φ−1 (Yt ))−1 ∇f (φ−1 (Yt )).\n“Mirror Map”\ny = ∇h(x)\nX̃\n\nỸ\n\nFunction f (x)\n\nFunction f (∇h∗ (y)) = f ̃(y)\n\nHessian Metric ∇2 h(x)\n\nHessian Metric ∇2 h∗ (y) = [∇h2 (x)]−1\nGradient Flow d Yt = −[∇2 h∗ (Yt )]−1 ∇f ̃(Yt )\n\nd\nGradient Flow dt\nXt = −[∇2 h(Xt )]−1 ∇f (Xt )\n\ndt\n\n= −∇f (Xt )\n\nFigure B.1: The mirror map represents the duality relationship between MF and NGF.\nIf we take g = ∇2 h and φ−1 = ∇h∗ , where h∗ : X̃ ∗ → X̃ → is the Legendre dual function\ndefined on a the dual space X̃ ∗ , then we obtain the identities,\n∇h(∇h∗ (y)) = y\n\n(B.15)\n\n∇2 h∗ (y)∇2 h(∇h∗ (y)) = I.\n\n(B.16)\n\nand\n\nUsing these identities, we can write the gradient flow on Ỹ = X̃ ∗ as dtd Yt = −∇f (∇h∗ (Yt )) =\n−∇f (Xt ).\nProjections We adopt the setting described at the beginning of the subsection, where X ⊆\nRd is a convex, compact set. We can write the MF (2.12) as the system of differential\nequations,\nd\nYt = −∇f (Xt )\ndt\nXt ∈ ΠX ∩X̃ (∇h∗ (Yt )).\n\n(B.17a)\n(B.17b)\n\nAPPENDIX B. CHAPTER TWO\n\n100\n\nHere,\nΠX ∩X̃ (x) := arg min Dh (y, x)\n\n(B.18)\n\ny∈X ∩X̃\n\nis a Bregman projection operator.\nWe can similarly write MD as,\nyk+1 = ∇h(xk ) − δ∇f (xk )\nxk+1 ∈ ΠX ∩X̃ (∇h∗ (yk+1 ))\n\n(B.19a)\n(B.19b)\n\nwhere we use the same Bregman projection operator ΠX (x) = arg miny∈X ∩X̃ Dh (y, x). A\nsimilar variational condition ∇h(xk ) = yk is implied using the mirror map. For this modified\nalgorithm, nearly all of the same Lyapunov arguments presented in this section follow using\nthe same Lyapunov functions; the only modification in each analysis involves recognizing the\nfollowing property of projection operator (A.28),\nDh (x∗ , xk+1 ) ≤ Dh (x∗ , yk+1 )\nAs a specific example, the following argument can be made for mirror descent where f is\nμ-strongly convex with respect to h (A.7), using Ẽk = Dh (x∗ , xk ):\nẼk+1 − Ẽk\n≤−\nδ\n\n\n∇h(yk+1 ) − ∇h(xk ) ∗\n, x − xk\nδ\n\n\n+ ε1k\n\n(B.19a)\n\n=\n\nh∇f (xk ), x∗ − xk i + ε1k\n\n≤ −μDh (x∗ , xk ) + ε2k ≤ −μẼk\nHere, the first line uses the inequality Ẽk+1δ−Ẽk ≤ 1δ Dh (x∗ , yk+1 )− 1δ Dh (x∗ , xk ). The first error\nscales as ε1k = −h(∇h(yk+1 ) − ∇h(xk ))/δ, xk − yk+1 i + 1δ Dh (yk+1 , xk ) = h∇f (xk ), xk − yk+1 i −\n1\nD (y , xk ). The second error scales as ε2k = f (x∗ )−f (yk+1 )−Df (yk+1 , xk )− 1δ Dh (yk+1 , xk ),\nδ h k+1\nwhich we can upper bound using the (1/δ)- smoothness of f with respect to h (A.14). In other\nwords, its the same argument as the unconstrated case, where we replace xk+1 with yk+1 .\nA projection step can be similarly added to each update of the MP algorithm (2.19) and\nthe same Lyapunov functions used, similar to what we have just shown.\nProximal Mirror Descent Suppose we can decompose the objective function into two\ncomponents, f = f1 + f2 where one of them is easy to optimize over. The forward-backward\nsplitting method, i.e. proximal mirror descent, is obtained by applying the forward-Euler (1.6)\ndiscretization to f1 and backward-Euler (1.5) discretization to f2 :\nyk+1 = ∇h(xk ) − δ∇f2 (xk )\n\n(B.20a)\n\nX̃ ∩X\nxk+1 ∈ Proxh,\n(∇h∗ (yk+1 )).\nδf1\n\n(B.20b)\n\nAPPENDIX B. CHAPTER TWO\n\n101\n\nh,X̃ ∩X\n= arg minx∈X̃ ∩X {f1 (x) + 1δ Dh (x, y)} is the Bregman proximal function. The\nHere, Proxδf\n1\nupdate (B.20) satisfies the variational condition,\n\n∇h(xk+1 ) − ∇h(xk )\n= −∇f2 (xk ) − ∇f1 (xk+1 ).\nδ\nLyapunov arguments for this FB-splitting method can be obtained by combing the Lyapunov\nfunctions for the Bregman method and mirror descent, given the vector field is additive and\nthe same Lyapunov functions can be used in both settings. We relax the differentiability of\nf1 in the next subsection.\nRelevant Citations The Bregman Proximal Minimization has a long established history [11]. Mirror descent has also been discussed by many [39, 8]. The continuous time\nLyapunov function (2.13) have been remarked on many times [39, 2, 75]; so too, has the dual\nrelationship between MF and NGF [8, 61]. The connection between MF/MD and information geometry, game theory and theormodynamics has been extensively studied by many [23,\n7, 22]. For a particularly nice survey on the connection between the replicator equation,\nevolutionary game theory, Nash equilibria and biology, see [7]\n\nB.3\n\nSubgradients and Time Reparameterization\n\nB.3.1\n\nStrongly Convex Functions\n\nWe analyze dynamics (2.22) in the setting where f is μ-strongly convex with respect to h (A.7)\nusing the parameterized Lyapunov function (B.14),\nEτt = eμτt Dh (x∗ , Yt ).\n\n(B.21)\n\nObserve that,\nd\nd\nd\nEτt = Dh (x∗ , Yt ) eμτt + eμτt Dh (x∗ , Yt )\ndt\ndt\ndt\n\n\nd\nμτt\n∗\nμτt\n∗\n= μτ̇t e Dh (x , Yt ) − e\n∇h(Yt ), x − Yt\ndt\n\u0010\nD\nE\u0011\n= eμτt τ̇t μDh (x∗ , Yt ) + G(Yt , Ẏt ), x∗ − Yt\n(A.6)\n\nd\n1\n≤ − (f (Xt ) − f (x∗ )) eμτt\nμ\ndt\n\nFrom this argument, we obtain the upper bound,\nDh (x∗ , Yt ) ≤\n\neμτ0 Dh (x∗ , Y0 )\neμτt\n\n(B.22)\n\nAPPENDIX B. CHAPTER TWO\n\n102\n\nRt\nand an O(eμτt ) convergence rate. Define X̂t = 0 Xs deμτs /eμτt . By Jensen’s f (X̂t ) ≤\nRt\nf (Xs )deμτs . From (B.22) we can also conclude the upper bound,\n0\nf (X̂t ) − f (x∗ ) ≤\n\nμEτ0\n,\neμτt\n\nas well as the fact that\nEτ t = e\n\nμτt\n\n1\nDh (x , Yt ) +\nμ\n∗\n\nZ t\n\nf (Ys ) − f (x∗ )deμτs\n\n0\n\nis a Lyapunov function.\nNotice the difference between these two settings. In the convex case, the two scalings of\ntime which appear explicitly in the dynamics and Lyapunov function are the tuple (τt , τ̇t ).\nThe two scalings of time that appear in the dynamic and Lyapunov function in the strongly\nconvex setting is (eμτt , τ̇t ). Therefore, when we identify the first element in the tuple with the\ndiscrete sequence Ak , the approximation of the time derivative will differ as (Ak , Ak+1δ−Ak ) and\nk+1 −Ak\n(Ak , AμδA\n), respectively. In the latter case, we made the approximation τ̇t = dtd eμτt /μeμτt ≈\nk+1\n(Ak+1 − Ak )/μδAk+1 := αk . With this approximation, the same argument can be made for\nthe scaled MD (2.24) and PM (2.27).\nMirror descent for non-smooth functions To analyze mirror descent (2.24) when f\nis μ-strongly convex with respect to h (A.7) we use the scale-free Lyapunov function\nEAk = Ak Dh (x∗ , yk ).\nObserve that,\nEAk+1 − EAk\nAk+1 − Ak\nDh (x∗ , yk+1 ) − Dh (x∗ , yk )\n= Dh (x∗ , yk )\n+ Ak+1\nδ\nδ\nδ\n\n\n∇h(y\n)\n−\n∇h(yk ) ∗\nk+1\n∗\n= Ak+1 αk μDh (x , yk ) − Ak+1\n, x − yk + ε1k\nδ\n= Ak+1 αk (μDh (x∗ , yk ) − hg(yk ), x∗ − yk i) + ε1k ≤ ε2k\n(B.23)\nwhere the first error scales as ε1k = Ak+1 (αk hg(yk ), yk − yk+1 i − 1δ Dh (yk+1 , yk )) and the second\nas, ε2k = Ak+1 (αk hg(yk ), yk − yk+1 i − 1δ Dh (yk+1 , yk ) − αk (f (yk ) − f (x∗ )) ≤ ε1k . We can upper\nbound ε2k using the same argument as in the convex case. We assume h is σ-strongly convex\n2\nk+1 −Ak )\nand apply Young’s inequality (A.25) to obtain the bound ε2k ≤ ε1k ≤ (A\nkg(yk )k2∗ −\n2μ2 σδAk+1\nAk+1 −Ak\n(f (yk ) − f (x∗ ))\nδμ\n\n:= ε3k . Assume k∂f (y)k2∗ ≤ G2 for all y ∈ X and some finite\n2\nconstant G. Choosing Ak = (k + 1)k and δ = 1 so that αk = δμ(k+2)\nand α̃k = αk Ak+1 =\nAk+1 −Ak\n= 2(k + 1)/δμ, we obtain the upper bound\nδμ\n\nDh (x∗ , yk ) ≤\n\n1\nA0 Dh (x∗ , y0 ) + δ 2σ\n\nAk\n\nα̃2k\n2\ns=0 Ak+1 G\n\nPk\n\n(B.24)\n\nAPPENDIX B. CHAPTER TWO\n\n103\n\nP\nP\nand an O(1/k) convergence rate. Define ŷk = ks=0 ys αs /Ak . By Jensen’s f (x̂k ) ≤ ks=0 f (ys )αs .\nFrom (B.23) we can also conclude the upper bound\nf (ŷk ) − f (x∗ ) ≤\n\n1\nμE0 + δ 2σ\n\nα̃2k\n2\ns=0 Ak+1 G\n\nPk\nAk\n\nas well as the fact that\nk−1\n\nAs+1 − As\n1X\n(f (xs ) − f (x∗ ))\nδ,\nEAk = Ak Dh (x , yk ) +\nμ s=0\nδ\n∗\n\nis a Lyapunov function.\nHolder Continuous Gradients If f is Holder-smooth (A.15), the following Lyapunov\nfunction,\n∗\n\nEAk = Dh (x , yk ) +\n\nk\nX\n\n(f (ys ) − f (x∗ ))\n\ns=0\n\nAs+1 − As\n.\nδ\n\nfor mirror descent (2.22) will full gradients. Using the analysis in the unsmooth case, it is\nto check\nEAk+1 − EAk\n= −Df (x∗ , yk )αk + ε1k\nδ\nwhere the error scales as ε1k = αk (f (yk+1 )−f (yk )+h∇f (yk ), yk −yk+1 i)− 1δ Dh (yk+1 , yk ). Using\nthe Holder continuity of the gradients, along with the σ-strong convexity of f , we obtain the\nL\nαk kyk+1 − yk k1+ν − σδ kyk+1 − yk k2 . We upper bound the error using\nupper bound ε1k = 1+ν\n1+ν\n\n1 1+ν\n1 2\nYoung’s inequality (A.25) 1+ν\nt\n≤ 2s\nt + 1−ν\ns 1−ν , with t = kyk+1 − yk k and s = δαk L/σ\n1+ν\n2\n\n1+ν\n\n1+ν\n\n1−ν 1 1−ν\nα L(σL/σ) 1−ν . The choice αk = Dh (x∗ , x0 )/k 2 leads\nprovides the upper bound ε1k ≤ 1+ν\n2 k\n1+ν\nto an O(k − 2 ) convergence rate.\n\nB.4\n\nAccelerated Mirror Prox\nEk+1 − Ek\n=−\nδ\n\n\n(2.55d)\n\n∇h(zk+1 ) − ∇h(zk ) ∗\n, x − xk+1\nδ\n\n= Df (xk+1 , x∗ )αk + ε1k\n\n\n+ αk (f (xk+1 ) − f (x∗ )) + ε1k\n\nAPPENDIX B. CHAPTER TWO\n\n104\n\nwhere the error scales as,\nf (xk+1 ) − f (xk )\n−\nε1k = Ak\nδ\n\n\n∇h(zk+1 ) − ∇h(zk )\n, xk+1 − zk+1\nδ\n\n\n1\n− Dh (zk+1 , zk )\nδ\n\n(2.55d)\n(A.27)\n\n1\nf (xk+1 ) − f (xk )\n0\n+ αk h∇f (xk+1 ), xk+1 − zk+1 i − Dh (zk+1 , zk+1\n)\nδ\nδ\n\n\n0\n∇h(zk+1\n) − ∇h(zk )\n1\n0\n0\n− Dh (zk+1 , zk ) −\n, zk+1 − zk+1\nδ\nδ\n\n= Ak\n\nUsing convexity, we can further upper-bound the error as folows,\n\n\n(2.55b)\nxk+1 − xk\n1\n1\n0\nεk ≤ Ak+1 ∇f (xk+1 ),\n+ αk h∇f (xk+1 ), xk − zk+1 i − Dh (zk+1 , zk+1\n)\nδ\nδ\n1\n0\n0\n, zk ) + αk h∇f (x0k+1 ), zk+1 − zk+1\n− Dh (zk+1\ni\nδ\n1\n1\n(2.55c)\n0\n0\n0\n= αk h∇f (xk+1 ) − ∇f (x0k+1 ), zk+1\n− zk+1 i − Dh (zk+1 , zk+1\n) − Dh (zk+1\n, zk )\nδ\nδ\nxk+1 −x0k+1\n=\nδ\nα2k\n0\n0\n0\n0\n0\nτk (zk+1 −zk ), the inequality αk h∇f (xk+1 )−∇f (xk+1 ), zk+1 −zk+1 i ≤ δ Ak+1 \u000f kzk+1 −zk+1 kkzk+1 −\n\nUsing the (1/\u000f)-smoothness of f , Cauchy-Schwartz (A.26) and the identity\n\nzk k and the σ-strong convexity of h gives the remaining upper bound (2.56).\n\nB.5\n\nDynamics\n\nB.5.1\n\nProof of Proposition 2.2.1\n\nWe compute the Euler-Lagrange equation for the second Bregman Lagrangian (2.39). Denote\nz = x + e−αt ẋ. The partial derivatives of the Bregman Lagrangian can be written,\n∂L\n(Xt , Ẋt , t) = μeβt +γt (∇h(Zt ) − ∇h(Xt ))\n∂v\n∂L\n∂L\nd\n(Xt , Ẋt , t) = μeαt\n(Xt , Ẋt , t) − μeβt +γt ∇h(Xt ) − eαt +βt +γt ∇f (Xt ).\n∂x\n∂v\ndt\nWe also compute the time derivative of the momentum p = ∂L\n(Xt , Ẋt , t),\n∂v\nd ∂L\n∂L\nd\nd\n(Xt , Ẋt , t) = (β̇t + γ̇t ) (Xt , Ẋt , t) + μeβt +γt ∇h(Zt ) − μeβt +γt ∇h(Xt ).\ndt ∂v\n∂v\ndt\ndt\nThe terms involving dtd ∇h(X) cancel and the terms involving the momentum will simplify under the scaling condition (2.37a) when computing the Euler-Lagrange equation ∂L\n(Xt , Ẋt , t) =\n∂x\nd ∂L\n(Xt , Ẋt , t). Compactly, the Euler-Lagrange equation can be written\ndt ∂v\nd\nμ∇h(Zt ) = −β̇t μ (∇h(Zt ) − ∇h(Xt )) − eαt ∇f (x).\ndt\n\nAPPENDIX B. CHAPTER TWO\n\n105\n\nRemark It interesting to compare with the partial derivatives of the first Bregman Lagrangian (A.2),\n∂L\n(Xt , Ẋt , t) = eγt (∇h(Zt ) − ∇h(Xt ))\n∂v\n∂L\nd\n∂L\n(Xt , Ẋt , t) = eαt\n(Xt , Ẋt , t) − eγt ∇h(Xt ) − eαt +βt +γt ∇f (Xt ),\n∂x\n∂v\ndt\nas well as the derivative of the momentum,\nd ∂L\nd\nd\n∂L\n(Xt , Ẋt , t) = γ̇t\n(Xt , Ẋt , t) + eγt ∇h(Zt ) − eγt ∇h(Xt ).\ndt ∂v\n∂v\ndt\ndt\nFor Lagrangian (A.2), not only do the terms involving dtd ∇h(X) cancel when computing\nthe Euler-Lagrange equation, but the ideal scaling will also force the terms involving the\nmomentum to cancel as well.\n\nB.5.2\n\nHamiltonian Systems\n\nBregman Hamiltonian. One way to understand a Lagrangian is to study its Hamiltonian, which is the Legendre conjugate (dual function) of the Lagrangian. Typically, when the\nLagrangian takes the form of the difference between kinetic and potential energy, the Hamiltonian is the sum of the kinetic and potential energy. The Hamiltonian is often easier to study\nthan the Lagrangian, since its second-order Euler-Lagrangian equation is transformed into\na pair of first-order equations. In our case, the Hamiltonian corresponding to the Bregman\nLagrangians (2.36) and are the following Bregman Hamiltonians,\n\u0001\n\u0001\nH(x, p, t) = eαt +γt Dh∗ ∇h(x) + e−γt p, ∇h(x) + eβt f (x) ,\n(B.26)\nand\nαt +β+γt\n\nH(x, p, t) = e\n\n\u0013\n\u0013\n\u0012\n\u0012\n1 −(βt +γt )\np, ∇h(x) + f (x) ,\nμDh∗ ∇h(x) + e\nμ\n\n(B.27)\n\nrespectively. These, indeed, have the form of the sum of the kinetic and potential energy.\nHere the kinetic energy is measured using the Bregman divergence of h∗ , which is the convex\ndual function of h.\nCalculating the Hamiltonian In this section we define and compute the Bregman Hamiltonian corresponding to the Bregman Lagrangian. In general, given a Lagrangian L(x, v, t),\nits Hamiltonian is defined by\nH(x, p, t) = hp, vi − L(x, v, t)\n\n(B.28)\n\nAPPENDIX B. CHAPTER TWO\n\n106\n\nwhere p = ∂L\nis the momentum variable conjugate to position. For the Bregman La∂v\ngrangian (2.36), the momentum variable is given by\np=\n\n\u0001\n∂L\n= eγt ∇h(x + e−αt v) − ∇h(x) .\n∂v\n\n(B.29)\n\nWe can invert this equation to solve for the velocity v,\n\u0001\nv = eαt ∇h∗ (∇h(x) + e−γt p) − x ,\n\n(B.30)\n\nwhere h∗ is the conjugate function to h (recall the definition in (A.24)), and we have used\nthe property that ∇h∗ = [∇h]−1 . So for the first term in the definition (B.28) we have\nhp, vi = eαt p, ∇h∗ (∇h(x) + e−γt p) − x .\nNext, we write the Bregman Lagrangian L(x, v, t) in terms of (x, p, t). We can directly\nsubstitute (B.30) to the definition (2.36) and calculate the result. Alternatively, we can use\nthe property that the Bregman divergences of h and h∗ satisfy Dh (y, x) = Dh∗ (∇h(x), ∇h(y)).\nTherefore, we can write the Bregman Lagrangian (2.36) as\n\u0001\n\u0001\nL(x, v, t) = eαt +γt Dh∗ ∇h(x), ∇h(x + e−αt v) − eβt f (x)\n\u0001\n\u0001\n= eαt +γt Dh∗ ∇h(x), ∇h(x) + e−γt p − eβt f (x)\n\u0001\n= eαt +γt h∗ (∇h(x)) − h∗ (∇h(x) + e−γt p) + e−γt h∇h∗ (∇h(x) + e−γt p), pi − eβt f (x) ,\nwhere in the second step we have used the relation ∇h(x+e−αt v) = ∇h(x)+e−γt p from (B.29),\nand in the last step we have expanded the Bregman divergence.\nSubstituting these calculations into (B.28) and simplifying, we get\n\u0001\nH(x, p, t) = eαt +γt h∗ (∇h(x) + e−γt p) − h∗ (∇h(x)) − hx, e−γt pi + eβt f (x) .\nFor the Bregman Langrangian (2.39), we can invert the equation for its momentum variable\n\u0012\n\u0013\n1 −(γt +βt )\nαt\n∗\nv = e\n∇h (∇h(x) + e\np) − x .\n(B.31)\nμ\nNow we can solve for the Hamiltonian\nH(x, p, t) = hp, vi − L(x, v, t)\n\n\u0012\n\u0013\n\n1 −(γt +βt )\nαt\n∗\n=e\np, ∇h\ne\np + ∇h(x) − x\nμ\n\u0012\n\u0013\n1 −γt +βt\n∗\nαt +γt +βt\n−e\nμDh (∇h (∇h(x) + e\np), x) − f (x)\nμ\n\nAPPENDIX B. CHAPTER TWO\n\n107\n\nExpanding, we have\n\u0012\n\n\u0013\n\n1 −(γt +βt )\n∗\nαt\np, ∇h\ne\np + ∇h(x) − x\nH(x, p, t) = e\nμ\n\u0012\n\u0012\n\u0013\u0013\n1 −γt +βt\n∗\n∗\nαt +γt +βt\nμ(h (∇h(x)) − h ∇h(x) + e\n−e\np\nμ\n\n\u0012\n\u0013\n1 −(γt +βt )\n∗\nαt\n∇h\n−e\ne\np + ∇h(x) , p − eαt +γt +βt f (x)\nμ\n\u0012 \u0012\n\u0013\n\u0013\n1 −(γt +βt )\n1 −(γt +βt )\nαt +γt +βt\n∗\n∗\n∗\n=e\nμ h ∇h(x) + e\np − h (∇h(x)) + e\nhp, ∇h (∇h(x))i\nμ\nμ\n+ eαt +βt +γt f (x)\n\u0013\n\u0013\n\u0012\n\u0012\n1 −(γt +βt )\nαt +γt +βt\np, ∇h(x) − f (x)\n=e\nμDh∗ ∇h(x) + e\nμ\nThus, our generalized Hamiltonian has the form\n\u0013\n\u0013\n\u0012\n\u0012\n1 −(γt +βt )\nαt +γt +βt\nH(x, p, t) = e\np, ∇h(x) − f (x)\nμDh∗ ∇h(x) + e\nμ\nHamiltonian equations of motion. The second-order Euler-Lagrange equation of a Lagrangian can be equivalently written as a pair of first-order equations\nd\n∂H\nXt =\n(Xt , Pt , t),\ndt\n∂p\n\nd\n∂H\nPt = −\n(Xt , Pt , t).\ndt\n∂x\n\n(B.32)\n\nFor the Bregman Hamiltonian (B.26), the equations of motion are given by\n\u0001\nd\nXt = eαt ∇h∗ (∇h(Xt ) + e−γt Pt ) − Xt\n(B.33a)\ndt\n\u0001\nd\nPt = −eαt +γt ∇2 h(Xt ) ∇h∗ (∇h(Xt ) + e−γt Pt ) − Xt + eαt Pt − eαt +βt +γt ∇f (Xt ).\ndt\n(B.33b)\nNotice that the first equation (B.34a) recovers the definition of momentum (B.29). Furthermore, when γ̇t = eαt , by substituting (B.34a) to (B.34b) we can write (B.34) as\nd \b\n∇h(Xt ) + e−γt Pt\ndt\n\n= ∇2 h(Xt ) Ẋt − γ̇t e−γt Pt + e−γt Ṗt = −eαt +βt ∇f (Xt ).\n\nSince ∇h(Xt )+e−γt Pt = ∇h(Xt +e−αt Ẋt ) by (B.34a), this indeed recovers the Euler-Lagrange\nequation (2.38).\nA Lyapunov function for the Hamiltonian equations of motion (B.34) is the following,\nwhich is simply the Lyapunov function (2.48) written in terms of (Xt , Pt , t),\n\u0001\nEt = Dh∗ ∇h(Xt ) + e−γt Pt , ∇h(x∗ ) + eβt (f (Xt ) − f (x∗ )).\n\nAPPENDIX B. CHAPTER TWO\n\n108\n\nFor the Bregman Hamiltonian (B.27), the equations of motion are given by\n\u0012\n\u0013\n1 −(βt +γt )\nd\n∗\nαt\n∇h (∇h(Xt ) + e\nXt = e\nPt ) − X t\n(B.34a)\ndt\nμ\n\u0012\n\u0012\n\u0013\n\u0013\n1 −(βt +γt )\nd\n2\nαt +βt γt\n∗\n−(βt +γt )\nμ∇ h(Xt ) ∇h (∇h(Xt ) + e\nPt = −e\nPt ) − X t − e\nPt + ∇f (Xt ) .\ndt\nμ\n(B.34b)\nA Lyapunov function for the Hamiltonian equations of motion (B.34) is the following,\nwhich is simply the Lyapunov function (2.48) written in terms of (Xt , Pt , t),\n\u0013\n\u0012\n1 −(βt +γt )\n∗\nPt , ∇h(x ) + eβt (f (Xt ) − f (x∗ )).\nEt = μDh∗ ∇h(Xt ) + e\nμ\nThe Hamiltonian formulation of the dynamics has appealing properties that seem worthy of further exploration. For example, Hamiltonian flow preserves volume in phase space\n(Liouville’s theorem); this property has been used in the context of sampling to develop the\ntechnique of Hamiltonian Markov chain Monte-Carlo, and may also be useful to help us design better algorithms for optimization. Furthermore, the Hamilton-Jacobi-Bellman equation\n(which is a reformulation of the Hamiltonian dynamics) is a central object of study in the\nfield of optimal control theory, and it would be interesting to study the Bregman Hamiltonian\nframework from that perspective.\n\nB.6\n\nAlgorithms derived from (2.38)\n\nWe prove the following proposition, which is more general than proposition 2.2.3\nProposition B.6.1. Assume that the distance-generating function h is σ-uniformly convex\nwith respect to the p-th power of the norm (p ≥ 2) (A.5) and the objective function is convex.\nUsing only the updates (2.46a) and (2.46b), and using the Lyapunov function (2.48), we\nhave the following bound:\nAk+1 − Ak\nEk+1 − Ek\n≤−\nDf (xk , x∗ ) + εk+1 ≤ εk+1\nδ\nδ\nwhere the error term scales as,\nεk+1 =\n\np\np\n1\n1\np − 1 − p−1\nf (yk+1 ) − f (xk+1 )\nσ\nδ p−1 αkp−1 k∇f (yk+1 ) k p−1 + Ak+1\np\nδ\n\nIf we use the updates (2.47a) and (2.47c) instead, the error term scales as,\n\n\np\np\n1\n1\np − 1 − p−1\nyk+1 − xk+1\np−1\np−1\np−1\nεk+1 =\nσ\nδ αk k∇f (yk+1 ) k\n+ Ak+1 ∇f (yk+1 ) ,\np\nδ\n\n(B.35a)\n\n(B.35b)\n\nAPPENDIX B. CHAPTER TWO\n\n109\n\nThe error bounds (2.50) were obtained using no smoothness assumption on f and h;\nthey also hold when full gradients of f are replaced with elements in the subgraident of f .\nThe bounds was also obtained without using the arbitrary update yk+1 = G(x). In particular,\naccelerated methods are obtained by picking a map G that results in a better bound on the error\nthan the straight forward discretization yk+1 = xk+1 . We immediately see that any algorithm\np\nfor which the map G satisfies the progress condition f (yk+1 ) − f (xk+1 ) ∝ −k∇f (xk+1 )k p−1 or\np\nh∇f (yk+1 ), yk+1 − xk+1 i ∝ −k∇f (yk+1 )k p−1 will obtain a O(1/\u000fσk p ) convergence rate. We\nnow present short descriptions of the main results for the aforementioned five papers.\n\nB.6.1\n\nProof of Proposition B.6.1\n\nWe show the initial bounds (B.35a) and (B.35b). We begin with algorithm (2.46):\n\n\n∇h (zk+1 ) − ∇h (zk ) ∗\nEk+1 − Ek\n1\nf (yk+1 ) − f (xk+1 )\n=−\n, x − zk+1 − Dh (zk+1 , zk ) + Ak+1\nδ\nδ\nδ\nδ\nf (xk+1 ) − f (yk )\nAk+1 − Ak\n(f (xk+1 ) − f (x∗ )) + Ak\n+\nδ\nδ\n1\nf (yk+1 ) − f (xk+1 )\n(2.46b)\n= αk h∇f (xk+1 ) , x∗ − zk+1 i − Dh (zk+1 , zk ) + Ak+1\nδ\nδ\nσ\n∗\n≤ αk h∇f (xk+1 ) , x − zk i + αk h∇f (xk+1 ) , zk − zk+1 i − kzk+1 − zk kp\nδp\nf (yk+1 ) − f (xk+1 ) Ak+1 − Ak\nf (xk+1 ) − f (yk )\n+ Ak+1\n+\n(f (xk+1 ) − f (x∗ )) + Ak\nδ\nδ\nδ\nf (xk+1 ) − f (yk ) Ak+1 − Ak\n≤ αk h∇f (xk+1 ) , x∗ − zk i Ak\n+\n(f (xk+1 ) − f (x∗ ))\nδ\nδ\np\np\n1\np − 1 − p−1\nf (yk+1 ) − f (xk+1 )\n+\nσ\nδ −1 (Ak+1 − Ak ) p−1 k∇f (xk+1 ) k p−1 + Ak+1\np\nδ\nThe first inequality follows from the σ-uniform convexity of h with respect to the p-th power\nof the norm and the last inequality follows from Young’s inequality (A.25). If we continue\nwith our argument, and plug in the identity (B.35a), it simply remains to use our second\nupdate (2.46a):\nEk+1 − Ek\nf (xk+1 ) − f (yk ) Ak+1 − Ak\n≤ αk h∇f (xk+1 ) , x∗ − zk i + Ak\n+\n(f (xk+1 ) − f (x∗ ))\nδ\nδ\nδ\np\np\n1\np − 1 − p−1\nf (yk+1 ) − f (xk+1 )\n+\nσ\nδ −1 (Ak+1 − Ak ) p−1 k∇f (xk+1 ) k p−1 + Ak+1\np\nδ\n\n\ny\n−\nx\nf\n(xk+1 ) − f (yk )\nk\nk+1\n≤ αk h∇f (xk+1 ) , x∗ − yk i + Ak+1 ∇f (xk+1 ) ,\n+ Ak\nδ\nδ\nAk+1 − Ak\n+\n(f (xk+1 ) − f (x∗ )) + εk+1\nδ\nAk+1 − Ak\n=−\nDf (x∗ , xk+1 ) − Ak+1 /δDf (xk+1 , yk ) + εk+1\nδ\n\nAPPENDIX B. CHAPTER TWO\n\n110\n\nFrom here, we can conclude Ek+1δ−Ek ≤ εk using the convexity of f .\nWe now show the bound (B.35b) for algorithm (2.47)\nDh (x∗ , zk+1 ) − Dh (x∗ , zk )\nEk+1 − Ek\n=\n+ Ak+1 (f (yk+1 ) − f (x)) − Ak (f (yk ) − f (x∗ ))\nδ\nδ\n1\nAk+1 − Ak\n(2.47c)\n= αk h∇f (yk+1 ), x∗ − zk+1 i − Dh (zk+1 , zk ) +\n(f (yk+1 ) − f (x∗ ))\nδ\nδ\nf (yk+1 ) − f (yk )\n+ Ak\nδ\nσ\n≤ αk h∇f (yk+1 ) , x∗ − zk i + αk h∇f (yk+1 ) , zk − zk+1 i − kzk+1 − zk kp\nδp\nAk+1 − Ak\nf\n(y\n)\n−\nf\n(y\n)\nk+1\nk\n+\n(f (yk+1 ) − f (x∗ )) + Ak\nδ\nδ\nf (yk+1 ) − f (yk ) Ak+1 − Ak\n+\n(f (yk+1 ) − f (x∗ ))\n≤ αk h∇f (yk+1 ), x∗ − zk i + Ak\nδ\nδ\nyk+1 − xk+1\n− Ak+1 h∇f (yk+1 ),\ni + εk+1\nδ\nThe first inequality follows from the uniform convexity of h and the second uses Young’s\ninequality (A.25) and definition (B.35b). Using the second update (2.47a), we obtain our\ninitial error bound:\nf (yk+1 ) − f (yk ) Ak+1 − Ak\nEk+1 − Ek\n≤ αk h∇f (yk+1 ) , x∗ − yk i + Ak\n+\nf (yk+1 ) − f (x∗ )\nδ\nδ\nδ\n\n\u0013\n\u0013\nyk − xk+1\nyk+1 − xk+1\n+ Ak+1 ∇f (yk+1 ) ,\n− Ak+1 ∇f (yk+1 ) ,\n+ εk+1\nδ\nδ\n= αk Df (x∗ , yk+1 ) − Ak /δDf (yk+1 , yk ) + εk+1\nAccelerated universal methods [40, 6, 46, 21] The term “universal methods” refers to\nthe algorithms designed for the class of functions with (\u000f, ν)-Holder-continuous higher-order\ngradients (2 ≤ p ∈ N, ν ∈ (0, 1], \u000f > 0),\n1\nk∇p−1 f (x) − ∇p−1 f (y)k ≤ kx − ykν .\n\u000f\n\n(B.36)\n\nTypically, practitioners care about the setting where we have Holder continuous gradients\n(p = 2) or Holder-continuous Hessians (p = 3), since methods which use higher-order information are often too computationally expensive. In the case p ≥ 3, the gradient update\n\u001a\n\u001b\nN\np̃\nG\u000f,p,ν,N (x) = arg min fp−1 (x; y) + kx − yk , p̃ = p − 1 + ν, N > 1\n(B.37)\ny∈X\n\u000fp̃\ncan be used to simplify the error (2.50b) obtained by algorithm (2.47). Notice, the gradient update is regularized by the smoothness parameter p̃. We summarize this result in the\nfollowing proposition.\n\nAPPENDIX B. CHAPTER TWO\n\n111\n\nLemma B.6.2. Assume f has Holder continuous higher-order gradients. Using the map\nyk+1 = G\u000f,p,ν,N (xk+1 ) defined by (B.37) in update (2.47b), results in the following progress\ncondition,\np̃−1\n\np̃\n1\n(N 2 − 1) 2p̃−2 p̃−1\nk∇f (yk+1 )k p̃−1 ,\nh∇f (yk+1 ), yk+1 − xk+1 i ≤ −\n\u000f\n2N\n\n(B.38)\n\nwhere p̃ = p − 1 + ν and p ≥ 3.\nLemma B.6.2 demonstrates that if the Taylor approximation is regularized according to\nthe smoothness of the function, the progress condition scales as a function of the smoothness in a particularly nice way. Using this inequality, we can simplify the error (2.50b) in\nalgorithm (2.47) to the following,\np̃\n\np̃\n1 (Ak+1 − Ak ) p̃−1\np̃ − 1 − p̃−1\nεk+1 =\nσ\nk∇f (yk+1 )k p̃−1\np̃\nδ\np̃−1\n\np̃\n1\nAk+1 (N 2 − 1) 2p̃−2 p̃−1\n\u000f k∇f (yk+1 )k p̃−1 ,\n−\nδ\n2N\n\nwhere we have assumed that the geometry scales nicely with the smoothness condition: Dh (x, y) ≥\nσ\nkx − ykp̃ . This requires the condition p ≥ 3. To ensure a non-positive error we choose a\np̃\nsequence which satisfies the bound,\np̃−1\n\np̃\n\n1\n(Ak+1 − Ak ) p̃−1\np̃ (N 2 − 1) 2p̃−2\n≤ (\u000fσ) p̃−1\n:= C\u000f,σ,p̃,N .\nAk+1\np̃ − 1\n2N\n\nThis bound is maximized by polynomials in k of degree p̃ with leading coefficient proporp̃−1\ntional to C\u000f,σ,p̃,N\n; this results in the convergence rate bound f (yk ) − f (x∗ ) ≤ O(1/\u000fσk p̃ ) =\np−1+ν\nO(1/\u000fσk\n). We can compare this convergence rate, to that obtained by using just gradient map yk+1 = G\u000f,p,p̃,N (yk ); this algorithm obtains a slower f (yk ) − f (x∗ ) ≤ O(1/\u000fσk p̃−1 ) =\nO(1/\u000fσk p−2+ν ) convergence rate under the same smoothness assumptions. This result unifies\nand extends the analyses of the accelerated (universal) cubic regularized Newton’s method [40,\n21] and accelerated higher-order methods [6]. Wibisono et. al. [76] show that kxk − yk k =\nO(\u000f1/p̃ ) and εk = O(\u000f1/p̃ ) so that as \u000f1/p̃ → 0 we recover the dynamics (2.41) and the statement Ėt ≤ 0 for Lyapunov function (2.38).\nWe end by mentioning that in the special case p = 2, Nesterov [46] showed that a slightly\nmodified gradient map,\nG\u000f ̃(x) = x − \u000f ̃ ∇f (x),\n\n(B.39)\n\nhas the following property when applied to functions with Holder continuous gradients.\n\nAPPENDIX B. CHAPTER TWO\n\n112\n\nLemma B.6.3. ([46, Lemma 1]) Assume f has (\u000f, ν)-Holder continuous gradients, where\n1−ν\n2\nν ∈ (0, 1]. Then for 1/ ̃\u000f ≥ (1/2δ̃) 1+ν (1/\u000f) 1+ν the following bound,\n\u000f ̃\nf (yk+1 ) − f (xk+1 ) ≤ − k∇f (xk+1 )k2 + δ̃,\n2\nholds for yk+1 = G\u000f ̃(xk+1 ) given by (B.39).\nThat is, if we take a gradient descent step with increased regularization and assume h is\nσ-strongly convex, the error for algorithm (2.46) when f is (\u000f, ν)-Holder continuous can be\nwritten as,\nεk+1 =\n\n\u000f ̃Ak+1\n(Ak+1 − Ak )2\nk∇f (xk+1 )k2 −\nk∇f (xk+1 )k2 + δ̃.\n2σδ\n2δ\n\n(B.40)\n\nThis allows us to conclude O(1/ ̃\u000fσk 2 ) convergence rate of the function to within δ̃, which is\ncontrolled by the amount of regularization \u000f ̃ we apply in the gradient update.\n\nB.6.2\n\nProof of Lemma B.6.2\n\nA similar progress bound was proved in Wibisono, Wilson and Jordan [76, Lem 3.2]. Note,\ny = G(x) satisfies the optimality condition\np−1\nX\n\nN\n1\n∇i f (x) (y − x)i−1 + ky − xkp̃−2 (y − x) = 0.\n(i − 1)!\n\u000f\ni=1\n\n(B.41)\n\nFurthermore, since ∇p−1 f is Holder-continuous (B.36), we have the following error bound\non the (p − 2)-nd order Taylor expansion of ∇f ,\np−1\nX\n\n1\n∇f (y) −\n∇i f (x)(y − x)i−1 =\n(i\n−\n1)!\ni=0\n\nZ 1\n\n[∇p−1 f (ty + (1 − t)x) − ∇p−1 f (x)](y − x)p−2 dt\n\n0\n\n1\n≤ ky − xkp−2+ν\n\u000f\n\nZ 1\n\n1\ntν = ky − xkp̃−1 (B.42)\n\u000f\n0\n\nSubstituting (B.41) to (B.42) and writing r = ky − xk, we obtain\n∇f (y) +\n\nN rp̃−2\nrp̃−1\n(y − x) ≤\n.\n\u000f\n\u000f\n∗\n\n(B.43)\n\nNow the argument proceeds as in [76]. Squaring both sides, expanding, and rearranging the\nterms, we get the inequality\nh∇f (y), x − yi ≥\n\n\u000f\n(N 2 − 1)rp̃\n2\nk∇f\n(y)k\n+\n.\n∗\n2N rp̃−2\n2N \u000f\n\n(B.44)\n\nAPPENDIX B. CHAPTER TWO\n\n113\n\nNote that if p̃ = 2, then the first term in (B.44) already implies the desired bound (B.38).\nNow assume p̃ ≥ 3. The right-hand side of (B.44) is of the form A/rp̃−2 + Brp̃ , which is a\no 1\nn\nA 2p̃−2\n, yielding a minimum value of\nconvex function of r > 0 and minimized by r∗ = (p̃−2)\np̃ B\np̃−2\np̃\nA\n+ B(r∗ )p = A 2p̃−2 B 2p̃−2\n∗\np̃−2\n(r )\n\n\"\u0012\n\np̃\np̃ − 2\n\n\u0013 2p̃−2\np̃−2\n\n\u0012\n+\n\np̃ − 2\np̃\n\np̃ #\n\u0013 p̃−2\n\np̃\n\np̃−2\n\n≥ A 2p̃−2 B 2p̃−2 .\n\n\u000f\nSubstituting the values A = 2N\nk∇f (y)k2∗ and B = 2N1 \u000f (N 2 − 1) from (B.44), we obtain\n\nh∇f (y), x−yi ≥\n\np̃−2\n\u0012\n\u0013 2p̃−2\np̃\n\u0011 2p̃−2\np̃\np̃−2\n1\n1\n(N 2 − 1) 2p̃−2 p̃−1\n2\n2\n=\nk∇f (y)k∗\n(N − 1)\n\u000f k∇f (y)k∗p̃−1 ,\n2N\n2N \u000f\n2N\n\n\u0010 \u000f\n\nwhich proves the progress bound (B.38).\n\nB.6.3\n\nProof of Proposition 2.2.4\n\nWe show the initial error bound (2.64). We check,\nEk+1 − Ek\nAk+1 − Ak\nf (yk+1 ) − f (yk )\n=\n(f (yk ) − f (x∗ ) − μDh (x∗ , zk )) + Ak+1\nδ\nδ\nδ\n\n∇h (zk+1 ) − ∇h (zk ) ∗\n, x − zk + ε1k\n− Ak+1 μ\nδ\n\n\nAk+1 − Ak\nxk − y k\n∗\n∗\n≤\n(f (yk ) − f (x ) − μDh (x , zk )) + Ak+1 ∇f (xk ),\nδ\nδ\n\n\n∇h (zk+1 ) − ∇h (zk ) ∗\nμ\n, x − zk + ε2k\n− Ak+1 Dh (xk , yk ) − Ak+1 μ\nδ\nδ\n\n\nxk − y k\n(2.62b) Ak+1 − Ak\n∗\n∗\n(f (yk ) − f (x ) − μDh (x , zk )) + Ak+1 ∇f (xk ),\n=\nδ\nδ\nμ\n− Ak+1 Dh (xk , yk ) + Ak+1 τk h∇f (xk ), x∗ − xk i + Ak+1 τk h∇f (xk ) , xk − zk i\nδ\n− μAk+1 τk h∇h (xk ) − ∇h (zk ) , x∗ − zk i + ε2k\nAk+1 − Ak\nμ\n=\n(f (yk ) − f (x∗ ) − μDh (x∗ , zk )) − Ak+1 Dh (xk , yk )\nδ\nδ\n+ Ak+1 τk h∇f (xk ), x∗ − xk i − μAk+1 τk h∇h (xk ) − ∇h (zk ) , x∗ − zk i + ε2k\nAk+1 − Ak\n≤\n(f (yk ) − f (x∗ ) − μDh (x∗ , zk )) − Ak+1 τk (f (xk ) − f (x∗ ) + μDh (x∗ , xk ))\nδ\nσμ\n− Ak+1 kxk − yk k2 − Ak+1 τk μ h∇h (xk ) − ∇h (zk ) , x∗ − zk i + ε2k\n2δ\n\nAPPENDIX B. CHAPTER TWO\n\n114\n\nHere, ε1k = Ak+1 μ ((h∇h (zk+1 ) − ∇h (zk )) /δ, zk − zk+1 i+ 1δ Dh (zk+1 , zk )) ≤ Ak+1 σμ\nk∇h (zk+1 )−\n2δ\n2\n∇h(zk )k , where the upper bound follows from the σ-strong convexity of h and Young’s in(xk )\n+Ak+1 σμ\nk∇h (zk+1 )−∇h (zk ) k2 . The first inequality uses the\nequality. ε2k = Ak+1 f (yk+1 )−f\nδ\n2δ\nμ-strong convexity of f with respect to h. The second inequality uses the strong convexity of\nf and σ-strong convexity of h. We continue by using the Bregman three point identity (A.27)\nEk+1 − Ek\nAk+1 − Ak\nσμ\n=\n(f (yk ) − f (xk ) + μDh (xk , zk )) − Ak+1 kxk − yk k2 + ε2k\nδ\nδ\n2δ\nAk+1 − Ak\n(h∇f (xk ) , yk − xk i + (1/\u000f)Dh (yk , xk ) − μDh (xk , zk ))\n≤\nδ\nσμ\n− Ak+1 kxk − yk k2 + ε2k\n2δ\nThe last line follows from using the (1/\u000f)-smoothness of f . Now we turn to the case where\nh = 12 kxk2 (so σ = 1)\n\u0012\n\u0013\nEk+1 − Ek\nAk+1 − Ak\nμ\n1\n2\n2\n≤\nh∇f (xk ) , yk − xk i + kyk − xk k − kxk − zk k\nδ\nδ\n2\u000f\n2\n2\n\nf (yk+1 ) − f (xk )\nμ xk − yk\nμ zk+1 − zk\n+ ε2k + Ak+1\n+ δAk+1\n2\nδ\nδ\n2\nδ\n\u0012\n\u0013\nAk+1 − Ak\nμ\n1\n2\n2\n=\nh∇f (xk ) , yk − xk i + kyk − xk k − 2 2 kxk − yk k\nδ\n2\u000f\n2τk δ\nf (yk + 1) − f (xk )\nμ\n− δAk+1 τk2 kzk − xk k2 + ε2k + Ak+1\n2\nδ\nμ\n2\n+ δAk+1 kτk (xk − zk − (1/μ)∇f (xk )) k\n2\n\u0013\n\u0012\n2\nαk δ\ny k − xk\nAk+1 μ\n−\n= −δAk+1\n2αk δ\n2Ak+1 \u000f\nδ\n\u0013\n\u0012\nf (yk+1 ) − f (xk )\n2 1\n2\n+ δτk k∇f (xk ) k\n+ Ak+1\nδ\n2μ\n\n2\n\n− δAk+1\n\nB.6.4\n\nProof of Theorem 2.2.6\n\nWe follow the framework of Su, Boyd and Candes [70, pg. 36]. It suffices to established that\nour Lyapunov function is monotonically decreasing. Although Et may not be differentiable,\nwe can study E(t + ∆t) − E(t))/∆t for small ∆t > 0. For the first term in (2.65), note that\n(t + ∆t)p (f (Xt+∆t ) − f (x)) − tp (f (Xt ) − f (x)) = tp (f (Xt+∆t ) − f (Xt ))\n+ ptp−1 (f (Xt+∆t ) − f (x))∆t + o(∆t)\n= tp hGf (Xt , Ẋt ), Ẋt i∆t\n+ ptp−1 (f (Xt+∆t ) − f (x))∆t + o(∆t)\n\nAPPENDIX B. CHAPTER TWO\n\n115\n\nwhere the second line follows since we assume f is locally Lipschitz, the o(∆t) does not affect\nthe function in the limit:\nf (Xt+∆t ) = f (X + ∆tẊt + o(∆t)) = f (X + ∆tẊt ) + o(∆t)\n= f (Xt ) + hGf (Xt , Ẋt ), Ẋt i∆t + o(∆t)\nThe second term Dh (x, Xt + pt Ẋt ) is differentiable, with derivative −\nHence,\n\u0010\n\u0011\n\u0010\nt + ∆t\nt \u0011\nDh x, Xt+∆t +\nẊt+∆t − Dh x, Xt + Ẋt\np\np\n\n\nd\n∇h(Zt ), x − Zt ∆t + o(∆t)\n=−\ndt\n\n(B.45)\n\nd\n∇h(Zt ), x − Zt\ndt\n\n.\n\n= ptp−1 hGφ (Xt , Ẋt ), x − Zt i∆t + o(∆t)\n= ptp−1 hGφ (Xt , Ẋt ), x − Xt i∆t + tp hGφ (Xt , Ẋt ), Ẋt i∆t + o(∆t)\n≤ −ptp−1 (f (Xt ) − f (x))∆t + tp hGφ (Xt , Ẋt ), Ẋt i∆t + o(∆t)\n= −ptp−1 (f (Xt ) − f (x))∆t + tp hGf (Xt , Ẋt ), Ẋt i∆t\nThe inequality follows from the convexity of f .Combining everything we have shown\nEt+∆t − Et\n≤ 0,\n∆t\n∆t→0+\n\nlim sup\n\nwhich along with the continuity of Et , ensures Et is a non-increasing of time. We can make a\nsimilar argument for dynamic (2.66). Notice the first term in the approximation E(t + ∆t) −\nE(t))/∆t, is the same as in the previous setting. Therefore we calculate the second term,\n\u0013\n\u0012 \u0010\n\u0010\n\u0011\n\u0010\nt \u0011\nt \u0011\nt + ∆t\np−1\np\nẊt+∆t − Dh x, Xt + Ẋt\n− pt Dh x, Xt + Ẋt ∆t\n(t + ∆t) Dh x, Xt+∆t +\np\np\np\n\u0012\n\n\u0013\n\u0010\n\u0011\nd\nt\n= (tp + ∆t) −\n∇h(Zt ), x − Zt ∆t + o(∆t) − ptp−1 Dh x, Xt + Ẋt ∆t\ndt\np\n\u0010\nD\nE\n\u0011\n(2.66)\n= ptp−1 − h∇h(Xt ) − ∇h(Zt ), x − Zt i ∆t + G(Xt , Ẋt ), x − Zt ∆t − Dh (x, Zt )∆t + ∆t\n\u0010\nD\nE \u0011\n(A.27)\n= ptp−1 Dh (x∗ , Xt )∆t + G(Xt , Ẋt ), x − Zt ∆t\n≤ −ptp−1 (f (Xt ) − f (x))∆t + tp hGf (Xt , Ẋt ), Ẋt i∆t\nwhere the last line follows from convexity. Combining everything we have shown\nEt+∆t − Et\n≤ 0,\n∆t\n∆t→0+\n\nlim sup\n\nwhich along with the continuity of Et , ensures Et is a non-increasing of time.\n\nAPPENDIX B. CHAPTER TWO\n\nB.7\n\n116\n\nEstimate Sequences\n\nIn this section we formalize the connection between estimate sequences and Lyapunov functions.\n\nB.7.1\n\nThe Quasi-Montone Subgradient Method\n\nThe discrete-time estimate sequence (2.72) for quasi-monotone subgradient method can be\nwritten:\n−1\n−1\nφk+1 (x) − A−1\nk+1 ε̃k+1 := f (xk+1 ) + Ak+1 Dh (x, zk+1 ) − Ak+1 ε̃k+1\n\u0001\n(2.72)\n= (1 − τk ) φk (x) − A−1\nε̃\n+ τk fk (x)\nk\nk\n\u0013\u0012\n\u0013\n\u0012\n1\nε̃k\nαk\nαk\nf (xk ) +\nDh (x, zk ) −\n+\nfk (x).\n= 1−\nAk+1\nAk\nAk\nAk+1\n\nMultiplying through by Ak+1 , we have\n−1\nAk+1 f (xk+1 ) + Dh (x, zk+1 ) − ε̃k+1 = (Ak+1 − αk )(f (xk ) + A−1\nk Dh (x, zk ) − Ak ε̃k )\n− (Ak+1 − αk )A−1\nk ε̃k + αk fk (x)\n\u0001\n−1\n= Ak f (xk ) + A−1\nD\n(x,\nz\n)\n−\nA\nε̃\n+ αk fk (x)\nh\nk\nk\nk\nk\n(2.71)\n\n≤ Ak f (xk ) + Dh (x, zk ) − ε̃k + αk f (x).\nRearranging, we obtain our Lyapunov argument Ek+1 ≤ Ek + εk+1 for (2.48):\nAk+1 (f (xk+1 ) − f (x)) + Dh (x, zk+1 ) ≤ Ak (f (xk ) − f (x)) + Dh (x, zk ) + εk+1 .\nGoing the other direction, from our Lyapunov analysis we can derive the following bound:\nEk ≤ E0 + ε̃k\n(B.46)\nAk (f (xk ) − f (x)) + Dh (x, zk ) ≤ A0 (f (x0 ) − f (x)) + Dh (x, z0 ) + ε̃k\n\u0013\n\u0012\n\u0013\n\u0012\n1\n1\n∗\nDh (x, zk ) ≤ (Ak − A0 )f (x) + A0 f (x0 ) +\nDh (x , z0 ) + ε̃k\nAk f (xk ) −\nAk\nA0\nAk φk (x) ≤ (Ak − A0 )f (x) + A0 φ0 (x) + ε̃k .\n(B.47)\nRearranging, we obtain our estimate sequence (2.69) (A0 = 1) with an additional error term:\n\u0010\nA0 \u0011\nA0\nε̃k\n1 \u0011\n1\nε̃k\nφk (x) ≤ 1 −\nf (x) +\nφ0 (x) +\n= 1−\nf (x) +\nφ0 (x) +\n.\nAk\nAk\nAk\nAk\nAk\nAk\n\u0010\n\n(B.48a)\n\nAPPENDIX B. CHAPTER TWO\n\nB.7.2\n\n117\n\nFrank-Wolfe\n\nThe discrete-time estimate sequence (2.72) for conditional gradient method can be written:\n\u0012\n\u0013\nε̃k+1\nε̃k+1 (2.72)\nε̃k\nφk+1 (x) −\n:= f (xk+1 ) −\n= (1 − τk ) φk (x) −\n+ τk fk (x)\nAk+1\nAk+1\nAk\n\u0012\n\u0013\u0012\n\u0013\nαk\nε̃k\nαk\nTable 2.8\n=\n1−\nf (xk ) −\n+\nfk (x).\nAk+1\nAk\nAk+1\nMultiplying through by Ak+1 , we have\n\u0012\n\u0013\n\u0012\n\u0013\nε̃k+1\nε̃k\nAk+1 f (xk+1 ) −\n= (Ak+1 − (Ak+1 − Ak )) f (xk ) −\n+ αk fk (x)\nAk+1\nAk\n\u0001\n= Ak f (xk ) − A−1\nk ε̃k + (Ak+1 − Ak )fk (x)\n(2.71)\n\n≤ Ak f (xk ) − ε̃k + (Ak+1 − Ak )f (x).\nRearranging, we obtain our Lyapunov argument Ek+1 − Ek ≤ εk+1 for (2.35) :\nAk+1 (f (xk+1 ) − f (x)) ≤ Ak (f (xk ) − f (x)) + εk+1 .\nGoing the other direction, from our Lyapunov analysis we can derive the following bound:\nEk ≤ E0 + ε̃k\nAk f (xk ) ≤ (Ak − A0 )f (x) + A0 f (x0 ) + ε̃k\nAk φk (x) ≤ (Ak − A0 )f (x) + A0 φ0 (x) + ε̃k\nRearranging, we obtain our estimate sequence (2.69) (A0 = 1) with an additional error term:\n\u0010\n\u0010\nA0 \u0011\nA0\nε̃k\n1 \u0011\n1\nε̃k\nf (x) +\nφ0 (x) +\n= 1−\nf (x) +\nφ0 (x) +\n.\nφk (x) ≤ 1 −\nAk\nAk\nAk\nAk\nAk\nAk\nSince the Lyapunov function property allows us to write\neβt f (Xt ) ≤ (eβt − eβ0 )f (x) + eβ0 f (X0 ),\nwe can extract {f (Xt ), eβt } as the continuous-time estimate sequence for Frank-Wolfe.\n\nB.7.3\n\nAccelerated Gradient Descent (Strong Convexity)\n\nThe discrete-time estimate sequence (2.72) for accelerated gradient descent can be written:\nφk+1 (x) := f (xk+1 ) +\n\n(2.71)\nμ\n(2.72)\nkx − zk+1 k2 = (1 − τk )φk (x) + τk fk (x) ≤ (1 − τk )φk (x) + τk f (x).\n2\n\nAPPENDIX B. CHAPTER TWO\n\n118\n\nTherefore, we obtain the inequality Ẽk+1 − Ẽk ≤ −τk Ẽk for our Lyapunov function Ẽk =\nf (xk ) − f (xa st) + μ2 kx∗ − xk k2 by simply writing φk+1 (x) − f (x) + f (x) − φk (x) ≤ −τk (φk (x) −\nf (x)):\n\u0010\n\u0011\nμ\nμ\n2\n2\nf (xk+1 ) − f (x) + kx − zk+1 k − f (xk ) − f (x) + kx − zk+1 k\n2\n2\n\u0011\n\u0010\nTable 2.8\nμ\n≤ −τk f (xk ) − f (x) + kx − zk+1 k2 .\n2\nGoing the other direction, we have,\nEk+1 − Ek ≤ −τk Ek\nφk+1 ≤ (1 − τk )φk (x) + τk f (x)\nAk+1 φk+1 ≤ Ak φk + (Ak+1 − Ak )f (x).\nSumming over the right-hand side, we obtain the estimate sequence (2.69):\n\u0010\nA0\n1 \u0011\n1\nA0 \u0011\nf (x) +\nφ0 (x) = 1 −\nf (x) +\nφ0 (x).\nφk+1 ≤ 1 −\nAk+1\nAk+1\nAk+1\nAk+1\n\u0010\n\nSince the Lyapunov function property allows us to write\n\u0010\n\u0011\n\u0011\n\u0010\nμ\nμ\neβt f (Xt ) + kx − Zt k2 ≤ (eβt − eβ0 )f (x) + eβ0 f (X0 ) + kx − Z0 k2 ,\n2\n2\nwe can extract {f (Xt ) + μ2 kx − Zt k2 , eβt } as the continuous-time estimate sequence for accelerated gradient descent in the strongly convex setting.\n\nB.7.4\n\nAdagrad with momentum\n\nWe analyze Adagrad with momentum (2.84) using the Lyapunov function (2.85). Denote\nWe check,\nEk+1 − Ek\n1\n1\nAk+1 − Ak\n= kx∗ − zk+1 k2Hk − kx∗ − zk k2Hk +\n(f (xk+1 ) − f (x∗ ))\nδ\n2\n2\nδ\nf (xk+1 ) − f (xk )\nAk\n+ ε1k\nδ\n\n\nzk+1 − zk ∗\nAk+1 − Ak\n= − Hk\n, x − zk+1 +\n(f (xk+1 ) − f (x∗ ))\nδ\nδ\nf (xk+1 ) − f (xk )\nAk\n+ ε1k\nδ\n(2.84b)\n\n= −αk Dfg (x∗ , xk+1 ) − αk hg(xk+1 ), xk+1 − zk+1 i + Ak (f (xk+1 ) − f (xk )) + ε1k\n\n(2.84b)\n\n= −αk Dfg (x∗ , xk+1 ) − Ak /δDfg (xk , xk+1 ) + ε2k\n\nAPPENDIX B. CHAPTER TWO\n\n119\n\nwhere the errors scale as ε1k = 21 kx∗ − zk+1 k2Hk+1 − 21 kx∗ − zk+1 k2Hk − 1δ kzk+1 − zk k2Hk and\nε2k = ε1k + αk h∇f (xk+1 ), zk − zk+1 i. We use Young’s inequality to obtain the upper bound\nα2\nε2k ≤ 2σk kg(xk+1 )k2Hk∗ + 12 kx∗ − zk+1 k2Hk+1 − 21 kx∗ − zk+1 k2Hk . Using Theorem 7 and Lemma 4 in\nDuchi et al [16], we conclude the bounds 12 kx∗ − zk+1 k2Hk+1 − 12 kx∗ − zk+1 k2Hk ≤ maxk≤K kx∗ −\nPK\n1/2\n1/2\n2\nzk k22 tr(HK ) = D2 tr(HK ) where D is the diameter of the set and\ns=1 kg(xs )kHs∗ ≤\n1/2\n\n∗\n2tr(H√\nK ). From these upper bounds, we can conclude the an optimal f (xk ) − f (x ) ≤\nO(1/ k) convergence rate. In particular, this method has a matching lower bound [16].\n\n120\n\nAppendix C\nChapter Three\nC.1\n\nPreliminaries\n\nNotation. The notation is standard. [n] = {1, 2, ..., n} refers to the set of integers from\n1 to n, and 2[n] refers to the set of all subsets of [n]. We let 1n ∈ Rn denote the vector of\nall ones. Given a square matrix M with real eigenvalues, we let λmax (M ) (resp. λmin (M ))\ndenote the maximum (resp. minimum) eigenvalue of M . For two symmetric matrices M , N ,\nthe notation M < N (resp. M \u001f N ) means that the matrix M − N is positive semi-definite\n(resp. positive definite). Every such M \u001f 0 defines a real inner productpspace via the\ninner product hx, yiM = xT M y. We refer to its induced norm as kxkM = hx, xiM . The\nstandard Euclidean inner product and norm will be denoted as h·, ·i and k·k2 , respectively.\nFor an arbitrary matrix M , we let M † denote its Moore-Penrose pseudo-inverse and PM the\northogonal projector onto the range of M , which we denote as R(M ). When M < 0, we\nlet M 1/2 denote its unique Hermitian square root. Finally, for a square n × n matrix M ,\ndiag(M ) is the n × n diagonal matrix which contains the diagonal elements of M .\nPartitions on [n]. In what follows, unless stated otherwise, whenever we discuss a partition\nS\nof [n] we assume that the partition is given by n/p\ni=1 Ji , where\nJ1 = {1, 2, ..., p} , J2 = {p + 1, p + 2, ..., 2p}, ... .\nThis is without loss of generality because for any arbitrary equal sized partition of [n], there\nexists a permutation matrix Π such that all our results apply by the change of variables\nA ← ΠT AΠ and b ← ΠT b.\n\nAPPENDIX C. CHAPTER THREE\n\n121\n\nC.2\n\nProofs for Separation Results (Section 3.4.3.1)\n\nC.2.1\n\nExpectation calculations (Propositions 3.4.1 and 3.4.2)\n\nRecall the family of n × n positive definite matrices A defined in (3.35) as\nAα,β = αI +\n\nβ\n1n 1Tn , α > 0, α + β > 0 .\nn\n\nWe first gather some elementary formulas. By the matrix inversion lemma,\n\u0012\n\u0013−1\nβ\nβ/n\n−1\nT\nAα,β = αI + 1n 1n\n1n 1Tn .\n= α−1 I −\nn\nα(α + β)\n\n(C.1)\n\n(C.2)\n\nFurthermore, let S ∈ Rn×p be any column selector matrix with no duplicate columns. We\nhave again by the matrix inversion lemma\n\u0012\n\u0013−1\nβ\nβ/n\nT\nT\n−1\n1p 1T .\n(S Aα,β S) = αI + 1p 1p\n= α−1 I −\n(C.3)\nn\nα(α + βp/n) p\nThe fact that the right hand side is independent of S is the key property which makes our\ncalculations possible. Indeed, we have that\nS(S T Aα,β S)−1 S T = α−1 SS T −\n\nβ/n\nS1p 1Tp S T .\nα(α + βp/n)\n\n(C.4)\n\nWith these formulas in hand, our next proposition gathers calculations for the case when S\nrepresents uniformly choosing p columns without replacement.\nProposition C.2.1. Consider the family of n × n positive definite matrices {Aα,β } from\n(C.1). Fix any integer p such that 1 < p < n. Let S ∈ Rn×p denote a random column\nselector matrix where each column of S is chosen uniformly at random without replacement\nfrom {e1 , ..., en }. For any Aα,β ,\n(n − 1)α + (p − 1)β\n(n − p)pβ\nI+\n1n 1Tn ,\n(n − 1)(nα + pβ)\nn(n − 1)(nα + pβ)\n(C.5)\n\u0012\n\u0013\n2\n1\n(n − p) β\nT\n−1 T −1\nT\n−1 T\nE[S(S Aα,β S) S Gα,β S(S Aα,β S) S ] =\n−\nI\nα (n − 1)((n − 1)α + (p − 1)β)(nα + pβ)\n(p − 1)β(nα(1 − 2n) + np(α − β) + pβ)\n+\n1n 1Tn .\n(n − 1)nα((n − 1)α + (p − 1)β)(nα + pβ)\n(C.6)\nE[S(S T Aα,β S)−1 S T Aα,β ] = p\n\nAbove, Gα,β = E[S(S T Aα,β S)−1 S T ].\n\nAPPENDIX C. CHAPTER THREE\n\n122\n\nProof: First, we have the following elementary expectation calculations,\np\nI,\nn\u0012\n\u0013\n\u0012\n\u0013\np\np−1\np p−1\nT T\nE[S1p 1p S ] =\n1−\nI+\n1n 1Tn ,\nn\nn−1\nn n−1\nE[SS T 1n 1Tp S T ] = E[S1p 1Tn SS T ] = E[SS T 1n 1Tn SS T ] = E[S1p 1Tp S T ] ,\n\u0012\n\u0013\n\u0012\n\u0013\np3\np−1\np3 p − 1\nT T\nT\nT T\nE[S1p 1p S 1n 1n S1p 1p S ] =\n1−\nI+\n1n 1Tn .\nn\nn−1\nn n−1\nE[SS T ] =\n\n(C.7)\n(C.8)\n(C.9)\n(C.10)\n\nTo compute Gα,β , we simply plug (C.7) and (C.8) into (C.4). After simplification,\n\u0012\n\u0012\n\u0013\u0013\np\nβ/n\np−1\np p−1\nβ/n\nT\n−1 T\nGα,β = E[S(S Aα,β S) S ] =\n1−\n1−\nI−\n1n 1Tn .\nαn\nα + βp/n\nn−1\nn n − 1 α(α + βp/n)\nFrom this formula for Gα,β , (C.5) follows immediately.\nT\n−1 T\nOur next goal is to compute E[S(S T Aα,β S)−1 S T G−1\nα,β S(S Aα,β S) S ]. To do this, we\nfirst invert Gα,β . Applying the matrix inversion lemma, we can write down a formula for the\ninverse of Gα,β ,\nG−1\nα,β =\n\n(p − 1)β(nα + pβ)\n(n − 1)α(nα + pβ)\nI+\n1n 1Tn .\n(n − 1)pα + (p − 1)pβ\nnp((n − 1)α + (p − 1)β)\n{z\n}\n{z\n}\n|\n|\nγ\n\n(C.11)\n\nη\n\nNext, we note for any r, q, using the properties that S T S = I, 1Tn S1p = p, and 1Tp 1p = p, we\nhave that\n(rSS T + qS1p 1Tp S T )(γI + η1n 1Tn )(rSS T + qS1p 1Tp S T )\n= γr2 SS T + 2rγqS1p 1Tp S T + ηr2 SS T 1n 1Tn SS T\n+ prηq(SS T 1n 1Tp S T + S1p 1Tn SS T ) + pq 2 γS1p 1Tp S T\n+ ηq 2 S1p 1Tp S T 1n 1Tn S1p 1Tp S T .\nTaking expectations of both sides of the above equation and using the formulas in (C.7),\n(C.8), (C.9), and (C.10),\nE[(rSS T + qS1p 1Tp S T )(γI + η1n 1Tn )(rSS T + qS1p 1Tp S T )]\n=\n\np(p(n − p)q 2 + 2(n − p)qr + (n − 1)r2 )γ + p(n − p)(pq + r)2 η\nI\nn(n − 1)\np(p − 1)(q(pq + 2r)γ + (pq + r)2 η)\n+\n1n 1Tn .\nn(n − 1)\n\nβ/n\nWe now set r = α−1 , q = − α(α+βp/n)\n, and γ, η from (C.11) to reach the desired formula for\n(C.6). Proposition 3.4.2 follows immediately from Proposition C.2.1 by plugging in α = 1\n\nAPPENDIX C. CHAPTER THREE\n\n123\n\ninto (C.5). We next consider how (C.4) behaves under a fixed partition of {1, ..., n}. Recall\nour assumption on partitions: n = pk for some integer k ≥ 1, and we sequentially partition\n{1, ..., n} into k partitions of size p, i.e. J1 = {1, ..., p}, J2 = {p + 1, ..., 2p}, and so on.\nDefine S1 , ..., Sk ∈ Rn×p such that Si is the column selector matrix for the partition Ji , and\nS uniformly chooses Si with probability 1/k.\nProposition C.2.2. Consider the family of n × n positive definite matrices {Aα,β } from\n(C.1), and let n, p, and S be described as in the preceding paragraph. We have that\nE[S(S T Aα,β S)−1 S T Aα,β ] =\n\npβ\npβ\np\nI+ 2\n1n 1Tn − 2\nblkdiag(1p 1Tp , ..., 1p 1Tp ) .\nn\nn α + npβ\nn α + npβ\n|\n{z\n}\nk times\n\n(C.12)\nProof: Once again, the expectation calculations are\np\np\nE[SS T ] = I, E[S1p 1Tp S T ] = blkdiag(1p 1Tp , ..., 1p 1Tp ) .\nn\nn\n|\n{z\n}\nk times\n\nTherefore,\nE[S(S T Aα,β S)−1 S T ] =\n\np\np\nβ/n\nI−\nblkdiag(1p 1Tp , ..., 1p 1Tp ) .\nαn\nn α(α + βp/n)\n\nFurthermore,\nblkdiag(1p 1Tp , ..., 1p 1Tp )1n 1Tn = 1n 1Tn blkdiag(1p 1Tp , ..., 1p 1Tp ) = p1n 1Tn ,\nHence, the formula for E[S(S T Aα,β S)−1 S T Aα,β ] follows.\nWe now make the following observation. Let Q1 , ..., Qk be any partition of {1, ..., n} into\nk partitions of size p. Let ES∼Qi denote expectation with respect to S uniformly chosen as\ncolumn selectors among Q1 , ..., Qk , and let ES∼Ji denote expectation with respect to the S in\nthe setting of Proposition C.2.2. It is not hard to see there exists a permutation matrix Π\nsuch that\nΠT ES∼Qi [S(S T Aα,β S)−1 S T ]Π = ES∼Ji [S(S T Aα,β S)−1 S T ] .\nUsing this permutation matrix Π,\nλmin (ES∼Qi [PA1/2 S ]) = λmin (ES∼Qi [S(S T Aα,β S)−1 S T ]Aα,β )\nα,β\n\n= λmin (ES∼Qi [S(S T Aα,β S)−1 S T ]ΠAα,β ΠT )\n= λmin (ΠT ES∼Qi [S(S T Aα,β S)−1 S T ]ΠAα,β )\n= λmin (ES∼Ji [S(S T Aα,β S)−1 S T ]Aα,β )\n= λmin (ES∼Ji [PA1/2 S ]) .\nα,β\n\nAbove, the second equality holds because Aα,β is invariant under a similarity transform by any\npermutation matrix. Therefore, Proposition C.2.2 yields the μpart value for every partition\nQ1 , ..., Qk . The claim of Proposition 3.4.1 now follows by substituting α = 1 into (C.12).\n\nAPPENDIX C. CHAPTER THREE\n\nC.2.2\n\n124\n\nProof of Proposition 3.4.3\n\nDefine ek = xk − x∗ , Hk = Sk (SkT ASk )† SkT and G = E[Hk ]. From the update rule (3.19),\nek+1 = (I − Hk A)ek =⇒ A1/2 ek+1 = (I − A1/2 Hk A1/2 )A1/2 ek .\nTaking and iterating expectations,\nE[A1/2 ek+1 ] = (I − A1/2 GA1/2 )E[A1/2 ek ] .\nUnrolling this recursion yields for all k ≥ 0,\nE[A1/2 ek ] = (I − A1/2 GA1/2 )k A1/2 e0 .\nChoose A1/2 e0 = v, where v is an eigenvector of I − A1/2 GA1/2 with eigenvalue λmax (I −\nA1/2 GA1/2 ) = 1 − λmin (GA) = 1 − μ. Now by Jensen’s inequality,\nE[kek kA ] = E[kA1/2 ek k2 ] ≥ kE[A1/2 ek ]k2 = (1 − μ)k ke0 kA .\nThis establishes the claim.\n\nC.3\n\nProofs for Convergence Results (Section 3.4.3.2)\n\nWe now state our main structural result for accelerated coordinate descent. Let P be a\nprobability measure on Ω = S n×n × R+ × R+ , with S n×n denoting n × n positive semi-definite\nmatrices and R+ denoting positive reals. Write ω ∈ Ω as the tuple ω = (H, Γ, γ), and let E\ndenote expectation with respect to P. Suppose that G = E[ γ1 H] exists and is positive definite.\nNow suppose that f : Rn −→ R is a differentiable and strongly convex function, and put\nf∗ = minx f (x), with x∗ attaining the minimum value. Suppose that f is both μ-strongly\nconvex and has L-Lipschitz gradients with respect to the G−1 norm. This means that for all\nx, y ∈ Rn , we have\nμ\n(C.13a)\nf (y) ≥ f (x) + h∇f (x), y − xi + ky − xk2G−1 ,\n2\nL\nf (y) ≤ f (x) + h∇f (x), y − xi + ky − xk2G−1 .\n(C.13b)\n2\nWe now define a random sequence as follows. Let ω0 = (H0 , Γ0 , γ0 ), ω1 = (H1 , Γ1 , γ1 ), ...\nbe independent realizations from P. Starting from y0 = z0 = x0 with x0 fixed, consider the\nsequence {(xk , yk , zk )}k≥0 defined by the recurrence\nτ (xk+1 − zk ) = yk − xk+1 ,\n1\nyk+1 = xk+1 − Hk ∇f (xk+1 ) ,\nΓk\n\u0012\n\u0013\n1\nzk+1 − zk = τ xk+1 − zk −\nHk ∇f (xk+1 ) .\nμγk\n\n(C.14a)\n(C.14b)\n(C.14c)\n\nAPPENDIX C. CHAPTER THREE\n\n125\n\nIt is easily verified that (x, y, z) = (x∗ , x∗ , x∗ ) is a fixed point of the aforementioned dynamical\nsystem. Our goal for now is to describe conditions on f , μ, and τ such that the sequence of\nupdates (C.14a), (C.14b), and (C.14c) converges to this fixed point. As described in Wilson et\nal. [77], our main strategy for proving convergence will be to introduce the following Lyapunov\nfunction\nEk = f (yk ) − f∗ +\n\nμ\nkzk − x∗ k2G−1 ,\n2\n\n(C.15)\n\nand show that Ek decreases along every trajectory. We let Ek denote the expectation conditioned on Fk = σ(ω0 , ω1 , ..., ωk−1 ). Observe that xk+1 is Fk -measurable, a fact we will use\nrepeatedly throughout our calculations. With the preceding definitions in place, we state and\nprove our main structural theorem.\nTheorem C.3.1. (Generalization of Theorem 3.4.4.) Let f and G be as defined above, with\nf satisfying μ-strongly convexity and L-Lipschitz gradients with respect to the k·kG−1 norm,\nas defined in (C.13a) and (C.13b). Suppose that for all fixed x ∈ Rn , we have that the\nfollowing holds for almost every ω ∈ Ω,\nf (Φ(x; ω)) ≤ f (x) −\n\n1\n1\nk∇f (x)k2H , Φ(x; ω) = x − H∇f (x) .\n2Γ\nΓ\n\nFurthermore, suppose that ν > 0 satisfies\n\u0015\n\u0014\n\u0015\n\u0014\n1\n1\n−1\nE 2 HG H 4 νE 2 H .\nγ\nγ\nThen as long as we set τ > 0 such that τ satisfies for almost every ω ∈ Ω,\nr\nr\nγ\nμ\nμ\nτ≤√\n, τ≤\n,\nL\nΓ ν\n\n(C.16)\n\n(C.17)\n\n(C.18)\n\nwe have that Ek defined in (C.15) satisfies for all k ≥ 0,\nEk [Ek+1 ] ≤ (1 − τ )Ek .\n\n(C.19)\n\nProof. First, recall the following two point equality valid for any vectors a, b, c ∈ V in a real\ninner product space V ,\nka − bk2V − kc − bk2V = ka − ck2V + 2ha − c, c − biV .\n\n(C.20)\n\nAPPENDIX C. CHAPTER THREE\n\n126\n\nNow we can proceed with our analysis,\nμ\nkzk+1 − zk k2G−1\n2\nμ\n= f (yk+1 ) − f (xk+1 ) + f (xk+1 ) − f (yk ) − μhzk+1 − zk , x∗ − zk iG−1 + kzk+1 − zk k2G−1\n2\n(C.13a)\nμ\n≤ f (yk+1 ) − f (xk+1 ) + h∇f (xk+1 ), xk+1 − yk i − kxk+1 − yk k2G−1\n2\nμ\n2\n− μhzk+1 − zk , x∗ − zk iG−1 + kzk+1 − zk kG−1\n(C.21a)\n2\nμ\n(C.14c)\n= f (yk+1 ) − f (xk+1 ) + h∇f (xk+1 ), xk+1 − yk i − kxk+1 − yk k2G−1\n2\n1\nμ\n+ τ h Hk ∇f (xk+1 ) − μ(xk+1 − zk ), x∗ − zk iG−1 + kzk+1 − zk k2G−1\nγk\n2\n(C.21b)\nμ\n= f (yk+1 ) − f (xk+1 ) + h∇f (xk+1 ), xk+1 − yk i − kxk+1 − yk k2G−1\n2\n1\n1\n+ τ h Hk ∇f (xk+1 ), x∗ − xk+1 iG−1 + τ h Hk ∇f (xk+1 ), xk+1 − zk iG−1\nγk\nγk\nμ\n− τ μhxk+1 − zk , x∗ − zk iG−1 + kzk+1 − zk k2G−1\n2\nμ\n(C.14c)\n= f (yk+1 ) − f (xk+1 ) + h∇f (xk+1 ), xk+1 − yk i − kxk+1 − yk k2G−1\n2\n1\n1\n+ τ h Hk ∇f (xk+1 ), x∗ − xk+1 iG−1 + τ h Hk ∇f (xk+1 ), xk+1 − zk iG−1\nγk\nγk\nτ2\nμ\nkHk ∇f (xk+1 )k2G−1\n− τ μhxk+1 − zk , x∗ − zk iG−1 + kτ (xk+1 − zk )k2G−1 +\n2\n2μγk2\n1\n(C.21c)\n− τ hxk+1 − zk , τ Hk ∇f (xk+1 )iG−1\nγk\n(C.16)\n1\nμ\n≤ −\nk∇f (xk+1 )k2Hk + h∇f (xk+1 ), xk+1 − yk i − kxk+1 − yk k2G−1\n2Γk\n2\n1\n1\n+ τ h Hk ∇f (xk+1 ), x∗ − xk+1 iG−1 + τ h Hk ∇f (xk+1 ), xk+1 − zk iG−1\nγk\nγk\nμ\nτ2\n− τ μhxk+1 − zk , x∗ − zk iG−1 + kτ (xk+1 − zk )k2G−1 +\nkHk ∇f (xk+1 )k2G−1\n2\n2μγk2\n1\n(C.21d)\n− τ hxk+1 − zk , τ Hk ∇f (xk+1 )iG−1 .\nγk\n(C.20)\n\nEk+1 − Ek = f (yk+1 ) − f (yk ) − μhzk+1 − zk , x∗ − zk iG−1 +\n\nAbove, (C.21a) follows from μ-strong convexity, (C.21b) and (C.21c) both use the definition\nof the update sequence given in (C.14), and (C.21d) follows using the gradient inequality\n\nAPPENDIX C. CHAPTER THREE\n\n127\n\nassumption (C.16). Now letting x ∈ Rn be fixed, we observe that\n\u0015 (C.17) \u0014\u0012 2\n\u0015\n\u0014 2\n\u0013\nτ ν\nτ\n1\n1\n2\n2\nT\n−1\nE\nk∇f (x)kH ≤ E\nk∇f (x)kH\n∇f (x) HG H∇f (x) −\n−\n2μγ 2\n2Γ\n2μγ 2 2Γ\n(C.18)\n\n≤0.\n\n(C.22)\n\nThe first inequality uses the assumption on ν, and the second inequality uses the requirement\n\nAPPENDIX C. CHAPTER THREE\nthat τ ≤ √γΓ\n\npμ\n\n128\n\n. Now taking expectations with respect to Ek ,\n\u0015\n\u0014 2\nτ\n1\nT\n−1\n2\nEk [Ek+1 ] − Ek ≤ Ek\n∇f (xk+1 ) Hk G Hk ∇f (xk+1 ) −\nk∇f (xk+1 )kHk\n2μγk2\n2Γk\nμ\n+ h∇f (xk+1 ), xk+1 − yk i − kxk+1 − yk k2G−1\n2\n+ τ h∇f (xk+1 ), x∗ − xk+1 i + τ h∇f (xk+1 ), xk+1 − zk i − τ μhxk+1 − zk , x∗ − zk iG−1\nμ\n+ kτ (xk+1 − zk )k2G−1 − τ hxk+1 − zk , τ ∇f (xk+1 )i\n2\n(C.22)\nμ\n≤ h∇f (xk+1 ), xk+1 − yk i − kxk+1 − yk k2G−1 + τ h∇f (xk+1 ), x∗ − xk+1 i\n2\n+ τ h∇f (xk+1 ), xk+1 − zk i − τ μhxk+1 − zk , x∗ − zk iG−1\nμ\n+ kτ (xk+1 − zk )k2G−1 − τ hxk+1 − zk , τ ∇f (xk+1 )i\n2\n\u0010\n\u0011\n(C.13a)\nμ\nμ\n≤ −τ f (xk+1 ) − f∗ + kxk+1 − x∗ k2G−1 + h∇f (xk+1 ), xk+1 − yk i − kxk+1 − yk k2G−1\n2\n2\n−1\n+ τ h∇f (xk+1 ), xk+1 − zk i − τ μhxk+1 − zk , x∗ − zk iG\nμ\n(C.23a)\n+ kτ (xk+1 − zk )k2G−1 − τ hxk+1 − zk , τ ∇f (xk+1 )i\n2\n\u0010\n\u0011\nμ\nμ\n(C.14a)\n= −τ f (xk+1 ) − f∗ + kxk+1 − x∗ k2G−1 − kxk+1 − yk k2G−1\n2\n2\n− τ μhxk+1 − zk , x∗ − zk iG−1\nμ\n(C.23b)\n+ kτ (xk+1 − zk )k2G−1 − τ hyk − xk+1 , ∇f (xk+1 )i\n2\n\u0010\n\u0011 μ\n(C.13b)\nμ\n≤ −τ f (xk+1 ) − f∗ + kxk+1 − x∗ k2G−1 − kxk+1 − yk k2G−1\n2\n2\n− τ μhxk+1 − zk , x∗ − zk iG−1\nμ\nτL\n+ kτ (xk+1 − zk )k2G−1 + τ (f (xk+1 ) − f (yk )) +\nkyk − xk+1 k2G−1\n2\n2\n(C.23c)\n\u0010\n\u0011\nμ\nμ\n(C.20)\n2\n2\n−1\n= −τ f (xk+1 ) − f∗ + kxk+1 − zk kG−1 + kzk − x∗ kG−1 + μhxk+1 − zk , zk − x∗ iG\n2\n2\nμ\n2\n− kxk+1 − yk kG−1 − τ μhxk+1 − zk , x∗ − zk iG−1\n2\nμ\nτL\n+ kτ (xk+1 − zk )k2G−1 + τ (f (xk+1 ) − f (yk )) +\nkyk − xk+1 k2G−1\n2\n2\n(C.23d)\nμ\nτμ\n(C.15)\n= −τ Ek − kxk+1 − yk k2G−1 −\nkxk+1 − zk k2G−1\n2\n2\nμ\nτ\nL\n+ kτ (xk+1 − zk )k2G−1 +\nkyk − xk+1 k2G−1\n2\n2\n\u0012\n\u0013\nτL\nμ\n(C.14a)\n= −τ Ek +\n−\nkyk − xk+1 k2G−1\n(C.23e)\n2\n2τ\nν\n\n(C.18)\n\n≤ −τ Ek .\n\nAPPENDIX C. CHAPTER THREE\n\n129\n\nAbove, (C.23a) follows from μ-strong convexity, (C.23b) and (C.23e) both use the definition\nof the sequence (C.14), (C.23c) follows from L-Lipschitz gradients, (C.23d) uses the p\ntwoμ\n.\npoint inequality (C.20), and the last inequality follows from the assumption of τ ≤\nL\nThe claim (C.19) now follows by re-arrangement.\n\nC.3.1\n\nProof of Theorem 3.4.5\n\nNext, we describe how to recover Theorem 3.4.5 from Theorem C.3.1. We do this by applying\nTheorem C.3.1 to the function f (x) = 12 xT Ax − xT b.\nThe first step in applying Theorem C.3.1 is to construct a probability measure on S n×n ×\nR+ ×R+ for which the randomness of the updates is drawn from. We already have a distribution on S n×n from setting of Theorem 3.4.5 via the random matrix H. We trivially augment\nthis distribution by considering the random variable (H, 1, 1) ∈ Ω. By setting Γ = γ = 1,\nthe sequence (C.14a), (C.14b), (C.14c) reduces to that of Algorithm 1. Furthermore, the\nrequirement on the ν parameter from (C.17) simplifies to the requirement listed in (3.31).\nThis holds by the following equivalences which are valid since conjugation by G (which is\nassumed to be positive definite) preserves the semi-definite ordering,\n\u0002\n\u0003\u0001\n\u0002\n\u0003\nλmax E (G−1/2 HG−1/2 )2 ≤ ν ⇐⇒ E (G−1/2 HG−1/2 )2 4 νI\n\u0002\n\u0003\n⇐⇒ E G−1/2 HG−1 HG−1/2 4 νI\n\u0002\n\u0003\n⇐⇒ E HG−1 H 4 νG .\n(C.24)\nIt remains to check the gradient inequality (C.16) and compute the strong convexity and\nLipschitz parameters. These computations fall directly from the calculations made in Theorem 1 of [58], but we replicate them here for completeness.\nTo check the gradient inequality (C.16), because f is a quadratic function, its second\norder Taylor expansion is exact. Hence for almost every ω ∈ Ω,\n1\nf (Φ(x; ω)) = f (x) − h∇f (x), H∇f (x)i + ∇f (x)T HAH∇f (x)\n2\n1\n= f (x) − h∇f (x), H∇f (x)i + ∇f (x)T S(S T AS)† S T AS(S T AS)† S T ∇f (x)\n2\n1\n= f (x) − h∇f (x), H∇f (x)i + ∇f (x)T S(S T AS)† S T ∇f (x)\n2\n1\nT\n= f (x) − ∇f (x) H∇f (x) .\n2\nHence the inequality (C.16) holds with equality.\nWe next compute the strong convexity and Lipschitz gradient parameters. We first show\nthat f is λmin (E[PA1/2 S ])-strongly convex with respect to the k·kG−1 norm. This follows since\n\nAPPENDIX C. CHAPTER THREE\n\n130\n\nfor any x, y ∈ Rn , using the assumption that G is positive definite,\n1\nf (y) = f (x) + h∇f (x), y − xi + (y − x)T A(y − x)\n2\n1\n= f (x) + h∇f (x), y − xi + (y − x)T G−1/2 G1/2 AG1/2 G−1/2 (y − x)\n2\nλmin (A1/2 GA1/2 )\nky − xk2G−1 .\n≥ f (x) + h∇f (x), y − xi +\n2\nThe strong convexity bound now follows since\nA1/2 GA1/2 = A1/2 E[H]A1/2 = E[A1/2 S(S T AS)† S T A1/2 ] = E[PA1/2 S ] .\nAn nearly identical argument shows that f is λmax (E[PA1/2 S ])-strongly convex with respect to\nthe k·kG−1 norm. Since the eigenvalues of projector matrices are bounded by 1, we have that\nf is 1-Lipschitz with respect to the k·k\npGμ−1 norm. This calculation shows that the requirement\non τ from (C.18) simplifies to τ ≤ ν , since L = 1 and ν ≥ 1 by Proposition C.6.1 which\nwe state and prove later.\nAt this point, Theorem C.3.1 yields that E[Ek ] ≤ (1 − τ )k E0 . To recover the final claim\n(3.32), recall that f (yk ) − f∗ = 12 kyk − x∗ k2A . Furthermore, μG−1 4 A, since\nμ ≤ λmin (A1/2 GA1/2 ) ⇐⇒ μ ≤ λmin (G1/2 AG1/2 )\n⇐⇒ μI 4 G1/2 AG1/2\n⇐⇒ μG−1 4 A .\nHence, we can upper bound E0 as follows\nμ\n1\nμ\nkz0 − x∗ k2G−1 = ky0 − x∗ k2A + kz0 − x∗ k2G−1\n2\n2\n2\n1\n1\n≤ ky0 − x∗ k2A + kz0 − x∗ k2A = kx0 − x∗ k2A .\n2\n2\n\nE0 = f (y0 ) − f∗ +\n\nOn the other hand, we have that 12 kyk − x∗ k2A ≤ Ek . Putting the inequalities together,\nr\np\np\n1\n1\n√ E[kyk − x∗ kA ] ≤ E[ kyk − x∗ k2A ] ≤ E[Ek ] ≤ (1 − τ )k E0 ≤ (1 − τ )k/2 kx0 − x∗ k2A ,\n2\n2\nwhere the first inequality holds by Jensen’s inequality. The claimed inequality (3.32) now\nfollows.\n\nC.3.2\n\nProof of Proposition 3.4.6\n\nWe first state and prove an elementary linear algebra fact which we will use below in our\ncalculations.\n\nAPPENDIX C. CHAPTER THREE\n\n131\n\u0014\n\n\u0015\nA B\nProposition C.3.2. Let A, B, C, D be n × n diagonal matrices, and define M =\n.\nC D\nThe eigenvalues of M are given by the union of the eigenvalues of the 2 × 2 matrices\n\u0014\n\u0015\nAi Bi\n, i = 1, ..., n ,\nCi Di\nwhere Ai , Bi , Ci , Di denote the i-th diagonal entry of A, B, C, D respectively.\nProof. For every s ∈ C we have that the matrices −C and sI − D are diagonal and hence\ncommute. Applying the corresponding formula for a block matrix determinant under this\nassumption,\n\u0014\n\u0015\nsI − A\n−B\n0 = det\n= det((sI − A)(sI − D) − BC)\n−C\nsI − D\n\u0014\n\u0015\nn\nn\nY\nY\ns − Ai −Bi\n=\n((s − Ai )(s − Di ) − Bi Ci ) =\ndet\n.\n−Ci s − Di\ni=1\n\ni=1\n\n\u0014\n\n\u0015\ny k − x∗\nNow we proceed with the proof of Proposition 3.4.6. Define ek =\n. It is easy to\nzk − x∗\nsee from the definition of Algorithm 1 that {ek } satisfies the recurrence\n\u0014\n\u0015\nI − Hk A\nτ (I − Hk A)\n1\n2\nek+1 =\nek .\n1 + τ τ (I − μ1 Hk A) I − τμ Hk A\nHence,\n\u0015\n\u0014 1/2\nA\n0\ne\n0\nμ1/2 G−1/2 k+1\n\u0014 1/2\n\u0015\u0014\n\u0015\nI − Hk A\nτ (I − Hk A)\n1\nA\n0\n2\n=\ne\n0\nμ1/2 G−1/2 τ (I − μ1 Hk A) I − τμ Hk A k\n1+τ\n\u0014\n\u0015\nA1/2 − A1/2 Hk A\nτ (A1/2 − A1/2 Hk A)\n1\n2\nek\n=\n1 + τ μ1/2 τ G−1/2 (I − μ1 Hk A) μ1/2 G−1/2 (I − τμ Hk A)\n\u0014\n\u0015\u0014\n\u0015\nI − A1/2 Hk A1/2\nμ−1/2 τ (A1/2 − A1/2 Hk A)G1/2 A1/2\n1\n0\n2\n=\ne .\nG−1/2 (I − τμ Hk A)G1/2\n0\nμ1/2 G−1/2 k\n1 + τ μ1/2 τ G−1/2 (I − μ1 Hk A)A−1/2\n\u0014\n\n\u0015\nA\n0\nDefine P =\n. By taking and iterating expectations,\n0 μG−1\nE[P\n\n1/2\n\n\u0014\n\u0015\nI − A1/2 GA1/2\nμ−1/2 τ (A1/2 G1/2 − A1/2 GAG1/2 )\n1\n2\nek+1 ] =\nE[P 1/2 ek ] .\nI − τμ G1/2 AG1/2\n1 + τ μ1/2 τ (G−1/2 A−1/2 − μ1 G1/2 A1/2 )\n\nAPPENDIX C. CHAPTER THREE\n\n132\n\nDenote the matrix Q = A1/2 G1/2 . Unrolling the recurrence above yields that\n\u0014\n\u0015\nI − QQT\nμ−1/2 τ (Q − QQT Q)\n1\n1/2\nk 1/2\n2\nE[P ek ] = R P e0 , R =\n.\nI − τμ QT Q\n1 + τ μ1/2 τ (Q−1 − μ1 QT )\nWrite the SVD of Q as Q = U ΣV T . Both U and V are n × n orthonormal matrices. It is\neasy to see that Rk is given by\n\u0015\n\u0014\n\u0015\u0014\n\u0015k \u0014 T\nI − Σ2\nμ−1/2 τ (Σ − Σ3 )\n1\nU 0\nU\n0\n2\n.\nR =\n0 VT\nI − τμ Σ2\n(1 + τ )k 0 V μ1/2 τ (Σ−1 − μ1 Σ)\nk\n\n(C.25)\n\nSuppose we choose P 1/2 e0 to be a right singular vector of Rk corresponding to the maximum\nsingular value σmax (Rk ). Then we have that\nE[kP 1/2 ek k2 ] ≥ kE[P 1/2 ek ]k2 = kRk P 1/2 e0 k2 = σmax (Rk )kP 1/2 e0 k2 ≥ ρ(Rk )kP 1/2 e0 k2 ,\nwhere ρ(·) denotes the spectral radius. The first inequality is Jensen’s inequality, and the\nsecond inequality uses the fact that the spectral radius is bounded above by any matrix norm.\nThe eigenvalues of Rk are the k-th power of the eigenvalues of R which, using the similarity\ntransform (C.25) along with Proposition C.3.2, are given by the eigenvalues of the 2 × 2\nmatrices Ri defined as\n\u0015\n\u0014\nμ−1/2 τ (σi − σi3 )\n1 − σi2\n1\n2\n, σi = Σii , i = 1, ..., n .\nRi =\n1 − τμ σi2\n1 + τ μ1/2 τ (σi−1 − μ1 σi )\nOn the other hand, since the entries in Σ are given by the eigenvalues of A1/2 G1/2 G1/2 A1/2 =\n√\nE[PA1/2 S ], there exists an i such that σi = μ. This Ri is upper triangular, and hence its\n2\neigenvalues can be read off the diagonal. This shows that 1−τ\n= 1 − τ is an eigenvalue of\n1+τ\nk\nk\nR, and hence (1 − τ ) is an eigenvalue of R . But this means that (1 − τ )k ≤ ρ(Rk ). Hence,\nwe have shown that\nE[kP 1/2 ek k2 ] ≥ (1 − τ )k kP 1/2 e0 k2 .\nThe desired claim now follows from\nq\nkP 1/2 ek k2 = kyk − x∗ k2A + μkzk − x∗ k2G−1\nq\n≤ kyk − x∗ k2A + kzk − x∗ k2A ≤ kyk − x∗ kA + kzk − x∗ kA ,\nwhere\nthe √first √\ninequality holds since μG−1 4 A and the second inequality holds since\n√\na + b ≤ a + b for non-negative a, b.\n\nAPPENDIX C. CHAPTER THREE\n\nC.4\n\n133\n\nRecovering the ACDM Result from Nesterov and\nStich [48]\n\nWe next show how to recover Theorem 1 of Nesterov and Stich [48] using Theorem C.3.1, in\nthe case of α = 1. A nearly identical argument can also be used to recover the result of AllenZhu et al. [1] under the strongly convex setting in the case of β = 0. Our argument proceeds\nin two steps. First, we prove a convergence result for a simplified accelerated coordinate\ndescent method which we introduce in Algorithm 2. Then, we describe how a minor tweak to\nACDM shows the equivalence between ACDM and Algorithm 2.\nBefore we proceed, we first describe the setting of Theorem 1. Let f : Rn −→ R be a\ntwice differentiable strongly convex function with Lipschitz gradients. Let J1 , ..., Jm denote\na partition of {1, ..., n} into m partitions. Without loss of generality, we can assume that\nthe partitions are in order, i.e. J1 = {1, ..., n1 }, J2 = {n1 + 1, ..., n2 }, and so on. This\nis without loss of generality since we can always consider the function g(x) = f (Πx) for\na suitable permutation matrix Π. Let B1 , ..., Bm be fixed positive definite matrices such\nthat Bi ∈ R|Ji |×|Ji | . Set Hi = Si Bi−1 SiT , where Si ∈ Rn×|Ji | is the column selector matrix\n−1/2\n−1/2\nassociated to partition Ji , and define√ Li = supx∈Rn λmax (Bi SiT ∇2 f (x)Si Bi ) for i =\ni\n.\n1, ..., m. Furthermore, define pi = Pm L√\nj=1\n\nC.4.1\n\nLj\n\nProof of convergence of a simplified accelerated coordinate\ndescent method\n\nNow consider the following accelerated randomized coordinate descent algorithm in Algorithm 2.\nTheorem C.3.1 is readily applied to Algorithm 2 to give a convergence guarantee which\nmatches the bound of Theorem 1 of Nesterov and Stich. We sketch the argument below.\nAlgorithm 2 instantiates (C.14) with the definitions above and particular choices Γk = Lik\nand γk = pik . We will specify the choice of μ at a later point. To see that this setting is valid,\nwe construct a discrete probability measure on S n×n × R+ × R+ by setting ωi = (Hi , Li , pi )\nand P(ω = ωi ) = pi for i = 1, ..., m. Hence, in the context of Theorem C.3.1, G = E[ γ1 H] =\nPm\n−1\n−1\n−1\ni=1 Hi = blkdiag(B1 , B2 , ..., Bm ). We first verify the gradient inequality (C.16). For\n\nAPPENDIX C. CHAPTER THREE\n\n134\n\nAlgorithm 2 Accelerated randomized coordinate descent.\nm\nm\nRequire: μ > 0, partition {Ji }m\ni=1 , positive definite {Bi }i=1 , Lipschitz constants {Li }i=1 ,\nn\nx0 ∈ R . √\nμ\n1: Set τ = Pm √L .\ni\ni=1\n\nHi = Si Bi−1 SiT for i = 1, ..., m.\npartition √Ji .\nLi\nfor i = 1, ..., m.\n3: Set pi = Pm √\n\n2: Set\n\nj=1\n\n// Si denotes the column selector for\n\nLj\n\n4: Set y0 = z0 = x0 .\n5: for k = 0, ..., T − 1 do\n6:\nik ← random sample from {1, ..., m} with P(ik = i) = pi .\n1\nτ\n7:\nxk+1 = 1+τ\nyk + 1+τ\nzk .\n\nyk+1 = xk+1 − L1i Hik ∇f (xk+1 ).\nk\n9:\nzk+1 = zk + τ (xk+1 − zk ) − μpτi Hik ∇f (xk+1 ).\nk\n10: end for\n11: Return yT .\n8:\n\nevery fixed x ∈ Rn , for every i = 1, ..., m there exists a ci ∈ Rn such that\n1\n1\nh∇f (x), Hi ∇f (x)i + 2 ∇f (x)T Hi ∇2 f (ci )Hi ∇f (x)\nLi\n2Li\n1\n= f (x) − h∇f (x), Hi ∇f (x)i\nLi\n1\n−1/2 −1/2\n−1/2 −1/2\n+ 2 ∇f (x)T Si Bi Bi SiT ∇2 f (ci )Si Bi Bi SiT ∇f (x)\n2Li\n1\n1\n≤ f (x) − h∇f (x), Hi ∇f (x)i +\n∇f (x)T Si Bi−1 SiT ∇f (x)\nLi\n2Li\n1\nk∇f (x)k2Hi .\n= f (x) −\n2Li\n\nf (Φ(x; ωi )) = f (x) −\n\nWe next compute the ν constant defined in (C.17). We do this by checking the sufficient\ncondition that Hi G−1 Hi 4 νHi for i = 1, ..., m. Doing so yields that ν = 1, since\nHi G−1 Hi = Si Bi−1 SiT blkdiag(B1 , B2 , ..., Bm )Si Bi−1 SiT = Si Bi−1 Bi Bi−1 SiT = Si Bi−1 SiT = Hi .\nTo complete the argument, we set μ as the strong convexity constant and L as the Lipschitz\ngradient constant of f with respect to the k·kG−1 norm. It is straightforward to check that\nμ = infn λmax (G1/2 ∇2 f (x)G1/2 ) , L = sup λmax (G1/2 ∇2 f (x)G1/2 ) .\nx∈R\n\nx∈Rn\n\nAPPENDIX C. CHAPTER THREE\n\n135\n\n√\nP √\nWe now argue that L ≤ m\nLi . Let x ∈ Rn achieve the supremum in the definition of\ni=1\nL (if no such x exists, then let x be arbitrarily close and take limits). Then,\nL = λmax (G1/2 ∇2 f (x)G1/2 ) = λmax ((∇2 f (x))1/2 G(∇2 f (x))1/2 )\n!\n!\nm\nX\n= λmax (∇2 f (x))1/2\nSi Bi−1 SiT (∇2 f (x))1/2\ni=1\nm\n(a) X\n\n≤\n\n(b)\n\n=\n\ni=1\nm\nX\n\nλmax ((∇2 f (x))1/2 Si Bi−1 SiT (∇2 f (x))1/2 )\nλmax (Si SiT ∇2 f (x)Si SiT Si Bi−1 SiT )\n\ni=1\n\n=\n\nm\nX\n\nλmax ((Si Bi−1 SiT )1/2 Si SiT ∇2 f (x)Si SiT (Si Bi−1 SiT )1/2 )\n\ni=1\nm\n(c) X\n−1/2\n−1/2\n=\nλmax (Si Bi SiT Si SiT ∇2 f (x)Si SiT Si Bi SiT )\n\n(d)\n\n=\n\ni=1\nm\nX\n\n−1/2\n\nλmax (Bi\n\n−1/2\n\nSiT ∇2 f (x)Si Bi\n\n)≤\n\nm\nX\n\nLi .\n\ni=1\n\ni=1\n\nAbove, (a) follows by the convexity of the maximum eigenvalue, (b) holds since SiT Si = I,\n(c) uses the fact that for any matrix Q satisfying QT Q = I and M positive semi-definite,\nwe have (QM QT )1/2 = QM 1/2 QT , and (d) follows√since λmax\nSiT ) = λmax (M ) for any\n√(Si M√\np × p symmetric matrix\nM\n√\n√ the fact that a + b ≤ a + b for any non-negative\nP.mUsing\na, b, the inequality L ≤ i=1 Li immediately follows. To conclude the proof, it remains\nto calculate the requirement on τ via (C.18). Since √γΓi i = √pLi i = Pm 1 √Li , we have that\n√\nμ\n√γi ≤ √1 , and hence the requirement is that τ ≤ Pm √ .\nΓi\nL\ni=1 Li\n\nC.4.2\n\ni=1\n\nRelating Algorithm 2 to ACDM\n\nFor completeness, we replicate the description of the ACDM algorithm from Nesterov and\nStich in Algorithm 3. We make one minor tweak in the initialization of the Ak , Bk sequence\nwhich greatly simplifies the exposition of what follows.\nWe first write the sequence produced by Algorithm 3 as\n(1 − αk )xk + αk (1 − βk )zk\n,\n1 − α k βk\n1\nxk+1 = yk −\nHi ∇f (yk ) ,\nLik k\n\u0012\n\u0013\nak+1\nzk+1 − zk = βk yk − zk −\nHi ∇f (yk ) .\nBk+1 pik βk k\nyk =\n\n(C.26a)\n(C.26b)\n(C.26c)\n\nAPPENDIX C. CHAPTER THREE\n\n136\n\nAlgorithm 3 ACDM from Nesterov and Stich [48], α = 1, β = 1/2 case.\nm\nm\nRequire: μ > 0, partition {Ji }m\ni=1 , positive definite {Bi }i=1 , Lipschitz constants {Li }i=1 ,\nn\nx0 ∈ R .\n1: Set Hi = Si Bi−1 SiT for i = 1, ..., m. // Si denotes the column selector for\npartition √Ji .\nLi\nfor i = 1, ..., m.\n2: Set pi = Pm √\nj=1\n\nLj\n\n3: Set A0 = 1, B0 = μ. // Modified from A0 = 0, B0 = 1.\nPm √\nLi .\n4: Set S1/2 =\ni=1\n5: Set y0 = z0 = x0 .\n6: for k = 0, ..., T − 1 do\n7:\nik ← random sample from {1, ..., m} with P(ik = i) = pi .\n2\n8:\nak+1 ← positive solution to a2k+1 S1/2\n= (Ak + ak+1 )(Bk + μak+1 ).\n9:\nAk+1 = Ak + ak+1 , Bk+1 = Bk + μak+1 .\n10:\nαk = Aak+1 , βk = μ Bak+1 .\nk+1\n\n11:\n12:\n\nk+1\n\nk +αk (1−βk )zk\n.\nyk = (1−αk )x1−α\nk βk\n1\nxk+1 = yk − Li Hik ∇f (yk ).\nk\n\nak+1\nHik ∇f (yk ).\nzk+1 = (1 − βk )zk + βk yk − Bk+1\np ik\n14: end for\n15: Return xT .\n\n13:\n\nSince βk Bk+1 = μak+1 , the zk+1 update simplifies to\n\u0012\n\u0013\n1\nHi ∇f (yk ) .\nzk+1 − zk = βk yk − zk −\nμpik k\nA simple calculation shows that\n(1 − αk βk )yk = (1 − αk )xk + αk (1 − βk )zk ,\nfrom which we conclude that\nαk (1 − βk )\n(yk − zk ) = xk − yk .\n1 − αk\n\n(C.27)\n\nObserve that\nAk+1 =\n\nk+1\nX\ni=1\n\nai + A0 , Bk+1 = μ\n\nk+1\nX\n\nai + B0 .\n\ni=1\n\nHence as long as μA0 = B0 (which is satisfied by our modification), we have that μAk+1 =\nBk+1 for all k ≥ 0. With this identity, we have that αk = βk for all k ≥ 0. Therefore, (C.27)\nsimplifies to\nβk (yk − zk ) = xk − yk .\n\nAPPENDIX C. CHAPTER THREE\n\n137\n\nWe now calculate the value of βk . At every iteration, we have that\n2\na2k+1 S1/2\n= Ak+1 Bk+1 =\n\n1 2\nak+1\n1\nBk+1 =⇒\n=√\n.\nμ\nBk+1\nμS1/2\n\nBy the definition of βk ,\n√\n√\nμ\nμ\nak+1\n=\n= Pm √ = τ .\nβk = μ\nBk+1\nS1/2\nLi\ni=1\nCombining these identities, we have shown that (C.26a), (C.26b), and (C.26c) simplifies to\n1\nτ\nxk +\nzk ,\n1+τ\n1+τ\n1\nHi ∇f (yk ) ,\nxk+1 = yk −\nLik k\n\u0013\n\u0012\n1\nHi ∇f (yk ) .\nzk+1 − zk = τ yk − zk −\nμpik k\nyk =\n\n(C.28a)\n(C.28b)\n(C.28c)\n\nThis sequence directly coincides with the sequence generated by Algorithm 2 after a simple\nrelabeling.\n\nC.4.3\n\nAccelerated Gauss-Seidel for fixed partitions from ACDM\n\nAlgorithm 4 Accelerated randomized block Gauss-Seidel for fixed partitions [48].\nRequire: A ∈ Rn×n , A \u001f 0, b ∈ Rn , x0 ∈ Rn , block size p, μpart defined in (3.21).\n1: Set A0 = 0, B0 = 1.\n2: Set σ = np μpart .\n3: Set y0 = z0 = x0 .\n4: for k = 0, ..., T − 1 do\n5:\nik ← uniform from {1, 2, ..., n/p}.\n6:\nSk ← column selector associated with partition Jik .\n7:\nak+1 ← positive solution to a2k+1 (n/p)2 = (Ak + ak+1 )(Bk + σak+1 ).\n8:\nAk+1 = Ak + ak+1 , Bk+1 = Bk + σak+1 .\n9:\nαk = Aak+1\n, βk = σ Bak+1\n.\nk+1\nk+1\nk +αk (1−βk )zk\nyk = (1−αk )x1−α\n.\nk βk\nT\n11:\nxk+1 = yk − Sk (Sk ASk )−1 SkT (Ayk − b).\nnak+1\n12:\nzk+1 = (1 − βk )zk + βk yk − pB\nSk (SkT ASk )−1 SkT (Ayk − b).\nk+1\n13: end for\n14: Return xT .\n\n10:\n\nWe now describe Algorithm 4, which is the specialization of ACDM (Algorithm 3) to\naccelerated Gauss-Seidel in the fixed partition setting.\n\nAPPENDIX C. CHAPTER THREE\n\n138\n\nAs mentioned previously, we set the function f (x) = 21 xT Ax − xT b. Given a partition\nn/p\n{Ji }i=1 , we let Bi = SiT ASi , where Si ∈ Rn×p is the column selector matrix associated to\nthe partition Ji . With this setting, we have that L1 = L2 = ... = Ln/p = 1, and hence\nwe have pi = p/n for all i (i.e. the sampling distribution is uniform over all partitions).\nWe now need to compute the strong convexity constant μ. With the simplifying assumption\nthat the partitions are ordered, μ is simply the strong convexity constant with respect to the\nnorm induced by the matrix blkdiag(B1 , B2 , ..., Bn/p ). Hence, using the definition of μpart\nfrom (3.21), we have that μ = np μpart . Algorithm 4 now follows from plugging our particular\nchoices of f and the constants into Algorithm 3.\n\nC.5\n\nA Result for Randomized Block Kaczmarz\n\nWe now use Theorem C.3.1 to derive a result similar to Theorem 3.4.5 for the randomized\naccelerated Kaczmarz algorithm. In this setting, we let A ∈ Rm×n , m ≥ n be a matrix with\nfull column rank, and b ∈ Rm such that b ∈ R(A). That is, there exists a unique x∗ ∈ Rn\nsuch that Ax∗ = b. We note that this section generalizes the result of [33] to the block case\n(although the proof strategy is quite different).\nWe first describe the randomized accelerated block Kaczmarz algorithm in Algorithm 5.\nOur main convergence result concerning Algorithm 5 is presented in Theorem C.5.1.\nAlgorithm 5 Accelerated randomized block Kaczmarz.\n−1\nRequire: A ∈ Rm×n , A full column rank, b ∈ R(A), sketching matrices {Sk }Tk=0\n⊆ Rm×p ,\nn\nx0 ∈ R ,p\nμ ∈ (0, 1), ν ≥ 1.\nμ/ν.\n1: Set τ =\n2: Set y0 = z0 = x0 .\n3: for k = 0, ..., T − 1 do\nτ\n1\n4:\nxk+1 = 1+τ\nyk + 1+τ\nzk .\nT\n5:\nyk+1 = xk+1 − (Sk A)† SkT (Axk+1 − b).\n6:\nzk+1 = zk + τ (xk+1 − zk ) − μτ (SkT A)† SkT (Axk+1 − b).\n7: end for\n8: Return yT .\n\nTheorem C.5.1. (Theorem 3.4.7 restated.) Let A be an m × n matrix with full column\nrank, and b ∈ R(A). Let x∗ ∈ Rn denote the unique vector satisfying Ax∗ = b. Suppose\neach Sk , k = 0, 1, 2, ... is an independent copy of a random sketching matrix S ∈ Rm×p . Let\nμ = λmin (E[PAT S ]). Suppose the distribution of S satisfies μ > 0. Invoke Algorithm 5 with μ\nand ν, where ν is defined as\n\u0002\n\u0003\u0001\nν = λmax E (G−1/2 HG−1/2 )2 , G = E[H] , H = PAT S .\n(C.29)\n\nAPPENDIX C. CHAPTER THREE\n\n139\n\nThen for all k ≥ 0 we have\nE[kyk − x∗ k2 ] ≤\n\n√\n\nr \u0013k/2\n\u0012\nμ\nkx0 − x∗ k2 .\n2 1−\nν\n\n(C.30)\n\nProof. The proof is very similar to that of Theorem 3.4.5, so we only sketch the main\nargument. The key idea is to use the correspondence between randomized Kaczmarz and\ncoordinate descent (see e.g. Section 5.2 of [29]). To do this, we apply Theorem C.3.1 to\nf (x) = 21 kx − x∗ k22 . As in the proof of Theorem 3.4.5, we construct a probability measure\non S n×n × R+ × R+ from the given random matrix H by considering the random variable\n(H, 1, 1). To see that the sequence (C.14a), (C.14b), and (C.14c) induces the same update\nsequence as Algorithm 5, the crucial step is to notice that\nHk ∇f (xk+1 ) = PAT Sk ∇f (xk+1 ) = AT Sk (SkT AAT Sk )† SkT A(xk+1 − x∗ )\n= AT Sk (SkT AAT Sk )† SkT (Axk+1 − b) = (SkT A)† SkT (Axk+1 − b) .\nNext, the fact that f is λmin (E[PAT S ])-strongly convex and 1-Lipschitz with respect to the\nk·kG−1 norm, where G = E[PAT S ], follows immediately by a nearly identical argument used in\nthe proof of Theorem 3.4.5. It remains to check the gradient inequality (C.16). Let x ∈ Rn\nbe fixed. Then using the fact that f is quadratic, for almost every ω ∈ Ω,\n1\nf (Φ(x; ω)) = f (x) − h∇f (x), H(x − x∗ )i + kH(x − x∗ )k22\n2\n1\n= f (x) − hx − x∗ , PAT S (x − x∗ )i + kPAT S (x − x∗ )k22\n2\n1\n= f (x) − hx − x∗ , PAT S (x − x∗ )i .\n2\nHence the gradient inequality (C.16) holds with equality.\n\nC.5.1\n\nComputing ν and μ in the setting of [33]\n\nWe first state a proposition which will be useful in our analysis of ν.\nProposition C.5.2. Let M1 , ..., Ms ⊆ Rn denote subspaces of Rn such that M1 + ... + Ms =\nRn . Then we have\n!−1\ns\ns\ns\nX\nX\nX\nPM i\nPM i\nPM i 4\nPM i .\ni=1\n\ni=1\n\ni=1\n\nProof. We will prove that for every 1 ≤ i ≤ s,\n!−1\ns\nX\nPM i\nPM i\nPM i 4 PM i ,\ni=1\n\n(C.31)\n\nAPPENDIX C. CHAPTER THREE\n\n140\n\nfrom which the claim immediately follows. By Schur complements, (C.31) holds iff\n\u0014\n\u0015 \u0014\n\u0015 \u0014\n\u0015\n0 P 0\nPM i P PM i\nPM i PM i\n04\n=\n+\ns\ns\n0\nPM i\nPM i PM i\nj6=i PMj\ni=1 PMi\n\u0014\n\u0015\n\u0014\n\u0015\n0 P 0\n1 1\n=\n⊗ PM i +\n.\ns\n0\n1 1\nj6=i PMj\nSince the eigenvalues of a Kronecker product are given by the Cartesian product of the\nindividual eigenvalues, (C.31) holds.\nNow we can estimate the ν and μ values. Let ai ∈ Rn denote each row of A, with\nkai k2 = 1 forP\nall i = 1, ..., m. In this setting, H = Pai = ai aTi with probability 1/m. Hence,\n1\n1 T\nT\nG = E[H] = m\ni=1 m ai ai = m A A. Furthermore,\n−1\n\nE[HG H] =\n\nm\nX\n\nai aTi m(AT A)−1 ai aTi\n\ni=1\n\n=\n\nm\nX\n\ni=1\nm\n(a) X\n\n4\n\n1\nm\n\nai aTi (AT A)−1 ai aTi\nai aTi = AT A = mG ,\n\ni=1\n\nwhere (a) follows from Proposition C.5.2. Hence, ν 6= m. On the other hand,\nμ = λmin (E[PAT S ]) = λmin (G) =\n\nC.6\n\n1\nλmin (AT A) .\nm\n\nProofs for Random Coordinate Sampling\n(Section 3.4.3.3)\n\nOur primary goal in this section is to provide a proof of Lemma 3.4.8. Along the way, we\nprove a few other results which are of independent interest. We first provide a proof of the\nlower bound claim in Lemma 3.4.8.\nProposition C.6.1. Let A be an n × n matrix and let S ∈ Rn×p be a random matrix. Put\nG = E[PA1/2 S ] and suppose that G is positive definite. Let ν > 0 be any positive number such\nthat\nE[PA1/2 S G−1 PA1/2 S ] 4 νG , G = E[PA1/2 S ] .\nThen ν ≥ n/p.\n\n(C.32)\n\nAPPENDIX C. CHAPTER THREE\n\n141\n\nProof. Since trace commutes with expectation and respects the positive semi-definite ordering, taking trace of both sides of (C.32) yields that\nn = Tr(GG−1 ) = Tr(E[PA1/2 S G−1 ]) = E[Tr(PA1/2 S G−1 )] = E[Tr(PA1/2 S G−1 PA1/2 S )]\n(C.32)\n\n= Tr(E[PA1/2 S G−1 PA1/2 S ]) ≤ νTr(E[PA1/2 S ])\n= νE[Tr(PA1/2 S )] = νE[rank(A1/2 S)] ≤ νp .\n\nNext, the upper bound relies on the following lemma, which generalizes Lemma 2 of [57].\nLemma C.6.2. Let M be a random matrix. We have that\nE[PM ] < E[M ](E[M T M ])† E[M T ] .\n\n(C.33)\n\nProof. Our proof follows the strategy in the proof of Theorem 3.2 from [78]. First, write\nPB = B(B T B)† B T . Since R(B T ) = R(B T B), we have by generalized Schur complements\n(see e.g. Theorem 1.20 from [78]) and the fact that expectation preserves the semi-definite\norder,\n\u0015\n\u0014\n\u0015\n\u0014 T\nE[B T B] E[B T ]\nB B BT\n< 0 =⇒\n<0.\nB\nPB\nE[B]\nE[PB ]\nTo finish the proof, we need to argue that R(E[B T ]) ⊆ R(E[B T B]), which would allow us to\napply the generalized Schur complement again to the right hand side. Fix a z ∈ R(E[B T ]);\nwe can write z = E[B T ]y for some y. Now let q ∈ Kern(E[B T B]). We have that E[B T B]q =\n0, which implies 0 = q T E[B T B]q = E[kBqk22 ]. Therefore, Bq = 0 a.s. But this means\nthat z T q = E[y T Bq] = 0. Hence, z ∈ Kern(E[B T B])⊥ = R(E[B T B]). Now applying the\ngeneralized Schur complement one more time yields the claim.\nWe are now in a position to prove the upper bound of Lemma 3.4.8. We apply Lemma C.6.2\nto M = A1/2 SS T A1/2 to conclude, using the fact that R(M ) = R(M M T ), that\nE[PA1/2 S ] = E[PA1/2 SS T A1/2 ] < E[A1/2 SS T A1/2 ](E[A1/2 SS T ASS T A1/2 ])† E[A1/2 SS T A1/2 ] .\n(C.34)\nElementary calculations now yield that for any fixed symmetric matrix A ∈ Rn×n ,\n\u0012\n\u0012\n\u0013\n\u0013\np\np p−1\np−1\nT\nT\nT\nE[SS ] = I,\nE[SS ASS ] =\nA+ 1−\ndiag(A) .\nn\nn n−1\nn−1\nHence plugging (C.35) into (C.34),\n\u0012\n\u0012\n\u0013\n\u0013−1\np p−1\np−1\n−1/2\n−1/2\nE[PA1/2 S ] <\nI + 1−\nA\ndiag(A)A\n.\nn n−1\nn−1\n\n(C.35)\n\n(C.36)\n\nAPPENDIX C. CHAPTER THREE\n\n142\n\nWe note that the lower bound (3.23) for μrand presented in Section 3.4.2 follows immediately\nfrom (C.36).\nWe next manipulate (3.31) in order to use (C.36). Recall that G = E[H] and H =\nS(S T AS)† S T . From (C.24), we have\n\u0003\u0001\n\u0002\n\u0003\n\u0002\nλmax E (G−1/2 HG−1/2 )2 ≤ ν ⇐⇒ E HG−1 H 4 νG .\nNext, a simple computation yields\nE[HG−1 H] = E[S(S T AS)−1 S T G−1 S(S T AS)−1 S T ] = A−1/2 E[PA1/2 S (E[PA1/2 S ])−1 PA1/2 S ]A−1/2 .\nAgain, since conjugation by A1/2 preserves semi-definite ordering, we have that\nE[HG−1 H] 4 νG ⇐⇒ E[PA1/2 S (E[PA1/2 S ])−1 PA1/2 S ] 4 νE[PA1/2 S ] .\nUsing the fact that for positive definite matrices X, Y we have X 4 Y iff Y −1 4 X −1 , (C.36)\nis equivalent to\n\u0012\n\u0012\n\u0013\n\u0013\nn p−1\np−1\n−1\n−1/2\n−1/2\n(E[PA1/2 S ]) \u0016\nI + 1−\nA\ndiag(A)A\n.\np n−1\nn−1\nConjugating both sides by PA1/2 S and taking expectations,\n\u0012\n\u0012\n\u0013\n\u0013\np−1\nn p−1\n−1/2\n−1/2\n−1\nE[PA1/2 S ] + 1 −\nE[PA1/2 S A\ndiag(A)A\nPA1/2 S ] .\nE[PA1/2 S (E[PA1/2 S ]) PA1/2 S ] \u0016\np n−1\nn−1\n(C.37)\nNext, letting J ⊆ 2[n] denote the index set associated to S, for every S we have\nPA1/2 S A−1/2 diag(A)A−1/2 PA1/2 S\n= A1/2 S(S T AS)−1 S T A1/2 A−1/2 diag(A)A−1/2 A1/2 S(S T AS)−1 S T A1/2\n= A1/2 S(S T AS)−1/2 (S T AS)−1/2 (S T diag(A)S)(S T AS)−1/2 (S T AS)−1/2 S T A1/2\n4 λmax ((S T diag(A)S)(S T AS)−1 )A1/2 S(S T AS)−1 S T A1/2\nmaxi∈J Aii\nP 1/2\n4\nλmin (AJ ) A S\n4 max κeff,J (A)PA1/2 S .\nJ∈2[n] :|J|=p\n\nPlugging this calculation back into (C.37) yields the desired upper bound of Lemma 3.4.8.\n\n143\n\nBibliography\n[1] Zeyuan Allen-Zhu, Peter Richtárik, Zheng Qu, and Yang Yuan. “Even Faster Accelerated Coordinate Descent Using Non-Uniform Sampling”. In: ICML. 2016.\n[2] Felipe Alvarez, Jérôme Bolte, and Olivier Brahic. In: SIAM Journal on Control and\nOptimization 43.2 (2004), pp. 477–501.\n[3] Shun-Ichi Amari. “Natural Gradient Works Efficiently in Learning”. In: Neural Computation (1998), pp. 251–276.\n[4] Michael Jordan Ashia Wilson Benjamin Recht. A Lyapunov Analysis of Momentum\nMethods in Optimization. Arxiv preprint arXiv1611.02635. 2016.\n[5] Haim Avron, Kenneth L. Clarkson, and David P. Woodruff. “Faster Kernel Ridge\nRegression Using Sketching and Preconditioning”. In: arXiv 1611.03220 (2017).\n[6] Michel Baes. Estimate sequence methods: Extensions and approximations. Aug. 2009.\n[7] John C. Baez and Blake S. Pollard. “Relative Entropy in Biological Systems”. In:\nEntropy 18.2 (2016), p. 46.\n[8] Amir Beck and Marc Teboulle. “A Fast Iterative Shrinkage-Thresholding Algorithm for\nLinear Inverse Problems”. In: SIAM Journal on Imaging Sciences 2.1 (2009), pp. 183–\n202.\n[9] Sébastien Bubeck, Yin Tat Lee, and Mohit Singh. “A geometric alternative to Nesterov’s accelerated gradient descent”. In: ArXiv preprint arXiv:1506.08187 (2015).\n[10] P. L Chebyshev. “Théorie des mécanismes connus sous le nom de parallélogrammes”.\nIn: Mémoires Présentés á l’Académie Impériale des Sciences de St-Pétersbourg VII.539568 (1854).\n[11] Gong Chen and Marc Teboulle. “Convergence Analysis of a Proximal-Like Minimization Algorithm Using Bregman Functions”. In: 3 (Aug. 1993).\n[12] Adam Coates and Andrew Y. Ng. “Learning Feature Representations with K-Means”.\nIn: Neural Networks: Tricks of the Trade. Springer, 2012.\n[13] Jelena Diakonikolas and Lorenzo Orecchia. “Accelerated Extra-Gradient Descent: A\nNovel Accelerated First-Order Method”. In: 9th Innovations in Theoretical Computer\nScience Conference, ITCS 2018, January 11-14, 2018, Cambridge, MA, USA. 2018,\n23:1–23:19.\n\nBIBLIOGRAPHY\n\n144\n\n[14] Yoel Drori and Marc Teboulle. “Performance of first-order methods for smooth convex\nminimization: a novel approach”. In: Math. Program. 145.1-2 (2014), pp. 451–482.\n[15] Dmitry Drusvyatskiy, Maryam Fazel, and Scott Roy. “An optimal first order method\nbased on optimal quadratic averaging”. In: ArXiv preprint arXiv:1604.06543 (2016).\n[16] John Duchi, Elad Hazan, and Yoram Singer. Adaptive Subgradient Methods for Online\nLearning and Stochastic Optimization. Tech. rep. EECS Department, University of\nCalifornia, Berkeley, 2010.\n[17] Olivier Fercoq and Peter Richtárik. “Accelerated, Parallel, and Proximal Coordinate\nDescent”. In: SIAM J. Optim. 25.4 (2015).\n[18] Kimon Fountoulakis and Rachael Tappenden. “A Flexible Coordinate Descent Method”.\nIn: arXiv 1507.03713 (2016).\n[19] Peter Giesl and Sigurdur F. Hafstein. “Construction of Lyapunov functions for nonlinear planar systems by linear programming”. In: 2011.\n[20] Robert M. Gower and Peter Richtárik. “Randomized Iterative Methods for Linear\nSystems”. In: SIAM Journal on Matrix Analysis and Applications 36 (4 2015).\n[21] Geovani Nunes Grapiglia and Yurii Nesterov. “Regularized Newton Methods for Minimizing Functions with Hölder Continuous Hessians”. In: SIAM Journal on Optimization 27.1 (2017), pp. 478–506.\n[22] Marc Harper. “The Replicator Equation as an Inference Dynamic”. In: (Nov. 2009).\n[23] “Information Theory and Statistical Mechanics”. In: Phys. Rev. 106.620-630 (1957).\n[24] Sahar Karimi and Stephen Vavasis. “A unified convergence bound for conjugate gradient and accelerated gradient”. In: (May 2016).\n[25] Walid Krichene, Alexandre Bayen, and Peter Bartlett. “Accelerated Mirror Descent\nin Continuous and Discrete Time”. In: Advances in Neural Information Processing\nSystems (NIPS) 29. 2015.\n[26] Walid Krichene, Alexandre Bayen, and Peter L Bartlett. “Accelerated Mirror Descent\nin Continuous and Discrete Time”. In: Advances in Neural Information Processing\nSystems 28. Ed. by C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R.\nGarnett. Curran Associates, Inc., 2015, pp. 2845–2853.\n[27] Joseph P LaSalle and Solomon Lefschetz. Stability by Liapunov’s Direct Method, with\nApplications. Academic Press, 1961.\n[28] Ching-Pei Lee and Stephen J. Wright. “Random Permutations Fix a Worst Case for\nCyclic Coordinate Descent”. In: arXiv 1607.08320 (2016).\n[29] Yin Tat Lee and Aaron Sidford. “Efficient Accelerated Coordinate Descent Methods\nand Faster Algorithms for Solving Linear Systems”. In: FOCS. 2013.\n\nBIBLIOGRAPHY\n\n145\n\n[30] Laurent Lessard, Benjamin Recht, and Andrew Packard. “Analysis and Design of Optimization Algorithms via Integral Quadratic Constraints”. In: SIAM Journal on Optimization 26.1 (), pp. 57–95.\n[31] Dennis Leventhal and Adrian S. Lewis. “Randomized Methods for Linear Constraints:\nConvergence Rates and Conditioning”. In: Mathematics of Operations Research 35.3\n(2010).\n[32] Qihang Lin, Zhaosong Lu, and Lin Xiao. “An Accelerated Proximal Coordinate Gradient Method”. In: NIPS. 2014.\n[33] Ji Liu and Stephen J. Wright. “An Accelerated Randomized Kaczmarz Algorithm”.\nIn: Mathematics of Computation 85.297 (2016).\n[34] Yuanyuan Liu, Fanhua Shang, James Cheng, Hong Cheng, and Licheng Jiao. “Accelerated First-order Methods for Geodesically Convex Optimization on Riemannian Manifolds”. In: Advances in Neural Information Processing Systems 30. Ed. by I. Guyon\net al. 2017, pp. 4868–4877.\n[35] Zhaosong Lu and Lin Xiao. “On the Complexity Analysis of Randomized BlockCoordinate Descent Methods”. In: Mathematical Programming 152.1–2 (2015).\n[36] A. M. Lyapunov and A. T. Fuller. General Problem of the Stability Of Motion. 1992.\n[37] Panayotis Mertikopoulos and Mathias Staudigl. Stochastic mirror descent dynamics\nand their convergence in monotone variational inequalities. Arxiv preprint arXiv. 2017.\n[38] Deanna Needell and Joel A. Tropp. “Paved with Good Intentions: Analysis of a Randomized Block Kaczmarz Method”. In: Linear Algebra and its Applications 441 (2014).\n[39] Arkadi Nemirovskii and David Yudin. Problem Complexity and Method Efficiency in\nOptimization. John Wiley & Sons, 1983.\n[40] Yurii Nesterov. “Accelerating the cubic regularization of Newton’s method on convex\nproblems”. In: Mathematical Programming 112.1 (2008), pp. 159–181.\n[41] Yurii Nesterov. Complexity bounds for primal-dual methods minimizing the model of\nobjective function. Tech. rep. Université Catholique de Louvain, Center for Operations\nResearch and Econometrics (CORE), 2015.\n[42] Yurii Nesterov. “Efficiency of Coordinate Descent Methods on Huge-Scale Optimization Problems”. In: SIAM J. Optim. 22.2 (2012).\n[43] Yurii Nesterov. Introductory Lectures on Convex Optimization: A Basic Course. Applied Optimization. Boston: Kluwer, 2004.\n[44] Yurii Nesterov. “Primal-dual subgradient methods for convex problems”. In: Mathematical Programming 120.1 (2009), pp. 221–259.\n[45] Yurii Nesterov. “Smooth Minimization of Non-smooth Functions”. In: Mathematical\nProgramming 103.1 (2005), pp. 127–152.\n\nBIBLIOGRAPHY\n\n146\n\n[46] Yurii Nesterov. “Universal gradient methods for convex optimization problems”. In:\nMathematical Programming (2014), pp. 1–24.\n[47] Yurii Nesterov and Vladimir Shikhman. “Quasi-monotone Subgradient Methods for\nNonsmooth Convex Minimization”. In: Journal of Optimization Theory and Applications 165.3 (2015), pp. 917–940.\n[48] Yurii Nesterov and Sebastian Stich. Efficiency of Accelerated Coordinate Descent Method\non Structured Optimization Problems. Tech. rep. Université catholique de Louvain,\nCORE Discussion Papers, 2016.\n[49] Julie Nutini, Mark Schmidt, Issam H. Laradji, Michael Friedlander, and Hoyt Koepke.\n“Coordinate Descent Converges Faster with the Gauss-Southwell Rule Than Random\nSelection”. In: ICML. 2015.\n[50] Julie Nutini et al. “Convergence Rates for Greedy Kaczmarz Algorithms, and Faster\nRandomized Kaczmarz Rules Using the Orthogonality Graph”. In: UAI. 2016.\n[51] Bernt Oksendal. Stochastic Differential Equations (3rd Ed.): An Introduction with Applications. New York, NY, USA: Springer-Verlag New York, Inc., 1992.\n[52] On Symplectic Optimization. Arxiv preprint arXiv1802.03653. 2018.\n[53] Neal Parikh and Stephen P. Boyd. “Proximal Algorithms”. In: Foundations and Trends\nin Optimization 1.3 (2014), pp. 127–239.\n[54] Boris T. Polyak. “Some methods of speeding up the convergence of iteration methods”.\nIn: USSR Computational Mathematics and Mathematical Physics 4.5 (1964), pp. 1–17.\n[55] Zheng Qu and Peter Richtárik. “Coordinate Descent with Arbitrary Sampling I: Algorithms and Complexity”. In: arXiv 1412.8060 (2014).\n[56] Zheng Qu and Peter Richtárik. “Coordinate Descent with Arbitrary Sampling II: Expected Separable Overapproximation”. In: arXiv 1412.8063 (2014).\n[57] Zheng Qu, Peter Richtárik, Martin Takác̆, and Olivier Fercoq. “SDNA: Stochastic Dual\nNewton Ascent for Empirical Risk Minimization”. In: ICML. 2016.\n[58] Zheng Qu, Peter Richtárik, and Tong Zhang. “Randomized Dual Coordinate Ascent\nwith Arbitrary Sampling”. In: NIPS. 2015.\n[59] Maxim Raginsky and Jake V. Bouvrie. “Continuous-time stochastic Mirror Descent\non a network: Variance reduction, consensus, convergence”. In: Proceedings of the 51th\nIEEE Conference on Decision and Control, CDC 2012, December 10-13, 2012, Maui,\nHI, USA. 2012, pp. 6793–6800.\n[60] Ali Rahimi and Benjamin Recht. “Random Features for Large-Scale Kernel Machines”.\nIn: NIPS. 2007.\n[61] Garvesh Raskutti and Sayan Mukherjee. “The Information Geometry of Mirror Descent”. In: IEEE Transactions on Information Theory 61.3 (2015), pp. 1451–1457.\n\nBIBLIOGRAPHY\n\n147\n\n[62] Benjamin Recht and Christopher Ré. “Parallel Stochastic Gradient Algorithms for\nLarge-Scale Matrix Completion”. In: Mathematical Programming Computation 5.2\n(2013), pp. 201–226.\n[63] Peter Richtárik and Martin Takác̆. “Iteration Complexity of Randomized Block-Coordinate\nDescent Methods for Minimizing a Composite Function”. In: Mathematical Programming 114 (1 2014).\n[64] R. Tyrrell Rockafellar. Convex analysis. Princeton Mathematical Series. Princeton University Press, 1970.\n[65] Alessandro Rudi, Luigi Carratino, and Lorenzo Rosasco. “FALKON: An Optimal Large\nScale Kernel Method”. In: arXiv 1705.10958 (2017).\n[66] David E. Rumelhart, Geoffrey E. Hinton, and Ronald J. Williams. “Learning representations by back-propagating errors”. In: Nature 323.6088 (9, 1986), pp. 533–536.\n[67] Bernhard Schölkopf and Alexander J. Smola. Learning with Kernels. MIT Press, 2001.\n[68] Evan R. Sparks, Shivaram Venkataraman, Tomer Kaftan, Michael Franklin, and Benjamin Recht. “KeystoneML: Optimizing Pipelines for Large-Scale Advanced Analytics”. In: ICDE. 2017.\n[69] Thomas Strohmer and Roman Vershynin. “A Randomized Kaczmarz Algorithm with\nExponential Convergence”. In: Journal of Fourier Analysis and Applications 15.1\n(2009).\n[70] Weijie Su, Stephen Boyd, and Emmanuel J. Candès. “A Differential Equation for\nModeling Nesterov’s Accelerated Gradient Method: Theory and Insights”. In: Advances\nin Neural Information Processing Systems (NIPS) 27. 2014.\n[71] Paul Tseng and Sangwoon Yun. “A Coordinate Gradient Descent Method for Nonsmooth Separable Minimization”. In: Mathematical Programming 117.1 (2009).\n[72] Stephen Tu, Rebecca Roelofs, Shivaram Venkataraman, and Benjamin Recht. “Large\nScale Kernel Learning using Block Coordinate Descent”. In: arXiv 1602.05310 (2016).\n[73] Stephen Tu et al. “Breaking Locality Accelerates Block Gauss-Seidel”. In: Proceedings\nof the 34th International Conference on Machine Learning, ICML 2017, Sydney, NSW,\nAustralia, 6-11 August 2017. 2017, pp. 3482–3491.\n[74] Andre Wibisono. Sampling as optimization in the space of measures: The Langevin\ndynamics as a composite optimization problem. Arxiv preprint arXiv1802.08089.\n[75] Andre Wibisono and Ashia Wilson. On Accelerated Methods in Optimization. Arxiv\npreprint arXiv1509.03616.\n[76] Andre Wibisono, Ashia C. Wilson, and Michael I. Jordan. “A variational perspective\non accelerated methods in optimization”. In: Proceedings of the National Academy of\nSciences 113.47 (2016), E7351–E7358.\n\nBIBLIOGRAPHY\n\n148\n\n[77] Ashia C. Wilson, Benjamin Recht, and Michael I. Jordan. “A Lyapunov Analysis of\nMomentum Methods in Optimization”. In: arXiv 1611.02635 (2016).\n[78] Fuzhen Zhang. The Schur Complement and its Applications. Vol. 4. Numerical Methods\nand Algorithms. Springer, 2005.\n[79] Hongyi Zhang and Suvrit Sra. “First-order Methods for Geodescially Convex Optimization”. In: Conference on Learning Theory (COLT) (2016).\n\n","pages":{"startPosition":[0,5000,9985,14999,20001,24997,29995,35000,39993,44997,49997,55001,59999,64986,70000,74997,80000,85001,89997,95000,99998,104999,109999,114999,119999,125001,129999,134998,139999,144999,149995,154993,159997,164992,169998,174996,180000,184997,190001,195000,199997,204998,210001,214997,219996,224999,229999,235001,240000,244999,250001,255001,259994,265001,270001,275000,280001,284993,289999,294999,300001,304998,309999]}},"html":{"comparison":{"identical":{"groupId":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44],"source":{"chars":{"starts":[3677845,3677862,3677870,3677887,3677895,3677912,3677920,3677937,3677945,3677962,3677970,3677987,3677995,3678012,3678020,3678037,3678045,3678062,3678070,3678087,3678095,3678112,3678120,3678137,3678145,3678162,3678170,3678187,3678195,3678212,3678220,3678237,3678245,3678262,3678270,3678696,3678713,3678721,3678738,3678746,3678763,3678771,3678788,3678796,3678813,3678821,3678838,3678846,3678863,3678871,3678888,3678896,3678913,3678921,3678938,3678946,3678963,3678971,3678988,3678996,3679013,3679021,3679038,3679046,3679597,3679614,3679622,3679639,3679647,3679664,3679672,3679689,3679697,3679714,3679722,3679739,3679747,3679764,3679772,3679789,3679797,3679814,3679822,3679839,3679847,3679864,3679872,3679889,3679897,3679914,3679922,3680867,3680884,3680892,3680909,3680917,3680934,3680942,3680959,3680967,3680984,3680992,3681009,3681017,3681034,3681042,3681059,3681067,3681084,3681092,3681109,3681117,3681134,3681142,3683779,3683796,3683804,3683821,3683829,3683846,3683854,3683871,3683879,3683896,3683904,3683921,3683929,3683946,3683954,3683971,3683979,3683996,3684004,3684021,3684029,3684046,3684054,3684071,3684079,3684096,3684104,3684121,3684129,3684146,3684154,3684171,3684179,3684196,3684204,3684221,3684229,3685290,3685307,3685315,3685332,3685340,3685357,3685365,3685382,3685390,3685407,3685415,3685432,3685440,3685457,3685465,3685482,3685490,3685507,3685515,3685532,3685540,3685557,3685565,3685829,3685846,3685854,3685871,3685879,3685896,3685904,3685921,3685929,3685946,3685954,3685971,3685979,3685996,3686004,3686021,3686029,3686046,3686054,3686071,3686079,3686096,3686104,3686694,3686711,3686719,3686736,3686744,3686761,3686769,3686786,3686794,3686811,3686819,3686836,3686844,3686861,3686869,3686886,3686894,3686911,3686919,3686936,3686944,3686961,3686969,3686986,3686994,3687011,3687019,3687036,3687044,3687061,3687069,3687086,3687094,3687111,3687119,3687136,3687144,3687161,3687169,3687186,3687194,3687211,3687219,3687236,3687244,3687944,3687961,3687969,3687986,3687994,3688011,3688019,3688036,3688044,3688061,3688069,3688086,3688094,3688111,3688119,3688136,3688144,3688161,3688169,3688186,3688194,3688211,3688219,3688236,3688244,3688261,3688269,3688286,3688294,3688319,3688336,3688344,3688361,3688369,3688386,3688394,3688411,3688419,3688436,3688444,3688461,3688469,3688486,3688494,3688511,3688519,3688536,3688544,3688561,3688569,3688586,3688594,3688611,3688619,3688636,3688644,3689874,3689891,3689899,3689916,3689924,3689941,3689949,3689966,3689974,3689991,3689999,3690016,3690024,3690041,3690049,3690066,3690074,3690091,3690099,3690116,3690124,3690141,3690149,3690166,3690174,3690191,3690199,3691980,3691997,3692005,3692022,3692030,3692047,3692055,3692072,3692080,3692097,3692105,3692122,3692130,3692147,3692155,3692172,3692180,3692197,3692205,3692222,3692230,3692247,3692255,3692647,3692664,3692672,3692689,3692697,3692714,3692722,3692739,3692747,3692764,3692772,3692789,3692797,3692814,3692822,3692839,3692847,3692864,3692872,3692889,3692897,3692914,3692922,3693697,3693714,3693722,3693739,3693747,3693764,3693772,3693789,3693797,3693814,3693822,3693839,3693847,3693864,3693872,3693889,3693897,3693914,3693922,3693939,3693947,3693964,3693972,3693989,3693997,3694014,3694022,3694039,3694047,3694064,3694072,3694089,3694097,3694114,3694122,3694147,3694164,3694172,3694189,3694197,3694214,3694222,3694239,3694247,3694264,3694272,3694289,3694297,3694314,3694322,3694339,3694347,3694364,3694372,3694389,3694397,3694414,3694422,3694439,3694447,3694878,3694895,3694903,3694920,3694928,3694945,3694953,3694970,3694978,3694995,3695003,3695020,3695028,3695045,3695053,3695070,3695078,3695095,3695103,3695120,3695128,3695145,3695153,3695509,3695526,3695534,3695551,3695559,3695576,3695584,3695601,3695609,3695626,3695634,3695651,3695659,3695676,3695684,3695701,3695709,3695726,3695734,3695751,3695759,3695776,3695784,3695801,3695809,3695826,3695834,3695851,3695859,3695876,3695884,3695901,3695909,3695926,3695934,3695951,3695959,3697388,3697405,3697413,3697430,3697438,3697455,3697463,3697480,3697488,3697505,3697513,3697530,3697538,3697555,3697563,3697580,3697588,3697605,3697613,3697630,3697638,3697655,3697663,3697680,3697688,3697705,3697713,3697730,3697738,3697763,3697780,3697788,3697805,3697813,3697830,3697838,3697855,3697863,3697880,3697888,3697905,3697913,3697930,3697938,3697955,3697963,3697980,3697988,3698005,3698013,3698030,3698038,3698928,3698945,3698953,3698970,3698978,3698995,3699003,3699020,3699028,3699045,3699053,3699070,3699078,3699095,3699103,3699120,3699128,3699145,3699153,3699170,3699178,3699195,3699203,3699220,3699228,3699245,3699253,3699270,3699278,3699295,3699303,3699320,3699328,3699345,3699353,3699681,3699698,3699706,3699723,3699731,3699748,3699756,3699773,3699781,3699798,3699806,3699823,3699831,3699848,3699856,3699873,3699881,3699898,3699906,3699923,3699931,3699948,3699956,3699973,3699981,3699998,3700006,3700023,3700031,3711844,3711861,3711869,3711886,3711894,3711911,3711919,3711936,3711944,3711961,3711969,3711986,3711994,3712011,3712019,3712036,3712044,3712061,3712069,3712086,3712094,3712111,3712119,3712136,3712144,3712161,3712169,3712186,3712194,3712211,3712219,3712449,3712466,3712474,3712491,3712499,3712516,3712524,3712541,3712549,3712566,3712574,3712591,3712599,3712616,3712624,3712641,3712649,3712666,3712674,3712691,3712699,3712716,3712724,3712741,3712749,3712766,3712774,3712791,3712799,3712816,3712824,3712841,3712849,3712866,3712874,3712899,3712916,3712924,3712941,3712949,3712966,3712974,3712991,3712999,3713016,3713024,3713041,3713049,3713066,3713074,3713091,3713099,3713116,3713124,3713141,3713149,3713166,3713174,3713191,3713199,3713601,3713618,3713626,3713643,3713651,3713668,3713676,3713693,3713701,3713718,3713726,3713743,3713751,3713768,3713776,3713793,3713801,3713818,3713826,3713843,3713851,3713868,3713876,3713893,3713901,3714469,3714486,3714494,3714511,3714519,3714536,3714544,3714561,3714569,3714586,3714594,3714611,3714619,3714636,3714644,3714661,3714669,3714686,3714694,3714711,3714719,3714736,3714744,3714761,3714769,3714786,3714794,3714811,3714819,3714836,3714844,3714861,3714869,3714886,3714894,3714919,3714936,3714944,3714961,3714969,3714986,3714994,3715011,3715019,3715036,3715044,3715061,3715069,3715086,3715094,3715111,3715119,3715136,3715144,3715161,3715169,3715186,3715194,3716229,3716246,3716254,3716271,3716279,3716296,3716304,3716321,3716329,3716346,3716354,3716371,3716379,3716396,3716404,3716421,3716429,3716446,3716454,3716471,3716479,3716496,3716504,3716521,3716529,3716546,3716554,3716571,3716579,3716596,3716604,3716621,3716629,3716646,3716654,3716671,3716679,3716696,3716704,3716721,3716729,3716746,3716754,3717086,3717103,3717111,3717128,3717136,3717153,3717161,3717178,3717186,3717203,3717211,3717228,3717236,3717253,3717261,3717278,3717286,3717303,3717311,3717328,3717336,3717353,3717361,3717378,3717386,3717403,3717411,3717428,3717436,3717453,3717461,3717478,3717486,3717503,3717511,3717835,3717852,3717860,3717877,3717885,3717902,3717910,3717927,3717935,3717952,3717960,3717977,3717985,3718002,3718010,3718027,3718035,3718052,3718060,3718077,3718085,3718102,3718110,3718127,3718135,3718152,3718160,3718177,3718185,3718202,3718210,3718227,3718235,3718252,3718260,3718277,3718285,3718302,3718310,3718327,3718335,3718352,3718360,3719062,3719079,3719087,3719104,3719112,3719129,3719137,3719154,3719162,3719179,3719187,3719204,3719212,3719229,3719237,3719254,3719262,3719279,3719287,3719304,3719312,3719329,3719337,3719354,3719362,3719379,3719387,3719404,3719412,3719429,3719437,3719454,3719462,3719479,3719487,3719504,3719512,3719529,3719537,3719554,3719562,3719579,3719587,3719604,3719612,3719629,3719637,3719654,3719662,3719679,3719687,3719704,3719712,3720534,3720551,3720559,3720576,3720584,3720601,3720609,3720626,3720634,3720651,3720659,3720676,3720684,3720701,3720709,3720726,3720734,3720751,3720759,3720776,3720784,3720801,3720809,3720826,3720834,3720851,3720859,3720876,3720884,3720901,3720909,3720926,3720934,3720951,3720959,3720976,3720984,3721001,3721009,3721026,3721034,3721051,3721059,3725121,3725138,3725146,3725163,3725171,3725188,3725196,3725213,3725221,3725238,3725246,3725263,3725271,3725288,3725296,3725313,3725321,3725338,3725346,3725363,3725371,3725388,3725396,3726458,3726475,3726483,3726500,3726508,3726525,3726533,3726550,3726558,3726575,3726583,3726600,3726608,3726625,3726633,3726650,3726658,3726675,3726683,3726700,3726708,3726725,3726733,3726750,3726758,3726775,3726783,3726800,3726808,3726825,3726833,3726850,3726858,3726875,3726883,3726900,3726908,3727475,3727492,3727500,3727517,3727525,3727542,3727550,3727567,3727575,3727592,3727600,3727617,3727625,3727642,3727650,3727667,3727675,3727692,3727700,3727717,3727725,3727742,3727750,3727767,3727775,3727792,3727800,3727817,3727825,3727842,3727850,3727867,3727875,3727892,3727900,3728165,3728182,3728190,3728207,3728215,3728232,3728240,3728257,3728265,3728282,3728290,3728307,3728315,3728332,3728340,3728357,3728365,3728382,3728390,3728407,3728415,3728432,3728440,3728457,3728465,3728482,3728490,3728507,3728515,3728532,3728540,3729039,3729056,3729064,3729081,3729089,3729106,3729114,3729131,3729139,3729156,3729164,3729181,3729189,3729206,3729214,3729231,3729239,3729256,3729264,3729281,3729289,3729306,3729314,3729331,3729339,3729356,3729364,3731122,3731139,3731147,3731164,3731172,3731189,3731197,3731214,3731222,3731239,3731247,3731264,3731272,3731289,3731297,3731314,3731322,3731339,3731347,3731364,3731372,3731389,3731397,3731414,3731422,3731439,3731447,3731464,3731472,3731489,3731497,3731514,3731522,3731539,3731547,3732962,3732979,3732987,3733004,3733012,3733029,3733037,3733054,3733062,3733079,3733087,3733104,3733112,3733129,3733137,3733154,3733162,3733179,3733187,3733204,3733212,3733229,3733237,3733254,3733262,3733279,3733287,3733304,3733312,3733329,3733337,3733759,3733776,3733784,3733801,3733809,3733826,3733834,3733851,3733859,3733876,3733884,3733901,3733909,3733926,3733934,3733951,3733959,3733976,3733984,3734001,3734009,3734026,3734034,3734051,3734059,3734076,3734084,3771437,3771464,3771472,3771489,3771497,3771514,3771522,3771539,3771547,3771564,3771572,3771589,3771597,3771614,3771622,3771639,3771647,3771664,3771672,3771689,3771697,3771714,3771722,3771739,3771747,3771764,3771772,3771789,3771797,3771814,3771822,3771839,3771847,3771864,3771872,3771889,3771897,3771914,3771922,3771939,3771947,3771964,3771972,3779484,3779501,3779509,3779526,3779534,3779551,3779559,3779576,3779584,3779601,3779609,3779626,3779634,3779651,3779659,3779676,3779684,3779701,3779709,3779726,3779734,3885584,3885611,3885619,3885636,3885644,3885661,3885669,3885686,3885694,3885711,3885719,3885736,3885744,3885761,3885769,3885786,3885794,3885811,3885819,3885836,3885844,3885861,3885869,3885886,3885894,3885911,3885919,3885936,3885944,3912114,3912141,3912149,3912166,3912174,3912191,3912199,3912216,3912224,3912241,3912249,3912266,3912274,3912291,3912299,3912316,3912324,3912341,3912349,3912366,3912374,3912391,3912399,3912416,3912424,3912441,3912449,3912466,3912474,3912491,3912499,3912516,3912524,3912541,3912549,3912566,3912574,3912591,3912599,3912616,3912624,3912641,3912649,3912666,3912674,3912691,3912699,3912716,3912724,3912741,3912749,3912766,3912774,4002593,4002618,4002626,4002643,4002651,4002668,4002676,4002693,4002701,4002718,4002726,4002743,4002751,4002768,4002776,4002793,4002801,4002818,4002826,4002843,4002851,4002868,4002876,4002893,4002901,4002918,4002926,4002943,4002951,4002968,4002976,4002993,4003001,4003018,4003026,4003043,4003051,4003068,4003076,4003093,4003101,4003118,4003126,4003143,4003151,4003168,4003176,4003193,4003201,4003218,4003226,4003243,4003251,4003268,4003276,4003293,4003301],"lengths":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,7,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,7,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,7,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,6,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]},"words":{"starts":[5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5866,5866,5866,5866,5866,5866,5866,5866,5866,5866,5866,5866,5866,5866,5866,5866,5866,5866,5866,5866,5866,5866,5866,5866,5866,5866,5866,5907,5907,5907,5907,5907,5907,5907,5907,5907,5907,5907,5907,5907,5907,5907,5907,5907,5907,5907,5907,5907,5907,5907,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,6050,6050,6050,6050,6050,6050,6050,6050,6050,6050,6050,6050,6050,6050,6050,6050,6050,6050,6050,6050,6050,6050,6050,6068,6068,6068,6068,6068,6068,6068,6068,6068,6068,6068,6068,6068,6068,6068,6068,6068,6068,6068,6068,6068,6068,6068,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6150,6150,6150,6150,6150,6150,6150,6150,6150,6150,6150,6150,6150,6150,6150,6150,6150,6150,6150,6150,6150,6150,6150,6150,6150,6150,6150,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6258,6258,6258,6258,6258,6258,6258,6258,6258,6258,6258,6258,6258,6258,6258,6258,6258,6258,6258,6258,6258,6258,6258,6280,6280,6280,6280,6280,6280,6280,6280,6280,6280,6280,6280,6280,6280,6280,6280,6280,6280,6280,6280,6280,6280,6280,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6329,6329,6329,6329,6329,6329,6329,6329,6329,6329,6329,6329,6329,6329,6329,6329,6329,6329,6329,6329,6329,6329,6329,6329,6329,6353,6353,6353,6353,6353,6353,6353,6353,6353,6353,6353,6353,6353,6353,6353,6353,6353,6353,6353,6353,6353,6353,6353,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6451,6451,6451,6451,6451,6451,6451,6451,6451,6451,6451,6451,6451,6451,6451,6451,6451,6451,6451,6451,6451,6451,6451,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6515,6515,6515,6515,6515,6515,6515,6515,6515,6515,6515,6515,6515,6515,6515,6515,6515,6515,6515,6515,6515,6515,6515,6515,6515,6515,6515,6515,6515,6537,6537,6537,6537,6537,6537,6537,6537,6537,6537,6537,6537,6537,6537,6537,6537,6537,6537,6537,6537,6537,6537,6537,6537,6537,6537,6537,6537,6537,6537,6537,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6576,6576,6576,6576,6576,6576,6576,6576,6576,6576,6576,6576,6576,6576,6576,6576,6576,6576,6576,6576,6576,6576,6576,6576,6576,6599,6599,6599,6599,6599,6599,6599,6599,6599,6599,6599,6599,6599,6599,6599,6599,6599,6599,6599,6599,6599,6599,6599,6599,6599,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6641,6641,6641,6641,6641,6641,6641,6641,6641,6641,6641,6641,6641,6641,6641,6641,6641,6641,6641,6641,6641,6641,6641,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6982,6982,6982,6982,6982,6982,6982,6982,6982,6982,6982,6982,6982,6982,6982,6982,6982,6982,6982,6982,6982,6982,6982,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7247,7247,7247,7247,7247,7247,7247,7247,7247,7247,7247,7247,7247,7247,7247,7247,7247,7247,7247,7247,7247,7247,7247,7247,7247,7247,7247,7247,7247,7247,7247,7274,7274,7274,7274,7274,7274,7274,7274,7274,7274,7274,7274,7274,7274,7274,7274,7274,7274,7274,7274,7274,7274,7274,7274,7274,7274,7274,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8154,8430,8430,8430,8430,8430,8430,8430,8430,8430,8430,8430,8430,8430,8430,8430,8430,8430,8430,8430,8430,8430,10662,10662,10662,10662,10662,10662,10662,10662,10662,10662,10662,10662,10662,10662,10662,10662,10662,10662,10662,10662,10662,10662,10662,10662,10662,10662,10662,10662,10662,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243,13243],"lengths":[17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28]}},"suspected":{"chars":{"starts":[2025,2025,2025,2025,2025,2025,2025,2025,2025,2025,2025,2025,2025,2025,2025,2025,2025,2025,2025,2025,2025,2025,2025,2025,2025,2025,2025,2025,2025,2025,2025,2025,2025,2025,2025,2112,2112,2112,2112,2112,2112,2112,2112,2112,2112,2112,2112,2112,2112,2112,2112,2112,2112,2112,2112,2112,2112,2112,2112,2112,2112,2112,2112,2112,2255,2255,2255,2255,2255,2255,2255,2255,2255,2255,2255,2255,2255,2255,2255,2255,2255,2255,2255,2255,2255,2255,2255,2255,2255,2255,2255,2490,2490,2490,2490,2490,2490,2490,2490,2490,2490,2490,2490,2490,2490,2490,2490,2490,2490,2490,2490,2490,2490,2490,3545,3545,3545,3545,3545,3545,3545,3545,3545,3545,3545,3545,3545,3545,3545,3545,3545,3545,3545,3545,3545,3545,3545,3545,3545,3545,3545,3545,3545,3545,3545,3545,3545,3545,3545,3545,3545,4437,4437,4437,4437,4437,4437,4437,4437,4437,4437,4437,4437,4437,4437,4437,4437,4437,4437,4437,4437,4437,4437,4437,4612,4612,4612,4612,4612,4612,4612,4612,4612,4612,4612,4612,4612,4612,4612,4612,4612,4612,4612,4612,4612,4612,4612,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4673,4860,4860,4860,4860,4860,4860,4860,4860,4860,4860,4860,4860,4860,4860,4860,4860,4860,4860,4860,4860,4860,4860,4860,4860,4860,4860,4860,4860,4860,4912,4912,4912,4912,4912,4912,4912,4912,4912,4912,4912,4912,4912,4912,4912,4912,4912,4912,4912,4912,4912,4912,4912,4912,4912,4912,4912,4948,4948,4948,4948,4948,4948,4948,4948,4948,4948,4948,4948,4948,4948,4948,4948,4948,4948,4948,4948,4948,4948,4948,4948,4948,4948,4948,4998,4998,4998,4998,4998,4998,4998,4998,4998,4998,4998,4998,4998,4998,4998,4998,4998,4998,4998,4998,4998,4998,4998,5257,5257,5257,5257,5257,5257,5257,5257,5257,5257,5257,5257,5257,5257,5257,5257,5257,5257,5257,5257,5257,5257,5257,5845,5845,5845,5845,5845,5845,5845,5845,5845,5845,5845,5845,5845,5845,5845,5845,5845,5845,5845,5845,5845,5845,5845,5845,5845,5845,5845,5845,5845,5845,5845,5845,5845,5845,5845,6203,6203,6203,6203,6203,6203,6203,6203,6203,6203,6203,6203,6203,6203,6203,6203,6203,6203,6203,6203,6203,6203,6203,6203,6203,6239,6239,6239,6239,6239,6239,6239,6239,6239,6239,6239,6239,6239,6239,6239,6239,6239,6239,6239,6239,6239,6239,6239,6284,6284,6284,6284,6284,6284,6284,6284,6284,6284,6284,6284,6284,6284,6284,6284,6284,6284,6284,6284,6284,6284,6284,6284,6284,6284,6284,6284,6284,6284,6284,6284,6284,6284,6284,6284,6284,6517,6517,6517,6517,6517,6517,6517,6517,6517,6517,6517,6517,6517,6517,6517,6517,6517,6517,6517,6517,6517,6517,6517,6517,6517,6517,6517,6517,6517,7009,7009,7009,7009,7009,7009,7009,7009,7009,7009,7009,7009,7009,7009,7009,7009,7009,7009,7009,7009,7009,7009,7009,7443,7443,7443,7443,7443,7443,7443,7443,7443,7443,7443,7443,7443,7443,7443,7443,7443,7443,7443,7443,7443,7443,7443,7443,7443,7443,7443,7443,7443,7443,7443,7443,7443,7443,7443,7583,7583,7583,7583,7583,7583,7583,7583,7583,7583,7583,7583,7583,7583,7583,7583,7583,7583,7583,7583,7583,7583,7583,7583,7583,7583,7583,7583,7583,7662,7662,7662,7662,7662,7662,7662,7662,7662,7662,7662,7662,7662,7662,7662,7662,7662,7662,7662,7662,7662,7662,7662,7662,7662,7662,7662,7662,7662,7662,7662,7751,7751,7751,7751,7751,7751,7751,7751,7751,7751,7751,7751,7751,7751,7751,7751,7751,7751,7751,7751,7751,7751,7751,7751,7751,7751,7751,7751,7751,7751,7751,7751,7751,7751,7751,7916,7916,7916,7916,7916,7916,7916,7916,7916,7916,7916,7916,7916,7916,7916,7916,7916,7916,7916,7916,7916,7916,7916,7916,7916,7999,7999,7999,7999,7999,7999,7999,7999,7999,7999,7999,7999,7999,7999,7999,7999,7999,7999,7999,7999,7999,7999,7999,7999,7999,8074,8074,8074,8074,8074,8074,8074,8074,8074,8074,8074,8074,8074,8074,8074,8074,8074,8074,8074,8074,8074,8074,8074,8074,8074,8074,8074,8074,8074,8074,8074,8074,8074,8074,8074,8159,8159,8159,8159,8159,8159,8159,8159,8159,8159,8159,8159,8159,8159,8159,8159,8159,8159,8159,8159,8159,8159,8159,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8236,8307,8307,8307,8307,8307,8307,8307,8307,8307,8307,8307,8307,8307,8307,8307,8307,8307,8307,8307,8307,8307,8307,8307,8307,8307,8307,8307,8307,8307,8307,8307,8307,8307,8307,8307,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8464,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,8801,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9068,9554,9554,9554,9554,9554,9554,9554,9554,9554,9554,9554,9554,9554,9554,9554,9554,9554,9554,9554,9554,9554,9554,9554,9788,9788,9788,9788,9788,9788,9788,9788,9788,9788,9788,9788,9788,9788,9788,9788,9788,9788,9788,9788,9788,9788,9788,9788,9788,9788,9788,9788,9788,9788,9788,9788,9788,9788,9788,9788,9788,10481,10481,10481,10481,10481,10481,10481,10481,10481,10481,10481,10481,10481,10481,10481,10481,10481,10481,10481,10481,10481,10481,10481,10481,10481,10481,10481,10481,10481,10481,10481,10481,10481,10481,10481,10517,10517,10517,10517,10517,10517,10517,10517,10517,10517,10517,10517,10517,10517,10517,10517,10517,10517,10517,10517,10517,10517,10517,10517,10517,10517,10517,10517,10517,10517,10517,11217,11217,11217,11217,11217,11217,11217,11217,11217,11217,11217,11217,11217,11217,11217,11217,11217,11217,11217,11217,11217,11217,11217,11217,11217,11217,11217,13464,13464,13464,13464,13464,13464,13464,13464,13464,13464,13464,13464,13464,13464,13464,13464,13464,13464,13464,13464,13464,13464,13464,13464,13464,13464,13464,13464,13464,13464,13464,13464,13464,13464,13464,13824,13824,13824,13824,13824,13824,13824,13824,13824,13824,13824,13824,13824,13824,13824,13824,13824,13824,13824,13824,13824,13824,13824,13824,13824,13824,13824,13824,13824,13824,13824,14224,14224,14224,14224,14224,14224,14224,14224,14224,14224,14224,14224,14224,14224,14224,14224,14224,14224,14224,14224,14224,14224,14224,14224,14224,14224,14224,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,3739,9965,9965,9965,9965,9965,9965,9965,9965,9965,9965,9965,9965,9965,9965,9965,9965,9965,9965,9965,9965,9965,7823,7823,7823,7823,7823,7823,7823,7823,7823,7823,7823,7823,7823,7823,7823,7823,7823,7823,7823,7823,7823,7823,7823,7823,7823,7823,7823,7823,7823,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,4082,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394,2394],"lengths":[35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62,62]},"words":{"starts":[292,292,292,292,292,292,292,292,292,292,292,292,292,292,292,292,292,292,292,292,292,292,292,292,292,292,292,292,292,292,292,292,292,292,292,328,328,328,328,328,328,328,328,328,328,328,328,328,328,328,328,328,328,328,328,328,328,328,328,328,328,328,328,328,375,375,375,375,375,375,375,375,375,375,375,375,375,375,375,375,375,375,375,375,375,375,375,375,375,375,375,465,465,465,465,465,465,465,465,465,465,465,465,465,465,465,465,465,465,465,465,465,465,465,801,801,801,801,801,801,801,801,801,801,801,801,801,801,801,801,801,801,801,801,801,801,801,801,801,801,801,801,801,801,801,801,801,801,801,801,801,1054,1054,1054,1054,1054,1054,1054,1054,1054,1054,1054,1054,1054,1054,1054,1054,1054,1054,1054,1054,1054,1054,1054,1108,1108,1108,1108,1108,1108,1108,1108,1108,1108,1108,1108,1108,1108,1108,1108,1108,1108,1108,1108,1108,1108,1108,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1126,1181,1181,1181,1181,1181,1181,1181,1181,1181,1181,1181,1181,1181,1181,1181,1181,1181,1181,1181,1181,1181,1181,1181,1181,1181,1181,1181,1181,1181,1199,1199,1199,1199,1199,1199,1199,1199,1199,1199,1199,1199,1199,1199,1199,1199,1199,1199,1199,1199,1199,1199,1199,1199,1199,1199,1199,1217,1217,1217,1217,1217,1217,1217,1217,1217,1217,1217,1217,1217,1217,1217,1217,1217,1217,1217,1217,1217,1217,1217,1217,1217,1217,1217,1235,1235,1235,1235,1235,1235,1235,1235,1235,1235,1235,1235,1235,1235,1235,1235,1235,1235,1235,1235,1235,1235,1235,1314,1314,1314,1314,1314,1314,1314,1314,1314,1314,1314,1314,1314,1314,1314,1314,1314,1314,1314,1314,1314,1314,1314,1482,1482,1482,1482,1482,1482,1482,1482,1482,1482,1482,1482,1482,1482,1482,1482,1482,1482,1482,1482,1482,1482,1482,1482,1482,1482,1482,1482,1482,1482,1482,1482,1482,1482,1482,1589,1589,1589,1589,1589,1589,1589,1589,1589,1589,1589,1589,1589,1589,1589,1589,1589,1589,1589,1589,1589,1589,1589,1589,1589,1607,1607,1607,1607,1607,1607,1607,1607,1607,1607,1607,1607,1607,1607,1607,1607,1607,1607,1607,1607,1607,1607,1607,1625,1625,1625,1625,1625,1625,1625,1625,1625,1625,1625,1625,1625,1625,1625,1625,1625,1625,1625,1625,1625,1625,1625,1625,1625,1625,1625,1625,1625,1625,1625,1625,1625,1625,1625,1625,1625,1713,1713,1713,1713,1713,1713,1713,1713,1713,1713,1713,1713,1713,1713,1713,1713,1713,1713,1713,1713,1713,1713,1713,1713,1713,1713,1713,1713,1713,1898,1898,1898,1898,1898,1898,1898,1898,1898,1898,1898,1898,1898,1898,1898,1898,1898,1898,1898,1898,1898,1898,1898,2061,2061,2061,2061,2061,2061,2061,2061,2061,2061,2061,2061,2061,2061,2061,2061,2061,2061,2061,2061,2061,2061,2061,2061,2061,2061,2061,2061,2061,2061,2061,2061,2061,2061,2061,2110,2110,2110,2110,2110,2110,2110,2110,2110,2110,2110,2110,2110,2110,2110,2110,2110,2110,2110,2110,2110,2110,2110,2110,2110,2110,2110,2110,2110,2146,2146,2146,2146,2146,2146,2146,2146,2146,2146,2146,2146,2146,2146,2146,2146,2146,2146,2146,2146,2146,2146,2146,2146,2146,2146,2146,2146,2146,2146,2146,2181,2181,2181,2181,2181,2181,2181,2181,2181,2181,2181,2181,2181,2181,2181,2181,2181,2181,2181,2181,2181,2181,2181,2181,2181,2181,2181,2181,2181,2181,2181,2181,2181,2181,2181,2242,2242,2242,2242,2242,2242,2242,2242,2242,2242,2242,2242,2242,2242,2242,2242,2242,2242,2242,2242,2242,2242,2242,2242,2242,2272,2272,2272,2272,2272,2272,2272,2272,2272,2272,2272,2272,2272,2272,2272,2272,2272,2272,2272,2272,2272,2272,2272,2272,2272,2301,2301,2301,2301,2301,2301,2301,2301,2301,2301,2301,2301,2301,2301,2301,2301,2301,2301,2301,2301,2301,2301,2301,2301,2301,2301,2301,2301,2301,2301,2301,2301,2301,2301,2301,2332,2332,2332,2332,2332,2332,2332,2332,2332,2332,2332,2332,2332,2332,2332,2332,2332,2332,2332,2332,2332,2332,2332,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2361,2389,2389,2389,2389,2389,2389,2389,2389,2389,2389,2389,2389,2389,2389,2389,2389,2389,2389,2389,2389,2389,2389,2389,2389,2389,2389,2389,2389,2389,2389,2389,2389,2389,2389,2389,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2444,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2549,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2628,2781,2781,2781,2781,2781,2781,2781,2781,2781,2781,2781,2781,2781,2781,2781,2781,2781,2781,2781,2781,2781,2781,2781,2849,2849,2849,2849,2849,2849,2849,2849,2849,2849,2849,2849,2849,2849,2849,2849,2849,2849,2849,2849,2849,2849,2849,2849,2849,2849,2849,2849,2849,2849,2849,2849,2849,2849,2849,2849,2849,3003,3003,3003,3003,3003,3003,3003,3003,3003,3003,3003,3003,3003,3003,3003,3003,3003,3003,3003,3003,3003,3003,3003,3003,3003,3003,3003,3003,3003,3003,3003,3003,3003,3003,3003,3021,3021,3021,3021,3021,3021,3021,3021,3021,3021,3021,3021,3021,3021,3021,3021,3021,3021,3021,3021,3021,3021,3021,3021,3021,3021,3021,3021,3021,3021,3021,3154,3154,3154,3154,3154,3154,3154,3154,3154,3154,3154,3154,3154,3154,3154,3154,3154,3154,3154,3154,3154,3154,3154,3154,3154,3154,3154,3623,3623,3623,3623,3623,3623,3623,3623,3623,3623,3623,3623,3623,3623,3623,3623,3623,3623,3623,3623,3623,3623,3623,3623,3623,3623,3623,3623,3623,3623,3623,3623,3623,3623,3623,3711,3711,3711,3711,3711,3711,3711,3711,3711,3711,3711,3711,3711,3711,3711,3711,3711,3711,3711,3711,3711,3711,3711,3711,3711,3711,3711,3711,3711,3711,3711,3804,3804,3804,3804,3804,3804,3804,3804,3804,3804,3804,3804,3804,3804,3804,3804,3804,3804,3804,3804,3804,3804,3804,3804,3804,3804,3804,842,842,842,842,842,842,842,842,842,842,842,842,842,842,842,842,842,842,842,842,842,842,842,842,842,842,842,842,842,842,842,842,842,842,842,842,842,842,842,842,842,842,842,2902,2902,2902,2902,2902,2902,2902,2902,2902,2902,2902,2902,2902,2902,2902,2902,2902,2902,2902,2902,2902,2210,2210,2210,2210,2210,2210,2210,2210,2210,2210,2210,2210,2210,2210,2210,2210,2210,2210,2210,2210,2210,2210,2210,2210,2210,2210,2210,2210,2210,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,944,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429,429],"lengths":[17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28]}}},"minorChanges":{"groupId":[45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49],"source":{"chars":{"starts":[3723013,3723038,3723046,3723072,3723080,3723108,3723116,3723138,3723146,3723171,3723179,3723204,3723212,3723229,3723237,3723254,3723262,3723279,3723287,3723304,3723312,3723329,3723337,3723354,3723362,3723379,3723387,3723404,3723412,3723429,3723437,3723454,3723462,3723479,3723487,3723504,3723512,3723529,3723537,3723554,3723562,3723579,3723587,3723604,3723612,3723629,3723637,3723654,3723662,3723679,3723687,3723704,3723712,3723729,3723737,3723754,3723762,3723779,3723787,3723804,3723812,3723829,3723837,3723858,3723866,3723930,3723955,3723963,3723987,3723995,3724024,3724032,3724054,3724062,3724090,3724098,3724115,3724123,3724140,3724148,3724165,3724173,3724190,3724198,3724215,3724223,3724240,3724248,3724265,3724273,3724290,3724298,3724315,3724323,3724340,3724348,3724365,3724373,3724390,3724398,3724415,3724423,3724440,3724448,3724465,3724473,3724490,3724498,3724515,3724523,3724540,3724548,3724565,3724573,3724590,3724598,3724615,3724623,3724640,3724648,3724665,3724673,3724690,3724698,3724715,3724723,3724740,3724748,3724765,3724773,3724794,3724802,3725489,3725514,3725522,3725552,3725560,3725588,3725596,3725626,3725634,3725659,3725667,3725684,3725692,3725709,3725717,3725734,3725742,3725759,3725767,3725784,3725792,3725809,3725817,3725834,3725842,3725859,3725867,3725884,3725892,3725909,3725917,3725934,3725942,3725959,3725967,3725984,3725992,3726009,3726017,3726034,3726042,3726059,3726067,3726084,3726092,3726109,3726117,3726134,3726142,3726159,3726167,3726184,3726192,3726213,3726221,3853089,3853116,3853124,3853147,3853155,3853187,3853195,3853223,3853231,3853248,3853256,3853273,3853281,3853298,3853306,3853323,3853331,3853348,3853356,3853373,3853381,3853398,3853406,3853423,3853431,3853448,3853456,3853473,3853481,3853498,3853506,3853523,3853531,3853548,3853556,3853573,3853581,3853598,3853606,3853623,3853631,3853648,3853656,3853673,3853681,3853698,3853706,3853723,3853731,3853748,3853756,3853773,3853781,3853801,3853809,3878820,3878843,3878851,3878876,3878884,3878915,3878923,3878945,3878953,3878976,3878984,3879014,3879022,3879039,3879047,3879064,3879072,3879089,3879097,3879114,3879122,3879139,3879147,3879164,3879172,3879189,3879197,3879214,3879222,3879239,3879247,3879264,3879272,3879289,3879297,3879314,3879322,3879339,3879347,3879364,3879372,3879389,3879397,3879414,3879422,3879439,3879447,3879464,3879472,3879489,3879497,3879514,3879522,3879539,3879547,3879564,3879572,3879589,3879597,3879614,3879622,3879639,3879647,3879664,3879672,3879692,3879700],"lengths":[5,1,6,1,8,1,2,1,5,1,6,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,5,1,4,1,9,1,2,1,9,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,5,1,11,1,8,1,10,1,6,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,7,1,3,1,12,1,9,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,3,3,1,5,1,11,1,2,1,3,1,11,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,3]},"words":{"starts":[6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6908,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6941,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,6995,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10005,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426,10426],"lengths":[32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33]}},"suspected":{"chars":{"starts":[9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9201,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9282,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,9592,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,4468,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658,5658],"lengths":[80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,80,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,76,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,82,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84,84]},"words":{"starts":[2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2675,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2706,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,2800,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1069,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430,1430],"lengths":[30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34]}}},"relatedMeaning":{"groupId":[],"source":{"chars":{"starts":[],"lengths":[]},"words":{"starts":[],"lengths":[]}},"suspected":{"chars":{"starts":[],"lengths":[]},"words":{"starts":[],"lengths":[]}}}}},"version":3}