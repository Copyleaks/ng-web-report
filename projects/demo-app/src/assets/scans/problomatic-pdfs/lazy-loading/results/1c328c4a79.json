{"statistics":{"identical":73,"minorChanges":21,"relatedMeaning":0},"text":{"comparison":{"identical":{"source":{"chars":{"starts":[59641,74370,77595,78977,80105],"lengths":[33,23,23,31,31]},"words":{"starts":[10298,13735,14573,14914,15144],"lengths":[16,11,11,15,15]}},"suspected":{"chars":{"starts":[3402,3521,3749,3898,4395],"lengths":[33,23,23,31,31]},"words":{"starts":[505,547,611,646,783],"lengths":[16,11,11,15,15]}}},"minorChanges":{"source":{"chars":{"starts":[51349],"lengths":[78]},"words":{"starts":[8505],"lengths":[20]}},"suspected":{"chars":{"starts":[3233],"lengths":[78]},"words":{"starts":[464],"lengths":[30]}}},"relatedMeaning":{"source":{"chars":{"starts":[],"lengths":[]},"words":{"starts":[],"lengths":[]}},"suspected":{"chars":{"starts":[],"lengths":[]},"words":{"starts":[],"lengths":[]}}}},"value":"QUANTIFYING MEASUREMENT UNCERTAINTIES\nUSING DIGITAL REPRESENTATIONS OF MATERIALS\nby\n\nNoah Wade\n\nA dissertation submitted to The Johns Hopkins University in conformity with the\nrequirements for the degree of Doctor of Philosophy.\n\nBaltimore, Maryland\nMarch, 2022\n\nc 2022 Noah Wade\nAll rights reserved\n\nAbstract\n\nMaterial characterization is important in many different engineering disciplines. It\nprovides valuable information to computational models with far reaching applications,\nbut it is also challenging and highly specialized. As such, there is potential to apply\nundue confidence in characterization data as it is collected and passed to modelers\nfor subsequent analysis.\nThis thesis looks at uncertainty quantification in material characterization at this\nsystems level. It considers not only the errors that might be present in a given\nmeasurement but also how those errors propagate into subsequent computational\nmodels. An uncertainly quantification framework uses a simulation-based approach\nto identify, measure, and propagate sources of uncertainty that arise in typical imagebased material characterization workflows. The framework uses the concept of a\nvirtual material to estimate probabilistic characteristics of measurement error. The\nframework is used to show how different sources of uncertainty propagate through\nthe system and suggest how characterization can be made more efficient.\nThe first part of this work applies this framework to the process of characterizing a\nii\n\nABSTRACT\n\n3D crystalline microstructure. Simulations of electron backscatter diffraction provide\na virtual data set that is subsequently evaluated using finite element simulation. Results show that some experimental efforts to reduce uncertainties prove unnecessary,\nsince those sources of error do not propagate through the system. At the same time\na number of other sources of error led to significant uncertainties in the end product\ncomputational models. Sampling resolution emerged as a source of error that has\nsignificant influence on the subsequent analyses. The second part of this work further examines the effects of sampling resolution. Simulated data collection provides a\nconditional distribution on key measurements as a function of resolution, from which\na Bayesian approach yields a distribution of the true material characteristic given a\nparticular measurement of that characteristic. These conditional measurement distributions allow for more efficient and effective collection of microstructural data.\nThe third part of this work considers the process of simulating material microstructures. In particular, this work studies potential sources of error in a machine learning\nmodel that is used to reconstruct images based on transfer learning from the VGG-19\nnetwork.\n\nAdvisor: Dr. Lori Graham-Brady\nReader: Dr. Jamie Guest Reader: Dr. Stavros Gaitanaros\n\niii\n\nAcknowledgments\nThe members of the Department of Civil and Systems Engineering have played a\nhuge roll in helping this work come to fruition. From the office support staff to my\nnumerous friends and colleagues, their support has been invaluable.\n\niv\n\nContents\n\nAbstract\n\nii\n\nAcknowledgments\n\niv\n\nList of Tables\n\nx\n\nList of Figures\n\nxi\n\n1 Introduction\n\n1\n\n1.1\n\nProblem Statement . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n1.2\n\nFundamentals, Applications, and Challenges of Material Characteriza-\n\n1.3\n\n5\n\ntion\n\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n7\n\n1.2.1\n\nFundamentals of Electron Microscopy . . . . . . . . . . . . . .\n\n11\n\n1.2.2\n\nImage Processing Challenges . . . . . . . . . . . . . . . . . . .\n\n14\n\n1.2.3\n\nApplication - Multiscale Modeling . . . . . . . . . . . . . . . .\n\n15\n\n1.2.4\n\nMicrostructural Reconstructions . . . . . . . . . . . . . . . . .\n\n16\n\nThe Computational Uncertainty Quantification Framework . . . . . .\n\n17\n\nv\n\nCONTENTS\n\n1.3.1\n\nFramework Details . . . . . . . . . . . . . . . . . . . . . . . .\n\n22\n\n1.3.1.1\n\nTask 1 - Defining a Virtual Material . . . . . . . . .\n\n22\n\n1.3.1.2\n\nTask 2 - Modeling the Physical Workflow\n\n. . . . . .\n\n23\n\n1.3.1.3\n\nTask 3 - Conducting a Parametric Study . . . . . . .\n\n25\n\n1.3.1.4\n\nTask 4 - Quantifying Uncertainty . . . . . . . . . . .\n\n25\n\n1.3.1.5\n\nFramework Summary . . . . . . . . . . . . . . . . . .\n\n27\n\n2 A Framework Model for Electron Backscatter Diffraction\n\n28\n\n2.1\n\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n28\n\n2.2\n\nMethods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n32\n\n2.2.1\n\nStep 1: Synthetic Material Generation - Phantoms . . . . . .\n\n33\n\n2.2.2\n\nStep 2: Simulation of Data Collection . . . . . . . . . . . . . .\n\n34\n\n2.2.2.1\n\nResolution . . . . . . . . . . . . . . . . . . . . . . . .\n\n36\n\n2.2.2.2\n\nInteraction Volume . . . . . . . . . . . . . . . . . . .\n\n36\n\n2.2.2.3\n\nRandom Noise . . . . . . . . . . . . . . . . . . . . .\n\n38\n\n2.2.2.4\n\nSummary of Data Collection Model . . . . . . . . . .\n\n38\n\nAdditional Notes on Methodology . . . . . . . . . . . . . . . .\n\n41\n\nIndividual Parameter Variation Examples . . . . . . . . . . . . . . . .\n\n42\n\n2.3.1\n\nStep 3: Error Measurements . . . . . . . . . . . . . . . . . . .\n\n43\n\n2.3.2\n\nResolution . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n46\n\n2.2.3\n2.3\n\n2.3.2.1\n\nAnalytical Model of Error Associated with Sample\nSpacing . . . . . . . . . . . . . . . . . . . . . . . . .\nvi\n\n48\n\nCONTENTS\n\n2.4\n\n2.5\n\n2.3.3\n\nInteraction Volume . . . . . . . . . . . . . . . . . . . . . . . .\n\n53\n\n2.3.4\n\nUnindexed Pixels . . . . . . . . . . . . . . . . . . . . . . . . .\n\n54\n\n2.3.5\n\nData Processing Parameters . . . . . . . . . . . . . . . . . . .\n\n57\n\n2.3.6\n\nBrief Discussion on Data Collection and Processing Error . . .\n\n60\n\nCase Study: Application to Finite Element Model . . . . . . . . . . .\n\n61\n\n2.4.1\n\nConclusions from the Case Study . . . . . . . . . . . . . . . .\n\n68\n\nConclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n69\n\n3 The Conditional Measurement Distribution\n3.1\n\nDerivation of conditional probability . . . . . . . . . . . . . . . . . .\n\n77\n\n3.1.1\n\nDistributions of material characteristics . . . . . . . . . . . . .\n\n77\n\n3.1.2\n\nDistribution of measured approximations to material characteristics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n78\n\nConditional distribution on the true characteristics . . . . . .\n\n81\n\nCalculation of the Conditional Probability Integral . . . . . . . . . .\n\n82\n\n3.2.1\n\nAn Analytical Model . . . . . . . . . . . . . . . . . . . . . . .\n\n83\n\n3.2.2\n\nSimulation-based approach to calculating the conditional prob-\n\n3.1.3\n3.2\n\n71\n\n3.2.3\n\n3.2.4\n\nability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n87\n\n3.2.2.1\n\nGeneration of ground-truth shapes . . . . . . . . . .\n\n88\n\nMeasurement Definitions . . . . . . . . . . . . . . . . . . . . .\n\n90\n\n3.2.3.1\n\nDefining the Perimeter . . . . . . . . . . . . . . . . .\n\n91\n\nSimulation-based conditional probability results . . . . . . . .\n\n94\n\nvii\n\nCONTENTS\n\n3.3\n\n3.4\n\n3.2.4.1\n\nEffects of Prior Distribution . . . . . . . . . . . . . .\n\n94\n\n3.2.4.2\n\nSize Effects . . . . . . . . . . . . . . . . . . . . . . .\n\n99\n\nConstruction of material characteristic distributions from data . . . . 102\n3.3.1\n\nSize Measurements . . . . . . . . . . . . . . . . . . . . . . . . 103\n\n3.3.2\n\nAspect Ratio Measurements . . . . . . . . . . . . . . . . . . . 110\n\n3.3.3\n\nPerimeter Measurements . . . . . . . . . . . . . . . . . . . . . 111\n\nConclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114\n\n4 Evaluating Computational Models\n\n117\n\n4.1\n\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117\n\n4.2\n\nTransfer learning model evolution and description . . . . . . . . . . . 119\n4.2.1\n\n4.3\n\n4.5\n\n4.2.1.1\n\nGram matrix . . . . . . . . . . . . . . . . . . . . . . 121\n\n4.2.1.2\n\nTotal varition loss . . . . . . . . . . . . . . . . . . . 123\n\nPerformance Indicators . . . . . . . . . . . . . . . . . . . . . . . . . . 124\n4.3.1\n\n4.4\n\nLoss Function . . . . . . . . . . . . . . . . . . . . . . . . . . . 120\n\nFEA model descriptions . . . . . . . . . . . . . . . . . . . . . 128\n\nResults . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131\n4.4.1\n\nBoundary Distortion Study . . . . . . . . . . . . . . . . . . . 138\n\n4.4.2\n\nAdditional Issues with The Total Variation Loss . . . . . . . . 143\n\nSummary Findings . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\n\n5 Conclusion\n\n146\n\nviii\n\nCONTENTS\n\n5.1\n\nChapter 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147\n5.1.1\n\nChapter 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148\n\n5.1.2\n\nChapter 4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151\n\n5.2\n\nFuture Directions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152\n\n5.3\n\nConcluding Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . 152\n\nBibliography\n\n154\n\nVita\n\n179\n\nix\n\nList of Tables\n1.1\n1.2\n1.3\n\nCommon material mechanics length scales . . . . . . . . . . . . . . .\nComparison of Microscope Methods . . . . . . . . . . . . . . . . . . .\nList of Chapter Summaries . . . . . . . . . . . . . . . . . . . . . . . .\n\n8\n12\n19\n\n2.1\n2.2\n2.3\n\nApproximate Interaction Volumes For Various Metals . . . . . . . . .\nError Expressed in Percentiles . . . . . . . . . . . . . . . . . . . . . .\nFEM Errors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n39\n45\n67\n\n3.1\n\nComparison to ASTM 2627 . . . . . . . . . . . . . . . . . . . . . . . 106\n\n4.1\n4.2\n\nTable of Assigned Phase Material Properties . . . . . . . . . . . . . . 129\nLooking across multiple studies the down side press on material properties is significant. Data does not include and cropped images. . . . 135\nEffects of Cropping on Mean Property Values . . . . . . . . . . . . . 139\n\n4.3\n\nx\n\nList of Figures\n1.1\n\nVisional illustration of the difference between randomness (aleatoric\nuncertainty) vs the bias (epistemic uncertainty). This has a direct\nparallel to the difference between precision vs. accuracy . . . . . . . .\nCommon scientific workflow for modeling material behavior using the\nHall-Petch relationship . . . . . . . . . . . . . . . . . . . . . . . . . .\nTypical Characterization Imaging Ranges . . . . . . . . . . . . . . . .\nIllustration of SEM Interaction Volume . . . . . . . . . . . . . . . . .\nFramework workflow . . . . . . . . . . . . . . . . . . . . . . . . . . .\nApplied example of workflow . . . . . . . . . . . . . . . . . . . . . . .\nIllustration of Absolute Error . . . . . . . . . . . . . . . . . . . . . .\n\n6\n10\n13\n20\n21\n27\n\n2.1 Framework outline . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.2 Virtual Microstructure Illustration . . . . . . . . . . . . . . . . . . .\n2.3 Random Error Effects . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.4 Dwell Time Error . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.5 Illustration of Resampled Phantom . . . . . . . . . . . . . . . . . . .\n2.6 Mismatched Volume Error . . . . . . . . . . . . . . . . . . . . . . . .\n2.7 1D Analytical Function Example . . . . . . . . . . . . . . . . . . . .\n2.8 Effect of Sample Point Location . . . . . . . . . . . . . . . . . . . . .\n2.9 MMV - 1D vs 3D . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.10 MMV - Interaction Volume Effects . . . . . . . . . . . . . . . . . . .\n2.11 Data Processing Steps . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.12 Illustration of Bad Data Points . . . . . . . . . . . . . . . . . . . . .\n2.13 CDF After Data Porcessing . . . . . . . . . . . . . . . . . . . . . . .\n2.14 Framework Outline . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.15 FEM Set-up . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.16 FEM Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n2.17 FEM Meshes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n\n33\n35\n39\n40\n44\n47\n49\n50\n52\n55\n56\n58\n59\n63\n64\n65\n66\n\n3.1\n\n79\n\n1.2\n1.3\n1.4\n1.5\n1.6\n1.7\n\nSampling Grid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nxi\n\n3\n\nLIST OF FIGURES\n\n3.2\n3.3\n3.4\n3.5\n3.6\n\n1D Analytical Function Example . . . . . . . . . . . . . . . . . . . .\nProbability Density Function for Small Measured Sizes . . . . . . . .\nShape Seed Images . . . . . . . . . . . . . . . . . . . . . . . . . . . .\nHistograms of Perimeter Measurements . . . . . . . . . . . . . . . . .\nPrior Size Distributions . . . . . . . . . . . . . . . . . . . . . . . . . .\n(a) Prior distributions on size . . . . . . . . . . . . . . . . . . . . .\n(b) Conditional distribution of true size given measured size=100 .\n3.7 Prior Aspect Ratio Distributions . . . . . . . . . . . . . . . . . . . .\n(a) Prior distributions on aspect ratio . . . . . . . . . . . . . . . . .\n(b) Conditional distribution of true size given measured size=100 .\n3.8 Conditional Size Distribution . . . . . . . . . . . . . . . . . . . . . .\n3.9 Conditional Shape Distribution . . . . . . . . . . . . . . . . . . . . .\n3.10 Conditional Measurement Distribution Convergence . . . . . . . . . .\n3.11 Conditional Aspect Ratio Distribution . . . . . . . . . . . . . . . . .\n3.12 Comparison to ASTM 2627 . . . . . . . . . . . . . . . . . . . . . . .\n3.13 CMD Single Trials . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n(a) 75,000 Px dataset . . . . . . . . . . . . . . . . . . . . . . . . . .\n(b) 1,500,000 Px dataset . . . . . . . . . . . . . . . . . . . . . . . .\n3.14 CMD Dataset - Size Trials . . . . . . . . . . . . . . . . . . . . . . . .\n3.15 CMD Dataset - Aspect RatioTrials . . . . . . . . . . . . . . . . . . .\n3.16 Perimeter Measurements Detail . . . . . . . . . . . . . . . . . . . . .\n3.17 CMD Dataset - Perimeter Trials . . . . . . . . . . . . . . . . . . . . .\n3.18 Best Sampling Resolutions . . . . . . . . . . . . . . . . . . . . . . . .\n\n83\n86\n89\n93\n95\n95\n95\n96\n96\n96\n97\n98\n100\n101\n105\n107\n107\n107\n108\n110\n112\n113\n115\n\n4.1\n4.2\n4.3\n\n123\n125\n127\n127\n127\n128\n128\n128\n129\n130\n130\n130\n130\n132\n132\n132\n132\n133\n\n4.4\n\n4.5\n4.6\n\n4.7\n\n4.8\n\nHigh frequency checker boarding . . . . . . . . . . . . . . . . . . . . .\nPorous Material Image #1 . . . . . . . . . . . . . . . . . . . . . . .\nExample of Material Type #1 . . . . . . . . . . . . . . . . . . . . . .\n(a) Material 1 Slice . . . . . . . . . . . . . . . . . . . . . . . . . . .\n(b) Reconstructed Image . . . . . . . . . . . . . . . . . . . . . . . .\nExample of Material Type #2 . . . . . . . . . . . . . . . . . . . . . .\n(a) Material 2 Slice . . . . . . . . . . . . . . . . . . . . . . . . . . .\n(b) Reconstructed Image . . . . . . . . . . . . . . . . . . . . . . . .\nMaterial Property Convergence . . . . . . . . . . . . . . . . . . . . .\nPhantomDistributions . . . . . . . . . . . . . . . . . . . . . . . . . .\n(a) Elastic Modulus . . . . . . . . . . . . . . . . . . . . . . . . . . .\n(b) Effective Thermal Coefficient . . . . . . . . . . . . . . . . . . .\n(c) Volume Fraction . . . . . . . . . . . . . . . . . . . . . . . . . .\nProperties of Material 1 . . . . . . . . . . . . . . . . . . . . . . . . .\n(a) Volume Fraction . . . . . . . . . . . . . . . . . . . . . . . . . .\n(b) Elastic Modulus . . . . . . . . . . . . . . . . . . . . . . . . . . .\n(c) Effective Thermal Coefficient . . . . . . . . . . . . . . . . . . .\nProperties of Material 2 . . . . . . . . . . . . . . . . . . . . . . . . .\nxii\n\nLIST OF FIGURES\n\n(a) Volume Fraction . . . . . . . . . . . . . . . . . . . . . . . . . .\n(b) Elastic Modulus . . . . . . . . . . . . . . . . . . . . . . . . . . .\n(c) Effective Thermal Coefficient . . . . . . . . . . . . . . . . . . .\n4.9 Slice Convergence Rate . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.10 Volume Fraction Shift . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.11 Shift in Mechanical Properties . . . . . . . . . . . . . . . . . . . . . .\n4.12 Example of Preferential Bias . . . . . . . . . . . . . . . . . . . . . . .\n(a) Type #2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n(b) White Noise Image . . . . . . . . . . . . . . . . . . . . . . . . .\n4.13 Example of Preferential Bias #2 . . . . . . . . . . . . . . . . . . . . .\n(a) M1 - No crop . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n(b) M1 -Cropped . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n4.14 Cropping Image to Remove Boundary Effects . . . . . . . . . . . . .\n4.15 Comparison of Reconstructions - Volume Fraction . . . . . . . . . . .\n4.16 Shift in Mechanical Properties . . . . . . . . . . . . . . . . . . . . . .\n4.17 Effect of Total Variation . . . . . . . . . . . . . . . . . . . . . . . . .\n\nxiii\n\n133\n133\n133\n134\n136\n137\n138\n138\n138\n140\n140\n140\n141\n142\n143\n144\n\nChapter 1\nIntroduction\nIn 2011 President Obama introduced the Materials Genome Initiative, emphasizing the importance of better understanding of the vast materials space [1]. The\ninitiative is a recognition that while much is known about material behaviors, there is\nstill a lot that is unknown. It set goals to improve materials characterization education\nand training, decrease the development time for new materials, and establish material\ndatabases to share material information. To date it is unclear how much progress has\nbeen made on these goals, but there is some evidence that progress has been made\nto reduce material development timelines [2]. At the same time, despite a number of\nefforts to build material databases1 that compile characterization results [4–6], many\nof these are difficult to use and still provide a sparse data landscape [7].\nPart of the challenge in establishing such a database is the inherent complexity\n\n1\n\nA list of 32 unique material databases related to Material Genome Initiative are listed in [3]\n\n1\n\nCHAPTER 1. INTRODUCTION\n\nand stochastic nature of materials leading to uncertainty in materials performance,\nwhich is often a major source of uncertainty in engineering applications [8]. The desire to incorporate highly detailed material characterization data stems from the fact\nthat material failure is often associated with small scale features of the material, such\nas defects, inclusions or grains. By explicitly modeling and accounting for the uncertainty in materials data, then the associated uncertainty in engineering applications\ncan be better understood and addressed.\nThere are two types of uncertainty observed in materials: aleatoric uncertainty\nstemming from the natural variability of the material, and epistemic uncertainty originating from our lack of knowledge and/or ability to measure features of the material.\nThere are many papers and discussions about aleatoric vs. epistemic uncertainty\nwith various definitions (both formal and informal) [9–12]. Here we consider aleatoric\nuncertainty to be natural variability (randomness) and epistemic uncertainty to be a\nlack of knowledge (systemic bias). Figure 1.1 visualizes this difference.\nAleatoric and epistemic uncertainties should be propagated differently [13]. While\naleatoric uncertainty is typically random, epistemic uncertainty might be more deterministic, as is the case with modeling error. This presents a challenge, because\nrandom errors tend to have an averaging effect when combined through algebraic operations, whereas systematic errors tend to accumulate linearly (see Introduction to\nerror analysis, the study of uncertainties in physical measurements [14] for a formal\ntreatment). Accounting for this difference mathematically can be challenging and is\n\n2\n\nCHAPTER 1. INTRODUCTION\n\nFigure 1.1: Visional illustration of the difference between randomness (aleatoric uncertainty) vs the bias (epistemic uncertainty). This has a direct parallel to the difference\nbetween precision vs. accuracy\n\nthe subject of many different research papers [15–19].\nExperimental efforts to collect material data are often attempting to quantify the\naleatoric uncertainty; however, it can be difficult to distinguish between aleatoric\nand epistemic uncertainty in the experimental context [9, 20]. While the goal of the\nexperiment is to measure the variability of a given material characteristic, epistemic\nuncertainties arise in the measurement process. For example, the plethora of studies\n\n3\n\nCHAPTER 1. INTRODUCTION\n\nregarding the size of statistical representative volumes [21–25] indicate that, there is\nsome uncertainty about how much data needs to be collected. There are of course\nother forms of epistemic uncertainty, such as imaging resolution, sampling error, data\nprocessing bias, etc.\nMany current uncertainty quantification studies in materials research do not account for the differences between these two types of uncertainty. These include efforts\nin: crystal plasticity models [26], polymer-matrix composites [27], multi-scale modeling [28], crack growth [29] and additive manufacturing [30]. However, there are some\nworks which make this distinction [31–33]. Probabilistic effforts are directed towards\nthe mathematical treatment of uncertainty with an application in mechanics. Some\nexample applications include: plate buckling using small datasets [15], high temperature characterization of Al [34], and sparse stress-strain curve data [35]. There is an\ninterest in quantifying uncertainty and that interest has lead to significant advances\nin the incorporation of UQ into material characterization.\nA major challenge remains in identifying the sources of uncertainty in materials\ndata. Ingrained practices based on empirical approaches can make it difficult to see\nsuch sources. For example, to those who follow the reports that grain size distributions\nfollow a log-normal distribution [36–39], it can be difficult to see that the assumption\nof a log-normal distribution in and of itself constitutes a source of uncertainty, not\njust the parameters describing this distribution. Properly identifying the sources of\nuncertainty is critical to advancing material characterizations efforts [40]. This is\n\n4\n\nCHAPTER 1. INTRODUCTION\n\nsummarized nicely in a report from the U.S. Department of Energy in 2010:\n“UQ studies all sources of error and uncertainty, including the following: systematic and stochastic measurement error; ignorance; limitations\nof theoretical models; limitations of numerical representations of those\nmodels; limitations of the accuracy and reliability of computations, approximations, and algorithms; and human error. A more precise definition\nis UQ is the end-to-end study of the reliability of scientific inferences.” [41]\nThe emphasis on the “end-to-end” study implies that uncertainty quantification is\nas much concerned with relationships between pieces of information as it is with the\nmeasures themselves [40]. As such, characteristics like the relationship between the\nsources of error, the propagation of uncertainty, and the effect that it has on our final\ninferences are most important.\n\n1.1\n\nProblem Statement\n\nResearch on material performance spans from experimental data collection to\ntesting to computational models based on the data. Typically these activities are\nperformed by multiple researchers as the wide range of required skills creates a need\nfor specialization. Figure 1.2 shows an example of one such problem. It illustrates\na workflow where experimental data (a microstructural image of grains) is used to\ncompute a specific value (e.g., mean grain size) describing that material. One use for\nthis data might be to incorporate it into an analytical relationship, such as the HallPetch relationship relating yield stress and mean grain size [42,43]. Recent works have\nreported an approach that considers the entire grain size distribution, not just the\n5\n\nCHAPTER 1. INTRODUCTION\n\nFigure 1.2: Common scientific workflow for modeling material behavior using the\nHall-Petch relationship\n\nmean grain size, in the Hall-Petch relationship [44, 45]. Advances in computational\ncapabilities have enabled the parallel approach of using computational modeling to\nrepresent the material microstructure explicitly.\nThese findings illustrate a change in the materials characterization landscape. As\nrecently as 2007 it was reported that properties derived from individual grains were\nnot possible because of a lack of a full statistical description [46]. This research\ndocuments the need for a full grain size distribution in place of the mean grain size\nrepresents a shift towards incorporating data on the scale of individual grains. It also\nbrings with it many questions about the accuracy of this characterization, whether\nour capacity to collect statistically descriptive data has improved, and how to meet\nthe demands of modern material characterizations.\nUncertainty quantification is the perfect lens for examining the questions previ6\n\nCHAPTER 1. INTRODUCTION\n\nously posed. It attempts to answer quantitatively whether or not the incorporation\nof highly detailed material information will improve our inferences about the material\nperformance. This thesis will address how uncertainty quantification principles play\na role in answering questions related to material characterization. Specifically, it examines the systematic error that arises when characterizing material microstructures.\nAs part of that examination, the need to distinguish epistemic measurement error\nfrom natural material variability will become apparent. A framework for quantifying\nepistemic measurement uncertainties introduced during the materials characterization\nprocess is described and illustrated through several cases studies.\n\n1.2\n\nFundamentals, Applications, and Challenges of Material Characterization\n\nThere is a broad range of length scales, time scales, and environments under\nwhich materials are characterized. Table 1.1 contains a list of physical length scales\nand the associated fields of mechanics that study materials at that scale. While each\nof these fields is interconnected, their data collection needs do not necessarily align.\nFor example, plasticity in metals is caused by the nucleation and slip of dislocations\nacross specific crystallographic planes. Dislocation interactions with voids, inclusions,\nand grain boundaries determine structural properties such as strength and ductility\n[48]; however, from a practical standpoint, more structural information might be\n7\n\nCHAPTER 1. INTRODUCTION\n\nTable 1.1: Common material mechanics length scales. Table constructed from data\nin [47].\nUnit\n\nLength scale\n\nTimescale\n\nMechanics\n\nComplex structure\n\n101 m\n\n106 s\n\nStructural mechanics\n\nSimple structure\n\n100 m\n\n103 s\n\nFracture mechanics\n\nComponent\n\n10− 1 m\n\n100 s\n\nContinuum mechanics\n\nGrain microstructure\n\n10− 4 m\n\n10− 3 s\n\nCrystal plasticity\n\nDislocation microstructure\n\n10− 6 m\n\n10− 6 s\n\nMicromechanics\n\nSingle dislocation\n\n10− 7 m\n\n10− 9 s\n\nDislocation dynamics\n\nAtomic\n\n10− 9 m\n\n10− 12 s\n\nMolecular dynamics\n\n8\n\nCHAPTER 1. INTRODUCTION\n\ngained from a standard test for ductility [49] as opposed to high resolution imaging of\ndislocation densities using a Transmission Electron Microscope (TEM). Dislocation\ndensity does not easily indicate a lot of information about material ductility, because\nthe connection between these length scales is not fully understood (see section 1.2.3).\nIn addition to length scales, materials operate under many different environments\nthat alter their behavior. Temperature has a dramatic effect on the yield stress of\nAl [50], the plastic deformation of polymers [51], and strength of recrystallization\nof metals [52]. Oxidation has been shown to have an impact on the hardness of\nprotective coatings [53] and strength of concrete reinforcement [54].\nThe range and sheer number of tests required to characterize even a single material across all these domains is a major challenge. Ceramics, metals, polymers and\ncomposites all have very different characterization needs, and some methods and work\nflows are material specific, so that specialization is almost always required.\nThis work does not attempt a review of all materials characterization methods but\ninstead focuses on characterization methods that primarily collect data via imaging,\nincluding optical microscopes, scanning electron microscopes (SEM) and transmission\nelectron microscopes (TEM). Table 1.2 summarizes some differences between these\nmethods, and Figure 1.3 shows the relative length scale over which they typically\noperate. Recently, the work of one research team pushed TEM well beyond historical\nlimits by imaging a 1 mm3 volume over 6 months [56], utilizing a fully automated\nsystem that yielded a dataset of more than 2 petabytes. Other researchers have rein-\n\n9\n\nCHAPTER 1. INTRODUCTION\n\nFigure 1.3: Approximate resolution ranges of various imaging methods. Characterization needs are routinely pushing the limits of these methods. Future characterization\nneeds will look to sample larger volumes of materials [55].\n\n10\n\nCHAPTER 1. INTRODUCTION\n\nforced the message that collection of such information is expensive, time consuming,\nand data intensive [55, 57]. To set the stage for the specific workflows studied in this\nthesis, the next section provides a brief summary of the fundamentals of electron\nmicroscopy.\n\n1.2.1\n\nFundamentals of Electron Microscopy\n\nElectron microscopy is not just a single technique but a wide array of methods\nthat all share the commonality of using an electron beam. The electron beam is directed at a material sample, and the beam’s interaction with the material is recorded\non a detector. The placement of the detector and the type of interaction it records\nis primarily what distinguishes the various methods. In a TEM, the detector is\nplaced underneath the sample and an image is recorded from the electrons which\npass through the material. In a SEM, detectors are placed above and partially to the\nsides of the sample. They image either back-scattered electrons, which are incident\nelectrons that have been reflected off the sample, or secondary electrons, which are\nelectrons emitted from the material due to the excitation of the electron beam. Each\nof these techniques uses a different experimental setup from different instrument manufacturers and variable test settings, all of which generate uncertainty about exactly\nwhat they are measuring. A full review of these settings and the specific set up is not\nattempted here, but more information on electron microscopy can be found in either\nScanning Electron Microscopy and X-Ray Microanalysis [59] by Joseph Goldstein, et\n11\n\nCHAPTER 1. INTRODUCTION\n\nCharacteristics\n\nLight Microscope\n\nSEM\n\nTEM\n\nRadiation used\n\nVisible Light\n\nElectrons\n\nElectrons\n\nWavelength\n\n380-760 nm\n\n0.008 nm\n\n0.003 nm\n\nMagnification\n\n1,000x\n\n200,000x\n\n2,000,000x\n\nResolution\n\n200 nm\n\n1 nm\n\n0.1 nm\n\nImage formation\n\nLight\n\nfrom\n\nthe\n\nElectrons\n\nare\n\nElectron\n\nbeam\n\nsource is scattered\n\nscattered\n\nfrom\n\npasses\n\nthrough\n\nby the sample and\n\ninside the sample.\n\nthe sample and is\n\nredirected by the\n\nEmitted electrons\n\nfocused with EM\n\nobjective lens\n\nare collected and\n\nlens to form an\n\nprocessed through\n\nimage\n\ndetectors\nType of image\n\nReal image\n\nProcessed image\n\nReal image\n\nSample thickness\n\nThin, Bulk\n\nBulk\n\nThin\n\nFeature studied\n\nSurface\n\nSurface or subsur-\n\nMicrostructure\n\nface\nCapital cost\n\nLow\n\nHigh\n\nHigh\n\nInterpretation of\n\nEasy\n\nModerate\n\nDifficult\n\nimages\nTable 1.2: Comparison defining characteristics of the common microscopic methods\n[58].\n12\n\nCHAPTER 1. INTRODUCTION\n\nFigure 1.4: An illustration of an electron beam’s interaction with a material sample.\n\n13\n\nCHAPTER 1. INTRODUCTION\n\nal. or Electron Microscopy and Analysis [60] by Peter Goodhew, et al..\n\n1.2.2\n\nImage Processing Challenges\n\nAs most microstructural characterization methods incorporate imaging it can still\nbe difficult to interpret the true meaning of what is being observed. For example one\ncommon problem is size and shape measurements made when 3D objects are projected\ninto the 2D image plane. Some projected measurements can not directly be related\nto their 3D quantities, while others can. ASTM E-112 [61], the primary standard\nfor grain size measurements, recommend reporting grain sizes in a stereologically\nconsistent manner. However, many researchers report and prefer to use the circle\nequivalent diameter which is not directly to any 3D quantity.\nThe identification and classification of objects also poses a challenge. Materials\nscientists must make subjective determinations about an object’s classification when\ntheir measurements are ambiguous [62]. This is important in TEM in which many\nimage artifacts might be mistaken for genuine features. It is also important for\nstudies in which researchers have to identify a particular region of significance, such\nas fatigue crack initiation associated with particular local grain arrangements [63–65].\nA misidentified value can add a high level of uncertainty with significant consequences\nin such applications.\nA third image processing challenge relates to data clean up. For example, with\nelectron backscatter diffraction (EBSD) data sets it is common to have a significant\n14\n\nCHAPTER 1. INTRODUCTION\n\nnumber of bad data points, in which an orientation assignment could not be determined definitively from the collected diffraction pattern [66]. A number of methods\nexist to “fix” bad data points by assigning them their most probable orientation,\nsuch as Erode-Dilate operations [67]; however, such approaches have the disadvantage of removing small microstructure features that may be important to the material\nbehavior. The accuracy of such methods requires further evaluation.\n\n1.2.3\n\nApplication - Multiscale Modeling\n\nThe goal of multiscale modeling is to reduce empiricism and incorporate more of\nthe relevant physics, through the incorporation of material information over multiple\nlength scales. Despite the many advances in computations, solving finite element\nanalysis (FEA) models of structural geometries (∼ 101 m) at the granular (∼ 10−4\nm) resolution is still infeasible [68]. Multiscale modeling is a rapidly expanding solution to that problem. One field, Integrated Computational Materials Engineering\n(ICME), has rapidly adopted multiscale modeling for crystal plasticity [69], polymer [70], polymer-matrix composites [71], and laminated composite [72] applications,\nto name a few. These applications use a variety of methods to leverage microscale\nmaterial properties to better predict macroscale behaviors.\nMultiscale modeling is an information transfer problem [73]. As such, these models introduce uncertainties that exist at each scale, as well as uncertainties that are\nintroduced in the transfer between scales [47, 74, 75]. Yan Wang et al. provides an\n15\n\nCHAPTER 1. INTRODUCTION\n\nexcellent summary of the current state of multiscale modeling uncertainty quantification in Uncertainty quantification in multiscale materials modeling [76] highlighting\nmany of the different sources of model form (epistemic) uncertainty and measured\nparameter (aleatoric) uncertainty present in multiscale modeling.\n\n1.2.4\n\nMicrostructural Reconstructions\n\nA very useful tool for uncertainty quantification is the ability to generate microstructures that are statistically equivalent to experimentally obtained microstructures of a given material. Such digitally generated microstructures, or “reconstructions” promise the ability to analyze an ensemble of microstructures as a means of\nunderstanding the variability of the material behavior. Of course, this process in itself\nadds uncertainty, given discrepancies that may remain between the reconstructions\nand the target material. However, there are several advantages to these reconstructions that often outweigh these concerns.\nExperimental data is often expensive, time consuming and labor intensive to collect, so evaluating computational models based solely on experimental data sets is\noften prohibitive. Using reconstructions, model sensitivities and uncertainties can be\nevaluated, and a range of possible responses can be efficiently evaluated. Reconstructions can also enable augmentation of limited data. For example, this approach can\nbe used to generate a 3D microstructure from 2D image data [77–79]. Finally, reconstructions are very useful in multi-scale models, in which each material point can\n16\n\nCHAPTER 1. INTRODUCTION\n\nhave a distinct microstructure reconstruction as a way to account for local variability\nin material behavior [80], [81].\nThe process by which reconstructions are generated are heavily dependent on\nthe type of microstructure being considered. Algorithms for their generation are\ngenerally developed on a case by case basis with common methods being developed\nfor key microstructural types. One key class of reconstructions featured in this thesis\nare tessellation models. These tessellations can be used to simulate grain growth and\nare therefore most applicable to crystalline materials [82, 83]. The basic idea is to\nsimulate the process by which grains crystalize, by seeding a volume with initiation\nsites. These initiation sites are expanded until they intersect with one another and\nthe space is filled. Another new class of reconstruction methods are transfer learning\nmodels, which use computational neural networks to generate statistically equivalent\ncopies of microstructural images [84–86].\n\n1.3\n\nThe Computational Uncertainty Quantification Framework\n\nThe proposed method to quantify epistemic measurement error is a simulationbased uncertainty quantification (UQ) framework which can quantify measurement\nuncertainties in the context of materials that have inherent aleatoric random variabilities. The basic idea of the framework is to leverage virtual materials that have\n17\n\nCHAPTER 1. INTRODUCTION\n\nwell understood aleatoric variability and then use a Bayesian model to perform a\nparametric analysis of the characterization process.\nAn advantage of the simulation-based approach is that experimental methods\nare an inherently costly venture that is difficult to control. Physical experiments\nrequire expensive lab equipment and materials, taking days or weeks to perform.\nThe simulation-based approach requires the initial effort of setting up the model, but\nsubsequent iterations have a smaller cost that facilitates a parametric study.\nAnother advantage is that the simulation-based approach allows for greater control\nover the experiment. The natural variation of physical samples can mask other sources\nof error, and distinguishing parametric error from sampling error is often not possible\n[10]. In contrast, a virtual material can be defined by stochastic parameters, but each\ngenerated virtual sample represents a known instantiation. In other words, there is\nno ambiguity in the true value being measured, and any variation from that value is\nknown to be a parametric source of error.\nA final advantage is that for a materials workflow that includes bridging characterization to computational modeling, simulations allow the different sources of\nuncertainty to be accounted for. This means that the result of a parametric analysis\nof a specific experimental protocol can be propagated through the workflow to obtain\nan “end-to-end” significance.\nThe downside of a simulation-based approach is that we must develop a computational approach that represents the physical aspects of the materials workflow.\n\n18\n\nCHAPTER 1. INTRODUCTION\n\nTable 1.3: The framework problem statements used in thesis chapter examples.\n\nBecause the computational simulations are not necessarily a prefect proxy for physical\nactions, the uncertainties measured by this process are themselves estimates. However, there is a consistency across all virtual specimens being generated, characterized\nand modeled that suggests that the relative changes in error and uncertainty are still\nhighly informative. The purpose of this framework is not necessarily to evaluate the\nerror bounds on a specific data set, but instead to compare the relative magnitude of\nuncertainty under different scenarios and on different quantities. This allows a quantitative approach to deciding where best to place effort on further characterization.\nAs long as reasonable justifications for the simulation methods are provided, that\ncomparison should not be highly compromised.\n\n19\n\nCHAPTER 1. INTRODUCTION\n\nFigure 1.5: An outline of Uncertainty Quantification Framework Steps\n\n20\n\nCHAPTER 1. INTRODUCTION\n\nFigure 1.6: A Framework workflow as it is applied in chapter 2.\n\n21\n\nCHAPTER 1. INTRODUCTION\n\n1.3.1\n\nFramework Details\n\nThe workflow in figure 1.5 outlines the basic steps of the materials workflow studied\nin this thesis.The framework is best illustrated through examples. Table 1.3 contains\na summary of the broad questions and related applications that are evaluated in this\nthesis.\nTo add more context, Figure 1.6 shows a detailed framework workflow applied to\nthe characterizing 3D EBSD data.\n\n1.3.1.1\n\nTask 1 - Defining a Virtual Material\n\nThe virtual material is a randomly generate microstructure that is deemed to have\ncharacteristics very similar to the material of interest. For example, tessellation-based\nsimulations might be used for polycrystalline materials, while Poisson placement of\nspheres might be used for porous materials. Regardless of the form of this simulation,\nany stochastically simulated virtual material is represented as:\n\nV = F (X1 , X2 , ..., Xn )\n\n(1.1)\n\nwhere V is the virtual material, F is a reconstruction algorithm similar to those\ndescribed in section 1.2.4 and each Xi is a random variable input to that reconstruction algorithm. When a virtual material sample is needed F is evaluated using a set\nof specific inputs {x1 , x2 , ..., xn } where each xi is a sample taken from the random\nvariable Xi . The result is an array, where each material point Vijk contains a phase\n22\n\nCHAPTER 1. INTRODUCTION\n\nassignment and each phase assignment contains relevant material information, such\nas Euler angles or mechanical properties.\nFor example, F might be a Voronoi tessellation algorithm which divides a 3D\nvolume into grains and then assigns orientations to each grain. In such a case there\ncould be two random inputs: X1 might be a list of randomly selected seed coordinates\nfor the Voronoi tessellation and X2 a set of randomly selected samples taken from\na distribution of Euler angles. The function F expands each seed point into grains,\nleading to a volume in which each point is assigned to a grain which in turn has a\nrandomly selected Euler angle.\n\n1.3.1.2\n\nTask 2 - Modeling the Physical Workflow\n\nThe first task is to represent the given application’s characterization workflow. It\nis important to identify a sequence of actions that represents the steps researchers\ntake while characterizing data. Ultimately each step is represented in a computational\nfunction. These functions are combined to form a model of the entire characterization\nprocess (see Algorithm 1). It is critical that this process represents the characterization process accurately, but simplifying assumptions will also be necessary. As such,\nthe development of this list of actions and the subsequent effort to model them must\nbe well documented and justified.\nOf particular importance is the development of models for each physical characterization process. These models are specific to the problem. For example, many\n\n23\n\nCHAPTER 1. INTRODUCTION\n\nAlgorithm 1 Process Model, S(V, I{...}), for Materials Characterization\nRequirements List of workflow steps - {L1 , L2 , ..., LN }\nA model, si (), for each step Li\nInputs Virtual material sample - V\n\n. ln can be a null set\n\nWorkflow step inputs - I{l1 (Inputs), l2 (Inputs), ..., ln (Inputs)}\nProcedure\nV ∗ ← s1 (V, I{1}))\n\n. Evaluate workflow step 1 return updated V ∗\n\nfor i = 2, N do\nV ∗ ← si (V ∗ , I{i})\n\n. Performs an operation and returns new V ∗\n\nend for\nVs ←V∗\nReturn V s\n\n. A simulated dataset associated with the virtual material sample\n\n24\n\nCHAPTER 1. INTRODUCTION\n\naspects of SEM imaging have been studied in great detail, and modeling tools have\nbeen developed for key parts of the process. Just a few examples include: Monte\nCarlo simulations of electron scattering [87], analytical formulas for estimating interaction volumes [88], the generation of secondary electrons [89], and the generation of\nbackscattered diffraction images [90]. Fortunately, most modern data processing and\nmodeling operations already exist as computational workflows, so using such models\ndoes not require significant additional effort.\n\n1.3.1.3\n\nTask 3 - Conducting a Parametric Study\n\nTask 3 involves performing a parametric study of algorithm 1. To quantify the\neffect of characterization choices many evaluations of the characterization algorithm\nare performed, with different input parameters describing the characterization process\nand/or the underlying material are performed. Each evaluation provides a unique\nrepresentation of the data (V si ) describing the virtual material sample corresponding\nto a set of inputs (Ii {...}).\n\n1.3.1.4\n\nTask 4 - Quantifying Uncertainty\n\nThe last task is using the simulations in Task 3 to quantify the uncertainty associated with the particular materials characterization workflow. Algorithm 1 amounts\nto a function S() which acts on the virtual material sample V with a set of inputs Ii :\nV si = S(V, Ii )\n25\n\n(1.2)\n\nCHAPTER 1. INTRODUCTION\nwhere Ii is the set of simulation inputs values and V si is simulated representation of\nthe virtual material sample.\nThere are two main type types of error measurements we can make but both\ninvolve comparing the simulation results back to to the virtual material, which is\ntaken to be our ground-truth measurement:\n1)Absolute errors - This type of error can be visualized in figure 1.7, in the case\nof considering a feature size. Absolute errors are differences (between V and V s1 )\nin the spatial values of a given property.2 The result is an array of equal size which\ncontains absolute differences at each material point. A sum over all material points\nwould then give a measure of the absolute error as a single real number.\n\nAbsolute error = Ae =\n\ny\nx X\nz\nX\nX\ni\n\nj\n\ns1\nVijk\n− Vijk\n\n(1.3)\n\nk\n\n2) Measurement Errors - Measurement errors are differences (between V and\nV s1 ) after a measurement operation M () has been used to compute a specific quantify\nwhich is not defined explicitly in the characterization process.\nMeasurement Errors = Me = Mi (V s1 ) − Mi (V )\n\n(1.4)\n\nwhere Mi () is a measurement operation. Examples of such measurements might be\nthe grain size distribution or the mean grain size.\n2\n\nRecall that Vijk is a phase assignment and phases can contain multiple property assignments.\n\nAbsolute errors can therefor be computed as a mismatch in phase assignment or difference in value\nof a specific property.\n\n26\n\nCHAPTER 1. INTRODUCTION\n\nFigure 1.7: Example of the absolute error (shown in yellow) when an original shape\n(black), is imaged resulting in pixel assignments (blue) and a pixelized shape boundary\n(red). The absolute error is the total area of non overlapping space between the\noriginal shape and the pixelized representation.\n\n1.3.1.5\n\nFramework Summary\n\nThe UQ framework proposed in this thesis represents an approach to quantify the\nepistemic uncertainty associated with materials characterization. Understanding the\nrelative levels of uncertainty introduces as a result of characterization choices helps\nguide the process toward smarter and more optimized material characterization. As\npreviously stated, the next few chapters will document three different studies that\ndemonstrate this framework to address specific applications.\n\n27\n\nChapter 2\nA Framework Model for Electron\nBackscatter Diffraction\n\n2.1\n\nIntroduction\n\nAdvances in integrated computational materials engineering (ICME) are fundamentally dependent on acquisition of quality microstructural material information\nin three dimensions (3D). DeHoff emphasized the importance of characterizing microstructures in 3D in 1983, and since then a number of other authors have illustrated\nthe benefits of collecting detailed 3D microstructural datasets [91, 92]. This recognition has spurred the development of a whole suite of tools and methods for collecting\ndata across many different length scales [93], which in turn has led to the development of more integrated material property-structure relationships. While simplified\n\n28\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nmicrostructures are commonly applied to computational models [94], more recent advances in computational power and automated sectioning techniques have allowed\nthe ICME community to begin exploring property-structure relationships which were\npreviously unattainable. This has encouraged significant investment of equipment\nand time in collecting detailed 3D microstructures.\nOne example of this has been the development of focused ion beam (FIB) milling\nwithin a scanning electron microscope (SEM) for rapid collection of 3D electron backscatter diffraction (EBSD) data sets. Many papers have been published about the\ndevelopment and advantages of this technique [55, 95–100]. Uchic et al. highlighted\none of the main advantages of FIB-SEM as filling a critical length-scale gap between\nmechanical serial sectioning and electron tomography [55], and this technology has\nenabled the study of many fine and ultra-fine grained alloys. Materials scientists have\nbeen tasked with the challenge of using this improved resolution to evaluate materials\nthat have property-structure relationships that scale across several orders of magnitude. For example, Rene-88 DT has parent grain sizes on the order of 20-100μm but\nhas features that exist at smaller length scales, like annealing twins that are approximately 100nm-1μm thick and precipitate phases that are approximately 10nm-1μm\nin diameter. Previous work has shown that all of these features, as well as the overall\ngrain boundary networks play a role in crack initiation and propagation [101], meaning that microstructural data needs to be collected at 100nm-1μm resolutions across\n1mm length scales, pushing the limits of FIB and mechanical serial sectioning.\n\n29\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nAs research continues to advance this technology, there is a growing tendency\ntowards generating large data sets, without a full understanding of the associated\nlimitations. For example, high resolution data sets provide more detailed information\nabout small-scale features, but they may not capture a representative volume due to\nresource limitations. This trade-off must be reconciled in the context of the properties\none hopes to infer from the data set. In fact, a whole field of research has emerged\nstudying the effects of various properties as a function of the representative volume\nelement from which they are derived, with the ultimate goal of determining the minimum volume from which to collect data without bias. Early data collection efforts\nprovided rough guidelines such as collecting enough slices to encompass a volume\nat least twice the diameter of the largest grain [102], although more recent efforts\nhave suggested that larger volumes than this are needed. One common statistical\napproach is to compare the variance of apparent properties through a Monte Carlo\n(MC) simulation of increasing RVE sizes [80, 103] or stochastic characterization of\nresponse quantities [104].\nOther efforts have looked at how the spatial resolution should be selected to ensure good convergence of properties; with some suggesting a minimum of ten samples across a feature diameter is a reasonable resolution to resolve statistical properties [105]. A later study looked at the effect of voxel resolution on the accuracy of\nensemble statistics by systematic downsampling of a synthetic microstructure, suggesting different values for various types of desired statistics [106].\n\n30\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nIn other circumstances researchers have looked at ways to improve interpretation\nof the data, thereby reducing the overall experimental cost. For example, DeGraef et\nal. introduced a dictionary-based indexing of diffraction patterns, which reduces the\nnumber of unindexed or misindexed pixels resulting from the lack of clearly identifiable\nKikuchi Bands [107].\nIn summary, each of these efforts has tried to identify ways of optimally allocating\nresources to obtain the highest quality data sets. This can be recast as an effort\nto reduce the error in collecting data from a physical sample and building a digital\nreconstruction of the material. Any error introduced during the generation of these\ndigital reconstructions is propagated to the material model. Understanding the effects\nof this error will help in the effort to develop more accurate computational models.\nThroughout these studies, several authors have noted that estimation of the uncertainty of 3D microstructures has been under-developed and is key to implementing\nICME [106, 108]. This work aims to introduce a framework for which the error associated with a given choice of characterization parameters is evaluated. Ultimately,\nsuch a framework will enable identification of the optimal data collection and cleanup parameters for a given class of materials. The approach makes use of synthetically generated phantom microstructures, that represent ”ground truth” specimens.\nSection 2 describes the method for simulating the data collection process. Section\n3 evaluates the error in the resulting reconstructed microstructures, resulting from\nvariations in four sources of error: resolution, interaction volume, random noise, and\n\n31\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\ndata processing parameters. Section 4 addresses the effect of data collection errors\non the predictions from computational models developed from the associated reconstructed microstructure, specifically for linear elastic stresses. Section 5 provides some\nconclusions and thoughts on possible future work.\n\n2.2\n\nMethods\n\nThe overall framework for the current work is shown in Figure 2.1. A synthetic\nmicrostructure that is presumed to be reasonably representative of the material of\ninterest serves as the basis for the analysis, providing a phantom microstructure that\nis viewed as the ”ground truth.” The serial-sectioned EBSD data collection process is\nrepresented by simulations that capture the effects of noise, resolution and interaction\nvolume. The resulting data from this virtual collection process is cleaned up using\nstandard protocols in DREAM.3D [109]. A comparison between this virtually reconstructed microstructure and the phantom microstructure provides a number of possible measures of microstructural error, including volumetric mismatch or differences in\ngrain size distribution. Finally, the virtually reconstructed microstructure is meshed\nand modeled using ABAQUS [110], to predict elastic stress. Because the phantom\nmicrostructure can be modeled directly, there is a set of ”ground truth” results to\nwhich the virtually reconstructed results are compared. This provides a quantitative way to measure the error associated with different choices of data collection and\n\n32\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nFigure 2.1: A general work flow of the main stages of the framework. The three\nstages are highlighted starting with the generation of a synthetic material (green),\nmaterial data collection and processing modeling (blue), and model evaluation and\nerror computation (yellow).\n\nprocessing parameters on computational models associated with the microstructure.\nThis framework is meant to be general and can be adapted for a number of serial\nsectioning techniques and/or computational models of interest. Each of these steps\nis described in greater detail in the subsequent subsections.\n\n2.2.1\n\nStep 1: Synthetic Material Generation - Phantoms\n\nOne of the challenges associated with 3D serial sectioning techniques is the inherently destructive nature of the process. Reevaluation of the sample is impossible,\nwhich makes comparisons between measurement strategies difficult. This motivates\n\n33\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nour use of a virtual material which can be copied and resampled repeatedly [106]. This\nvirtual material, or phantom, should reasonably represent the true physical material\nof interest through statistical similarities of key microstructural properties, such as\nthe grain size, orientation distributions, neighbor distributions, etc. The intention is\nthat while the phantom may not be an exact instantiation of a physical material, its\nproperties are presumed to be similar enough that it can be assumed that parameter\nstudies based on the phantom will generalize to the material of interest.\nThe generation of synthetic volumes has seen many developments. A review of\nseveral possible techniques for polycrystalline materials can be found in [111]. For the\nexamples described in this work, phantoms are generated using a DREAM.3D [109]\nsynthetic microstructure generation pipeline. A simple example of this process can be\nfound in the DREAM.3D software tutorials. [112] Various phantoms were used but in\ngeneral phantoms featured on the order of 1000’s of grains and typically 5000 voxels\nper grain. Figure 2.2 is a visual representation of a typical phantom, with some basic\nstatistical information. Additional phantom microstructures of various types can also\nbe seen in Figure 2.6.\n\n2.2.2\n\nStep 2: Simulation of Data Collection\n\nTo model the serial sectioning data collection process, a simulation-based model is\nemployed. Some efforts have been made to model more specific aspects of the EBSD\nprocess [105–107]; however, these efforts focused primarily on a single aspect such\n34\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nFigure 2.2: An example of a typical equiaxed phantom generated using DREAM.3D.\nTypical grain sizes range between 103 -803 voxels.\n\n35\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nas simulating the diffraction pattern. In the current work, the efforts focus on the\neffects of resolution, sample size, interaction volume, and random noise. Of course,\nthe framework allows expansion to any number of data collection parameters.\n\n2.2.2.1\n\nResolution\n\nOne of the most important experimental determinations to be made is assessing\nwhere to collect data, and at what resolution. To model this, the EBSD simulation\nallows users to individually vary sample spacing in the x−, y− and z− directions. The\nsampling points are not limited to uniform spacing. A common example of this could\nbe randomly varying the slice thicknesses removed from the sample due to variations\nin the serial sectioning process, for example, as often observed in metallographic\npolishing.\n\n2.2.2.2\n\nInteraction Volume\n\nThe physics of EBSD is a complicated but well understood process [59]. In short,\nthe diffraction process occurs within a region of material in which electrons from an\nincident beam are forward scattered out of the sample, with some of these electrons\ncollected on a detector. The pattern of scattered electrons, comprised of what are\nknown as Kikuchi bands, is analyzed to assign a crystallographic orientation to the\ninterrogation point. It is important to note that the diffraction pattern represents a\nfinite volume of the material (known as the interaction volume), and it is not truly a\n\n36\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\npoint process. This interaction volume is related to the incident beam energy, which\nis one of the tuned parameters available to the user in serial-sectioned EBSD. One\ncommon method of approximating this interaction volume was proposed by Kanaya\nand Okayama in 1972. Their estimate of the interaction volume was given as the\nradius of a hemisphere centered on the beam impact point and can be modeled as:\nRko = 27.6(A/Z 0.89 ρ)Eo1.67\n\n(2.1)\n\nwhere A is the atomic weight, Z is the atomic number, ρ is the density and Eo is\nthe incident beam energy [88]. The Kanaya-Okayama model provides good estimates\nfor interaction volumes in pure metals exposed to a perpendicular electron source,\nthe results of which can be seen for various metals in Table 2.1. Because the current\nwork is attempting to present an overall framework that is not specific to a particular\nmaterial, the integration volume is left as a free parameter which defines the semiellipsoid over which the EBSD process operates. In simplifying the Kanaya-Okayama\nmodel we removed the inherent accounting of differing absorption properties of metals\nand replaced it with a single variable, the equivalent material radius. In reality,\nthe interaction volume is a semi-ellipsoid because of the angle of the incident beam\nrelative to the surface of the sample. For the purposes of the analysis performed here,\nhowever, an equivalent radius representing this semi-ellipsoidal interaction volume is\na reasonable representation. This equivalent material radius could be calibrated to\nreflect a specific material’s absorption properties but for the current work interaction\nvolumes were selected to be consistent with the ranges shown in Table 2.1.\n37\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\n2.2.2.3\n\nRandom Noise\n\nAnother parameter that affects the interpretation of EBSD data is the dwell time,\na key factor in the ability to correctly index an interrogation point through clearly\nidentifiable Kikuchi bands. During EBSD, data collection error can be group into\ntwo primary types: 1) geometric noise, which results from double diffraction near\ngrain boundaries or where too much surface damage or deformation has disrupted\nthe regular crystal structure, and 2) random noise, where indexing was not possible\ndue to poor diffraction patterns or pseudosymmetry, leading to misindexing [113].\nDifferent levels of random noise for one microstructure are illustrated in Figure 2.3,\nwhere the unindexed pixels are shown in black. The number of unindexed pixels can\nbe shown to be inversely related to the dwell time of the electron beam. Figure 2.4\nshows an estimate of the unindexed pixels as a function of dwell time, based on data\ncollected on a Tescan Vega SEM with Bruker eFlash 1000 EBSD detector at AFRL.\nBy fitting a curve to this data, a noise model was developed for the simulated EBSD\ndata collection process, where unindexed pixels are randomly generated. To reflect\na decrease in dwell time, increased random noise is included in the simulation (see\nFigure 2.3).\n\n2.2.2.4\n\nSummary of Data Collection Model\n\nThe primary goal of the EBSD model is to develop a computationally cheap\napproximation of the data collection process. By evaluating different combinations\n38\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nFigure 2.3: Effect of increasing random error on simulated microstructures. Pixels\nshown in black represent bad data points where no orientation assignment is made.\n\n5 KeV\n\n10 Kev\n\n20 KeV\n\n30 KeV\n\nC\n\n450nm\n\n1.4μm\n\n4.5μm\n\n8.9μm\n\nAl\n\n413nm\n\n1.3μm\n\n4.2μm\n\n8.2μm\n\nFe\n\n159nm\n\n505nm\n\n1.6μm\n\n3.2μm\n\nNi\n\n138nm\n\n438nm\n\n1.4μm\n\n2.7μm\n\nAu\n\n85nm\n\n270nm\n\n860nm\n\n1.7μm\n\nTable 2.1: The Kanaya-Okayama Equation evaluated for various metals. Typical\ninteraction volumes range from 80nm - 10μm [88]\n\n39\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nFigure 2.4: Data collected with various interrogation point dwell times, showing the\nnon-linear relationship between the ability to compute orientation data and the time\nspent collecting a diffraction pattern.\n\n40\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nof parameters, the process allows for both a general estimate of the magnitude of\nthe expected error and a quantitative means to evaluate the cost/benefits of different\nexperimental resource allocations. The detail to which the processes are analyzed\ncan easily be scaled through user inputs, by adding new modules, or fixing certain\nparameters which are of less interest. The relatively cheap approximation used here\nwere chosen to demonstrate the utility of modeling processes for error estimation, and\nto allow for the incorporation of many different parameters to be analyzed within a\nreasonable time frame. Nonetheless, the results presented in the following sections can\noffer some insights into important trends and will serve to demonstrate the potential\nof the framework.\n\n2.2.3\n\nAdditional Notes on Methodology\n\nOne goal in developing the framework was to create a simple tool which can help\ninform the choice of data collection parameters, even in an in situ manner. It provides\nan outline for analyzing how changes to the data collection and data processing of\nmicrostructural datasets, and to do so it was necessary to develop simple models\nrelying on several simplifying assumptions. However, additional capabilities or refined\nmodels can easily be implemented to meet the desires of the user. If users feel model\nassumptions may not generally hold for their specific application, models can easily be\ncalibrated and/or refined to more accurately model the process in any given system.\nFor example, the data collected as part of section 2.2.2.3 is instrument specific and\n41\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nusers might want to collect data to develop a model for their specific instrument setup.\nSimilarly, an improved physics-based model of the interaction volume (section 2.2.2.2)\nthat accounts for chemical compositions could also be implemented. Ultimately, the\nmodel framework was designed to allow for the variation of individual input variables.\nAs such, any doubt surrounding the effects of a certain quantitative input (ex. the\nsize interaction volume) can be studied through direct variation of said parameter.\nBy varying a parameter of interest over a range of reasonable values, and examining\nthe output, a sensitivity to said parameter can be developed. Model assumptions\nrelating to parameters with high sensitivity can then be refined as needed.\nAdditional, the framework is intended to be able to incorporate computational\nmodels in its evaluation of the error between true and measured microstructures. For\nthis a third step is added were the computational model is applied. An example of\nsuch evaluation is included as part of section 2.4.\n\n2.3\n\nIndividual Parameter Variation Examples\n\nOne benefit of the framework is that it is possible to quantitatively analyze the\neffect of various characterization parameters. This allows for the sensitivity to be\nquantified and compared for any parameter, allowing for a more detailed study of the\nevolution and propagation of error in the sample. In this section, several simulations of\n42\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nEBSD data collection are conducted over a range of typical values for the parameters\nof interest. Each simulation was analyzed and compared directly to the phantom,\nusing only the interior non-biased features. The exact size of the simulation and\nthe total number of features varied, but typically ∼1000 features were used for the\ndetermination of error, ensuring good statistical convergence. The results illustrate\nseveral key observations and demonstrate how the framework is useful in analyzing\ndifferent types of error.\n\n2.3.1\n\nStep 3: Error Measurements\n\nOne of the primary motivations of the proposed framework is the ability to explicitly compute various error metrics. Using the phantom microstructure as a baseline,\none measure of error is the percent of mismatched voxels (MMV) defined as:\n\nPl\nMMV =\n\ni=1\n\nPm Pn\nj=1\n\nk=1 P (i, j, k) 6= S(i, j, k)\n\nlmn\n\n(2.2)\n\nwhere, P , the phantom, and S, the simulation, are l × m × n matrices of general\nmicrostructural properties voxel such as crystal orientation or phase assignments.\nOther measures can address error in statistical quantities that describe features of\nthe microstructure, such as the grain size distribution:\npPn\nL2 =\n\n2\ni=1 [Pgs (xi ) − Sgs (xi )]\npPn\n2\ni=1 Pgs (xi )\n\n43\n\n(2.3)\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nFigure 2.5: Slice of (A) Phantom Microstructure and (B) Simulation sampled with\nnormalized resolution of 0.14.\n\nwhere Pgs (xi ) and Sgs (xi ) are the CDF’s of grain size xi for the phantom and simulation respectively, and n is the total number of grain sizes considered. Another\nmeasure of error is the number of lost features, which occurs when none of the voxels\nin the reconstructed microstructure are assigned the address associated with a feature\nin the phantom microstructure.\nAs an example, Table 2.2 shows the 3 measures of error resulting from a comparison between the phantom microstructure in Figure 2.5A and a simulated reconstruction of the microstructure in Figure 2.5B. In this table, the resulting errors are\nseparated into 4 different groups based on the percentile value associated with the\ngrain size. Because the smallest grains are the most poorly resolved, it is not surprising that these grains exhibit the most error, in terms of mismatched volume, grain\nsize distribution, and lost features.\n\n44\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nPercentile Range\n\nMMV\n\nL2 Grain Size\n\nLost Features\n\n0 − 25th\n\n13.62%\n\n0.054\n\n1\n\n25th − 50th\n\n1.12%\n\n0.015\n\n0\n\n50th − 75th\n\n0.58%\n\n0.010\n\n0\n\n75th − 100th\n\n0.53%\n\n0.0044\n\n0\n\nTotal\n\n5.02%\n\n0.034\n\n1\n\nTable 2.2: Changes in various error metrics across various percentiles, of grain size.\nMore error is found in the smallest 25% of grains, for all 3 error measures.\n\nMore complex error metrics can be defined such as the PDF of the grain aspect\nratio distribution. For most data sets the most appropriate error metric is typically\ndependent on the desired application. For data collection efforts seeking to identify unique sites within a microstructure might prefer a counting metric, such as the\nnumber of triple lines or quad points where three or more grains meet. In each case\nany desired error metric can be computed directly by examining the difference between phantom and simulation volumes. For microstructures collected to support\ncomputational models, the best error metric might be differences between the predicted response from the model based on the phantom and the model based on the\nsimulated microstructure, as will be described in Section 2.4.\n\n45\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\n2.3.2\n\nResolution\n\nOne of most important parameters in data collection is the resolution at which\ndata is collected. The resolution or spacing between interrogation points sets a minimum feature size threshold, which in practice should be larger than the spacing\nitself, in order to resolve that feature. The accuracy resolving shape, size, and feature boundaries is dependent on the resolution. Moreover, the appropriate resolution\nshould be determined relative to microstructural features of interest, and for this reason the current discussion normalizes resolution by the average feature size. Often a\nminimum of ten samples across a feature diameter is recommended to resolve statistical properties [105]. By varying the spacing of interrogation points, we can examine\nin more detail this rule of thumb and develop an estimate of the error associated with\nchanging resolution.\nFigure 2.6 shows the effect of varying resolution in a single coordinate direction\nfor various material types. This is analogous to varying the slice thickness during\nserial sectioning. In each simulation the in-plane resolution is one-to-one resampling\nof the phantom. In other words, the sample spacing in the 1D out-of-plane direction is the sole source of error. When averaged over a large number of phantoms\n(30) an approximately linear trend of increasing mismatched volume (MMV) with\nincreasing sample spacing is clearly present. Normalizing by the average feature size,\nthis trend can be generalized for various material types. In Figure 2.6 large (603\nvoxels), and small (153 voxels) equiaxed materials all show the same dependence on\n46\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nFigure 2.6: Plot of mismatched volume (MMV) vs. normalized 1D sample spacing,\nbased on simulations from various types of microstructures: A. Large grained equiaxed\nstructure, B. Fine grained equiaxed structure, C. Large grained equiaxed structure\nwith inserted twins, D. Composite with circular fiber inclusions, and E. Non-equiaxed\nstructure. Images of a single slice of each phantom are shown for comparison. Results\nfrom the 1D analytical model described in Section 2.3.2.1 are included for comparison.\n\n47\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nincreasing resolution along one direction. Considering the general rule of thumb of\nten samples across a feature diameter (0.1 normalized resolution), this translates to\nan estimated 2-3% error in the geometric volume. Other less equiaxed microstructure\ntypes showed similar linearly increasing trends, although with different slopes. This\ncan be attributed to the various length scales that exist within the microstructure,\nwhich may not be reflected through normalization by the average feature size. For example, in a composite microstructure (see Figure 2.6D) the mean fiber size is used as\nthe normalizing feature size; however, the distance to the nearest neighbor fibers can\nbe smaller than the fiber diameter. This would create a smaller relative length scale\nwhere sampling resolution is not sufficient to resolve matrix between fibers, leading\nto a larger error.\nThe general linear trend for various material types suggests that resolving resolution is geometrically dependent on an underlying length scale. To evaluate this, a\nsimplified analytical model is described in the next section.\n\n2.3.2.1\n\nAnalytical Model of Error Associated with Sample\nSpacing\n\nIn order to develop an analytical model based on sample spacing, we start by\nconsidering 1D samples of the microstructure. Specifically, consider the grain identification number (grain ID) along a line through the microstructure. The grain ID\nalong this line is represented by a piecewise constant function, where the value within\n48\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nFigure 2.7: Illustration of how a line slice of a phantom (A) could be represented as\na 1D piecewise function (B).\n\neach constant region is the identification number of the grain through which the line\ntravels (see Figure 2.7B). The measured grain ID along this line is a function of the\nsample spacing. If the sample spacing approaches zero, then the microstructure is\ncaptured exactly, although the required number of sample points becomes infinite. If\nthe sample spacing is very large, then there is significant misassignment of grain ID\nalong the line.\nThe analysis is further simplified by assuming that all grains are of equal length Lg .\nIf the sample spacing ∆x is equal to the grain size, then the fraction of mismatched\nvolume is derived following the illustrations in Figure 2.8. If the sample points happen\nto fall in the middle of the grains, then the microstructure is captured with zero\nmismatch (Figure 2.8A). At the other extreme, if the sample points happen to fall\non the grain boundaries (either just to the left or just to the right of the grain\nboundary), then there will be a 0.5 mismatch in the sampled microstructure (Figure\n49\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nFigure 2.8: Detailed view illustrating how the location of a sample point relative to\nthe feature will produce varying amounts of mismatched length. By integrating over\nall possible locations relative to the feature the expected mismatch length can be\ndetermined in 1D.\n\n50\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\n2.8B). If the sample points fall somewhere between the grain boundary and the grain\ncenter, then the mismatch will scale linearly with the distance from the grain center\n(Figure 2.8C). Therefore, the lineal fraction of mismatched grain ID is a function of\nthe sample location x∗ :\n\n|x∗ − Xgc |\nm(x ) = 0.5\nLg /2\n∗\n\n(2.4)\n\nwhere Xgc is the location of the nearest grain center to x∗ . Assuming that x∗ is a\nuniform random variable on the interval [−Lg /2, Lg /2], then the average fraction of\nthe line with mismatched grain ID (M M L) is derived as:\n\nZ\n0.5 Lg /2 |x∗ − Xgc | ∗\ndx = 0.25\nMML =\nLg −Lg /2 Lg /2\n\n(2.5)\n\nThe mismatch is zero when sample spacing ∆x = 0, which corresponds to exact\nresolution. Assuming that the mismatch scales linearly with the sample spacing,\nthen a reasonable approximation to the probability of mismatch is therefore:\n\nPm = 0.25\n\n∆x\nLg\n\n(2.6)\n\nwhere Lg is the average grain size and ∆x is the sample spacing. Noting that this 1D\nmodel of MML is the equivalent to a 3D model of MMV if we assume full resolution\nin the other two dimensions, these results are compared to the MMV that is obtained\nwhen performing 1D sampling from lines extracted from the microstructures in Figure\n2.6. This figure shows that the results from this simple 1D analytical approximation\n51\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nFigure 2.9: Mismatched volume (MMV) vs normalized sample spacing based on oneand three-dimensional sampling, from both the simulations and from the analytical\nmodels. The simulated values were obtained from an equiaxed microstructure. The\n1D model predicts a slope of 0.25 while the simulated values are 0.266. The 3D\nmodel predicts a less linear function than that found from the simulated values, but\nthe values from both compare reasonably well.\n\nare a good match to those from the simulations for equiaxed microstructures, though\nit is not as good an approximation for twinned, non-equiaxed and composite microstructures.\nAssuming finite sampling occurs in only one coordinate direction is not physically\nrealistic, since infinite sampling in the other two directions is infeasible. The analytical model is therefore extended to consider the effect of sample spacing in all three\ncoordinate directions in a 3D microstructure. This is enabled by assuming that the\n\n52\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nprobability of a correctly assigned grain ID is independent in all three directions. In\nother words, the grain ID at a point is only matched correctly if there is no mismatch\ndue to sample spacing in any of the 3 coordinate directions. Therefore, the probability p3 of a correctly matched value at a given 3D location is the cubed probability of\na correctly matched grain ID at a 1D location:\n\n\u00133\n\u0012\n∆x\np3 = 1 − 0.25\nLg\n\n(2.7)\n\nThe probability of an incorrectly matched grain ID at a 3D location (or the mismatched volume M M V ) is simply the complement of p3 :\n\n∆x\nM M V = 1 − p3 = 0.75\n− 0.1875\nLg\n\n\u0012\n\n∆x\nLg\n\n\u00132\n\n\u0012\n+ .015625\n\n∆x\nLg\n\n\u00133\n(2.8)\n\nFigure 2.9 shows a comparison between this approximation and simulated mismatched\nvolume, indicating reasonable agreement. While the analytical model is based on a\nnumber of assumptions, it provides a useful approximation that can be applied to\ndetermine a reasonable resolution without undergoing lengthy simulations.\n\n2.3.3\n\nInteraction Volume\n\nAs discussed in Section 2.2, changing the size of the interaction volume (IV) in\nthe simulation is a representation of changing beam energy. More realistic predictions\nof the relationship between interaction volume and beam engery in a specific SEM\n\n53\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nconfiguration for a given material requires calibration, or the use of simplified models\nsuch as Equation 2.1. The example shown here serves only to illustrate how relative\nincreases or decreases in interaction volume affect error.\nAs was done in the resolution study, the size of the interaction volume is normalized by the average feature size. Figure 2.10 shows the mismatched volume MMV\nas a function of the normalized interaction volume, with zero resolution error. It is\nworth mentioning that for large features (¿10μm) interaction volumes on the order of\n10-25% are infeasible in modern SEM; however for small features they are certainly\npossible. The MMV values for the smaller values of normalized interaction volume\nare lower than the typical MMV values associated with typical sampling resolution,\nsuggesting that the error due to interaction volume may be lower than that due to\nresolution in many situations.\n\n2.3.4\n\nUnindexed Pixels\n\nDuring EBSD data collection it is common that some interrogation points will\nreturn diffraction patterns that are unable to be indexed to the local crystal orientation. These points become unindexed pixels or ”bad data” which often needs to be\naccounted for after data collection is completed. As described in Section 2.2.2.3 the\nprimary way that these unindexed pixels enter our model is through the assignment\nof a dwell time which produces a corresponding level of random noise. A second\nmeans by which unindexed pixels can be accounted for is through the assignment\n54\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nFigure 2.10: Mismatched volume (MMV) as a function of the interaction volume\nnormalized by the average feature size, assuming that sample spacing ∼ 0 so that\nresolution error is zero.\n\nof a threshold to the interaction volume (i.e., if a certain percentage of the interaction volume is not dominated by a single grain, an unindexed pixel is assigned). As\nboth of these methods are dependent on user input, quantifying the resulting error\nis trivial. For example, an assigned dwell time associated with 10% noise, produces\n10% mismatched volume. However, the incorporation of unindexed pixels into the\nsimulation is very important, since this supports a study of how well these pixels are\ncorrected during the data processing step.\n\n55\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nFigure 2.11: Details of how data processing error εdp is categorized. Erode/Dilate is a\ndata cleaning process where by small noisy elements are shrunk in size and then filled\nin by their nearest neighbor elements. Items 1-3 are some of the parameters which\ncan be used to define the process, and are provided as examples for what parameters\ncould be changed.\n\n56\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\n2.3.5\n\nData Processing Parameters\n\nData processing algorithms come in many forms. There are algorithms for addressing known errors in the collected data set, e.g., assigning values to unindexed\ninterrogation points, and those which transform or alter the data to be used in other\nways, e.g. creating a meshing for finite element analysis (FEM). Depending on the\ndata, and its desired use, different algorithms may be applied, with each algorithm\npotentially having many of its own parameters. Figure 2.11 highlights some details\nin the data processing section of the outlined framework (see Figure 2.1), focusing on\none common post processing technique known as erode/dilate, which is used to assign\nvalues to missing or incorrectly assigned points in the data set. In the context of the\nframework for analyzing errors introduced though data processing, each algorithm\nand its parameters are varied and individually applied to simulated data sets. The\nreconstructed data sets are then compared in order to determine which algorithms\nand parameter combinations are most effective in correcting data collection errors.\nThe erode/dilate filters can effectively remove unindexed pixels and spurious data\npoints. Classical versions of these filters typically work by first eroding feature surfaces, effectively creating an unassigned property region between features, and then\ndilating features to fill these regions with data assignments from the closest feature to\neach voxel. DREAM.3D offers an Erode/Dilate filter that essentially does the reverse,\nfirst dilating the bad data and then eroding the bad data through feature assignment\n(For details see [112]). The effect is that features smaller than the half erosion length,\n57\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nFigure 2.12: A partial slice of an equiaxed phantom simulated with 7% random noise,\n(A) before and (B) after the DREAM.3D Erode/Dilate filter was applied. Each black\npixel represents a data point where an orientation assignment could not be made.\nEach of these points has been ”cleaned” by the filter, resulting in a reduction of the\nmismatched volume, from 7.1% to 0.3%.\n\nsuch as those resulting from a single bad data point, vanish and are replaced with the\nassignment of their surrounding feature (see Figure 2.12).\nFor data with less than 10% noise that is evenly distributed over the volume, nearly\nall noise can be removed by erode/dilate filters. However, in certain microstructures\nwith small or highly asymmetric features and/or with noise more prevalent in local\nregions such as grain boundaries, erode/dilate filters can introduce more error. Figure\n2.13 shows results from two different simulations where 7% noise was added to an\nequiaxed and twinned microstructure. An isotropic erode/dilate filter was applied\n\n58\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nFigure 2.13: Comparison of the cumulative distribution function (CDF) of feature\nsize, before and after 7% random noise was cleaned from an equiaxed and a twinned\nmicrostructure, using erode/dilate filters.\n\nto assign orientations to the unindexed pixels. The result was that for the equiaxed\nmicrostructure (largely isotropic) almost no noticeable error in the grain size distribution was observed, while the twinned microstructure (strongly anisotropic) had\nmany of its small plate like features removed, altering the feature size distribution\nsignificantly. This resulted in a total MMV for the twinned microstructure of 7.2%,\nwhich is significantly higher than the MMV of 0.3% for the equiaxed microstructure.\nThese results demonstrate how the erode/dilate filters can introduce error, despite being effective in removing random noise. Application of the filter was able\nto reduce noise error although a biasing towards parent grains was observed during\nreassignment.\n\n59\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\n2.3.6\n\nBrief Discussion on Data Collection and Processing Error\n\nThe selection of experimental parameters is important to data collection, and the\nability to study the individual effects of varying parameters will undoubtedly prove\nuseful. The observation of linear dependence of mismatched volume on resolution is\nuseful for estimating expected errors or biases. Furthermore, the application of data\nprocessing filters, which is highly dependent on the needs of a collected data set, can\nhave both positive and negative effects. The ability to quantify the application of\ndifferent filters to compare their outputs to an expected norm will prove useful for\nanalyzing which filters to use and where new filters need to be developed.\nWhile examining the relative effects and magnitudes of individual parameters is\nof interest, some of these conclusions can be trivial and misleading without the context of the data collection process as a whole. Changing a data collection parameter\nto address one source of error may require different choices of other data collection\nparameters that lead to new sources of error. For example, electron beam energy is\nindirectly related to the dwell time, as the overall strength of a diffraction pattern\nis related to both. The electron beam energy can be reduced in order to reduce the\ninteraction volume, which would decrease the error that arises from potential ambiguity in the diffraction pattern associated with a finite sampling volume. However,\nif the dwell time is not increased, then this would result in a decrease in the overall\n\n60\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nstrength of the output signal, which will diminish the quality of the diffraction patterns. If there are resource limitations that limit the total characterization time, then\nthe choice to increase dwell time would have to be offset by a decreased number of\ninterrogation points. This could be achieved by decreasing resolution or decreasing\nsample size, both of which can increase error. Given typical constraints on instrumentation time, this interaction illustrates the balance and trade-offs that must be\nmade during the data collection process.\n\n2.4\n\nCase Study: Application to Finite Element Model\n\nTo this point the work has focused on purely geometric measures of the error of\nthe simulated microstructure compared to the ground truth phantom. While this\nform of error is important, it might not fully reflect how these reconstructions are\nultimately used. In practice these reconstructions are often used to inform computational models, either as direct inputs or through the extraction of key statistics. To\nanalyze this interaction requires extending the analysis to apply the microstructural\ndata to a computational model. The extension is relatively straightforward, because\ndata processing tools such as DREAM.3D that perform meshing allow direct modeling of the simulated microstructures. This addition allows computational models\nto serve as the context for measuring error. Given that the results from computa61\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\ntional models are the primary outcome, evaluating their sensitivity to microstructural\ndataset inputs and subsequently the data collection processes used to collect them is\nclearly of interest. This is shown in this section through an example case study.\nTo illustrate how the proposed framework can help in determining the error associated with resolution, a simple example was performed. An outline of the compuational framework in shown in figure 2.14. For this example a 500x500x500 voxel\nequiaxed phantom encompassing ∼1500 interior grains, with an average grain diameter of 18.2 voxels, was generated using DREAM.3D. Data collection was then\nperformed at various interrogation point spacings, over various volumes, and with\ndifferent levels of noise. A pictorial representation of the problem is shown in Figure\n2.15. Each simulated microstructure and the larger phantom were meshed using standard DREAM.3D filters and exported as ABAQUS input files. Individual grains were\nassigned elastic material properties based on their crystallographic orientation. The\naverage von Mises stress in each interior grain at a global strain of 2% was evaluated.\nThe error in this average grain stress between the phantom microstructure and the\nsimulated microstructure was then averaged across all interior grains. Results are\nshown in Figure 2.16 for various normalized sample sizes and resolutions.\nFigure 2.16 shows a greater dependence of the mean average stress on the total\nnumber of grains resolved (i.e. sample size). In small samples, boundary conditions\ndominate the grain-averaged stresses. For this reason, increasing the total number of\ninterrogation points without also increasing the volume over which they were placed\n\n62\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nFigure 2.14: Outline of the computational framework for error evaluation. The total\nnumber of parameters to be evaluated is left open, as well as the inclusion/choice of\ncomputational model.\n\n63\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nFigure 2.15: An illustration of data collection over at different resolutions. (A) shows\nwide interrogation point spacing over a large volume, (B) shows the same number of\ninterrogation points with a narrower spacing over the same area of (C), the phantom.\n\n64\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nFigure 2.16: Percentage of error in grain-averaged elastic von Mises stress as a function\nof the volume of the sample (Vs ) normalized by the average grain size (Vg ). Various\nsimulations on a single phantom highlighted the importance of selecting a sufficient\nsample size in reducing error.\n\n65\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nFigure 2.17: 2D projections of two meshes based on 729,000 interrogation points,\ncollected across a sample of 8 full grains across the face (Blue) and across a sample\nof 4 full grains across the face (Red). Even though smaller mesh is better resolved,\nthe resulting meshes are very similar.\n\n66\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nSample Size 1 - 4.4 Grains\nLevel of random noise\n\nSample Size 2 - 8.1 Grains\n\nTotal error after simulation\n\n3 percent\n\n4.181%\n\n1.384%\n\n5 percent\n\n4.182%\n\n1.384%\n\n15 percent\n\n4.185%\n\n1.389%\n\nTable 2.3: Results for variation of random noise levels(associated with dwell time).\nChanges in the level of random noise had negligible effect on total error compared to\nthe sample size.\n\ndoes not result in any significant improvement in the error. Similarly, increased or\ndecreased dwell times (as reflected by random noise) had no meaningful effect on\ncomputed error (see Table 2.3).\nThere are several arguments for these findings. First, the Laplacian smoothing\napplied to the mesh in DREAM.3D resulted in a partial correction of the error introduced through limited resolution. Second, Figure 2.17 shows a 2D projection of\nnodes from the 3D mesh. The lower resolution mesh (shown in blue), has minimal\ndifferences within the region of overlap from the high resolution mesh (shown in red);\nmeaning that within this region both simulations had similar representation of the\nvolume. Third, the effectiveness of the data clean-up algorithms in removing bad\ndata points where orientation could not be assigned, neutralized the effects of random noise. This was possible in part because of the equiaxed nature of the phantom\n\n67\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nand may not be true for other microstructure types . Finally, the choice of a linear\nelastic model leads to minimal localizations and other behaviors that would increase\nthe sensitivity of the computational model to local microstructural features such as\ngrain boundary geometry.\n\n2.4.1\n\nConclusions from the Case Study\n\nSeveral conclusions can be drawn from this case study. First, the potential for\noversampling can be mitigated. While it’s not universally true, in this case little is\ngained by Herculean efforts to collect highly resolved data. As shown, collecting data\nat over 10x the number of interrogation points did not ultimately have any meaningful\neffect on the error in the mean grain stress. Second, proper data processing can be\nvery effective at reducing errors introduced during data collection. Finally, the size\nof the sample has a strong influence on the predicted elastic stresses.\nThe mean elastic stress of interior grains is a relatively simple measure from the\ncomputational model, and it is highly insensitive to the details of the microstructure.\nWhile other measures could be used in future studies, this averaged elastic stress\nserves as a reasonable baseline measure. For example, a failure to represent the mean\nelastic stress values would lead to decreased accuracy for more complicated models\nof inelastic behavior.\nThese conclusions may not hold for different microstructural data collection efforts, but they are an example of how a priori analysis of the data collection process\n68\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nas a whole can inform data collection efforts. Using the results of this study, efficient\ndata collection parameters such as a large sample volume, short dwell times and wide\nresolution spacing could be selected, resulting in a more efficient use of experimental\nresources. Given the relatively low cost in terms of computational effort and physical time that such an analysis requires, there are certainly gains to be made in the\nefficiency and accuracy of microstructural data set collection.\n\n2.5\n\nConclusions\n\nGrowth in the capabilities to collect 3D microstructural data and apply this information to computational models has been a key research focus, but quantitative\nanalysis of error propagation to the models from data collection has lagged behind.\nThe proposed framework based on a phantom microstructure provides a means for\nanalyzing the error associated with individual data collection and data processing\nparameters all the way through to computational models. The approach can easily\nintroduce new modules and/or additional complexity as needed.\nWe show how the framework can provide detailed insight into the influence of data\ncollection parameters, such as resolution, electron beam energy, and dwell time. The\nresolution study showed that increasing sample point spacing results in an approximately linear increase in mismatched volume, and an analytical model was developed\nthat provides basic insights into this behavior. Additional studies showed how changes\n\n69\n\nCHAPTER 2. EBSD FRAMEWORK MODEL\n\nto the interaction volume (i.e. electron beam energy) or increased levels of random\nnoise (i.e. shorter dwell times) also affect error. It was also demonstrated that through\nproper data processing parameters much of this error can be mitigated; however, an\nimproperly applied erode/dilate data processing filter can increase error for certain\nmicrostructural types. Finally, an example was provided in which the framework was\nused to analyze the propagation of error from characterization through to a simple\nfinite element model based on the characterized microstructure. For the particular\nstudy here, it was shown that sample size was more critical to accurate evaluation of\nmean elastic stress in each grain than either resolution or integration volume. Such\nconclusions provide input as to the most efficient data collection parameters that will\nlead to accurate results from the associated computational models.\nA natural extension of the framework presented here will be more formal optimization of data collection parameters, balancing cost and accuracy. Defining an\nobjective function based on costs, subject to the constraints of acceptable error levels, such an optimization is feasible. Furthermore, the framework can be extended\nto more detailed physically-based characterization parameters and/or to more challenging computational models, such as those that attempt to predict the onset and\ngrowth of fatigue cracks.\n\n70\n\nChapter 3\nThe Conditional Measurement\nDistribution\nAdvanced material modeling is increasingly reliant on material property distributions in place of averaged properties. Models that account for spatial differences\nin material properties have led to advancements in the plastic deformation of polycrystalline materials [25, 114], multi-scale modeling [115], and microstructure reconstruction [82]. However, the inclusion of heterogenous material properties comes with\nsignificant challenges. Often advanced imaging with high resolution optical microscopes or scanning electron microscopes (SEM) are required to resolve the material\nmicrostructure. These data acquisition techniques require specialized equipment and\ncarry a significant experimental cost. In addition, resolution of material property distributions requires large volumes of the material to be imaged, which are significantly\n\n71\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nlarger than those needed to find only averaged quantities.\nThe inverse relationship between the volume of material which can be reasonably\nbe sampled and the resolution at which the data is collected further complicated this\nproblem [55]. It is understood that collecting data at a lower resolution will result\nin increased epistemic error, but a detailed evaluation of the tradeoff between the\nincreased epistemic error and the reduced sampling error isn’t found to date in the\nliterature. Currently, the best practice is to use measurement standards published\nby one of the international measurement societies to select an appropriate resolution\nand attempt to collect as much data as possible.\nThe basis for most microstructural experiments on polycrystalline materials are\nstandards for the measurement of the grain size. Beginning in 1955 the American\nSociety for Testing and Materials (ASTM) introduced standards for the measurement\nof grain size using a light optical microscope. The original technique works well\nonly if grain boundaries can be easily delineated by etching [116]. As such ASTME112 [61] has been updated several times as methods and technological limits have\nprogressed and still serves as a primary reference for measuring grain boundaries\nusing etching. One of the technological innovations includes the adoption of Electron\nBack-scatter Diffraction (EBSD) for determining grain size. EBSD can more clearly\nidentify grains boundaries using their orientation. This leads to the introduction\nof ASTM-E2627 [117] in 2013, which outlines how to use EBSD to determine the\naverage grain size. For consistency it still reports the final grain size in terms of\n\n72\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nan ASTM grain size number, G, which is defined in E112 based on the number of\ngrains/square inch. The ASTM grain size number is used because of its simplicity\nin reporting the number of grains per unit area. However, due to its lack of an\nintuition many researchers have begun adopting the other methods of reporting grain\nsize, such as the circle equivalent diameter [105, 118, 119]. As such ISO 13067 [120],\nthe International Organization for Standardization (ISO) equivalent of ASTM-E2627,\nincorporates a formula to compute the circle equivalent diameter measure directly into\nits standard. There are several key differences between these standards, aside from\nthe means of reporting grain size. Most notable is the significant difference between\nthe average grain size resolution. E2627 recommends an average grain resolution\nof 500 px while ISO 13067 recommends at least a 10 px lineal intercept across the\naverage grain, or approx. 80-100 px per grain. There is no clear explanation in the\nliterature as to the reasoning for this large difference. A NIST study of the ISO 13067\nstandard revealed that this less conservative bound still produced a repeatably reliable\nmeasurement [121]. Additional details of the difference between the two standards\nare discussed in Coutinho, al et. [45], but there appears to be no clear reconciliation\nof the differences and quantitative merits of the two standards.\nThe primary motivation of this chapter is to investigate microstructural measurements errors associated with the resolution at which the measurements are collected.\nDoing so will provide researchers with a much needed tool to (1) report microstructural property distributions in place of mean values, (2) report measurement error\n\n73\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nfor various metrics, and (3) assess the best ways to go about collecting microstructural data and making key measurements of crystalline materials. Currently the best\npractices for these areas are lacking in several key aspects.\nFirst, many current methods focus on the computation of mean values in place of\na property distribution. This can be attributed to historical preference, as reporting a\ndistribution of the grain size (or any other measurement) can be difficult and leads to\nmore data being stored and understood. All this said, material property distributions\nare increasing being recognized for their importance. One paper reported that using\na distribution of grain size in place of the mean resulted in a 4% difference in the\ncomputed yield strength while using the Hall-Petch relation [45]. Other authors have\nnoted that variation in the grain size distributions lead to material heterogeneity,\nand evaluating the tails of the distribution are important to a full understanding [44].\nA National Physics Laboratory report also used the grain size distribution in their\nevaluation of the reproducibility of EBSD grain size measurements [122].\nSecond, there are few to no standards for other measurement metrics. Imaged data\nis routinely used for measurement of aspect ratio, shape characteristics such as circularity and perimeter measurements, and connectivity [123–125]. These measurements\nare increasingly being used to enhance understanding of the material morphology,\nwith several works using them to fit key model parameters [80,123]. Significant effort\nhas gone into developing methods to accurately measure these quantities. For example\nnumerous techniques exist for estimating the perimeter of pixel objects [126–128], yet\n\n74\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nno clear method is universally applicable. It appears to be common practice to either\nuse the standards for grain size to resolve the data set for these other measurements,\nor alternatively to resolve the microstructure to the best available resolution based\non experimental limitations, and then assume the resolution is sufficient for these\nmeasurements. This practice often expends unnecessary experimental resources in\nhopes of obtaining highly accurate data, rather than using uncertainty quantification\n(UQ) tools to evaluate what resolution is actually needed for a specific application.\nThird, there is no clear understanding of how to process data which does not fully\nmeet established standards. It is unclear what a user might do with a data set which\ndoesn’t meet the ASTM-E2627 average feature size standard of 500 px. Discarding\nand recollecting new data is wasteful and ultimately might be infeasible. One field in\nwhich this issue is already proving to be of importance is metal additive manufacturing\n(AM). It has been reported that high throughput and in situ characterization is\na key component of linking processing parameters to material properties need for\nmetal AM [129, 130]. High throughput or in situ monitoring applications in which\nmicrostructural data is collected for hundreds or thousands of samples will require\nfast processing, and a 500 px average feature sizes may not be feasible. Collecting\nthis data under the requirements of ASTM-E2627 would be very challenging on an\nindustry wide scale [131].\nThis chapter seeks to address these pitfalls by developing a method whereby the\nuncertainty of a measurement can be estimated using a numerical simulation of the\n\n75\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nimaging process of crystalline materials. This is achieved by establishing a conditional\ndistribution on the measured quantity given a set of simulated virtual microstructures\nand computational models of the characterization process. This conditional distribution is then applied into a Bayesian construct to determine the distribution of possible\ntrue values associated with a given measured value. This method is applicable to not\nonly grain size measurements but any measurement which can be made on segmented\nmicrostructural images, providing a valuable tool for standardizing error evaluation\nfor these measurements. Furthermore, it leads to a simple construction of full property distributions without the use of histograms or distribution fitting algorithms.\nFinally, it provides estimates for the measurement error for objects as small as 5 px,\nremoving much of the ambiguity of lower resolution data sets.\nA basic analytical model for this method, showing the variation in area measurement for rectangular objects, is developed in section 3.2.1. This model is then\nexpanded to incorporate more general grain and object structures in section 3.1. Finally, in addition to grain size measurements detailed examples of the model being\napplied to aspect ratio and perimeter measurement are presented in section 3.2.4.\n\n76\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\n3.1\n\nDerivation of conditional probability\n\n3.1.1\n\nDistributions of material characteristics\n\nWe begin by defining S as a random geometric feature that is observed as a\ndiscrete object during characterization. Examples from materials characterization\ninclude grains, inclusions, or twins. S is treated as a random variable, because it is\nnot typical that the feature is fully understood before it is observed. It is therefore\nviewed as a feature randomly selected from an infinite set of possible features that are\nassociated with a given system under characterization. Each feature is described by\na vector Γ, which contains a set of characteristics that are measured from the feature:\n\nΓ = M (S)\n\n(3.1)\n\nExamples of such characteristics include feature size, number of sides, aspect\nratio, or perimeter length. The sample space of Γ is discretized into vector γj ; j =\n1, 2, ...Ng . By integrating over the probability distribution function describing the\nrandom features fS (s) for all s that are a member of the feature space ΩS , the\nprobability that Γ falls within a given interval on this discretized space is found to\nbe:\n\nZ\nP [γj ≤ Γ ≤ γj + ∆γ] = P [Γ = γj ] =\n\ng(γj , s)fS (s) ds\ns∈ΩS\n\n77\n\n(3.2)\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nin which\ng(γj , s) = I[M (s) = γj ]\n\n(3.3)\n\nwhere I[·] is the indicator function, set equal to 1 if the expression in the brackets is\ntrue and 0 if false. To simplify notation in this and subsequent equations, we express\nthe event that γj ≤ Γ ≤ γj + ∆γ as Γ = γj .\nQuantification of Γ for a randomly selected feature S is typically the final goal\nof the characterization, but materials characterization only provides estimates of the\nmeasurements Γ̂ for a given feature s. Therefore, a relationship between these estimates Γ̂ and the true characteristics Γ is needed.\n\n3.1.2\n\nDistribution of measured approximations to\nmaterial characteristics\n\nFor practical purposes, measurement of Γ is performed from characterizations\nthat provide an approximation to each feature s. Frequently, s is discretized onto a\nsampling grid G through a discretization operation D(s, G), as illustrated in figure\n3.1, which simulates data collection processes that rely on a 2D pixelized image. The\nsampling grid, G = G(∆x, V, Θ) is defined by a sample point spacing ∆x, an in-plane\nshift vector V that lies in the range (0, ∆x) along each coordinate direction, and a\nrotation Θ of the grid relative to the feature. This discretization process G(∆x, V, Θ)\nintroduces random uncertainty into measurement, due to the random in-plane shift\n\n78\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nFigure 3.1: Illustrations of the process of discretizing a shape, drawn in black. The\nsampling grid G(...) shown has a ∆x = 5, random shift along x and y, and no rotation\nabout the origin.\n\n79\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nV and random rotation Θ. The characteristic Γ for a given feature s is therefore\napproximated by Γ̂(S = s):\n\nΓ̂(s) = M (D(s, G(∆x, V, Θ)))\n\n(3.4)\n\nSimilar to Γ, the set of possible Γ̂ is discretized as γ̂i : i = 1, 2, ...N̂g , so that the\nevent Γ̂ = γ̂i is equated to the event γ̂i ≤ Γ̂ ≤ γ̂i + ∆γ̂. The probability that Γ̂ = γ̂i\nfor feature s at a resolution level ∆x is calculated by integrating over all possible grid\norientations θ and shift vectors v:\n\nZ\n\nZ\n\nP [Γ̂ = γ̂i |S = s] =\n\nĝ(γ̂i , s, ∆x, v, θ)fV (v)fΘ (θ) dθ dv\n\n(3.5)\n\nv∈V θ∈Θ\n\nwhere\n\nĝ(γ̂i , s, ∆x, v, θ) = I[M (D(s, G(∆x, v, θ))) = γ̂i ]\n\n(3.6)\n\nThe functions fV (v) and fΘ (θ) are the probability distribution functions describing\nthe shift vector V and the rotation θ, respectively. The shift vector and orientation are\nassumed to be independent, both following a uniform distribution. Each component\nof the shift vector lies on the range [0,∆x] and the orientation lies on the range [0,2π].\nEquation (3.5) can therefore be recast as:\n\nZ∆xZ2π\nP [Γ̂ = γ̂i S = s] =\n0\n\n0\n\n80\n\nĝ(γ̂i , s, ∆x, v, θ)\ndθ dv\n2π∆xd\n\n(3.7)\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nwhere d is the number of dimensions of the feature s. This probability for a randomly\nselected feature S is found by integrating over the feature distribution fS (s):\n\nZ∆xZ2π\n\nZ\nP [Γ̂ = γ̂i ] =\n\ns∈ΩS 0\n\n3.1.3\n\nĝ(γ̂i , s, ∆x, v, θ)\nfS (s) dθ dv ds\n2π∆xd\n\n(3.8)\n\n0\n\nConditional distribution on the true characteristics\n\nThe indicator functions inside the integrals in equations (3.2) and (3.8) are easily\ncombined to find the probability that both Γ̂ = γ̂i and Γ = γj :\nZ∆xZ2π\n\nZ\nP [(Γ̂ = γ̂i ) ∩ (Γ = γj )] =\n\ns∈ΩS 0\n\nĝ(γ̂i , s, ∆x, v, θ)g(γj , s)\nfS (s) dθ dv ds\n2π∆xd\n\n(3.9)\n\n0\n\nSubstituting equations (3.8) and (3.9) into the general equation for conditional probability:\n\nP [(Γ = γj ) (Γ̂ = γ̂i )] =\nR\n=\n\n∆x\nR R2π\n\ns∈ΩS 0\n\nR\n\nP [(Γ̂ = γ̂i ) ∩ (Γ = γj )]\nP [Γ̂ = γ̂i ]\n\nĝ(γ̂i , s, ∆x, v, θ)g(γj , s) fS (s) dθ dv ds\n\n0\n∆x\nR R2π\n\ns∈ΩS 0\n\n(3.10)\nĝ(γ̂i , s, ∆x, v, θ)fS (s) dθ dv ds\n\n0\n\nThis expression gives the probability of a true feature characteristic falling into the\nspecified range, given a particular measurement value. This equation is the foundation for subsequent Bayesian analysis of a finite set of measurements, so that the\n81\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\ndistribution of features fS (s) is a prior distribution. In such analyses, it is typically\nassumed that the prior distribution is a uniform distribution across all feasible values\nof S. This assumption is rooted in the idea that no information is known about the\nfeatures beforehand, so any feature is equally likely as the next. Previous work in\nBayesian approaches suggests that this conditional probability is not very sensitive to\nthe prior. This will be studied in more detail in the context of a numerical example\nin the next section.\n\n3.2\n\nCalculation of the Conditional Probability Integral\n\nA major challenge to directly implementing equation (3.10) is that closed form\nexpressions for ĝ and g are difficult to identify for most realistic feature families.\nSection 3.2.1 develops a solution for characterizing the length and area of 1D lines\nand 2D rectangles, respectively. Even for these simple features for which closedform expression for ĝ and g are available, the integration and subsequent solution\nare cumbersome. To expand the applicability of this approach to arbitrary feature\nshapes and characteristics, a simulation-based approach based on a discretized version\nof equation (3.10) gives an estimate of these integrals in Section 3.2.2.\n\n82\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nFigure 3.2: Examples of the conditions of equation 3.12. The combined length of v\nand n must be between n̂ and n̂ + 1.\n\n3.2.1\n\nAn Analytical Model\n\nEquation (3.10) can be applied directly for a few very simple cases. For example,\nconsider a 1D line segment of random length measured with a fixed sample spacing\n∆x = 1, in which an integer number N̂ sample points are recorded to lie within that\nline segment. The value N = L is a real-valued random variable that lies between\nN̂ −1 and N̂ +1. We assume here that the prior distribution of the actual length fN (n)\nis uniformly distributed across a range of values from zero to length M . Equating N to\nΓ and N̂ to Γ̂ and recognizing that there is no grid rotation θ in this 1D configuration,\n\n83\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nthe expression in Equation (3.10) simplifies to:\nR1\nf [(N = n) (N̂ = n̂)] =\n\nĝ(n̂, n, v) dv\n\n0\nn̂+1\nR R1\n\n(3.11)\nĝ(n̂, s, v) dv ds\n\nn̂−1 0\n\nwhere the function g(n, s)/dn was recognized to be equivalent to the dirac delta\nfunction δ(n − s), which allows further simplification of this expression. Comparing\nthe length n to the shift distance v and adjacent points n̂−1, n̂ and n̂+1 the function\nĝ is found to be (see figure 3.2):\n\n1; n̂ ≤ n ≤ n̂ + 1, 0 ≤ v ≤ 1 − n + n̂\nĝ(n̂, n, v) = 1; n̂ − 1 ≤ n ≤ n̂, n̂ − n ≤ v ≤ 1\n\n(3.12)\n\n0; otherwise\nSubstituting equation(3.12) into equation (3.11) and completing the integrations, the\nprobability density function describing the true length N given the measured length\nN̂ = n̂ is calculated as:\n\nfN |N̂ (n|n̂) =\n\n\n1\n\n(1 − n̂ + n); n̂ − 1 ≤ n ≤ n̂\n\n2\n\n\n1\n(1 + n̂ − n; ) n̂ ≤ n ≤ n̂ + 1\n2\n\n\n0;\notherwise\n\n(3.13)\n\nEquation (3.13) is a triangular distribution with an expected value, E(N ) = n̂.\nFurther expanding the model to two dimensions, consider a rectangle with random\ndimensions N1 ∆x × N2 ∆x with axes aligned with the grid so that there is no rotation\n\n84\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nθ, and with random measured values N̂1 ∆x × N̂2 ∆x. If we assume the actual side\ndimensions are independent, then the conditional distribution on the true area given\nmeasurements N̂1 = n̂1 and N̂2 = n̂2 is [132]:\n\nZ (Nˆ1 +1)(Nˆ2 +1)\nfA|N̂1 ,N̂2 (a|n̂1 , n̂2 ) =\n\n(Nˆ1 −1)(Nˆ2 −1)\n\nfN1 |N̂1 (n1 |n̂1 )fN2 |N̂2 (\n\na\n1\nn̂2 ) dn1\nn1\nn1\n\n(3.14)\n\nThe PDF describing the area is calculated by substituting Equations 3.13 into Equation 3.14. Because these functions are piecewise linear, the individual integrations are\nstraightforward, but it requires care to account correctly for the intervals on the piecewise integrations. For the special case of n̂1 = n̂2 = n̂, the probability distribution\nfunction describing the true area becomes:\n\n\n\u0011\n\u0010\n\n\na\nC ln (n̂−1)\n− 2a + 2(n̂ − 1)2\n\n2\n\n\n\u0010 2(B+C)\n\u0011\n\n\nn̂\n(n̂−1)2B\n\n\nln\n+ 6a − 2(3n̂ + 1)(n̂ − 1)\n\na2B+C\n\n\n\u0010\n\u0011\nn̂2(B+C)\nfA|N̂ (a|n̂) =\nln\n+ 2a − 2(n̂ − 1)2\naC (n̂+1)2B\n\n\n\u0010\n\u0011\n\n\na2B+D\n\nln n̂2(B+D) (n̂+1)2B − 6a + 2(3n̂ − 1)(n̂ + 1)\n\n\n\u0010\n\u0011\n\n\nD ln (n̂+1)2 + 2a − 2(n̂ + 1)2\na\n\n(n̂ − 1)2 ≤ a ≤ n̂2 − n̂\nn̂2 − n̂ ≤ a ≤ n̂2 − 1\nn̂2 − 1 ≤ a ≤ n̂2\nn̂2 ≤ a ≤ n̂2 + n̂\nn̂2 + n̂ ≤ a ≤ (n̂ + 1)2\n(3.15)\n\nwhere\n\n85\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nFigure 3.3: Probability density function fA (a) describing the true distribution of a\nrectangular feature given measurements of 2x2, 3x3, 4x4 and 5x5 pixels.\n\nB = n̂2 − 1 + a\nC = (n̂ − 1)2 + a\n\n(3.16)\n\nD = (n̂ + 1)2 + a\nFigure 3.3 shows some of the conditional probabilities evaluated using equation\n(3.15). While the above formulation is cumbersome, it is useful in that it provides\ninsights into the distribution of true feature area given a set of area measurements. In\n\n86\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nparticular, these results suggest that the distribution of true area given a particular set\nof measurements is something akin to a bounded Gaussian distribution for larger size\nmeasurements. It is more skewed for very small measurements such as n̂ = 1. The\nlimitation to rectangular features in this analytical approach significantly reduces\nthe applicability of this formulation to true microstructural features that are not\ntypically rectangular. With this in mind, the next section describes a simulationbased approach to approximating the distribution of true feature sizes given pixelized\nmeasurements, for a range of different feature shapes.\n\n3.2.2\n\nSimulation-based approach to calculating the\nconditional probability\n\nUsing standard image discretization, the functions ĝ and g can be evaluated explicitly for any given feature s, grid discretization ∆x , grid orientation θ, and grid\nshift v. Therefore, an approximate solution to Equation (3.10) is enabled for a family\nof two-dimensional features using a discretized integral:\n\nNs\nP\n\nP [(Γ = γj ) (Γ̂ = γ̂i )] =\n\nNθ\nNv P\nNv P\nP\n\ng(γj , sm ) f (sm )\n\nm=1\n\nn1 =1 n2 =1 p=1\nNs\nP\nm=1\n\nf (sm )\n\nNθ\nNv P\nNv P\nP\nn1 =1 n2 =1 p=1\n\n1 ∆x n2 ∆x\nĝ(γ̂i , sm , ∆x, ( nN\n, Nv ), 2πp\n)\nNθ\nv\n\n1 ∆x n2 ∆x\nĝ(γ̂i , sm , ∆x, ( nN\n, Nv ), 2πp\n)\nNθ\nv\n\n(3.17)\nMost of this summation itself is very straightforward to implement. As in the previous\n\n87\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nsection, this prior distribution on the features fS (s) is assumed to follow a uniform\ndistribution. More discussion of this prior distribution and its effect on the results\nwill be provided in section 3.2.4.1. In general, these features are not universal quantities. They depend on the type of microstructure under evaluation. For example,\nthe feature family for a 2D image of a porous material might be a set of circular\nshapes with varying size. On the other hand, microstructures with long features such\nas fibers or twins might be better described as elliptical shapes with varying size and\naspect ratio. This work focuses on polycrystalline materials with grain features that\nare typically polygonal, akin to those found in a Voronoi tessellation, with varying\nsize and aspect ratio. A randomly selected set of exact 2D Voronoi cells is simulated, providing ground truth features with known characteristics Γ (the size, aspect\nratio, and perimeter are considered). These features are discretized and measured\nto generate approximate characteristics Γ̂, following the procedure shown in figure\n3.1. Performing these analyses over a large number of input features (Ns ) and grids\n(Nv , Nθ ), equation (3.17) gives an estimate of the probability of the true feature\ncharacteristic(s) being γj , conditioned on the measured value(s) γ̂i .\n\n3.2.2.1\n\nGeneration of ground-truth shapes\n\nIn this analysis a set of features sm is generated by first selecting a set of shapes\nand then varying size and aspect ratio of each shape through scaling and stretching\nof the base shape. The shape S1 is drawn randomly from a set of individual grains\n\n88\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nFigure 3.4: Examples of shapes taken from Voronoi tessellation. Each shape seed, n,\nwas scaled to produce over 600,000 unique shapes with sizes.\n\nextracted from a Voronoi tessellation. Voronoi tessellations are selected because they\nare commonly used to represent synthetic microstructures of polycrystalline materials,\nand their ability to match grain size measurements has been shown to be reasonable\n[133]. In a method similar to that which was performed in Coutinho et al. [45],\nindividual shapes are extracted from a tessellation built in Matlab, in which each\nshape is fully defined by the locations of the vertices. Examples of such shapes are\nshown in Figure 3.4. Each individual shape is subsequently scaled and stretched\nto produce a set of feature with varying size S2 and aspect ratio S3 . Each feature\nsm : m = 1, 2, ...Ns in the full simulated data set is therefore defined by a unique\ncombination of shape s1i : i = 1, 2...Ns1 , size s2j : j = 1, 2, ...Ns2 , and aspect ratio\ns3k : k = 1, 2, ...Ns3 . The total number of features Ns is therefore:\n89\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nNs = Ns1 Ns2 Ns3\n\n(3.18)\n\nAssuming no dependence between these three characteristics, the feature distribution,\nfS (s), is the product of three independent distributions:\n\nfS (s) = fS1 (s1 ) fS2 (s2 ) fS3 (s3 )\n\n(3.19)\n\nwhere the individual characteristics are assumed to follow a uniform prior distribution:\n\nfS1 (s1 ) = U (1, Ns1 )\nfS2 (s2 ) = U (1, Ns2 )\nfS3 (s3 ) = U (1, Ns3 )\nUsing other initial priors is straightforward. Some alternatives have been considered\nand a study of their effects on the resulting conditional distribution are detailed in\nsection 3.2.4.1, which will show that sensitivity of these results to the selection of the\nprior distribution is low.\n\n3.2.3\n\nMeasurement Definitions\n\nSince the Voronoi shapes are fully defined by their vertices, the characteristics\nΓ = M (S1 , S2 , S3 ) are known exactly for each simulated feature. The approximate\nmeasures for a given feature s, Γ̂(s), are calculated for every given grid G(∆x, vj , θk ))),\n\n90\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nfollowing the process shown in figure 3.1. In particular, for each fundamental shape\nS1 = s1 , the measured size γ̂1 is determined from the pixelized data using a simple\ncount of the number of grid points that lie within the feature. There exist different techniques for estimating the aspect ratio, γ̂2 , for nonregular geometric shapes.\nBounding box methods are commonly used, but these are highly sensitive to orientation [124]. A more rigorous method of estimation is determined by equating the polar\nmoment of inertia of the pixelized feature to the known polar moment of inertia of\nan ellipse of the same size as the pixelized feature with aspect ratio a/b. The polar\nmoment of inertia of the pixelized feature is:\n\nN\nX\nI=\n[(cx − xi )2 + (cy − yi )2 ]∆x2\n\n(3.20)\n\ni=1\n\nwhere N is the number of pixels in the feature, xi and yi are the coordinates of each\npixel, (c1 , c2 ) is the location of the centroid of the pixelized feature, and ∆x2 is the\narea of each pixel. The major and minor axis lengths of the equivalent ellipse are\ndetermined algebraically to define γ̂2 .\n\n3.2.3.1\n\nDefining the Perimeter\n\nThe feature perimeter is an additional measure of interest here, but it will not be\nsimulated directly like the other three characteristics that are completely controlled in\nthe data generation process. Instead, the perimeter of each feature in the previously\ngenerated set will be calculated. The exact measurement of the perimeter of pixel\n91\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nobjects is an unsolved problem. It is commonly understood that the simple and\nstraightforward method of counting the combined edge length of all boundary pixels\nproduces an erroneous over estimate of the true boundary length. Many studies\nhave analyzed the 4 or 8 nearest neighbors of boundary pixels to predict the location\nand curvature of the boundary and thereby provide a more accurate estimate of the\nperimeter [127]. In a resent work Coutinho et al., used a pattern matching library to\nprovide an even more accurate measurement [45]. However, each of these methods\nare limited in that they seek to estimate an exact measurement without any bounds\non that estimate. The current work uses two different methods to measure perimeter:\nthe simple method of counting the combined edge length, and a method developed by\nVossepoel which assigns fractional values of length based on a the number of neighbors\na boundary pixels has [126]. An illustration of these methods can bee seen in figure\n3.5 along with histogram data for perimeter measurements made with both methods.\nBoth methods introduced bias. Vossepoel’s method is slightly more accurate than\nthe simple method and its bias decreases with resolution, where as the simple measure\ndoes not. However utilizing the the conditional measurement distribution it is possible\nto correct for both of these biases equally well (see section 3.3.3)\n\n92\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nFigure 3.5: Results for simulated data collection on a shape with a true perimeter\nlength of 21.03∆x. Histograms for two measurements of the perimeter both showed\nsignificant bias. The simple perimeter measurement over estimated the true by ∼\n25% while matlab regionprops produced and underestimate by ∼ 16%. Using the\nConditional Measurement Distribution the bias can be mapped and both methods\ncan be effectively used to predict true perimeter measurements and distributions. An\nillustration of the two methods is provided as a visual reference only.\n\n93\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\n3.2.4\n\nSimulation-based conditional probability results\n\nAs noted earlier evaluating Equation 3.17 over a large number of features Ns gives\nan estimate for the probability of the true measurement being γj given a measured\nvalue of γ̂i . The previously described simulated data set is used to evaluate Equation\n3.17 over a finite range of shapes, grain sizes, and aspect ratios. In total 30 different\nshapes are selected (Ns1 = 30), and each is scaled to produce grain sizes ranging from\n1 Px to 1500 Px in 1 px increments (Ns2 = 1500), and aspect ratios ranging from 1 to\n5, with a step size of 0.01 (Ns3 = 401). The bounds of these domains are selected to\nencompass typical ranges for grains in a polycrystalline material, noting that changes\nto these bounds are straightforward to implement. In total this process led to a set\nof ∼ 18 million features, each of which are then sampled 240 times using different\nsemi-randomly generated sampling grids G(∆x, v1 , v2 , θ). Figures 3.6b and 3.7b show\nthe probability distribution of the true feature size given a measured size of 100, for\ndifferent prior distributions on the size and aspect ratio, respectively.\n\n3.2.4.1\n\nEffects of Prior Distribution\n\nFigure 3.6a shows three different prior distributions describing size, fS2 (s2 ). Despite varying significantly, they all produce very similar solutions in Figure 3.6b, which\nshows that there is little effect of the prior distribution on the results. In a similar\n\n94\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\n(a) Prior distributions on size\n\n(b) Conditional distribution of true size given\nmeasured size=100\n\nFigure 3.6: Three different assumed prior distributions (shown in A) all produced\nnearly identical Conditional Measurement Distributions (shown in B) for an assumed\nmeasured size of 100 px.\n\nfashion Figure 3.7 shows the effect on the conditional size distribution of changing\nthe prior distribution describing aspect ratio, fS3 (s3 ). Again three different priors on\naspect ratio all yielded approximately the same result conditional distribution on size.\nVarious combinations of prior distributions on size and aspect ratio were examined,\nand no meaningful variations in the resulting conditional distribution describing size\nwas found (not shown here).\nChanging the prior shape distribution, fS1 (s1 ), is less straight forward. For the\nassumed crystalline material structure there is no logical reason to assume that one\nshape seed should be favored over another; therefore, a uniform distribution is assumed. Figure 3.8 shows the effect of specific shape selection on the conditional size\n\n95\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\n(a) Prior distributions on aspect ratio\n\n(b) Conditional distribution of true size given\nmeasured size=100\n\nFigure 3.7: Using different prior distributions of aspect ratio, fS2 (), did not have any\nsignificant effect on the conditional distribution for size.\n\ndistribution for a measured size of 125 px computed using Ns1 = 1 for the 6 different\nshapes shown in figure 3.4. The variability across individual shapes is small, but\nis more noticeable than that observed when changing the prior distributions of size\nor aspect ratio. For perimeter measurements the difference is even more noticeable.\nFigure 3.9 shows conditional perimeter distribution (measured at an equivalent resolution) for the same 6 shapes. Different shapes showed varying amounts of skew.\nThis is in contrast to what is seen in Figure 3.8 where the shape had very little effect\non the distribution form. Nevertheless the addition of more shapes seeds lead to a\nconvergence of Eq.3.17. Figure 3.10 shows the convergence of the conditional distribution as it is averaged over an increasing number of underlying shapes. Convergence\nwas evaluated via the Root Mean Squared Error (RMSE) between CMD [Ns1 = N ]\n\n96\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nFigure 3.8: The conditional size distribution shown when Ns1 = 1 for 6 different shape\nIDs. The averaged (black) distribution was computed using Ns1 = 30 with each of\nthe 30 unique shape seeds being equally weighted.\n\n97\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nFigure 3.9: The shape of a feature was very important to the perimeter measurement.\nConsider Shape ID 3, where certain side proportions forced a bi-modal measurement.\n\n98\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nand CMD [Ns1 = N + 1]. Ultimately, 30 unique shapes were selected to serve as the\nfeature space, as the relative change between CMD [Ns1 = 29] and CMD [Ns1 = 30]\nwas ' 1%.\nStudies of the effects of prior distributions were repeated for the conditional aspect\nratio distribution, conditional simple perimeter distribution, and conditional Vossepoel perimeter distribution. In general the results were similar, with the effect of\nthe prior distribution having little effect on the converged conditional distribution.\nThe notable exception occurs in the poorly framed cases where an assumed prior has\nzero probability within the domain where actual feature measurements exist; under\nthese conditions the solution will be entirely incorrect. Assuming a uniform distribution across the entire feasible domain works well for these analyses, because this\nassumption ensures that such spurious results will not occur.\n\n3.2.4.2\n\nSize Effects\n\nWhen studying the conditional aspect ratio distribution, it became apparent that\nthere was a clear relationship between the measured size (γ̂SIZE ) of an object and\nthe variability of its measured aspect ratio (γ̂AR ). Figure 3.11 shows the conditional\naspect ratio distribution (for γ̂AR = 1.5) evaluated different conditions; conditioned\nover a finite range of measured sizes and without any condition on measured sizes.\nSmall features (< 35 px) are show to have a wide range of possible true aspect ratios\nfor a given measured aspect ratio, which heavily affect the prediction. However, if\n\n99\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nFigure 3.10: Curves showing the relative change in computed conditional measurement distribution as the number of shapes in the feature space increased. The conditional distribution was evaluated for measurements of: size (Blue), aspect ratio (Red),\nsimple perimeter (Yellow), and Vossepoel perimeter (Purple). All showed a convergence to less than 1% with the conditional size distribution converging for Ns1 = 6.\nThe convergence of the perimeter measurements were the slowest (see figure 3.9).\n\n100\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nFigure 3.11: Features with smaller measured sizes have much wider distributions.\nThis dependance was independent of the actual measured aspect ratio as all measured aspect ratios had a comparable coefficient of variation for all measured sizes.\nEvaluating Eq. (3.17) for subdivided regions size yielded more accurate results\n\n101\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nthe measured size is know we can condition the distribution on that information to\nyield a more precise prediction than evaluating it over the entire size domain.\n\n3.3\n\nConstruction of material characteristic distributions from data\n\nTo this point, the simulated data provides the basis for establishing a conditional\ndistribution on measures Γ given an observation Γ̂ = γ̂i . This conditional distribution\nprovides a tool for calculating the distribution on Γ̂ given a set of experimental measurements Γ̄ = γ̄i : i = 1, 2, ...Nd . In particular the law of total probability suggests\nthat the distribution on the true characteristics can be estimated as:\n\nP [Γ = γj ] =\n\nNd\nX\n\nP [Γ = γj Γ̂ = γ̂i ]P [Γ̄ = γ̄i ]\n\n(3.21)\n\ni=1\n\nSince each data point can be viewed as equally likely, then\nNd\nP\n\nP [Γ = γj ] =\n\nP [Γ = γj Γ̂ = γ̂i ]]\n\ni=1\n\nNd\n\n(3.22)\n\nThis property distribution may not be smooth if relatively few data points have been\ncollected, but it converges towards the true distribution as more data is incorporated.\nTo demonstrate the ability of equation (3.22) to correctly predict property distributions, trial datasets were constructed to test its performance. In particular, this\ndata was generated by sampling from prescribed distributions for the grain size and\n102\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nthe grain aspect ratio. Most simulations assume a lognormal grain size distribution\nwith a mean feature size of 251 px, and a truncated [1, 5] exponential aspect ratio\ndistribution (μ = 0.5). The shapes of the features are selected from a pool that is\ndistinct from those used to construct the conditional distribution. In other words,\nthe following steps were followed to generate each data point: (1) a random shape\nwas selected, (2) the shape was scaled by random variables drawn from the grain\nsize and aspect distributions, generating a feature s, (3) a discretization operation,\nD(s, G(∆x, V, Θ) was performed to generate an image of the feature for a randomly\nselected shift vector v and grid orientation θ, and (4) any desired measurements (Eq.\n3.4) of the feature were performed and recorded. This process was repeated until a\npredetermined number of features and/or pixel counts were exceeded.\nThe analysis was performed several times, using different sample point spacings\n∆x, so that the effect of resolution could be analyzed. This resulted in a set of\nmeasurements for each of the Nd grains at multiple resolutions.\n\n3.3.1\n\nSize Measurements\n\nFigure 3.12 provides a histogram for an example of data set which meets all the\nrequirements of ASTM 2627 [117], which recommends a minimum image resolution.\nThe grain sizes were sampled from a lognormal distribution with parameters μ =\nlog(525) and σ = 0.15, corresponding to a mean feature size of 531 Px. The simulated\ndata set was constructed by measuring 750 features comprising a total of ∼ 400, 000\n103\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\npixels, using a spacing of ∆x = 1. The first entry of Table 3.1 shows the mean and\nstandard deviation of the average feature size computing using section 13 and 14 of\nASTM 2627, with an error in the mean relative to the true mean of 531 Px of 0.5%.\nAlso plotted in Figure 3.12 is a data set collected and processed using the conditional distribution approach proposed in this work. This data is collected at a lower\nresolution, using a spacing of ∆x = 4.47. Keeping the total number of pixels constant, this resolution results in an average of only 26 pixels per feature (Px/F) but a\nmuch larger number of features (∼ 15, 000) sampled. Processing this data using the\nappropriate conditional distributions we are left with a result that also provides an\naccurate representation of the true data. Using the computed distribution to estimate\nthe mean grain size led to similar (in this case slightly less) error than the 531 Px/F\nresolution dataset (see Row 2 of Table 3.1). This table also shows results when averaging over 10 different datasets, using both the ASTM 2627 standard and the data\nprocessed from the conditional distribution. Again, the level of error is very small using both approaches, though there is a slightly higher error observed in the data based\non the conditional distribution. These results demonstrate that using the conditional\ndistribution based on simulated data can be applied to experimentally obtained data,\nin order to account for the variability of low resolution measurements. This enables\nreconstruction of the property distributions that closely match those obtained using\nlarger high resolution datasets, benefiting from an increase in the number of features\nthat can be sampled with the same number of total pixels.\n\n104\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nFigure 3.12: Histogram of dataset meeting the recommendations of ASTM 2627 compared to a predicted distribution using a low resolution dataset and the Conditional\nMeasurement Distribution.\n\n105\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nResolution\n\nMethod\n\nMean\n\nStd.\n\nError\n\n531 Px/F\n\nASTM2627 - 1 Trial\n\n533.61\n\n82.73\n\n0.5 %\n\n26 Px/F\n\nMED - 1 Trial\n\n528.54\n\n88.68\n\n0.45 %\n\n531 Px/F\n\nASTM2627 - Avg.\n\n530.64\n\n80.57\n\n0.06 %\n\n531 Px/F\n\nMED - Avg.\n\n530.62\n\n80.55\n\n0.06 %\n\n265 Px/F\n\nMED - Avg.\n\n529.65\n\n80.54\n\n0.24 %\n\n66 Px/F\n\nMED - Avg.\n\n528.10\n\n86.87\n\n0.53 %\n\n44 Px/F\n\nMED - Avg.\n\n527.76\n\n88.36\n\n0.60 %\n\n26 Px/F\n\nMED - Avg.\n\n527.44\n\n90.09\n\n0.66 %\n\nTable 3.1: Expected value of mean grain size sampled at different resolutions. Results for the Conditional Measurement Distribution (MED) were averaged over 10\nsimulations.\n\n106\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\n(a) 75,000 Px dataset\n\n(b) 1,500,000 Px dataset\n\nFigure 3.13: Constructed property distributions for two different data set sizes (a)\n75,000 and (b) 1,500,000 px. Construction of data sampled at a lower resolution\nyielded a smoother feature size distribution. As the total number of sample points\nincrease the heigh resolution measurements we able to make gains and out perform\nlower resolution measurement.\n\nFigure 3.13 explores the effect of the data size (in terms of total number of pixels\ncollected) and resolution (defined in terms of average pixels per feature, Px/F). These\nresults assumed a lognormal feature size distribution with parameters μ = log(225)\nand σ = 0.48. The error between the predicted distribution using the conditional\nprobabilities and the true lognormal distribution was calculated as a Root Mean\nSquared Error (RMSE), normalized by the point spacing.\nIn absolute terms the large 1.5M Px dataset is the better of the two, which is\nto be expected. However, the 42 Px/F resolution performs much better with the\nsmall data set of 75K data points. In fact, this resolution performs almost equally\n\n107\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nFigure 3.14: Average error in the measure size distribution, compared to the true\ndistribution computed for an increasing data set size. Higher resolution data limited\nthe total number of sampling points leading to a higher average error. Shaded regions\nshow the 95th percentile range for each resolution both resolutions converge to true\ndistribution.\n\n108\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nas well at 75K Px as the 125 Px/F resolution does at 1.5M Px. Figure 3.14 shows\nthe measurement error as a function of the total number of pixels in the dataset. 5\ndifferent resolutions were examined by averaging results over a 100 trials at each total\npixel number. The 95% confidence interval for each point is indicated by the lighter\ncolored shading above and below the curves. The lowest resolution data at 21 Px/F\noutperformed the higher resolution datasets by a considerable margin, until around\n1.2M pixels of data was collected at which point most distributions converged to a\nvery good approximation of the true. The highest resolution of 251 Px/F on average\nstill had measurably higher error than the other resolutions (≈ 2% higher) at a total\nsample size of 1.5M Px.\nThese results can be interpreted as follows: when sampling with a resolution below\n50 Px/F there are more features in the dataset, even if they are poorly resolved.\nAlso, the conditional distribution on the true measure given the data from a lower\nresolution feature has a higher variance, which has the effect of smoothing out the\npredicted probability distribution between adjacent observations in the data. At\nhigher resolutions, the increased confidence resulting from a more finely sampled\nfeature results in a conditional distribution with a lower coefficient of variation. This\nleads to predicted distributions which looked noisier because they do less smoothing\nbetween adjacent observations of feature size. This effect is readily apparent in figure\n3.13. It is also important to note that size is a measure that is not sensitive to shape\nof the feature, so that a higher resolution observation of the feature is less likely to\n\n109\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nFigure 3.15: Mar () exhibits many of the same trends as Ms () however due to the\nhigher sensitivity to measured size, higher resolution begin to do better sooner.\n\nprovide significantly different information. Other features such as aspect ratio and\nperimeter are expected to be more heavily influenced by resolution.\n\n3.3.2\n\nAspect Ratio Measurements\n\nFigure 3.15 shows the error between the true aspect ratio distribution (Truncated [1 ∞) exponential(μ = 0.5)) and predicted aspect ratio distribution use the\nconditional distribution. As explain in section 3.2.4.1 the conditional aspect ratio\n\n110\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\ndistribution was further condition on the measured size size, nevertheless the effects\nof smaller measured sizes on the variance was noticed. A moderate number of pixels,\nthe 42 Px/F resolution began outperformed the resolution of 21 Px/F for even very\nsmall sample sizes (15,000 total Px). Similarly, for data sets larger than 1, 000, 000\nPx the optimal resolution was ∼ 60 Px/F.\n\n3.3.3\n\nPerimeter Measurements\n\nThe measurement of the distribution of perimeter lengths has one small difference\nfrom the prior two examples. The perimeter is a function of the shape, aspect ratio\nand size of an object. As such, when generating shapes the true perimeter distribution\nwas not explicitly defined because it is not independent. Instead the distribution\nof perimeter lengths was calculated using the know perimeters from all 18 million\nfeatures, and is referenced as the true perimeter distribution.\nIn Figure 3.16 the distribution of perimeter lengths compute with simulated data\n(for the both the simple and Vossepoel measurement) are compared to true perimeter\ndistribution. Despite the biases that originally existed with both methods (see figure\n3.9, the conditional probability distribution was able to reproduce accurate estimates\nof true perimeter distribution.\nIt is noteworthy that while the Vossepoel method does a better job at capturing\nindividual measurements, the predicted property distribution appears less smooth.\nThis effect is reduced The precision introduced by estimating the boundaries works\n111\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nFigure 3.16: Construction of the perimeter length distribution for a simulated data\nset. Despite differences in bias the conditional probability formulation was able to\ncorrect both measurements. The mean perimeter lengths were within less than 1% of\nthe true value. The measurement error of the distribution as a whole was lower for\nthe simple perimeter measurement by just over 1%.\n\n112\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nFigure 3.17: Mp () has the lowest resolution cross overs of the measurements considered. For low resolutions the error plateaued above 4%.\n\nagainst the smoothing provided by the conditional distribution on the true perimeter\ngiven a measured value. By properly accounting for the measurement error introduced, the simple method provides a very smooth and reasonably accurate result.\nFigure 3.17 shows the error in the predicted perimeter distribution (based on the\nsimple perimeter measure), as a function of the total number of pixels for different\nresolutions. The optimal resolution is at the lowest resolution for small data sets less\nthan about 15,000 pixels, but higher resolution data collection becomes optimal as\nthe size of the data set increases. The higher resolution data for perimeter performs\n113\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nbetter for smaller data sets than for either feature size or aspect ratio.\nAn examination of the detailed window shows that for a data set consisting of\nmore that 200k pixels a resolution of 125Px/F is needed. The general trend appears\nto be that the more complex/abstract measures (like perimeter and aspect ratio) are\nmore accurate with require higher resolutions than the more simple measurements\n(like feature size), which are best measured at lower resolutions.\nOne powerful application of the approach is estimating the optimal sampling resolution under various experimental constraints. Figure 3.18 shows the best preforming\nresolution for a fixed number of pixels for each measurement type. These results can\ninform an ideal sampling resolution if it is known what measurements are going to be\nmade. They can also inform the relative gains that recollecting the data at a different\nresolution might have.\n\n3.4\n\nConclusions\n\nThe Conditional Measurement Distribution effectively combines individual data\npoints, using a framework which accounts for the inherent measurement error, to\nconstruct property distributions. It provides a standardized method for the construction of property distributions which can be applied across varying length scales. The\nmodel was shown to work effectively for different types of measurements, and on data\nsets ranging from a small to medium large in size (< 2M Px). While the model was\n\n114\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\nFigure 3.18: The best preforming sampling resolution for each measurement type.\n\nnot explicitly evaluated for very large image data sets (> 5M Px) there is no reason to\nbelieve that it would not function equal as well for the prediction of property distributions. Smaller data set sizes were chosen to better highlight the relative differences\nbetween sampling resolutions.\nThe use of high resolution data collection, was found to have an application dependent impact on the construction of property distributions when data set sizes\nare limited. The high resolution data sets limit the number of features sampled and\ntherefor increase sampling error. The post-processing of data to calculate a property\ndistribution largely negated the high resolution measurements improved accuracy.\nThis effect was exhibited when comparing all three measurement methods to varying\n\n115\n\nCHAPTER 3. THE CONDITIONAL MEASUREMENT DISTRIBUTION\n\ndegrees. However, for the perimeter measurements were found to require the higher\nresolution data.\nUltimately, it was found that average feature sizes which were much lower than\nthose recommended by ASTM 2627 could be effectively used. ISO standard 13067 was\nfound to more closely approximate the appropriate sampling resolutions. However,\nwhen grain size data is the primary object even smaller resolutions can be used.\n\n116\n\nChapter 4\nEvaluating Computational Models\n\n4.1\n\nIntroduction\n\nThe computational uncertainty quantification framework can also be used to further traditional computational model sensitivity and reliability studies. One basis\nfor this framework is using a set of digitally generated statistically representative\nmicrostructures, in order to assess variations from one material sample to the next.\nTraditional stochastic simulation-based and simulated annealing approaches suffer\nfrom very slow convergence of each individual microstructure and/or poor representation of microstructural geometries. Currently there are number of different efforts\nto use computational neural networks for such microstructure generations, including\nGenerative Adversarial Networks (GAN) and transfer learning. These methods provide a highly efficient alternative that is able to capture more realistic shapes and\n\n117\n\nCHAPTER 4. EVALUATING COMPUTATIONAL MODELS\n\nconnectivity of the microstructure.\nGAN networks pit algorithms against each other [134]. One algorithm will attempt\nto generate artificial microstructures while the other will evaluate these artificial microstructures; comparing them to real microstructures and attempting to characterize\nthe difference. As such, GAN networks are working on both the microstructural generation and evaluation problems simultaneously. They have been applied to two-phase\nbinary microstructures [135], 3D porous media microstructures [136], 3D multiphase\nmicrostructures [137], and polycrystalline grain shapes [138]. A drawback to the GAN\napproach is that a significant amount of training data is needed for the microstructures to be realistic. Transfer learning is an alternative subclass of machine learning\ntechniques, which attempts to apply knowledge for new tasks from a related task\nwhich has already been learned [139]. Because transfer learning approaches rely so\nheavily on past knowledge to make their inferences they typically do not require additional training data and as such can be ideal for microstructural applications in which\nlarge sets of training data aren’t available. Transfer learning approaches use convolutional neural networks (CNN) to find links and correlations between parameters that\naren’t readily apparent. They have been used to predict finite element simulation results [140], structure–property predictions [141], and carbon fiber reinforced polymer\n(CFRP) production [142].\nThis chapter focuses on documenting research relating to the development of a\ntransfer learning based algorithm for reconstructing porous microstructures [84]. The\n\n118\n\nCHAPTER 4. EVALUATING COMPUTATIONAL MODELS\n\napproach has already been shown to have computational efficiency over traditional\niterative pixel swapping algorithms [143, 144] and to be adaptable to other material\nclasses [86]. The goal is to use synthetically generated virtual materials to probe and\nanalyze the model in unique ways. The first task will be to quantify and evaluate\nhow well the method characterizes materials and captures their mechanical response.\n\n4.2\n\nTransfer learning model evolution and\ndescription\n\nLi et al. published a generalized microstructure reconstruction method which\nadapted the existing VGG-19 [145] network trained to classify images [84]. In their\napproach the Gram-matrix (GM) [146] was used as the measurement of statistical\nequivalence between the original and the reconstructed microstructure. In each layer\nof the CNN the current Gram-matrix of the reconstruction is compared to the original. Then using a backward computation with information from the previous step\na new gradient is computed and fed into a nonlinear optimization, updating the reconstruction iteratively until convergence was found. The approach showed favorable\nresults as compared to common two-point correlation and Gaussian random field approaches. This approach was later adapted by Bhaduri et al. [85] to incorporate a\ncombination of gram matrix (GM) layers and microstructural descriptors such as the\n2-point probability function into a weighted loss function.\n119\n\nCHAPTER 4. EVALUATING COMPUTATIONAL MODELS\n\n4.2.1\n\nLoss Function\n\nCritically important to the transfer learning approach is the formulation of the\nloss function, L(x).\n\ny = arg min L(x)\n\ns.t. 0 ≤ xij ≤ 255 ∩ i ∈ 1, 2, ...m, j ∈ 1, 2, ...n\n\n(4.1)\n\nx\n\nwhere x is a m × n image, and y is the image that minimizes the loss function, or in\nother words best matches key characteristics of a given target image x̂.\nThe loss function in Bhaduri et al. was defined as a linear combination of 3 components: the gram matrix loss LG , the total variation loss LT , and the 2 point probability\nloss, LP :\nL(x) = wg LG + wt LT + wp LP\n\n(4.2)\n\nWeights were used to account for the relative differences in magnitude of each metric.\nInterestingly, despite having been historically referenced as an effective means of\ncharacterizing material architecture [147], Bhaduri et al. found that the inclusion of\nthe two-point probability function directly into the loss function had a negligible effect\non the performance. As such, this is excluded from the loss function in this work (e.g.\nset wp = 0), as computing the two-point probability function at every iteration of the\noptimization adds significant computational effort.\n\n120\n\nCHAPTER 4. EVALUATING COMPUTATIONAL MODELS\n\n4.2.1.1\n\nGram matrix\n\nThe gram matrix loss is the primary driver of our optimization problem, generally\ntaken as a high order measurement of the similarities between a target image x̂ and\na given reconstruction x. Those similarities are captured though the application\nof image processing filters, the most common of which are in the form of weighted\naveraging. A specific set of filters defines what is known as the network architecture,\nand the VGG-19 network [145] is a very commonly used and understood set that has\nbeen trained on extensive image data from many applications.\nWith a set of filters (i.e. a network) in hand, both x̂ and x are passed through\nl\nthe network. For each network layer (i.e. a subset of filters) a feature map Fjk\nis\n\ncomputed, which stores the value of the activation of the j th filter at position k in\nlayer l. These feature maps are then processed to remove any spacial dependence by\ncomputing the gram matrix:\n\nGlij =\n\nX\n\nFik l Fjk l\n\n(4.3)\n\nk=1\n\n[146]\nWhere Glij is a neural network response map for the measured correlations between\nthe ith and j th feature maps in layer l. Once a gram matrix has been computed for\nx and x̂, yielding Glij and Ĝlij respectively, the gram matrix loss is computed as the\nleast squares difference between the two [146]:\n\n121\n\nCHAPTER 4. EVALUATING COMPUTATIONAL MODELS\n\nLG =\n\nL\nX\nl=1\n\nWl\n\nm X\nn\nX\n\n[Glij − Ĝlij ]2\n\n(4.4)\n\ni=1 j=1\n\nwith\nWl =\n\nwl\n4Nl2 Ml2\n\n(4.5)\n\nwhere L is the number of layers, Nl is the number of filters in each layer and Ml is\nthe size of each filter. The layer weight wl is sometimes varied in order to weight\ncertain layers, filter some layers more heavily than others, or to remove intermediate\nlayers from the loss calculation to improve computational performance [148]. The\nchoice of an appropriate network and the subsequent assignment of layer weights wl\nis very much an active research area with differing opinions. Part of the popularity\nof the VGG-19 network stems from its training on image classification. The layers\nand layer weights it uses were learned as part of its extensive development process.\nTherefore, changing weights internal to the network will introduce uncertainty about\nthe relative proportions of all of the other learned weights in the system. As such,\nthis work treats them as a single fixed network layer, with the understanding that\nthe standard implementation of in-network layers remains unchanged. Therefore, the\ngram matrix loss is simplified as:\n\nLG = summ\ni=1\n\nn\nX\nj=1\n\n122\n\n[Gij − Ĝij ]2\n\n(4.6)\n\nCHAPTER 4. EVALUATING COMPUTATIONAL MODELS\n\nFigure 4.1: Example of the high frequency checker boarding which arises naturally\nduring the evolution of the reconstructed image.\n\n4.2.1.2\n\nTotal varition loss\n\nWhen reconstructing microstructures based solely on the gram matrix loss, localized regions of spurious checkerboard patterns are observed (see figure 4.1). Total\nvariation (TV) loss is incorporated here to reduce these high frequency noise artifacts.\nAdding this to the loss function has been shown to speed up the overall optimization\nby removing the high frequency checker boarding more quickly, resulting in images\nwhich have relatively small amount of noise [86]. Some reconstruction methods use\npost processing operations to directly reduce or eliminate noise [84] as an alternative,\nbut such approaches are somewhat ad hoc.\nTV is defined as the absolute difference between neighboring pixels. For an m × n\n\n123\n\nCHAPTER 4. EVALUATING COMPUTATIONAL MODELS\n\nimage X the TV is\n\nTV =\n\nm−1\nn−1\nXX\n\n|Xi,j − Xi,j+1 | + |Xi,j − Xi+1,j |\n\n(4.7)\n\ni=1 j=1\n\n[149]\nIn the literature less attention is placed on the TV weight than on other aspects\nof the loss function, like the gram matrix layer weights. The current best practice\nis to manually adjust the TV weight, relying on a visual inspection of the noise to\ncalibrate the weight, as values for wt reported in the literature range from 1e-6 [85]\nto 1012 [86], depending on the range of image intensity values (i.e. binary [0 1] vs 8\nbit [0 255]) and the image sizes (i.e. 2D vs 3D network images).\n\n4.3\n\nPerformance Indicators\n\nIn previous works, the transfer learning model’s performance was measured relative to geometric descriptors such as the two-point probability function. Bhaduri\net al. later extended their performance metrics to include effective thermomechanical\nproperties calculated via Finite Element Analysis (FEA) simulation. Their approach\nwas tested on a set of 185 slices of a porous ceramic microstructure measured via\nx-ray tomography, an example of which is shown in figure 4.2. The reconstructed\nimages were shown to have similar elastic material properties compared to those of\nthe 185 porous ceramic slices. The average absolute error was just under 5% (with\n\n124\n\nCHAPTER 4. EVALUATING COMPUTATIONAL MODELS\n\nFigure 4.2: One slice of 185 taken of a porous material.\n\n125\n\nCHAPTER 4. EVALUATING COMPUTATIONAL MODELS\n\nQ1 ' 2.5% and Q3 ' 7.5%) for the elastic modulus, however the error in the effective thermal conductivity was significantly higher at ' 17.5% (with Q1 ' 9% and\nQ3 ' 25%). This difference in performance was attributed to thermal conductivity’s\ngreater dependance on localizations, which are inherently harder to capture in these\nreconstructions.\nThe present study builds on this previous work and aims to quantify the “endto-end” uncertainty as it relates to generating and using reconstruction for FEA\nsimulations. To achieve this, two virtual material samples will be used to generate\nreconstructions with the transfer learning model over a wider range of initial values.\nThe error in the volume fraction, the effective thermal conductivity, and the effective\nelastic modulus will be quantified for both the virtual ”ground truth” materials and\nthe reconstructed microstructure generated through the transfer learning algorithm.\nThe 185 slices of a porous ceramic microstructure in the previous work had a\nrelatively narrow range of volume fractions. The current materials probe a wider\nrange of volume fractions in the virtual materials. The two virtual materials (generally\nclassified as being a 2-phase solid/void porous structure) were created as follows:.\nMaterial 1 was generated by randomly placement of randomly sized spheres into an\nempty 550x950x350 volume, until a minimum threshold volume fraction was achieved.\nThen using an ellipsoidal growth model [82], each grain was grown until the entire\nvolume was filled. Grains were then randomly assigned to the solid/void phase.\nA swapping filler was used to change phase assignments of a few individual pixels\n\n126\n\nCHAPTER 4. EVALUATING COMPUTATIONAL MODELS\n\n(a) Material 1 Slice\n\n(b) Reconstructed Image\n\nFigure 4.3: Material Type #1 - Comparison of (a) material image and (b) reconstructed image. Black pixels denote the solid phase.\n\nnear grain boundaries until the exact target volume fraction was achieved Material\n2 was generated by repeatedly generating a randomly sized 3D ellipsoid, randomly\norientating it, and then placing into a solid volume until a predetermined volume\nfaction was achieved. The ellipsoids were assigned to the void phase, thereby ensuring\nfull connectivity of the solid phase.1 . Both materials were cropped to 500x900x300\nvoxels and sliced into 300 images. A representative slice for each material is shown in\nfigures 4.3a and 4.4a, along with an example of a reconstruction of that slice. Finally,\neach material phase was also assigned material properties as list in table 4.1). These\nproperties were later used as part of finite element analysis (FEA) when characterizing\nthe effective material properties.\n\n1\n\nEllipsoids were allowed to over lap freely to allow for void region connectivity\n\n127\n\nCHAPTER 4. EVALUATING COMPUTATIONAL MODELS\n\n(a) Material 2 Slice\n\n(b) Reconstructed Image\n\nFigure 4.4: Material Type #2 - Comparison of (a) material image and (b) reconstructed image. Black pixels denote the solid phase.\n\n4.3.1\n\nFEA model descriptions\n\nThe effective young’s modulus (Ē):\n\nĒ =\n\nσ̄yy\n\u000f ̄yy\n\n(4.8)\n\nwas determined from the nodal reaction forces found from a plane strain FEA analysis,\nusing an applied displacement uy applied to the top edge of the sample. The effective\nthermal conductivity (λ̄) was found using an FEA heat conduction model with a 30\nK ◦ temperature gradient applied to the top and bottom surfaces of the slice.\nThe effective properties calculated from each slice were combined to provide a distribution of properties for the target microstructures. Figure 4.5 shows a convergence\nplot of the Root Mean Squared Error (RMSE) between the distributions calculated\nwith N volumes and those calculated from N + 1 volumes (each volume represented\n300 slices). In total, 25 volumes and 7500 slices were used to quantify the effective\n128\n\nCHAPTER 4. EVALUATING COMPUTATIONAL MODELS\n\nTable 4.1: Material property assignments for the two phase phases. During the\nimplementation of the finite element models that void phase was model with material\nproperties more closely resembling a waker secondary solid al simulations were elastic.\n\nFigure 4.5: Convergence of the virtual material property distributions using RMSE\nchange in the properties PDF. Sufficient convergence was set at < 2% change.\n\n129\n\nCHAPTER 4. EVALUATING COMPUTATIONAL MODELS\n\n(a) Elastic Modulus\n\n(b) Effective Thermal Coefficient\n\n(c) Volume Fraction\n\nFigure 4.6: Histograms of the material properties of each material. The 185 slices\nused in the previous study are plotted as a reference.\n\n130\n\nCHAPTER 4. EVALUATING COMPUTATIONAL MODELS\n\nproperty distributions of the target materials.\n\n4.4\n\nResults\n\nSince each reconstruction is generated from a randomly selected seed, or a random\nwhite noise image, there is variability in effective properties from one reconstruction to\nthe next. In order to study this more carefully, a single characteristic slice from each\nmaterial was selected to serve as a target microstructure. 350 reconstructed images\nwere generated from each of the target slices. In Figures 4.7 and 4.8, histograms\nfor various properties are shown for 350 unique reconstruction images, all generated\nfrom a single representative target slice of that particular material. In all cases, the\nhistograms appeared to carry some bias relative to the target value. For example, the\nvolume fraction of the target image of material 2 was 56.5%, as opposed to an average\nof 55.9% for the reconstructed images, a small difference of just 1.19 %. However, the\naverage effective thermal conductivity for the 350 reconstructions of material 1 was\n11.53% below the effective thermal conductivity of the target material.\nIn order to evaluate the significance of these measurements, the difference from\nthe target material properties is plotted as a function of the number of reconstructed\nimages in Figure 4.9. The reconstruction converges fairly quickly, only requiring 10 20 reconstructions to show convergence in the percent difference.\nCollectively, figures 4.7a - 4.8c represent results from a large pool of reconstruc-\n\n131\n\nCHAPTER 4. EVALUATING COMPUTATIONAL MODELS\n\n(a) Volume Fraction\n\n(b) Elastic Modulus\n\n(c) Effective Thermal Coefficient\n\nFigure 4.7: Histograms of the material properties for material 1 computed from a set\nof 350 reconstructions of a single target. The (a) the average volume fraction ' −1.12\n% lower, (b) the average elastic modulus ' 4 % lower and (c) the average change\n' −11.53 % lower.\n\n132\n\nCHAPTER 4. EVALUATING COMPUTATIONAL MODELS\n\n(a) Volume Fraction\n\n(b) Elastic Modulus\n\n(c) Effective Thermal Coefficient\n\nFigure 4.8: Histograms of the material properties for material 2 computed from a set\nof 350 reconstructions of a single target. The (a) the average volume fraction ' −1.19\n% lower, (b) the average elastic modulus ' −4.6 % lower and (c) the average change\n' −2.25 % lower.\n\n133\n\nCHAPTER 4. EVALUATING COMPUTATIONAL MODELS\n\nFigure 4.9: The relative bias, (B)i = μ(d ̄p )i − Imi , converges quickly. In all cases\n15 reconstructions was sufficient to ensure less than a 1% change. The std. (σ) also\ncoverages quickly.\n\n134\n\nCHAPTER 4. EVALUATING COMPUTATIONAL MODELS\n\nTable 4.2: Looking across multiple studies the down side press on material properties\nis significant. Data does not include and cropped images.\n\ntions but they originate from only a single target sample of each material. To more\nadequately assess systematic bias, a new study with 25 different target slices from\neach of material 1 and material 2 was performed. Each target slice was used in turn\nto generate 25 reconstructions, leading to a total of 225 reconstructed images for\neach material. The results confirm the presence of a systemic model bias for volume\nfraction measurements. Figure 4.10 shows the average volume fraction, Vb , for each\nbatch of 25 reconstructed microstructures vs. the volume fraction of the input image.\nOnly 2 of 25 Material 1 and 5 of 25 Material 2 input slices in this study had a lower\nvolume fraction than the mean of reconstructed microstructures. There is also a clear\ndifference between material 1 and 2 with material 2 having ∼ 50% smaller bias. The\nexact reason behind this is unknown as of yet, but is a subject of continued study.\nThe effects on the thermal and elastic properties are less clear. There is still a\nstatistically significant bias (see table4.2); however, some of this is probably tied to\n\n135\n\nCHAPTER 4. EVALUATING COMPUTATIONAL MODELS\n\nFigure 4.10: Relative volume fraction bias for the Input Image vs. Reconstruction\nfor 25 different slices of Material 1 and Material 2 . Each point is the mean volume\nfraction from 25 images reconstructions.\n\n136\n\nCHAPTER 4. EVALUATING COMPUTATIONAL MODELS\n\nFigure 4.11: Relative Shift for in λ and E.\n\nthe bias of the volume fraction. The bigger issue appears to be significant variations\nin the effective properties for material 1 reconstructions relative to the target properties (see figure 4.16). The large scatter in the effective thermal conductivity and\nelastic modulus of material 1 in figure 4.6b might indicate that the 500x900 px image\nsize was insufficiently large, failing to be statistically representative of the material.\nComparatively, in figure 4.16 the spread of the transfer learning model reconstructions was much smaller for material 2, but without a valid result from material 1 as\na comparison, no definitive judgements can be made.\nIn investigating these results it is apparent that the reconstructed microstructures\nshow some distortion at the edges, in the form of preferential placement of white\npixels near the boundaries. This was investigated as a possible cause for the lack of\nagreement from these effective property results.\n\n137\n\nCHAPTER 4. EVALUATING COMPUTATIONAL MODELS\n\n4.4.1\n\nBoundary Distortion Study\n\nThe reconstructed images show a slight preferential bias when placing the material\nnear the edges of the image. It is not obvious from a single reconstructed image but\ncan be observed when viewing the average of many reconstructed images as shown in\nfigure 4.12. If the placement of features were truly random2 we’d expect that in the\nlimit as N → ∞ the averaged image would become a smooth solid gray image with\npixel values AvgI(i, j) ' Vf . This was not the case with the reconstructed images.\nFigures 4.12 and 4.13 clearly show that the reconstructed images have preferential\nplacement near the boundary. To quantify this bias we compute the variance of the\npixel values in the image. The reconstructed images had variances of 3.8e−3 (Material\n1) and 2.8e − 3 (Material 2), compared to 1.3e − 3 for the white noise images.\n\n(a) Type #2\n\n(b) White Noise Image\n\nFigure 4.12: Averaged Images computed from (a) 200 reconstructions and (b) 200\nwhite noise images.\n\n2\n\nRandom placement does not mean that the image has no structure, but rather that the structure\n\nit does have is randomly located.\n\n138\n\nCHAPTER 4. EVALUATING COMPUTATIONAL MODELS\n\nVolume Fraction\n\nElastic Modulus\n\nThermal Coefficient\n\nType 1 Cropped\n\n2.0%\n\n8.0%\n\n-10.5%\n\nType 1 NonCropped\n\n-1.1%\n\n4.0%\n\n-11.5%\n\nType 2 Cropped\n\n1.4%\n\n3.1%\n\n4.5%\n\nType 2 NonCropped\n\n-1.2%\n\n-4.6%\n\n-2.3%\n\nType 3 Cropped\n\n2.7%\n\n0.4%\n\n3.0%\n\nType 3 NonCropped\n\n-0.5%\n\n-6.8%\n\n-12.6%\n\nTable 4.3: The relative percent difference of the mean reconstructed value vs. seed\nslice value of various material properties. The effect of oversizing and cropping the\nimage resulted in a universal positive shift in the volume fraction. Effects for other\nproperties differed for the three different material types. Cells highlighted in red show\nwhere cropping had a net negative effect on the property measure, cells in blue show\na positive net effect.\n\n139\n\nCHAPTER 4. EVALUATING COMPUTATIONAL MODELS\n\n(a) M1 - No crop\n\n(b) M1 -Cropped\n\nFigure 4.13: Averaged Images computed from 200 reconstructions for Material: (a)\nnot cropped and (b) cropped. The variance were (a) 3.8e − 3 and (b) 1.3e − 3.\n\nOne proposed method for correcting this bias is to reconstruct an oversized image and crop out the edges, in order to remove the biases at the boundaries. This\nmethod works well at removing the boundary shading as can be seen in figure 4.14.\nHowever, it has a negative consequence of distorting the volume fraction of the image. Because there is a preference towards placing white pixels near the boundary,\ncropping removes proportionally more white pixels and biases the volume fraction\ntowards black pixels. This is clearly visible in figure 4.15. Cropping the image shifts\nthe volume fraction higher by about 4%, which also affects the other material properties. These effects are highlighted in table 4.3. Unfortunately, this distortion also\nmeans that no determination could be made about whether the variability observed\nin the reconstructed properties of material 1 was caused by the boundary distortion.\n\n140\n\nCHAPTER 4. EVALUATING COMPUTATIONAL MODELS\n\nFigure 4.14: Reconstructed image was oversized and an undistorted region was\ncropped out of the center.\n\n141\n\nCHAPTER 4. EVALUATING COMPUTATIONAL MODELS\n\nFigure 4.15: Variation in volume fraction of the 200 reconstructed images is significantly higher for the cropped images.\n\n142\n\nCHAPTER 4. EVALUATING COMPUTATIONAL MODELS\n\nFigure 4.16: Relative Shift for in λ and E.\n\n4.4.2\n\nAdditional Issues with The Total Variation\nLoss\n\nIn addition to the boundary distortion, another issue was observed with the total\nvariation. When the weight of the total variation parameter is adjusted, the reconstructions sometimes fail. Figure 4.17 shows the evolution of the loss function and\nthe resulting reconstruction image after 300 steps for two different reconstructions.\nThe only difference between these images is an adjustment to the TV weight, but the\nsecond reconstruction completely fails to capture relevant microstructural features.\nHowever, the issue is more complex than just selecting the correct TV weight. TV\nloss and GM loss scales differently when the reconstructed image size is changed to\naccommodated the cropping approach. They also scale differently when the target\nimage is changed from material 1 to material 2. An effort was made to diagnose this\n143\n\nCHAPTER 4. EVALUATING COMPUTATIONAL MODELS\n\nFigure 4.17: Changing the Total Variation weight from (A) 1e-3 to (B) 1e-1 dramatically changed the reconstruction. Initially Reconstruction (B) began to converge\nmuch quicker but it soon formed large blobs that are clearly an unacceptable result.\n\neffect, by comparing the relative size of the gram matrix and total variation loss, but\nno clear relation or link was found. Further investigation of this effect is needed and\nis part of an ongoing effort.\n\n4.5\n\nSummary Findings\n\nIn this chapter a transfer learning model for microstructure reconstruction of 2\nphase porous materials was evaluated. The model was tested with two virtual ma-\n\n144\n\nCHAPTER 4. EVALUATING COMPUTATIONAL MODELS\n\nterials and used to create numerous reconstructions from various target slices. The\ntransfer learning model was found to have a bias towards reducing the volume fraction, elastic modulus, and effective thermal coefficients of the reconstruction images\ncompared to the target images. Approximately ∼ 70% of the reconstruction saw a\nreduction in their material property values. Two challenges were identified which\nprevented a more complete evaluation of the uncertainty introduced by the model. A\npreference towards placing white pixels near the boundary and a relationship between\nthe magnitudes of the gram matrix and total variation loss. Attempts were made to\nidentify solutions to these challenges, however the source of the problem was never\nproperly identified and no reliable solution was found. This is the subject of ongoing\nresearch.\n\n145\n\nChapter 5\nConclusion\nQuantifying uncertainties associated with materials characterization is a broad\nand far reaching challenge. The development of the uncertainty quantification framework established the viability of using virtual materials as a backbone for future\nstudies. Ultimately this thesis covered only a small number of materials characterization uncertainties. The wide range of applications and experimental techniques made\nit necessary to focus on smaller subclasses of image-based characterization methods.\nHowever, the results from each chapter looked at uncertainty quantification at a few\ndifferent scales. Chapter 2 looked at uncertainty at the materials workflow level,\nexamining how errors propagate from experiments to models. Chapter 3 quantified\nthe uncertainty at a materials characterization level, studying how imaging resolution\nintroduced error and how that error links directly to measurements. Chapter 4 evaluated a ML-based approach to efficient generation of virtual 2-phase microstructures\n\n146\n\nCHAPTER 5. CONCLUSIONS AND FUTURE DIRECTIONS\n\nand identified some issues that arise when using this technique.\n\n5.1\n\nChapter 2\n\nIn this chapter a computational model for simulating the collection of EBSD\ndata was built to assess how experimental design choices propagated through to the\ncomputational modeling. This study represents a true “end to end” analysis of the\nuncertainty propagation. The main finding is that many smaller forms of error such\nas the random noise are easily overshadowed by the constraints of the computational\nmodel. Imaging resolution emerge as the largest source of error. When sampling\nat high resolutions, too few grains are resolved and the grain boundary network is\nnot fully captured. There were several examples of operations that work against\neach other. For example, the meshing operation included a smoothing algorithm\nthat worked against the high resolution data collection efforts. It enables an extra\ndegree of freedom in the post processing algorithms that slightly shifts the grain\nboundaries, which makes a more significant difference in the high resolution image.\nAnother example of this is in increasing the beam dwell time. Dwell time is modeled\nthrough the introduction of random noise, which is easily removed in the data cleaning\noperations. There is of course a limit to this ability to clean up the image, but for\nthe most part shorter dwell times does not have a significantly adverse effect on the\nresults.\n\n147\n\nCHAPTER 5. CONCLUSIONS AND FUTURE DIRECTIONS\n\nAs an illustration of the functionality of the uncertainty quantification framework\nthe study was successful. The importance of carrying experimental uncertainties\nthrough to computational models was clearly demonstrated. The results about the\nresolution are important as well. When constraints are placed on the number of\nmeasurements which can be made, the decision to try to collect the highest resolution\ndata was exposed. This showed that at a full workflow level the balance of sampling\nerror vs. measurement error is a key issue.\nThe main limitation of this study is its application to a linear elastic material\nmodel. Expanding this study to incorporate plasticity in any form would help better\ncapture the relative effects of some the errors. Resolution is still likely be the main\nsource of error, but it would be interesting to assess the interplay between functions\nlike the mesh smoothing and resolution for these problems. Attempts to add more\nrealism to the model through more explicitly representing the data collection components (such as a more detailed interaction volume simulation) would likely yield\nsimilar results for linear elasticity, but could be significantly different for more complex material behavior.\n\n5.1.1\n\nChapter 3\n\nIn chapter 3 conditional measurement distributions were established to link an\napproximate measurement with the distribution of the associated true value. The\nfundamental concept is to capture the natural uncertainty of a measurement at the\n148\n\nCHAPTER 5. CONCLUSIONS AND FUTURE DIRECTIONS\n\nresolution at which is was collected. This concept was validated with an analytical\nmodel for measuring the area of a rectangular feature, but geometric limitations motivated a simulation based study. The measurement error distribution was computed\nfor measurements taken on an assumed crystalline structure. It was verified through\ndetailed studies for the assumed prior distributions and through application to 4 different measurements (size, aspect ratio, and 2 perimeter measurements). Results\nfollowed our intuition about the quality of the different measurements. For example,\nthe general understanding that a 500 px/feature resolution is more accurate than a\n100 px/feature measurement, can be replaced with a statement about difference in\ntheir coefficient of variation.1 It also shows that we can accept more small measurements (¡100 px), as their variation was quantified and shown to be well behaved and\nbounded. Results from the construction of property distributions showed that sampling error is often larger than measurement error and we should be careful aiming\nto only collect the highest possible resolution data, if there is a fixed budget for characterization. Resolution at the expense of a statistically significant set of features\nmight not be the optimal choice. Results also show that different measurement types\nhave different optimal resolutions. The optimal sampling resolutions for perimeter\nmeasurements are much higher than those for the the measured size. Helping determine standards for other types of measurements is one potential application of the\nconditional measurement distributions.\n\n1\n\nCV100 = 0.036 vs. CV500 = 0.016\n\n149\n\nCHAPTER 5. CONCLUSIONS AND FUTURE DIRECTIONS\n\nOne powerful application is the ability to infer measurement uncertainties from\ndata that does not have clear error bands. If a data source contains the original images\nor pixel measurements, it can be reanalyzed to incorporate a conditional measurement\ndistribution that might allow the data to be used in new ways. A potential practical\napplication of this would be to pull multiple smaller data sets together to form a larger\ndata set. The conditional measurement distribution accounts for the differences in\nmeasured size and properly weight each data point accordingly. This concept is an\ninteresting future direction. An application such as this would be useful for validating\nthe utility of the data and to motivate an effort to evaluate an expanded measurement\ndistribution.\nOne caution to using this process is that the assumed microstructural features\ngenerated in the simulation must reasonably represent the physical material, or else\nthe conditional measurement distribution will be unrealistic. Ultimately, this needs\nto be validated by a subsequent study with exhaustive experimental data. However,\nthe mathematical formulation of the model is sound, and shifts in the shape seeds are\nnot shown to have a significant effect on the results so that minor deviations from\nreality are not expected to introduce major errors in the conditional measurement\ndistribution.\nThe conditional measurement distribution was demonstrated for 2D tessellation\ngrains, but the model is generalizable and could easily expanded to 3D2 , which would\n\n2\n\nConceptually moving to 3D would not be difficult but it would be computationally expensive.\n\n150\n\nCHAPTER 5. CONCLUSIONS AND FUTURE DIRECTIONS\n\nadd significant utility.\n\n5.1.2\n\nChapter 4\n\nIn chapter 4 a transfer learning model for microstructure reconstruction was reviewed. The goal of this study was to assess how the transfer learning model propagated known variations between two materials. It was used to reconstruct two\ndifferent virtual microstructures and quantify how much variation in reconstructions\nexisted compared to the original materials. The quality of reconstructions was assessed via computed material properties such as the elastic modulus and the effective\nthermal conductivity. Results showed the model produced biased reconstructions.\n∼ 70% of the reconstructions had smaller average property values than the original\nseed images. The variability of the reconstructions was also different for the two\nmaterials, although the reasoning for this was not determined. Another issue that\nwas identified was the preferential bias of reconstruction to placing white pixels near\nthe boundary. Attempts to correct for this were not entirely successful, and as such\nmade making further quantitative assessments (e.g. about the variability) difficult.\nGeneralizing this challenge, the lack of knowledge about how machine learning\nmodel work inside the algorithm means that our understanding of how they propagate\nuncertainties is lacking. A careful consideration of the internal workings of these\nAny practical expansion to 3D would benefit from a redevelopment of codes with computational\nefficiency in mind.\n\n151\n\nCHAPTER 5. CONCLUSIONS AND FUTURE DIRECTIONS\n\nmodels is needed to trace errors to their source.\n\n5.2\n\nFuture Directions\n\nA short term task which remains to be completed is the identification of uncertainty sources in the machine learning model. This involves adapting the approach\nto monitor the sub-steps of the model. This will hopefully lead to a clearer methodology for dealing with complex machine learning uncertainties. In the longer term,\nthere is real potential to apply some of the principles of conditional measurement\ndistributions to a physical workflow. For example, using the model for experimental\nEBSD simulation to help set up and optimize the use of an actual SEM lab would be\na suitable demonstration of the power of this approach. Not only would this validate\nthis approach, but it would also facilitate and apply structure to a complex task.\n\n5.3\n\nConcluding Remarks\n\nIn closing, the potential of virtual materials to aid in the development and application of uncertainty quantification methods needs to be emphasized. They are\nextremely versatile and can be created quickly or laboriously depending on the application. Most importantly is the clarity they provide. Data collection is by definition\ninvestigative, meaning that it is unknown what is in the system. This makes it very\nhard to know what the end product should be. A virtual material can alleviate this\n152\n\nCHAPTER 5. CONCLUSIONS AND FUTURE DIRECTIONS\n\nunknown.\n\n153\n\nBibliography\n[1] National Science and Technology Council (US). Materials genome initiative for\nglobal competitiveness. Executive Office of the President, National Science and\nTechnology Council, 2011.\n[2] Juan-Pablo Correa-Baena, Kedar Hippalgaonkar, Jeroen van Duren, Shaffiq Jaffer, Vijay R Chandrasekhar, Vladan Stevanovic, Cyrus Wadia, Supratik Guha,\nand Tonio Buonassisi. Accelerating materials development via automation, machine learning, and high-performance computing. Joule, 2(8):1410–1420, 2018.\n[3] Martin L Green, CL Choi, JR Hattrick-Simpers, AM Joshi, I Takeuchi, SC Barron, E Campo, T Chiang, S Empedocles, JM Gregoire, et al. Fulfilling the\npromise of the materials genome initiative with high-throughput experimental\nmethodologies. Applied Physics Reviews, 4(1):011105, 2017.\n[4] Nicola Nosengo. Can artificial intelligence create the next wonder material?\nNature News, 533(7601):22, 2016.\n[5] Kathleen Feldman and Sean R Agnew. The materials genome initiative at\n154\n\nBIBLIOGRAPHY\n\nthe national science foundation: A status report after the first year of funded\nresearch. JOM, 66(3):336, 2014.\n[6] Anubhav Jain, Shyue Ping Ong, Geoffroy Hautier, Wei Chen, William Davidson\nRichards, Stephen Dacek, Shreyas Cholia, Dan Gunter, David Skinner, Gerbrand Ceder, et al. Commentary: The materials project: A materials genome\napproach to accelerating materials innovation. APL materials, 1(1):011002,\n2013.\n[7] Dennis M. Dimiduk, Elizabeth A. Holm, and Stephen R. Niezgoda. Perspectives\non the impact of machine learning, deep learning, and artificial intelligence\non materials, processes, and structures engineering. Integrating Materials and\nManufacturing Innovation, 7(3):157–172, 2018.\n[8] Nikola Kovachki, Burigede Liu, Xingsheng Sun, Hao Zhou, Kaushik Bhattacharya, Michael Ortiz, and Andrew Stuart. Multiscale modeling of materials:\nComputing, data science, uncertainty and goal-oriented optimization. Mechanics of Materials, 165:104156, 2022.\n[9] Armen Der Kiureghian and Ove Ditlevsen. Aleatory or epistemic? does it\nmatter? Structural safety, 31(2):105–112, 2009.\n[10] Scott Ferson and Lev R Ginzburg. Different methods are needed to propagate\nignorance and variability. Reliability Engineering & System Safety, 54(2-3):133–\n144, 1996.\n155\n\nBIBLIOGRAPHY\n\n[11] Jon C Helton, Jay D Johnson, William L Oberkampf, and Cedric J Sallaberry.\nRepresentation of analysis results involving aleatory and epistemic uncertainty.\nInternational Journal of General Systems, 39(6):605–646, 2010.\n[12] Thomas Augustin and Marco Cattaneo. Foundations of probability. International Encyclopedia of Statistical Science, 2011.\n[13] Michael Beer, Scott Ferson, and Vladik Kreinovich. Imprecise probabilities in\nengineering analyses. Mechanical systems and signal processing, 37(1-2):4–29,\n2013.\n[14] John Taylor. Introduction to error analysis, the study of uncertainties in physical measurements. 1997.\n[15] Jiaxin Zhang and Michael D Shields. On the quantification and efficient propagation of imprecise probabilities resulting from small datasets. Mechanical\nSystems and Signal Processing, 98:465–483, 2018.\n[16] Michael S Eldred, Laura Painton Swiler, and Gary Tang.\n\nMixed\n\naleatory-epistemic uncertainty quantification with stochastic expansions and\noptimization-based interval estimation.\n\nReliability Engineering & System\n\nSafety, 96(9):1092–1113, 2011.\n[17] T Igusa, SG Buonopane, and BR Ellingwood. Bayesian analysis of uncertainty\nfor structural engineering applications. Structural Safety, 24(2-4):165–186, 2002.\n\n156\n\nBIBLIOGRAPHY\n\n[18] Yudi Pawitan. In all likelihood: statistical modelling and inference using likelihood. Oxford University Press, 2001.\n[19] Th Fetz and Michael Oberguggenberger. Propagation of uncertainty through\nmultivariate functions in the framework of sets of probability measures. Reliability Engineering & System Safety, 85(1-3):73–87, 2004.\n[20] Burigede Liu, Xingsheng Sun, Kaushik Bhattacharya, and Michael Ortiz. Hierarchical multiscale quantification of material uncertainty. Journal of the Mechanics and Physics of Solids, 153:104492, 2021.\n[21] Xiaolei Yin, Wei Chen, Albert To, Cahal McVeigh, and Wing Kam Liu. Statistical volume element method for predicting microstructure–constitutive property\nrelations. Computer methods in applied mechanics and engineering, 197(4344):3516–3529, 2008.\n[22] Martin Ostoja-Starzewski. Material spatial randomness: From statistical to\nrepresentative volume element. Probabilistic engineering mechanics, 21(2):112–\n132, 2006.\n[23] Toufik Kanit, Samuel Forest, Isabelle Galliet, Valérie Mounoury, and Dominique\nJeulin. Determination of the size of the representative volume element for\nrandom composites: statistical and numerical approach. International Journal\nof solids and structures, 40(13-14):3647–3679, 2003.\n\n157\n\nBIBLIOGRAPHY\n\n[24] Katherine A Acton, Sarah C Baxter, Bahador Bahmani, Philip L Clarke, and\nReza Abedi. Voronoi tessellation based statistical volume element characterization for use in fracture modeling. Computer Methods in Applied Mechanics\nand Engineering, 336:135–155, 2018.\n[25] Akbar Bagri, George Weber, Jean-Charles Stinville, William Lenthe, Tresa\nPollock, Christopher Woodward, and Somnath Ghosh. Microstructure and\nproperty-based statistically equivalent representative volume elements for polycrystalline ni-based superalloys containing annealing twins. Metallurgical and\nMaterials Transactions A, 49(11):5727–5744, 2018.\n[26] Shravan Kotha, Deniz Ozturk, and Somnath Ghosh. Uncertainty-quantified\nparametrically homogenized constitutive models (uq-phcms) for dual-phase α/β\ntitanium alloys. npj Computational Materials, 6(1):1–20, 2020.\n[27] N. Vu-Bac, T. Lahmer, Y. Zhang, X. Zhuang, and T. Rabczuk. Stochastic predictions of interfacial characteristic of polymeric nanocomposites (pncs). Composites Part B: Engineering, 59:80–95, 2014.\n[28] N Vu-Bac, Roham Rafiee, Xiaoying Zhuang, Tom Lahmer, and Timon Rabczuk.\nUncertainty quantification for multiscale modeling of polymer nanocomposites\nwith correlated parameters. Composites Part B: Engineering, 68:446–464, 2015.\n[29] Shankar Sankararaman, You Ling, and Sankaran Mahadevan. Uncertainty\n\n158\n\nBIBLIOGRAPHY\n\nquantification and model validation of fatigue crack growth prediction. Engineering Fracture Mechanics, 78(7):1487–1504, 2011.\n[30] Felipe Lopez, Paul Witherell, and Brandon Lane. Identifying uncertainty in\nlaser powder bed fusion additive manufacturing models. Journal of Mechanical\nDesign, 138(11), 2016.\n[31] Pinar Acar and Veera Sundararaghavan. Uncertainty quantification of microstructural properties due to experimental variations.\n\nAIAA Journal,\n\n55(8):2824–2832, 2017.\n[32] Pinar Acar and Veera Sundararaghavan. Do epistemic uncertainties allow for\nreplacing microstructural experiments with reconstruction algorithms? AIAA\nJournal, 57(3):1078–1091, 2019.\n[33] Pengda Niu, Ruidi Li, Shuya Zhu, Minbo Wang, Chao Chen, and Tiechui Yuan.\nHot cracking, crystal orientation and compressive strength of an equimolar cocrfemnni high-entropy alloy printed by selective laser melting. Optics and Laser\nTechnology, 127:106147, 2020.\n[34] Aakash Bangalore Satish et al. Multimodel Bayesian estimation of total uncertainty and its application to modeling the yield strength of structural aluminum\nat elevated temperature. PhD thesis, Johns Hopkins University, 2020.\n[35] Vicente J Romero, JF Dampsey, Ben Schroeder, John Lewis, Nicole Breivik,\n\n159\n\nBIBLIOGRAPHY\n\nGeorge Orient, Bonnie Antoun, Justin Winokur, and Matthew Glickman. Evaluation of a simple uq approach to compensate for sparse stress-strain curve data\nin solid mechanics applications. In 19th AIAA Non-Deterministic Approaches\nConference, page 0818, 2017.\n[36] B Roebuck. Measurement of grain size and size distribution in engineering\nmaterials. Materials science and technology, 16(10):1167–1174, 2000.\n[37] M Fátima Vaz and MA Fortes. Grain size distribution: The lognormal and the\ngamma distribution functions. Scripta metallurgica, 22(1):35–40, 1988.\n[38] B. Raeisinia and C.W. Sinclair. A representative grain size for the mechanical\nresponse of polycrystals. Materials Science and Engineering: A, 525(1):78–82,\n2009.\n[39] Torsten Luther and Carsten Könke. Polycrystal models for the analysis of intergranular crack growth in metallic materials. Engineering Fracture Mechanics,\n76(15):2332–2343, 2009.\n[40] Timothy John Sullivan. Introduction to uncertainty quantification, volume 63.\nSpringer, 2015.\n[41] Dave M Higdon, Mark C Anderson, Salman Habib, Richard Klein, Mark\nBerliner, Curt Covey, Omar Ghattas, Carlo Graziani, Mark Seager, Joseph\n\n160\n\nBIBLIOGRAPHY\n\nSefcik, Philip Stark, and James Stewart. Uncertainty quantification and error\nanalysis. U.S. Department of Energy, 2010.\n[42] EO Hall. The deformation and ageing of mild steel: Iii discussion of results.\nProceedings of the Physical Society. Section B, 64(9):747, 1951.\n[43] NJ Petch. The cleavage strength of polycrystals. Journal of the iron and steel\ninstitute, 174:25–28, 1953.\n[44] S.P. Donegan, J.C. Tucker, A.D. Rollett, K. Barmak, and M. Groeber. Extreme value analysis of tail departure from log-normality in experimental and\nsimulated grain size distributions. Acta Materialia, 61(15):5595–5604, 2013.\n[45] Y. A. Coutinho, S. C. K. Rooney, and E. J. Payton. Analysis of ebsd grain\nsize measurements using microstructure simulations and a customizable pattern\nmatching library for grain perimeter estimation. Metallurgical and Materials\nTransactions A, 48(5):2375–2395, 2017.\n[46] S. Berbenni, V. Favier, and M. Berveiller. Impact of the grain size distribution on the yield stress of heterogeneous materials. International Journal of\nPlasticity, 23(1):114–142, 2007.\n[47] Aleksandr Chernatynskiy, Simon R Phillpot, and Richard LeSar. Uncertainty\nquantification in multiscale simulation of materials: A prospective. Annual\nReview of Materials Research, 43:157–182, 2013.\n\n161\n\nBIBLIOGRAPHY\n\n[48] Rob Phillips and Phillips Rob. Crystals, defects and microstructures: modeling\nacross scales. Cambridge University Press, 2001.\n[49] Mechanical testing of metals — ductility testing — compression test for porous\nand cellular metals. Technical report, International Organization for Standardization, 2020.\n[50] BS Aakash, JohnPatrick Connors, and Michael D Shields. Variability in the\nthermo-mechanical behavior of structural aluminum. Thin-Walled Structures,\n144:106122, 2019.\n[51] RF Egerton, P Li, and M Malac. Radiation damage in the tem and sem. Micron,\n35(6):399–409, 2004.\n[52] P Peczak. A monte carlo study of influence of deformation temperature on\ndynamic recrystallization. Acta metallurgica et materialia, 43(3):1279–1291,\n1995.\n[53] Allen Skaja, Dilhan Fernando, and Stuart Croll. Mechanical property changes\nand degradation during accelerated weathering of polyester-urethane coatings.\nJCT research, 3(1):41–51, 2006.\n[54] Muhammad Usman Rashid. Experimental investigation on durability characteristics of steel and polypropylene fiber reinforced concrete exposed to natural\nweathering action. Construction and Building Materials, 250:118910, 2020.\n\n162\n\nBIBLIOGRAPHY\n\n[55] M. Uchic, L. Holzer, B. Inkson, E. Principe, and P Munroe. Three-dimensional\nmicrostructural characterization using focused ion beam tomography. MRS\nBulletin, 32(5):408–416, 2007.\n[56] Wenjing Yin, Derrick Brittain, Jay Borseth, Marie E Scott, Derric Williams,\nJedediah Perkins, Christopher S Own, Matthew Murfitt, Russel M Torres,\nDaniel Kapner, et al. A petascale automated imaging pipeline for mapping\nneuronal circuits with high-throughput transmission electron microscopy. Nature communications, 11(1):1–12, 2020.\n[57] Michael D Uchic, Michael Groeber, Robert Wheeler IV, Frank Scheltens, and\nDennis M Dimiduk. Augmenting the 3d characterization capability of the dual\nbeam fib-sem. Microscopy and Microanalysis, 10(S02):1136–1137, 2004.\n[58] Anwar Ul-Hamid. A beginners’ guide to scanning electron microscopy, volume 1.\nSpringer, 2018.\n[59] J. Goldstein, D. Newbury, J.Michae, N. Ritchie, J. Scott, and D. Joy. Scanning\nElectron Microscopy and X-Ray Microanalysis. Springer US, 2018.\n[60] Peter J Goodhew, John Humphreys, and Richard Beanland. Electron microscopy and analysis. CRC press, 2000.\n[61] Standard test methods for determing average grain size. Technical report,\nASTM International, West Conshohocken, PA, 2010.\n\n163\n\nBIBLIOGRAPHY\n\n[62] Surya R. Kalidindi and Marc De Graef. Materials data science: Current status\nand future outlook. Annual Review of Materials Research, 45(1):171–193, 2015.\n[63] Rong Jiang, Fabrice Pierron, Sari Octaviani, and PAS Reed. Characterisation\nof strain localisation processes during fatigue crack initiation and early crack\npropagation by sem-dic in an advanced disc alloy. Materials Science and Engineering: A, 699:128–144, 2017.\n[64] XF Ma, HL Zhai, L Zuo, WJ Zhang, SS Rui, QN Han, JS Jiang, CP Li,\nGF Chen, GA Qian, et al. Fatigue short crack propagation behavior of selective\nlaser melted inconel 718 alloy by in-situ sem study: Influence of orientation and\ntemperature. International Journal of Fatigue, 139:105739, 2020.\n[65] Yi-Bo Shang, Hui-Ji Shi, Zhao-Xi Wang, and Guo-Dong Zhang. In-situ sem\nstudy of short fatigue crack propagation behavior in a dissimilar metal welded\njoint of nuclear power plant. Materials & Design, 88:598–609, 2015.\n[66] Valerie Randle. Electron backscatter diffraction: Strategies for reliable data\nacquisition and processing. Materials Characterization, 60(9):913–922, 2009.\n[67] Mariusz Jankowski. Erosion, dilation and related operators. Department of\nElectrical EngineeringUniversity of Southern Maine Portland, Maine, USA,\n2006.\n[68] Ted Belytschko, Robert Gracie, and Giulio Ventura.\n\n164\n\nA review of ex-\n\nBIBLIOGRAPHY\n\ntended/generalized finite element methods for material modeling. Modelling\nand Simulation in Materials Science and Engineering, 17(4):043001, apr 2009.\n[69] David W Eastman, Zafir Alam, George Weber, Paul A Shade, Michael D Uchic,\nWilliam C Lenthe, Tresa M Pollock, and Kevin J Hemker. Benchmarking crystal\nplasticity models with microtensile evaluation and 3d characterization of rené\n88dt. In Superalloys 2016: Proceedings of the 13th Intenational Symposium of\nSuperalloys, pages 811–820. John Wiley & Sons, Inc. Hoboken, NJ, USA, 2016.\n[70] Jiaying Gao, Modesar Shakoor, Gino Domel, Matthias Merzkirch, Guowei Zhou,\nDanielle Zeng, Xuming Su, and Wing Kam Liu. Predictive multiscale modeling\nfor unidirectional carbon fiber reinforced polymers. Composites Science and\nTechnology, 186:107922, 2020.\n[71] Yancheng Zhang, Ning Wei, Junhua Zhao, Yadong Gong, and Timon Rabczuk.\nQuasi-analytical solution for the stable system of the multi-layer folded\ngraphene wrinkles. Journal of Applied Physics, 114(6):063511, 2013.\n[72] Evan J Pineda, Brett A Bednarcyk, and Steven M Arnold. Achieving icme\nwith multiscale modeling: the effects of constituent properties and processing\non the performance of laminated polymer matrix composite structures. In 55th\nAIAA/ASMe/ASCE/AHS/SC Structures, Structural Dynamics, and Materials\nConference, page 0461, 2014.\n\n165\n\nBIBLIOGRAPHY\n\n[73] E Weinan and Bjorn Engquist. Multiscale modeling and computation. Notices\nof the AMS, 50(9):1062–1070, 2003.\n[74] Julia A Elliott. Novel approaches to multiscale modelling in materials science.\nInternational Materials Reviews, 56(4):207–225, 2011.\n[75] William Yi Wang, Jinshan Li, Weimin Liu, and Zi-Kui Liu. Integrated computational materials engineering for advanced materials: A brief review. Computational Materials Science, 158:42–48, 2019.\n[76] Yan Wang and David L McDowell. Uncertainty quantification in multiscale\nmaterials modeling. Woodhead Publishing, 2020.\n[77] Anna Sciazko, Yosuke Komatsu, and Naoki Shikazono. Unsupervised generative adversarial network for 3-d microstructure synthesis from 2-d image. ECS\nTransactions, 103(1):1363, 2021.\n[78] Se-Yun Kim, Ji-Su Kim, Jae Hun Lee, Jong Hak Kim, and Tong-Seok Han.\nComparison of microstructure characterization methods by two-point correlation functions and reconstruction of 3d microstructures using 2d tem images\nwith high degree of phase clustering. Materials Characterization, 172:110876,\n2021.\n[79] Hongyi Xu, Dmitriy A Dikin, Craig Burkhart, and Wei Chen. Descriptor-\n\n166\n\nBIBLIOGRAPHY\n\nbased methodology for statistical characterization and 3d reconstruction of microstructural materials. Computational Materials Science, 85:206–216, 2014.\n[80] M. Pinz, G. Weber, W.C. Lenthe, M.D. Uchic, T.M. Pollock, and S. Ghosh.\nMicrostructure and property based statistically equivalent rves for intragranular\n’ microstructures of ni-based superalloys. Acta Materialia, 157:245 – 258, 2018.\n[81] James Nolen, Grigorios A Pavliotis, and Andrew M Stuart. Multiscale modelling\nand inverse problems. In Numerical analysis of multiscale problems, pages 1–34.\nSpringer, 2012.\n[82] Kirubel Teferra and Lori Graham-Brady. Tessellation growth models for polycrystalline microstructures. Computational Materials Science, 102:57–67, 2015.\n[83] Farjas J. and Roura P. Modification of the kolmogorov-johnson-mehl-avrami\nrate equation for non-isothermal experiments and its analytical solution. Acta\nMaterialia, 54(20):5573 – 5579, 2006. Cited by: 141; All Open Access, Green\nOpen Access.\n[84] Xiaolin Li, Yichi Zhang, He Zhao, Craig Burkhart, L Catherine Brinson, and\nWei Chen. A transfer learning approach for microstructure reconstruction and\nstructure-property predictions. Scientific reports, 8(1):1–13, 2018.\n[85] Anindya Bhaduri, Ashwini Gupta, Audrey Olivier, and Lori Graham-Brady.\n\n167\n\nBIBLIOGRAPHY\n\nAn efficient optimization based microstructure reconstruction approach with\nmultiple loss functions. arXiv preprint arXiv:2102.02407, 2021.\n[86] Ramin Bostanabad. Reconstruction of 3d microstructures from 2d images via\ntransfer learning. Computer-Aided Design, 128:102906, 2020.\n[87] M El Azzouzi, L Khouchaf, and A Achahbar. Monte carlo study of the interaction volume changes by the beam skirt in vp-sem. Acta Physica Polonica, A.,\n132(4), 2017.\n[88] K Kanaya and S Okayama. Penetration and energy-loss theory of electrons in\nsolid targets. Journal of Physics D: Applied Physics, 5(1):43, 1972.\n[89] Mauro Ciappa, Emre Ilgünsatiroglu, and Alexey Yu Illarionov. Monte carlo simulation of emission site, angular and energy distributions of secondary electrons\nin silicon at low beam energies. Microelectronics Reliability, 52(9-10):2139–2143,\n2012.\n[90] Y. Chen, S. Park, D Wei, G. Newstadt, M. Jackson, J. Simmons, M. De Graef,\nand A. Hero. A dictionary approach to electron backscatter diffraction indexing.\n21(3):739–752, 2015.\n[91] R. T. DeHoff. Quantitative serial sectioning analysis: preview. Journal of\nMicroscopy, 131(3):259–263, 1983.\n[92] M. Uchic. Serial Sectioning Methods for Generating 3D Characterization Data\n168\n\nBIBLIOGRAPHY\n\nof Grain- and Precipitate-Scale Microstructures, pages 31–52. Springer US,\nBoston, MA, 2011.\n[93] X. Lui, D Furrer, J. Kosters, and J. Holmes. Vision 2040: A roadmap for integrated, multiscale modeling and simulation of materials and systems. Technical\nreport, NASA Glenn Research Center, 2018.\n[94] M. Groeber. Digital Representation of Materials Grain Structure, pages 53–97.\nSpringer US, Boston, MA, 2011.\n[95] T. Sakamoto, Z. Cheng, M. Takahashi, M.Owari, and Y. Nihei. Development\nof an ion and electron dual focused beam apparatus for three-dimensional microanalysis. Japanese Journal of Applied Physics, 37(4R):2051, 1998.\n[96] S. Zaefferer, S. Wright, and D. Raabe.\n\nThree-dimensional orientation mi-\n\ncroscopy in a focused ion beam–scanning electron microscope: A new dimension\nof microstructure characterization. Metallurgical and Materials Transactions A,\n39(2):374–389, Feb 2008.\n[97] J. Guyon, N. Gey, D. Goran, S. Chalal, and F. Pérez-Willard. Advancing fib\nassisted 3d ebsd using a static sample setup. Ultramicroscopy, 161:161 – 167,\n2016.\n[98] T.L. Burnett, R. Kelley, B. Winiarski, L. Contreras, M. Daly, A. Gholinia, M.G.\n\n169\n\nBIBLIOGRAPHY\n\nBurke, and P.J. Withers. Large volume serial section tomography by xe plasma\nfib dual beam microscopy. Ultramicroscopy, 161:119 – 129, 2016.\n[99] S. Monteiro and S. Paciornik. From historical backgrounds to recent advances\nin 3d characterization of materials: An overview. JOM, 69(1):84–92, Jan 2017.\n[100] M. Echlin., A. Mottura, C.J. Torbet, and T. Pollock. A new tribeam system\nfor three-dimensional multimodal materials analysis. Review of Scientific Instruments, 83(2):023701, 2012.\n[101] W.C. Lenthe. Twin Related Domains in Polycrystalline Nickel-Base Superalloys: 3D Structure and Fatigue. PhD thesis, UCSB, 2017. Copyright - Database\ncopyright ProQuest LLC; ProQuest does not claim copyright in the individual\nunderlying works; Last updated - 2018-04-28.\n[102] F. Rhines, K. Craig, and D. Rousse. Measurement of average grain volume and\ncertain topological parameters by serial section analysis. Metallurgical Transactions A, 7(11):1729–1734, 1976. cited By 31.\n[103] T. H. Hoang, M. Guerich, and J. Yvonnet. Determining the size of rve for\nnonlinear random composites in an incremental computational homogenization\nframework. Journal of Engineering Mechanics, 142(5):04016018, 2018/10/11\n2016.\n[104] K. Teferra and L. Graham-Brady. A random field-based method to estimate\n\n170\n\nBIBLIOGRAPHY\n\nconvergence of apparent properties in computational homogenization. Computer\nMethods in Applied Mechanics and Engineering, 330:253 – 270, 2018.\n[105] Michael Groeber, Somnath Ghosh, Michael D. Uchic, and Dennis M. Dimiduk.\nA framework for automated analysis and simulation of 3d polycrystalline\nmicrostructures. part 2: Synthetic structure generation.\n\nActa Materialia,\n\n56(6):1274–1287, 2008.\n[106] G. Loughnane, M. Groeber, M. Uchic, M.Shah, R. Srinivasan, and Ramana\nGrandhi. Modeling the effect of voxel resolution on the accuracy of phantom\ngrain ensemble statistics. Materials Characterization, 90:136 – 150, 2014.\n[107] F. Ram, S. Wright, S. Singh, and M. De Graef. Error analysis of the crystal\norientations obtained by the dictionary approach to ebsd indexing. Ultramicroscopy, 181:17 – 26, 2017.\n[108] Implementing integrated computational materials engineering (icme) in the\naerospace, automotive, and maritime industries. Technical report, The Minerals, Metals, and Materials Society, http://www.tms.org/icmestudy, 2013.\n[109] M Groeber and M. Jackson. Dream.3d: A digital representation environment for\nthe analysis of microstructure in 3d. Integrating Materials and Manufacturing\nInnovation, 3(1):5, Apr 2014.\n[110] Dassault Systèmes. Abaqus, 2017.\n\n171\n\nBIBLIOGRAPHY\n\n[111] K. Teferra and L.Graham-Brady. Tessellation growth models for polycrystalline\nmicrostructures. Computational Materials Science, 102:57 – 67, 2015.\n[112] BlueQuartz, http://dream3d.bluequartz.net/.\n\nDream.3D User Manual -\n\nErode/Dilate Bad Data.\n[113] V.Randle. Electron backscatter diffraction: Strategies for reliable data acquisition and processing. Materials Characterization, 60(9):913 – 922, 2009.\n[114] D.M. Dimiduk, M.D. Uchic, and T.A. Parthasarathy. Size-affected single-slip\nbehavior of pure nickel microcrystals. Acta Materialia, 53(15):4065–4077, 2005.\n[115] Javier Segurado, Ricardo A. Lebensohn, Javier LLorca, and Carlos N. Tomé.\nMultiscale modeling of plasticity based on embedding the viscoplastic selfconsistent formulation in implicit finite elements. International Journal of Plasticity, 28(1):124–140, 2012.\n[116] J Friel, S Wright, and S Sitzman. Astm grain size by ebsd-a new standard.\nMicroscopy and Microanalysis, 17(S2):838–839, 2011.\n[117] Standard practice for determining average grain size using electron backscatter diffraction (ebsd) in fully recrystallized polycrystalline materials. ASTM\nInternational.\n[118] O.V. Rofman, P.S. Bate, I. Brough, and F. J. Humphreys.\n\n172\n\nStudy of dy-\n\nBIBLIOGRAPHY\n\nnamic grain growth by electron microscopy and ebsd. Journal of Microscopy,\n233(3):432–441, 2009.\n[119] K.P. Mingard, B. Roebuck, E.G. Bennett, M.G. Gee, H. Nordenstrom,\nG. Sweetman, and P. Chan. Comparison of ebsd and conventional methods\nof grain size measurement of hardmetals. International Journal of Refractory\nMetals and Hard Materials, 27(2):213–223, 2009. International Conference on\nthe Science of Hard Materials - 9.\n[120] Microbeam analysis—electron backscatter diffraction—measurement of average\ngrain size. Technical report, International Organization for Standardization,\n2020.\n[121] Creuziger Adam and Mark Vaudin. Report on vamas round robin of iso 13067 :\nMicrobeam analysis - electron backscatter diffraction - measurement of average\ngrain size. Technical report, National Institute of Standards and Technology,\nGaithersburg, MD, 2011.\n[122] K P Mingard and M S Quested, P N andPeck. Determination of grain size by\nebsd - report on a round robin measurement of equiaxed titanium. Technical\nReport MAT 56, National Physical Laboratory, 2012.\n[123] Xianshuang Xia, Mei Liu, Tieqiao Zhang, Qiang Dong, Lanting Zhang, Ligang\nZhou, and Mingqiang Li. Dependence of grain size and aspect ratio on grain\n\n173\n\nBIBLIOGRAPHY\n\nboundary additives in hot-deformed nd-fe-b magnets. Materials Characterization, 168:110543, 2020.\n[124] Melissa R. Cox and Muniram Budhu. A practical approach to grain shape\nquantification. Engineering Geology, 96(1):1–16, 2008.\n[125] V. Sinha, M. Gonzales, R.A. Abrahams, B.S. Song, and E.J. Payton. Correlative microscopy for quantification of prior austenite grain size in af9628 steel.\nMaterials Characterization, 159:109835, 2020.\n[126] A.M. Vossepoel and A.W.M. Smeulders. Vector code probability and metrication error in the representation of straight lines of finite length. Computer\nGraphics and Image Processing, 20(4):347–364, 1982.\n[127] Joseph Barba, Kin S Chan, and Joan Gil. Quantitative perimeter and area\nmeasurements of digital images. Microscopy research and technique, 21(4):300–\n314, 1992.\n[128] Zenon Kulpa. Area and perimeter measurement of blobs in discrete binary\npictures. Computer graphics and image processing, 6(5):434–451, 1977.\n[129] Mohsen Seifi, Ayman Salem, Jack Beuth, Ola Harrysson, and John J\nLewandowski. Overview of materials qualification needs for metal additive manufacturing. Jom, 68(3):747–764, 2016.\n[130] Zhen Hu and Sankaran Mahadevan. Uncertainty quantification in prediction of\n174\n\nBIBLIOGRAPHY\n\nmaterial properties during additive manufacturing. Scripta Materialia, 135:135–\n140, 2017.\n[131] Christopher U Brown, Christopher U Brown, and Alkan Donmez. Microstructure Analysis for Additive Manufacturing: A Review of Existing Standards. US\nDepartment of Commerce, National Institute of Standards and Technology,\n2016.\n[132] Andrew G Glen, Lawrence M Leemis, and John H Drew. Computing the distribution of the product of two continuous random variables. Computational\nstatistics & data analysis, 44(3):451–464, 2004.\n[133] Vratislav Horálek. Astm grain-size model and related random tessellation models. Materials Characterization, 25(3):263–284, 1990.\n[134] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David WardeFarley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. Advances in neural information processing systems, 27, 2014.\n[135] Rahul Singh, Viraj Shah, Balaji Pokuri, Soumik Sarkar, Baskar Ganapathysubramanian, and Chinmay Hegde. Physics-aware deep generative models for creating synthetic microstructures. arXiv preprint arXiv:1811.09669, 2018.\n[136] Lukas Mosser, Olivier Dubrule, and Martin J Blunt. Stochastic reconstruction\n\n175\n\nBIBLIOGRAPHY\n\nof an oolitic limestone by generative adversarial networks. Transport in Porous\nMedia, 125(1):81–103, 2018.\n[137] Tim Hsu, William K Epting, Hokon Kim, Harry W Abernathy, Gregory A\nHackett, Anthony D Rollett, Paul A Salvador, and Elizabeth A Holm. Microstructure generation via generative adversarial network for heterogeneous,\ntopologically complex 3d materials. JOM, 73(1):90–102, 2021.\n[138] Devendra K Jangid, Neal R Brodnik, Amil Khan, Michael G Goebel, McLean P\nEchlin, Tresa M Pollock, Samantha H Daly, and BS Manjunath. 3d grain shape\ngeneration in polycrystals using generative adversarial networks. Integrating\nMaterials and Manufacturing Innovation, pages 1–14, 2022.\n[139] L Torrey and J Shavlik. Transfer learning in handbook of research on machine\nlearning applications (eds. soria, e., martin, j., magdalena, r., martinez, m. &\nserrano, a.) 242–264, 2009.\n[140] Sagar H Nikam and NK Jain. Modeling and prediction of residual stresses\nin additive layer manufacturing by microplasma transferred arc process using\nfinite element simulation. Journal of Manufacturing Science and Engineering,\n141(6):061003, 2019.\n[141] Zeliang Liu, CT Wu, and M Koishi. Transfer learning of deep material network for seamless structure–property predictions. Computational Mechanics,\n64(2):451–465, 2019.\n176\n\nBIBLIOGRAPHY\n\n[142] Simon Stieber. Transfer learning for optimization of carbon fiber reinforced\npolymer production. In Organic Computing: Doctoral Dissertation Colloquium,\nvolume 2018, 2018.\n[143] CLY Yeong and Salvatore Torquato. Reconstructing random media. Physical\nreview E, 57(1):495, 1998.\n[144] S Torquato and CLY Yeong. Reconstructing random media ii. three-dimensional\nmedia from two-dimensional cuts. Physical Review E, 58(1):224–233, 1998.\n[145] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for\nlarge-scale image recognition. arXiv preprint arXiv:1409.1556, 2014.\n[146] Leon Gatys, Alexander S Ecker, and Matthias Bethge. Texture synthesis using convolutional neural networks. Advances in neural information processing\nsystems, 28, 2015.\n[147] David T. Fullwood, Stephen R. Niezgoda, and Surya R. Kalidindi. Microstructure reconstructions from 2-point statistics using phase-recovery algorithms.\nActa Materialia, 56(5):942–948, 2008.\n[148] Nicholas Lubbers, Turab Lookman, and Kipton Barros.\n\nInferring low-\n\ndimensional microstructure representations using convolutional neural networks. Physical Review E, 96(5):052111, 2017.\n[149] Leonid I Rudin, Stanley Osher, and Emad Fatemi. Nonlinear total variation\n177\n\nBIBLIOGRAPHY\n\nbased noise removal algorithms. Physica D: nonlinear phenomena, 60(1-4):259–\n268, 1992.\n\n178\n\nVita\n\nNoah Wade was born in San Diego, California. He competed his B.S. in Civil\nand Environmental Engineering at Cornell University in 2015. During his time there\nhe was a member and team captain of the Cornell Baja Racing Team, which won\nthe world championship in 2014. Upon graduating he joined Professor Lori GrahamBrady’s research group studying uncertainty quantification in material characterization. From 2015-2018 he was a member of the Center of Excellence in Integrated\nMaterials Modeling (CEIMM). Noah received a masters degree in Mechanical Engineering at Johns Hopkins in 2021, and completed the requirements for a doctoral\ndegree in the Civil and Systems Engineering department in the spring of 2022.\n\n179\n\n","pages":{"startPosition":[0,5001,10001,14994,20001,24999,29992,35000,39992,44995,49999,54998,60001,64990,69999,75001,79999,85000,90000,94994,99999,104995,110001,115000,119993,125001,129999,134997,139991,144996,149996,154998,160000,164998,169998,174996,179997,185001,189997,194997,199998,204982,210000,215001]}},"html":{"comparison":{"identical":{"groupId":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4],"source":{"chars":{"starts":[3874994,3875011,3875019,3875036,3875044,3875061,3875069,3875086,3875094,3875111,3875119,3875136,3875144,3875161,3875169,3875186,3875194,3875211,3875219,3875236,3875244,3875261,3875269,3875286,3875294,3875311,3875319,3875336,3875344,3875361,3875369,3875386,3875394,4027458,4027475,4027483,4027500,4027508,4027525,4027533,4027550,4027558,4027575,4027583,4027600,4027608,4027625,4027633,4027650,4027658,4027675,4027683,4027700,4027708,4027725,4027733,4064367,4064384,4064392,4064409,4064417,4064434,4064442,4064459,4064467,4064484,4064492,4064509,4064517,4064534,4064542,4064559,4064567,4064584,4064592,4064609,4064617,4064634,4064642,4074420,4074437,4074445,4074462,4074470,4074487,4074495,4074512,4074520,4074537,4074545,4074562,4074570,4074587,4074595,4074612,4074620,4074637,4074645,4074662,4074670,4074687,4074695,4074712,4074720,4074737,4074745,4074762,4074770,4074787,4074795,4081529,4081546,4081554,4081571,4081579,4081596,4081604,4081621,4081629,4081646,4081654,4081671,4081679,4081696,4081704,4081721,4081729,4081746,4081754,4081771,4081779,4081796,4081804,4081821,4081829,4081846,4081854,4081871,4081879,4081896,4081904],"lengths":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]},"words":{"starts":[10298,10298,10298,10298,10298,10298,10298,10298,10298,10298,10298,10298,10298,10298,10298,10298,10298,10298,10298,10298,10298,10298,10298,10298,10298,10298,10298,10298,10298,10298,10298,10298,10298,13735,13735,13735,13735,13735,13735,13735,13735,13735,13735,13735,13735,13735,13735,13735,13735,13735,13735,13735,13735,13735,13735,13735,14573,14573,14573,14573,14573,14573,14573,14573,14573,14573,14573,14573,14573,14573,14573,14573,14573,14573,14573,14573,14573,14573,14573,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144],"lengths":[16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15]}},"suspected":{"chars":{"starts":[3402,3402,3402,3402,3402,3402,3402,3402,3402,3402,3402,3402,3402,3402,3402,3402,3402,3402,3402,3402,3402,3402,3402,3402,3402,3402,3402,3402,3402,3402,3402,3402,3402,3521,3521,3521,3521,3521,3521,3521,3521,3521,3521,3521,3521,3521,3521,3521,3521,3521,3521,3521,3521,3521,3521,3521,3749,3749,3749,3749,3749,3749,3749,3749,3749,3749,3749,3749,3749,3749,3749,3749,3749,3749,3749,3749,3749,3749,3749,3898,3898,3898,3898,3898,3898,3898,3898,3898,3898,3898,3898,3898,3898,3898,3898,3898,3898,3898,3898,3898,3898,3898,3898,3898,3898,3898,3898,3898,3898,3898,4395,4395,4395,4395,4395,4395,4395,4395,4395,4395,4395,4395,4395,4395,4395,4395,4395,4395,4395,4395,4395,4395,4395,4395,4395,4395,4395,4395,4395,4395,4395],"lengths":[33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31]},"words":{"starts":[505,505,505,505,505,505,505,505,505,505,505,505,505,505,505,505,505,505,505,505,505,505,505,505,505,505,505,505,505,505,505,505,505,547,547,547,547,547,547,547,547,547,547,547,547,547,547,547,547,547,547,547,547,547,547,547,611,611,611,611,611,611,611,611,611,611,611,611,611,611,611,611,611,611,611,611,611,611,611,646,646,646,646,646,646,646,646,646,646,646,646,646,646,646,646,646,646,646,646,646,646,646,646,646,646,646,646,646,646,646,783,783,783,783,783,783,783,783,783,783,783,783,783,783,783,783,783,783,783,783,783,783,783,783,783,783,783,783,783,783,783],"lengths":[16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15]}}},"minorChanges":{"groupId":[5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5],"source":{"chars":{"starts":[3794463,3794490,3794498,3794523,3794531,3794559,3794567,3794595,3794603,3794631,3794639,3794664,3794672,3794689,3794697,3794714,3794722,3794739,3794747,3794764,3794772,3794789,3794797,3794814,3794822,3794839,3794847,3794864,3794872,3794889,3794897,3794914,3794922,3794939,3794947,3794964,3794972,3794989,3794997,3795017,3795025],"lengths":[7,1,5,1,8,1,8,1,8,1,5,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,3]},"words":{"starts":[8505,8505,8505,8505,8505,8505,8505,8505,8505,8505,8505,8505,8505,8505,8505,8505,8505,8505,8505,8505,8505,8505,8505,8505,8505,8505,8505,8505,8505,8505,8505,8505,8505,8505,8505,8505,8505,8505,8505,8505,8505],"lengths":[20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20]}},"suspected":{"chars":{"starts":[3233,3233,3233,3233,3233,3233,3233,3233,3233,3233,3233,3233,3233,3233,3233,3233,3233,3233,3233,3233,3233,3233,3233,3233,3233,3233,3233,3233,3233,3233,3233,3233,3233,3233,3233,3233,3233,3233,3233,3233,3233],"lengths":[78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78,78]},"words":{"starts":[464,464,464,464,464,464,464,464,464,464,464,464,464,464,464,464,464,464,464,464,464,464,464,464,464,464,464,464,464,464,464,464,464,464,464,464,464,464,464,464,464],"lengths":[30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30]}}},"relatedMeaning":{"groupId":[],"source":{"chars":{"starts":[],"lengths":[]},"words":{"starts":[],"lengths":[]}},"suspected":{"chars":{"starts":[],"lengths":[]},"words":{"starts":[],"lengths":[]}}}}},"version":3}