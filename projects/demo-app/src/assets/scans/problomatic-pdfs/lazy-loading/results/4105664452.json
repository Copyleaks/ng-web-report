{"statistics":{"identical":1301,"minorChanges":0,"relatedMeaning":0},"text":{"comparison":{"identical":{"source":{"chars":{"starts":[40213,40311,41068,41224,41456,41669,41963,42638,42850,43112,43295,43581,43890,44091,44189,44271,44443,44636,45050,45139,45338,45424,45537,45615,45715,45996,46816,47516,47701,47897,47994,48099,48177,48415,48952,49139,49233,49939,50039,50112,50203,50306,50912,51165,51297,51521,51617,51979,52149,52244,52323,52484,63150,70463],"lengths":[45,39,37,59,53,57,39,61,37,53,39,47,59,43,35,43,53,43,51,51,43,51,35,49,41,35,35,47,59,49,43,35,49,43,55,55,55,41,37,35,59,49,49,43,47,47,53,53,51,45,53,45,59,73]},"words":{"starts":[5805,5835,5999,6032,6096,6135,6198,6311,6374,6436,6489,6558,6623,6684,6714,6740,6779,6829,6914,6946,7000,7028,7064,7088,7119,7188,7399,7524,7582,7652,7684,7714,7738,7799,7908,7970,8002,8155,8183,8207,8240,8276,8416,8453,8480,8532,8563,8654,8709,8741,8768,8803,11106,12658],"lengths":[22,19,18,29,26,28,19,30,18,26,19,23,29,21,17,21,26,21,25,25,21,25,17,24,20,17,17,23,29,24,21,17,24,21,27,27,27,20,18,17,29,24,24,21,23,23,26,26,25,22,26,22,26,32]}},"suspected":{"chars":{"starts":[4041,4095,4223,4328,4516,4693,4939,5108,5239,5685,5932,5986,6093,6396,7269,7789,7992,8303,8479,8781,8922,8990,9044,9228,9345,9608,9732,9786,9854,10293,10543,10610,10664,10828,10916,11501,11749,12276,12988,13392,13468,13843,13994,14109,14354,15417,15731,15785,16043,16142,16261,16315,15500,5493],"lengths":[45,39,37,59,53,57,39,61,37,53,39,47,59,43,35,43,53,43,51,51,43,51,35,49,41,35,35,47,59,49,43,35,49,43,55,55,55,41,37,35,59,49,49,43,47,47,53,53,51,45,53,45,59,73]},"words":{"starts":[572,599,653,700,781,847,931,1007,1061,1210,1278,1305,1337,1426,1714,1891,1965,2068,2139,2264,2321,2348,2375,2450,2503,2603,2657,2684,2712,2900,3004,3031,3058,3104,3137,3333,3428,3589,3823,3971,3998,4151,4207,4252,4354,4685,4804,4831,4927,4959,5013,5040,4722,1143],"lengths":[22,19,18,29,26,28,19,30,18,26,19,23,29,21,17,21,26,21,25,25,21,25,17,24,20,17,17,23,29,24,21,17,24,21,27,27,27,20,18,17,29,24,24,21,23,23,26,26,25,22,26,22,26,32]}}},"minorChanges":{"source":{"chars":{"starts":[],"lengths":[]},"words":{"starts":[],"lengths":[]}},"suspected":{"chars":{"starts":[],"lengths":[]},"words":{"starts":[],"lengths":[]}}},"relatedMeaning":{"source":{"chars":{"starts":[],"lengths":[]},"words":{"starts":[],"lengths":[]}},"suspected":{"chars":{"starts":[],"lengths":[]},"words":{"starts":[],"lengths":[]}}}},"value":"~ ROA Version, 8/2002. Essentially identical to the Tech Report, with new pagination (but the same\n\nfootnote and example numbering); correction of typos, oversights & outright errors; improved typography;\nand occasional small-scale clarificatory rewordings. Citation should include reference to this version.\n\nOPTIMALITY THEORY\nConstraint Interaction in Generative Grammar\nFirst circulated: April, 1993\nRuCCS-TR-2; CU-CS-696-93: July, 1993\nMinor Corrections: December, 1993\nROA Version: August, 2002\n\nAlan Prince\n\nPaul Smolensky\n\nDepartment of Linguistics\nRutgers Cognitive Science Center\nRutgers University\n\nDepartment of Cognitive Science\nThe Johns Hopkins University\n[1993: University of Colorado at Boulder]\n\nprince@ruccs.rutgers.edu\n\nsmolensky@cogsci.jhu.edu\n\nEverything is possible but not\neverything is permitted ...\n— Richard Howard, “The Victor Vanquished”\n“It is demonstrated,” he said, “that things cannot be\notherwise: for, since everything was made for a purpose,\neverything is necessarily made for the best purpose.”\n— Candide ou l’optimisme. Ch. I.\n\nRemark. The authors’ names are arranged in lexicographic order.\n\nAcknowledgments\n\nSpecial thanks to John McCarthy for detailed discussion of virtually every issue raised here and for\na fine-grained skepsis of the entire first draft of the ms., which resulted in innumerable\nimprovements and would have resulted in innumerably more, were this a better world. We are\nparticularly grateful for his comments and suggestions in r‘ Chs. 7 and 9. We also wish to thank\nRobert Kirchner, Armin Mester, and Junko Itô for remarks that have had significant impact on the\ndevelopment of this work, as well as David Perlmutter, Vieri Samek-Lodovici, Cheryl Zoll,\nHenrietta Hung, Mark Hewitt, Jane Grimshaw, Ad Neeleman, Diana Archangeli, Henry Churchyard,\nDoug Pulleyblank, Moira Yip, Tom Bever, Larry Hyman, Andy Black, Mike Jordan, Lauri\nKarttunen, René Kager, Paul Kiparsky, Mike Kenstowicz, Ellis Visch, András Kornai, Akin\nAkinlabi, Géraldine Legendre, Clayton Lewis, Merrill Garrett, Jim Martin, Clara Levelt, Mike\nMozer, Maria Bittner, Alison Prince, Dave Rumelhart, Mark Liberman, Jacques Mehler, Steve\nPinker, Daniel Büring, Katharina Hartmann, Joshua Legendre Smolensky, Ray Jackendoff, Bruce\nHayes, Geoff Pullum, Gyanam Mahajan, Harry van der Hulst, William Labov, Brian McHugh, Gene\nBuckley, Will Leben, Jaye Padgett and Loren Billings. None of these individuals can be sensibly\ncharged with responsibility for any errors that may have crept into this work.\nTo Merrill Garrett (Cognitive Science, University of Arizona, Tucson) and to the organizers\nof the Arizona Phonology Conference we are grateful for providing in April 1991 the first public\nforums for the presentation of the theory, which proved a significant stimulus to the cohering thereof.\nWe would also like to thank audiences at our 1991 LSA Summer Institute course and at the Feature\nWorkshop there, at WCCFL 1992, at the OTS (Utrecht), University of California at Berkeley\n(Phonology Laboratory), the University of Colorado at Boulder and the Boulder Connectionist\nResearch Group, Rutgers University (New Brunswick and Piscataway), Brandeis University, the\nUniversity of Pennsylvania (the Linguistics Department and the Institute for Research in Cognitive\nScience), Princeton University Cognitive Science Center, Stanford University (Phonology Workshop\nand Parallel Distributed Processing Seminar), the University of Rochester Cognitive Science\nProgram, and the International Computer Science Institute of Berkeley CA.\nFinancial support was provided by a University of Colorado Faculty Fellowship, by research\nfunds from Rutgers University and from the Rutgers Center for Cognitive Science, and, most\ncrucially, by NSF SGER BNS-90 16806 without which the rigors of long-distance collaboration\nwould have proved daunting indeed.\nWe remember Robert Jeffers with special appreciation for constructing the Rutgers\nenvironment that so greatly facilitated the progress of this work.\n\nTable of Contents\n1. Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n1.1 Background and Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\n1.2 Optimality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n1.3 Overall Structure of the Argument . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\n\nPart I Optimality and Constraint Interaction\nOverview of Part I . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\n2. Optimality in Grammar: Core Syllabification in Imdlawn Tashlhiyt Berber . . . . . . . . . . . . . . . . . . . 11\n2.1 The Heart of Dell & Elmedlaoui . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n2.2 Optimality Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\n2.3 Summary of discussion to date . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n3. Generalization-Forms in Domination Hierarchies I\nBlocking and Triggering: Profuseness and Economy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n3.1 Epenthetic Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n3.2 Do Something Only When:\nThe Failure of Bottom-up Constructionism . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n4. Generalization-Forms in Domination Hierarchies II\nDo Something Except When: Blocking, or The Theory of Profuseness . . . . . . . . . . . . . . . . . . . . 33\n4.1 Edge-Oriented Infixation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n4.2 Interaction of Weight Effects with Extrametricality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38\n4.2.1 Background: Prominence-Driven Stress Systems . . . . . . . . . . . . . . . . . . . . . . . . . 38\n4.2.2 The Interaction of Weight and Extrametricality: Kelkar’s Hindi . . . . . . . . . . . . . 41\n4.3 Nonfinality and Nonexhaustiveness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\n4.3.1 Nonfinality and the Laws of Foot Form: Raw Minimality . . . . . . . . . . . . . . . . . . 49\n4.3.2 Nonfinality and the Laws of Foot Form:\nExtended Minimality Effects . . . . . . . . . . . . . . . . . . . . . . . . . 54\n4.4 Summary of Discussion of the Except When Effect . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\n4.5 Except meets Only: Triggering and Blocking in a Single Grammar . . . . . . . . . . . . . . . . . . 59\n5. The Construction of Grammar in Optimality Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\n5.1 Construction of Harmonic Orderings\nfrom Phonetic and Structural Scales . . . . . . . . . . . . . . . . . . . . . . . . . . 73\n5.2 The Theory of Constraint Interaction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74\n5.2.1 Comparison of Entire Candidates by a Single Constraint . . . . . . . . . . . . . . . . . . 74\n5.2.1.1 ONS: Binary constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75\n5.2.1.2 HNUC: Non-binary constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78\n5.2.2 Comparison of Entire Candidates by an Entire Constraint Hierarchy . . . . . . . . . 79\n5.2.3 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83\n5.2.3.1 Non-locality of interaction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83\n5.2.3.2 Strictness of domination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85\n5.2.3.3 Serial vs. Parallel Harmony Evaluation and Gen . . . . . . . . . . . . . . . . . 86\n5.2.3.4 Binary vs. Non-binary constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88\n5.3 P~Ãini’s Theorem on Constraint Ranking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88\niii\n\nPart II\n\nSyllable Theory\n\nOverview of Part II . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92\n6. Syllable Structure Typology I: the CV Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93\n6.1 The Jakobson Typology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93\n6.2 The Faithfulness Interactions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95\n6.2.1 Groundwork . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95\n6.2.2 Basic CV Syllable Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98\n6.2.2.1 Onsets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99\n6.2.2.2 Codas . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102\n6.2.3 The Theory of Epenthesis Sites . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104\n7. Constraint Interaction in Lardil Phonology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107\n7.1 The Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107\n7.2 The Ranking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117\n7.2.1 Some Ranking Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117\n7.2.2 Ranking the Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120\n7.3 Verification of Forms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\n7.3.1 Consonant-Final Stems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128\n7.3.2 Vowel Final Stems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132\n7.4 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135\n8. Universal Syllable Theory II:\nOrdinal Construction of C/V\nand Onset/Coda Licensing Asymmetry . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139\n8.1 Associational Harmony . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\n8.1.1 Deconstructing HNUC: Berber, Take 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\n8.1.2 Restricting to Binary Marks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147\n8.2 Reconstructing the C and V Classes:\nEmergent Parameter Setting via Constraint Ranking . . . . . . . . . . . . 152\n8.2.1 Harmonic Completeness of Possible Onsets and Peaks . . . . . . . . . . . . . . . . . . . 152\n8.2.2 Peak- and Margin-Affinity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154\n8.2.3 Interactions with PARSE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 156\n8.2.4 Restricting Deletion and Epenthesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157\n8.2.5 Further Necessary Conditions on Possible Onsets and Nuclei . . . . . . . . . . . . . . 158\n8.2.6 Sufficient Conditions on Possible Onsets and Nuclei . . . . . . . . . . . . . . . . . . . . 160\n8.3 The Typology of Onset, Nucleus, and Coda Inventories . . . . . . . . . . . . . . . . . . . . . . . . . . 165\n8.3.1 The Typology of Onset and Nucleus Inventories . . . . . . . . . . . . . . . . . . . . . . . . 165\n8.3.2 Onset/Coda Licensing Asymmetries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171\n8.3.3 An Example: Berber, Take 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178\n8.4 Simplifying the Theory by Encapsulating Constraint Packages . . . . . . . . . . . . . . . . . . . . . 183\n8.4.1 Encapsulating the Association Hierarchies . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183\n8.4.2 An Example: Berber, Take 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185\n8.4.3 Sufficiency and Richness of the Encapsulated Theory . . . . . . . . . . . . . . . . . . . 185\n\niv\n\nPart III\n\nIssues and Answers in Optimality Theory\n\n9. Inventory Theory and the Lexicon . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191\n9.1 Language-Particular Inventories . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191\n9.1.1 Harmonic Bounding and Nucleus, Syllable, and Word Inventories . . . . . . . . . 193\n9.1.2 Segmental Inventories . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195\n9.2 Universal Inventories . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202\n9.2.1 Segmental Inventories . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202\n9.2.2 Syllabic Inventories . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 208\n9.3 Optimality in the Lexicon . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 209\n10. Foundational Issues and Theory-Comparisons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215\n10.1 Thinking about Optimality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215\n10.1.1 Fear of Optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215\n10.1.2 The Reassurance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215\n10.2 The Connectionism Connection, and other Computation-based Comparisons . . . . . . . . 217\n10.2.1 Why Optimality Theory has nothing to do with connectionism . . . . . . . . . . . . 217\n10.2.2 Why Optimality Theory is deeply connected to connectionism . . . . . . . . . . . . 218\n10.2.3 Harmony Maximization and Symbolic Cognition . . . . . . . . . . . . . . . . . . . . . . 219\n10.3 Analysis of ‘Phonotactics+Repair’ Theories . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 221\n10.3.1 CV Syllable Structure and Repair . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224\n10.3.2 General Structure of the Comparisons: Repair Analysis . . . . . . . . . . . . . . . . . 226\n10.3.3 Persistent Rule Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228\n10.3.3.1 English Closed Syllable Shortening . . . . . . . . . . . . . . . . . . . . . . . . . 229\n10.3.3.2 Shona Tone Spreading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\n10.3.3.3 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233\n10.3.4 The Theory of Constraints and Repair Strategies . . . . . . . . . . . . . . . . . . . . . . . 233\nAppendix +incomplete, . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 241\nA.1 The Cancellation and Cancellation/Domination Lemmas . . . . . . . . . . . . . . . . . . . . . . . . 241\nA.2 CV Syllable Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 241\nA.3 P~Ãini's Theorem on Constraint-ranking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 241\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 243\n\nv\n\n1. Preliminaries\n1.1 Background and Overview\nAs originally conceived, the RULE of grammar was to be built from a Structural Description\ndelimiting a class of inputs and a Structural Change specifying the operations that altered the input\n(e.g. Chomsky 1962). The central thrust of linguistic investigation would therefore be to explicate\nthe system of predicates used to analyze inputs — the possible Structural Descriptions of rules —\nand to define the operations available for transforming inputs — the possible Structural Changes of\nrules. This conception has been jolted repeatedly by the discovery that the significant regularities\nwere to be found not in input configurations, nor in the formal details of structure-deforming\noperations, but rather in the character of the output structures, which ought by rights to be nothing\nmore than epiphenomenal. We can trace a path by which “conditions” on well-formedness start out\nas peripheral annotations guiding the interpretation of rewrite rules, and, metamorphosing by stages\ninto constraints on output structure, end up as the central object of linguistic study.\nAs the theory of representations in syntax has ramified, the theory of operations has dwindled\nin content, even to triviality and, for some, nonexistence. The parallel development in phonology and\nmorphology has been underway for a number of years, but the outcome is perhaps less clear — both\nin the sense that one view has failed to predominate, and in the sense that much work is itself\nimperfectly articulate on crucial points. What is clear is that any serious theory of phonology must\nrely heavily on well-formedness constraints; where by ‘serious’ we mean ‘committed to Universal\nGrammar’. What remains in dispute, or in subformal obscurity, is the character of the interaction\namong the posited well-formedness constraints, as well as the relation between such constraints and\nwhatever derivational rules they are meant to influence. Given the pervasiveness of this unclarity,\nand the extent to which it impedes understanding even the most basic functioning of the grammar,\nit is not excessively dramatic to speak of the issues surrounding the role of well-formedness\nconstraints as involving a kind of conceptual crisis at the center of phonological thought.\nOur goal is to develop and explore a theory of the way that representational well-formedness\ndetermines the assignment of grammatical structure. We aim therefore to ratify and to extend the\nresults of the large body of contemporary research on the role of constraints in phonological\ngrammar. This body of work is so large and various as to defy concise citation, but we would like\nto point to such important pieces as Kisseberth 1972, Haiman 1972, Pyle 1972, Hale 1973,\nSommerstein 1974, where the basic issues are recognized and addressed; to Wheeler 1981, 1988,\nBach and Wheeler 1981, Broselow 1982, Dressler 1985 Singh 1987, Paradis 1988ab, Paradis &\nPrunet 1991, Hulst 1984, Kaye & Lowenstamm 1984, Kaye, Lowenstamm & Vergnaud 1985,\nCalabrese 1988, Myers 1991, Goldsmith 1990, 1991, Bird 1990, Coleman 1991, Scobbie 1991,\nwhich all represent important strands in recent work; as well as to Vennemann 1972, Bybee 1972,\n1985, Liberman 1975, Goldsmith 1976, Liberman & Prince 1977, McCarthy 1979, McCarthy &\nPrince 1986, Selkirk 1980ab, 1981, Kiparsky 1980, 1982, Kaye & Lowenstamm 1981, McCarthy\n1981, 1986, Lapointe & Feinstein 1982, Cairns & Feinstein 1982, Steriade 1982, Prince 1983, 1990,\nKager & Visch 1983, Hayes 1984, Hyman 1985, Dressler 1985, Wurzel 1985, Borowsky 1986ab,\nItô 1986, 1989, Mester 1986, 1992, Halle & Vergnaud 1987, Lakoff 1988, in press, Yip 1988, Cairns\n1988, Kager 1989, Visch 1989, Clements 1990, Legendre, Miyata, & Smolensky 1990ab , Mohanan\n1991, in press, Archangeli & Pulleyblank 1992, Burzio 1992ab, Itô, Kitagawa & Mester 1992, Itô\n& Mester 1992 — a sample of work which offers an array of perspectives on the kinds of problems\n\n2\n\nChapter 1\n\nPrince & Smolensky\n\nwe will be concerned with — some close to, others more distant from our own, and some\ncontributory of fundamental representational notions that will put in appearances throughout this\nwork (for which, see the local references in the text below). Illuminating discussion of fundamental\nissues and an interesting conception of the historical development is found in Goldsmith 1990;\nScobbie 1992 reviews some recent work. The work of Stampe 1973/79, though framed in a very\ndifferent way, shares central abstract commitments with our own; perhaps more distantly related are\nChapter 9 of Chomsky & Halle 1968 and Kean 1975. The work of Wertheimer 1923, Lerdahl &\nJackendoff 1983 (chs. 3 and 12), Jackendoff 1983 (chs. 7 and 8), 1987, 1991, though not concerned\nwith phonology at all, provides significant conceptual antecedents; similarly, the proposals of\nChomsky 1986, and especially 1989, 1992, though very different in implementation, have\nfundamental similarities with our own. Rizzi 1990, Bittner 1993, and Legendre, Raymond, &\nSmolensky 1993, and Grimshaw in prep., are among recent works in syntax and semantics that\nresonate with our particular concerns.\nThe basic idea we will explore is that Universal Grammar consists largely of a set of constraints on\nrepresentational well-formedness, out of which individual grammars are constructed. The\nrepresentational system we employ, using ideas introduced into generative phonology in the 1970’s\nand 1980’s, will be rich enough to support two fundamental classes of constraints: those that assess\noutput configurations per se and those responsible for maintaining the faithful preservation of\nunderlying structures in the output. Departing from the usual view, we do not assume that the\nconstraints in a grammar are mutually consistent, each true of the observable surface or of some level\nof representation. On the contrary: we assert that the constraints operating in a particular language\nare highly conflicting and make sharply contrary claims about the well-formedness of most\nrepresentations. The grammar consists of the constraints together with a general means of resolving\ntheir conflicts. We argue further that this conception is an essential prerequisite for a substantive\ntheory of UG.\nIt follows that many of the conditions which define a particular grammar are, of necessity,\nfrequently violated in the actual forms of the language. The licit analyses are those which satisfy the\nconflicting constraint set as well as possible; they constitute the optimal analyses of underlying\nforms. This, then, is a theory of optimality with respect to a grammatical system rather than of wellformedness with respect to isolated individual constraints.\nThe heart of the proposal is a means for precisely determining which analysis of an input best\nsatisfies (or least violates) a set of conflicting conditions. For most inputs, it will be the case that\nevery possible analysis violates many constraints. The grammar rates all these analyses according\nto how well they satisfy the whole constraint set and produces the analysis at the top of this list as\nthe output. This is the optimal analysis of the given input, and the one assigned to that input by the\ngrammar. The grammatically well-formed structures are those that are optimal in this sense.\nHow does a grammar determine which analysis of a given input best satisfies a set of\ninconsistent well-formedness conditions? Optimality Theory relies on a conceptually simple but\nsurprisingly rich notion of constraint interaction whereby the satisfaction of one constraint can be\ndesignated to take absolute priority over the satisfaction of another. The means that a grammar uses\nto resolve conflicts is to rank constraints in a strict dominance hierarchy. Each constraint has\nabsolute priority over all the constraints lower in the hierarchy.\n\nOptimality Theory\n\nChapter 1\n\n3\n\nSuch prioritizing is in fact found with surprising frequency in the literature, typically as a\nsubsidiary remark in the presentation of complex constraints.1 We will show that once the notion of\nconstraint-precedence is brought in from the periphery and foregrounded, it reveals itself to be of\nremarkably wide generality, the formal engine driving many grammatical interactions. It will follow\nthat much that has been attributed to narrowly specific constructional rules or to highly particularized\nconditions is actually the responsibility of very general well-formedness constraints. In addition, a\ndiversity of effects, previously understood in terms of the triggering or blocking of rules by\nconstraints (or merely by special conditions), will be seen to emerge from constraint interaction.\nAlthough we do not draw on the formal tools of connectionism in constructing Optimality Theory,\nwe will establish a high-level conceptual rapport between the mode of functioning of grammars and\nthat of certain kinds of connectionist networks: what Smolensky (1983, 1986) has called ‘Harmony\nmaximization’, the passage to an output state with the maximal attainable consistency between\nconstraints bearing on a given input, where the level of consistency is determined exactly by a\nmeasure derived from statistical physics. The degree to which a possible analysis of an input satisfies\na set of conflicting well-formedness constraints will be referred to as the Harmony of that analysis.\nWe thereby respect the absoluteness of the term ‘well-formed’, avoiding terminological confusion\nand at the same time emphasizing the abstract relation between Optimality Theory and Harmonytheoretic network analysis. In these terms, a grammar is precisely a means of determining which of\na pair of structural descriptions is more harmonic. Via pair-wise comparison of alternative analyses,\nthe grammar imposes a harmonic order on the entire set of possible analyses of a given underlying\nform. The actual output is the most harmonic analysis of all, the optimal one. A structural description\nis well-formed if and only if the grammar determines it to be the optimal analysis of the\ncorresponding underlying form.\nWith an improved understanding of constraint interaction, a far more ambitious goal becomes\naccessible: to build individual phonologies directly from universal principles of well-formedness.\n(This is clearly impossible if we imagine that constraints must be surface- or at least level-true.) The\ngoal is to attain a significant increase in the predictiveness and explanatory force of grammatical\ntheory. The conception we pursue can be stated, in its purest form, as follows: Universal Grammar\nprovides a set of highly general constraints. These often conflicting constraints are all operative in\nindividual languages. Languages differ primarily in how they resolve the conflicts: in the way they\nrank these universal constraints in strict domination hierarchies that determine the circumstances\nunder which constraints are violated. A language-particular grammar is a means of resolving the\nconflicts among universal constraints.\nOn this view, Universal Grammar provides not only the formal mechanisms for constructing\nparticular grammars, it also provides the very substance that grammars are built from. Although we\nshall be entirely concerned in this work with phonology and morphology, we note the implications\nfor syntax and semantics.\n\n1\n\nOne work that uses ranking as a systematic part of the analysis is Cole 1992; thanks to Robert Kirchner\nfor bringing this to our attention.\n\n4\n\nChapter 1\n\nPrince & Smolensky\n\n1.2 Optimality\nThe standard phonological rule aims to encode grammatical generalizations in this format:\n(1)\n\nA ÿ B / C—D\n\nThe rule scans potential inputs for structures CAD and performs the change on them that is explicitly\nspelled out in the rule: the unit denoted by A takes on property B. For this format to be worth\npursuing, there must be an interesting theory which defines the class of possible predicates CAD\n(Structural Descriptions) and another theory which defines the class of possible operations A ÿ B\n(Structural Changes). If these theories are loose and uninformative, as indeed they have proved to\nbe in reality, we must entertain one of two conclusions:\n(i) phonology itself simply doesn’t have much content, is mostly ‘periphery’ rather than\n‘core’, is just a technique for data-compression, with aspirations to depth subverted by the inevitable\nidiosyncrasies of history and lexicon; or\n(ii) the locus of explanatory action is elsewhere.\nWe suspect the latter.\nThe explanatory burden can of course be distributed quite differently than in the re-write rule\ntheory. Suppose that the input-output relation is governed by conditions on the well-formedness of\nthe output, ‘markedness constraints’, and by conditions asking for the exact preservation of the input\nin the output along various dimensions, ‘faithfulness constraints’. In this case, the inputs falling\nunder the influence of a constraint need share no input-specifiable structure (CAD), nor need there\nbe a single determinate transformation (AÿB) that affects them. Rather, we generate (or admit) a\nset of candidate outputs, perhaps by very general conditions indeed, and then we assess the\ncandidates, seeking the one that best satisfies the relevant constraints. Many possibilities are open\nto contemplation, but some well-defined measure of value excludes all but the best.2 The process can\nbe schematically represented like this:\n(2) Structure of Optimality-theoretic grammar\nÿ\na. Gen (Ink)\nb. H-eval( Outi, 1#i#4 )\nÿ\n\n{Out1, Out2, ... }\nOutreal\n\nThe grammar must define a pairing of underlying and surface forms, (inputi, outputj). Each input is\nassociated with a candidate set of possible analyses by the function Gen (short for ‘generator’), a\nfixed part of Universal Grammar. In the rich representational system employed below, an output\nform retains its input as a subrepresentation, so that departures from faithfulness may be detected\n2\n\nThis kind of reasoning is familiar at the level of grammar selection in the form of the Evaluation Metric\n(Chomsky 1951, 1965). On this view, the resources of UG define many grammars that generate the same\nlanguage; the members of that set are evaluated, and the optimal grammar is the real one.\n\nOptimality Theory\n\nChapter 1\n\n5\n\nby scrutiny of output forms alone. A ‘candidate’ is an input-output pair, here formally encoded in\nwhat is called ‘Outi’ in (2). Gen contains information about the representational primitives and their\nuniversally irrevocable relations: for example, that the node F may dominate a node Onset or a node\n: (implementing some theory of syllable structure), but never vice versa. Gen will also determine\nsuch matters as whether every segment must be syllabified – we assume not, below, following\nMcCarthy 1979 et seq. – and whether every node of syllable structure must dominate segmental\nmaterial – again, we will assume not, following Itô 1986, 1989. The function H-eval determines the\nrelative Harmony of the candidates, imposing an order on the entire set. An optimal output is at the\ntop of the harmonic order on the candidate set; by definition, it best satisfies the constraint system.\nThough Gen has a role to play, the burden of explanation falls principally on the function H-eval,\na construction built from well-formedness constraints, and the account of interlinguistic differences\nis entirely tied to the different ways the constraint-system H-eval can be put together, given UG.\nH-eval must be constructible in a general way if the theory is to be worth pursuing. There are\nreally two notions of generality involved here: general with respect to UG, and therefore crosslinguistically; and general with respect to the language at hand, and therefore across constructions,\ncategories, descriptive generalizations, etc. These are logically independent, and success along either\ndimension of generality would count as an argument in favor of the optimality approach. But the\nstrongest argument, the one that is most consonant with the work in the area, and the one that will\nbe pursued here, broaches the distinction, seeking a formulation of H-eval that is built from\nmaximally universal constraints which apply with maximal breadth over an entire language.\nOptimality Theory, in common with much recent work, shifts the burden from the theory of\noperations (Gen) to the theory of well-formedness (H-eval). To the degree that the theory of wellformedness can be put generally, the theory will fulfill the basic goals of generative grammar. To the\nextent that operation-based theories cannot be so put, they must be rejected.\nAmong possible developments of the optimality idea, we need to distinguish some basic\narchitectural variants. Perhaps nearest to the familiar derivational conceptions of grammar is what\nwe might call ‘harmonic serialism’, by which Gen provides a set of candidate analyses for an input,\nwhich are harmonically evaluated; the optimal form is then fed back into Gen, which produces\nanother set of analyses, which are then evaluated; and so on until no further improvement in\nrepresentational Harmony is possible. Here Gen might mean: ‘do any one thing: advance all\ncandidates which differ in one respect from the input.’ The Gen W H-eval loop would iterate until\nthere was nothing left to be done or, better, until nothing that could be done would result in increased\nHarmony. A significant proposal of roughly this character is the Theory of Constraints and Repair\nStrategies of Paradis 1988ab, with a couple of caveats: the constraints involved are a set of parochial\nlevel-true phonotactic statements, rather than being universal and violable, as we insist; and the\nrepair strategies are quite narrowly defined in terms of structural description and structural change\nrather than being of the ‘do-unto-\"’ variety. A key aspect of Paradis’s work is that it confronts the\nproblem of well-definition of the notion ‘repair’: what to do when applying a repair strategy to\nsatisfy one constraint results in violation of another constraint (at an intermediate level of\nderivation). Paradis refers to such situations as ‘constraint conflicts’ and although these are not\nconflicts in our sense of the term — they cannot be, since all of her constraints are surface- or leveltrue and therefore never disagree among themselves in the assessment of output well-formedness —\nher work is of unique importance in addressing and shedding light on fundamental complexities in\n\n6\n\nChapter 1\n\nPrince & Smolensky\n\nthe idea of wellformedness-driven rule-application. The ‘persisent rule’ theory of Myers 1991 can\nsimilarly be related to the notion of Harmony-governed serialism. The program for Harmonic\nPhonology in Goldsmith 1990, 1991 is even more strongly of this character; within its lexical levels,\nall rules are constrained to apply harmonically. Here again, however, the rules are conceived of as\nbeing pretty much of the familiar sort, triggered if they increase Harmony, and Harmony itself is to\nbe defined in specifically phonotactic terms. A subtheory which is very much in the mold of\nharmonic serialism, using a general procedure to produce candidates, is the ‘Move-x’ theory of\nrhythmic adjustment (Prince 1983, Hayes 1991/1995).3\nA contrasting view would hold that the Input ÿ Output map has no internal structure: all\npossible variants are produced by Gen in one step and evaluated in parallel. In the course of this\nwork, we will see instances of both kinds of analysis, though we will focus predominantly on\ndeveloping the parallel idea, finding strong support for it, as do McCarthy & Prince 1993. Definitive\nadjudication between parallel and serial conceptions, not to mention hybrids of various kinds, is a\nchallenge of considerable subtlety, as indeed the debate over the necessity of serial Move-\"\nillustrates plentifully (e.g. Aoun 1986, Browning 1991, Chomsky 1981), and the matter can be\nsensibly addressed only after much well-founded analytical work and theoretical exploration.\nOptimality Theory abandons two key presuppositions of earlier work. First, that it is possible\nfor a grammar to narrowly and parochially specify the Structural Description and Structural Change\nof rules. In place of this is Gen, which generates for any given input a large space of candidate\nanalyses by freely exercising the basic structural resources of the representational theory. The idea\nis that the desired output lies somewhere in this space, and the constraint system of the grammar is\nstrong enough to single it out. Second, Optimality Theory abandons the widely held view that\nconstraints are language-particular statements of phonotactic truth. In its place is the assertion that\nconstraints are essentially universal and of very general formulation, with great potential for\ndisagreement over the well-formedness of analyses; an individual grammar consists of a ranking of\nthese constraints, which resolves any conflict in favor of the higher-ranked constraint. The\nconstraints provided by Universal Grammar are simple and general; interlinguistic differences arise\nfrom the permutations of constraint-ranking; typology is the study of the range of systems that reranking permits. Because they are ranked, constraints are regularly violated in the grammatical forms\nof a language. Violability has significant consequences not only for the mechanics of description,\nbut also for the process of theory construction: a new class of predicates becomes usable in the\nformal theory, with a concomitant shift in what we can think the actual generalizations are. We\ncannot expect the world to stay the same when we change our way of describing it.\n\n3\n\nAn interesting variant is what we might call ‘anharmonic serialism’, in which Gen produces the\ncandidate set by a nondeterministic sequence of constrained procedures (‘do one thing; do another one’)\nwhich are themselves not subject to harmonic evaluation. The candidate set is derived by running through\nevery possible sequence of such actions; harmonic evaluation looks at this candidate set. To a large extent,\nclassical Move-\" theories (Chomsky, 1981) work like this.\n\nOptimality Theory\n\nChapter 1\n\n7\n\n1.3 Overall Structure of the Argument\nThis work falls into three parts. Part I develops the basic groundwork, theoretical and empirical, and\nillustrates the characteristic kinds of analytical results that can be gotten from the theory. Part II\npropounds a theory of universal syllable typology at two levels of idealization, drawing on and then\nadvancing beyond various constraints introduced in Part I. The syllable structure typology provides the\nbasis for a full-scale analysis of the rich system of prosodically-conditioned alternations in the Lardil\nnominal paradigm. Part III begins with an investigation of the way that inventories are delimited both\nin UG and in particular grammars. A variety of issues are then explored which have to do with the\nconceptual structure of the theory and with its relation to other work along the same general lines. We\nconclude with an Appendix containing proofs of some theorems stated in the text proper and other\nmaterial of interest.\nThe argument ranges over a variety of issues, problems, generalizations, and theoretical\nconstructions. Some are treated rapidly, with the aim of extracting a general point, others are pursued\nin detail; sometimes the treatment is informal, at other times it is necessary to formalize carefully so\nthat nonobvious results can be established by explicit proof. We have tried to segregate and modularize\nas much as possible, but the reader should feel free on first reading to tunnel through bits that do not\nappeal: the formalist can surely find another formal patch up ahead, the connoisseur of generalizations\nanother generalization. We have tried to sign-post the way in the text.\nIf the reader’s interest is piqued by the present contents, the following works, which make use\nof Optimality Theory in various ways, may be of interest:\nArchangeli, Diana and Douglas Pulleyblank. 1992. Grounded phonology. Ms. University of Arizona\nand University of British Columbia.\nBlack, H. Andrew. 1993. Constraint-ranked derivation: truncation and stem binarity in Southeastern\nTepehuan. Ms. UC Santa Cruz.\nChurchyard, Henry. 1991. Biblical Hebrew prosodic structure as the result of preference-ranked\nconstraints.\nGoodman, Beverley. 1993. The integration of hierarchical features into a phonological system.\nDoctoral dissertation, Cornell University.\nHung, Henrietta. 1992. Relativized suffixation in Choctaw: a constraint-based analysis of the verb\ngrade system. Ms. Brandeis University.\nHung, Henrietta. in preparation. The rhythmic and prosodic organization of edge constituents.\nDoctoral dissertation. Brandeis University.\nItô, Junko. Yoshihisa Kitagawa. and R. Armin Mester. 1992. prosodic type preservation in japanese:\nevidence from zuuja-go. SRC-92-05. Syntax Research Center. UC Santa Cruz.\nItô, Junko and R. Armin Mester. 1992. Weak layering and word binarity. Ms. University of California.\nSanta Cruz.\nItô, Junko and R. Armin Mester. to appear. Licensed segments and safe paths. In Constraints,\nviolations, and repairs in phonology. Special issue of the Canadian Journal of Linguistics.\nKirchner, Robert. 1992a. Harmonic Phonology within One Language: An Analysis of Yidiny. MA\nthesis. University of Maryland. College Park.\nKirchner, Robert. 1992b. Yidiny prosody in Harmony Theoretic Phonology. Ms. UCLA.\n\n8\n\nChapter 1\n\nPrince & Smolensky\n\nLegendre, Géraldine, William Raymond, and Paul Smolensky. Analytic typology of case marking and\ngrammatical voice.\nMcCarthy, John. to appear. A case of surface constraint violation. Canadian Journal of Linguistics.\nspecial issued edited by Carole Paradis. Darlene LaCharité. and Emmanuel Nikiema.\nMcCarthy, John and Alan Prince. 1993. Prosodic Morphology I: constraint interaction and\nsatisfaction.\nMester, R. Armin. to appear. The quantitative trochee in Latin. Natural Language & Linguistic\nTheory.\nPrince, Alan. 1990/92. Quantitative consequences of rhythmic organization.\nRosenthall, Sam. in preparation. The phonology of vowels and glides. Doctoral dissertation. University\nof Massachusetts, Amherst.\nSamek-Lodovici, Vieri. 1992. Universal constraints and morphological gemination: a crosslinguistic\nstudy. Ms. Brandeis University.\nSamek-Lodovici, Vieri. 1993. A unified analysis of crosslinguistic morphological gemination. In\nProceedings of CONSOL-1.\nSelkirk. Elisabeth. 1993. The prosodic structure of functional elements: affixes, clitics, and words.\nhandout of talk presented at Signal to Syntax Conference. Brown University.\nSherer, Tim. in preparation. Prosodic Phonotactics. Doctoral dissertation. University of\nMassachusetts. Amherst.\nYip, Moira. 1992. Cantonese loan word phonology and Optimality Theory. To appear in Journal of\nEast Asian Linguistics.\nYip, Moira. 1993. Phonological constraints, optimality, and phonetic realization in Cantonese. UPenn\nColloquium.\nZec, Draga. in preparation. Coda constraints and conditions on syllable weight. Cornell University.\nZoll, Cheryl. 1992. When syllables collide: a theory of alternating quantity. Ms. Brandeis University.\nZoll, Cheryl. 1993. Ghost consonants and optimality. WCCFL, Santa Cruz.\n\nPART I\nOptimality and Constraint Interaction\n\n10\n\nChapter 2\n\nPrince & Smolensky\n\nOverview of Part I. §§2-5.\nOur first goal will be to establish that the notion of optimality is, as claimed, indispensable to\ngrammar. In §2 we will argue this point from the results of Dell and Elmedlaoui in their landmark\nstudy of syllabification in Imdlawn Tashlhiyt Berber. In the course of this argument, we will\nintroduce the notion of constraint domination and the fundamental mechanism for computing\noptimality with respect to a set of constraints that have been prioritized with this notion. We then\nmove on in §3 and §4 to analyze fundamental recurrent patterns of grammatical generalization,\nshowing that constraint domination explicates and improves on the notions of triggering and\nblocking that figure prominently in current linguistic discussion. We examine a number of\nphenomena central to prosodic theory, including (aspects of) the relation between foot structure and\nsyllable structure; the interactions of prominence, minimality, and extrametricality; and the relation\nbetween syllable structure and the prosodic-morphological processes of edge-oriented infixation,\narguing that proper understanding of constraint domination sheds new light on these phenomena. The\nformal theory of extrametricality is dissolved into interaction effects between independently-required\nconstraints. We conclude §4 with an analysis of prosodic structure in Latin which brings together\nthe various empirical and theoretical themes pursued in the discussion. Part I draws to a close with\na formal characterization of the notion ‘evaluation with respect to a constraint hierarchy’ and study\nof some properties of constraint ranking.\n\nOptimality Theory\n\nChapter 2\n\n11\n\n2. Optimality in Grammar: Core Syllabification in Imdlawn Tashlhiyt Berber\nHere we argue that certain grammatical processes can only be properly understood as selecting the\noptimal output from among a set of possibilities, where the notion optimal is defined in terms of the\nconstraints bearing on the grammatical domain at issue.\n\n2.1 The Heart of Dell & Elmedlaoui\nThe Imdlawn Tashlhiyt dialect of Berber (ITB) has been the object of a series of remarkable studies\nby François Dell and Mohamed Elmedlaoui (Dell & Elmedlaoui 1985, 1988, 1989). Perhaps their\nmost suprising empirical finding is that in this language any segment — consonant or vowel,\nobstruent or sonorant — can form the nucleus of syllable. One regularly encounters syllables of the\nshape tK, rB, xZ, wL, for example. (Capitalization represents nucleus-hood of consonants.) The\nfollowing table provides illustrative examples, with periods used to mark syllable edges:4\nNucleus Type\n\nExample\n\nMorphology\n\nReference\n\nvoiceless stop\n\n.ra.tK.ti.\n\nra-t-kti\n\n1985: 113\n\nvoiced stop\n\n.bD.dL.\n.ma.ra.tGt.\n\nbddl\nma=ra-t-g-t\n\n1988: 1\n1985: 113\n\nvoiceless fricative\n\n.tF.tKt.\n.tX.zNt.\n\nt-ftk-t\nt-xzn-t\n\n1985: 113\n1985: 106\n\nvoiced fricative\n\n.txZ.nakkw.\n\nt-xzn#nakkw\n\n1985: 113\n\nnasal\n\n.tzMt.\n.tM.z£.\n\nt-zmt\nt-mz£\n\n1985: 112\n1985: 112\n\nliquid\n\n.tR.gLt.\n\nt-rgl-t\n\n1985: 106\n\nhigh vowel\n\n.il.di.\n.rat.lult.\n\ni-ldi\nra-t-lul-t\n\n1985: 106\n1985: 108\n\nlow vowel\n\n.tR.ba.\n\nt-rba\n\n1985: 106\n\nDell and Elmedlaoui marshall a compelling range of evidence in support of the claimed patterns of\nsyllabification. In addition to native speaker intuition, they adduce effects from segmental phonology\n(emphasis spread), intonation, versification practice, and prosodic morphology, all of which agree\nin respecting their syllabic analysis.\n\n4\n\nGlosses are ratkti ‘she will remember’; bddl ‘exchange!’; maratgt ‘what will happen to you?’; tftkt ‘you\n(2psg) suffered (pf.)a strain’, txznt ‘you stored’; txznakkw ‘she even stockpiled’; tzmt ‘it(f.) is stifling; tmz£\n‘she jested’; trglt ‘you locked’; ildi ‘he pulled’; ratlult ‘you will be born’; trba ‘she carried-on-her-back’.\n\n12\n\nChapter 2\n\nPrince & Smolensky\n\nThe domain of syllabification is the phonological phrase. All syllables must have onsets\nexcept when they occur in absolute phrase-initial position. There, syllables may begin with vowels,\neither with or without glottal striction (Dell & Elmedlaoui 1985: 127 fn. 20), evidently a matter of\nphonetic implementation. Since any segment at all can form the nucleus of a syllable, there is\nmassive potential ambiguity in syllabification, and even when the onset requirement is satisfied, a\nnumber of distinct syllabifications will often be potentially available. But the actual syllabification\nof any given string is almost always unique. Dell & Elmedlaoui discovered that assignment of\nnuclear status is determined by the relative sonority of the elements in the string. Thus we find the\nfollowing typical contrasts:\n(3) Sonority Effects on Nuclear Status\n(a)\ntzMt — *tZmt\n‘m beats z as a nucleus’\n(b)\nrat.lult — *ra.tL.wLt.‘u beats l as a nucleus’\nOrthography: we write u for the nuclear version, w for the marginal version of the high back vocoid,\nand similarly for i and y: as with every other margin/nucleus pair, we assume featural identity.\nAll the structures in (3), including the ill-formed ones, are locally well-formed, composed\nof licit substructures. In particular, there is nothing wrong with syllables tZ, tL, or wLt nor with\nword-final sequences mt — but the more sonorous nucleus is chosen in each case. By examining the\nfull range of such contrasts, Dell and Elmedlaoui establish the relevance of the following familiar\nkind of 8-point hierarchy:\n(4) Sonority Scale\n*Low V*>*High V*>*Liquid* >*Nasal*>*Voiced Fric.*>*Voiceless Fric.*>*Voiced Stop*>*Voiceless Stop*\n\nWe write *\"* for the sonority or intrinsic prominence of \".\nWith the sonority scale in hand, Dell and Elmedlaoui then propose an iterative syllableconstruction procedure that is designed to select the correct nuclei. Their algorithm can be stated in\nthe following way, modified slightly from Dell & Elmedlaoui 1985: 111(15):\n(5) Dell&Elmedlaoui Algorithm for Core Syllabification (DEA)\nBuild a core syllable (“CV”) over each substring of the form XY, where\nX is any segment (except [a]), and\nY is a matrix of features describing a step of the sonority scale.\nStart Y at the top of the sonority scale and replace it successively with the matrix of features\nappropriate to the next lower step of the scale.\n(Iterate from Left to Right for each fixing of the nuclear variable Y.)\nLike all such procedures, the DEA is subject to the Free Element Condition (FEC: Prince 1986),\nwhich holds that rules establishing a level of prosodic structure apply only to elements that are not\nalready supplied with the relevant structure. By the FEC, the positions analyzed by the terms X,Y\nmust be free of syllabic affiliation. Effectively, this means that any element seized as an onset is no\n\nOptimality Theory\n\nChapter 2\n\n13\n\nlonger eligible to be a nucleus, and that a segment recruited to nucleate a syllable is not then\navailable to serve as an onset.\nThere are other syllabification phenomena in ITB that require additional rules beyond the\nDEA; we will abstract away from these and focus on the sense of DEA itself.5 We will also put aside\nsome wrinkles in the DEA which are related to parenthesized expressions in (5) — the lack of a glide\ncounterpart for /a/, the phrase-initial loosening of the onset requirement, and the claimed left-torightness of the procedure.6\nThe DEA is a rule, or rather a schema for rules, of exactly the classical type A ÿ B / C—D.\nEach rule generated by the schema has a Structural Description specified in featural terms and a\nStructural Change (‘construct a core syllable’). To see how it works, consider the following\nderivations:\n\n5\n\nNot the least of these is that syllables can have codas; the DEA serves essentially to locate syllable\nnuclei, which requires that onsets be taken into consideration. But it is not difficult to imagine plausible\nextensions which lead to adjunction of codas. More subtle, perhaps, are these phenomena:\na. obstruents are always nonsyllabic in the envs. #— and —#.\nb. sonorant C’s are optionally nonsyllabic —# under certain conditions.\nc. the 1st element of a tautomorphemic geminate is never an onset.\nIn addition, the DEA does completely resolve sequences /~aa~/, which according to other sources, surface\nas ~aya~ (Guerssel 1985). The appropriate approach to epenthetic structure within OT involves the constraint\nFILL, which makes its appearance below in §3.1 and receives full discussion in §6.\n6\n\nWe deal with the fact that [a] cannot occupy syllable margins in §8.1.1. The commonly encountered\nrelaxation of the onset requirement in initial position is resolved in McCarthy & Prince 1993 in terms of\nconstraint interaction, preserving the generality of ONS. Dell & Elmedlaoui are themselves somewhat\nambivalent about the need for directionality (Dell & Elmedlaoui 1985: 108); they suggest that “the\nrequirement [of directionality] is not concerned with left to right ordering per se, but rather with favoring\napplication of [the DEA] that maximize the sonority differences between [onset and nucleus]” (Dell &\nElmedlaoui 1985:127, fn. 22). In addition, they note that directionality falsely predicts *.i.tBd.rin. from\n/i=t-!bdri-n/ ‘for the cockroaches’, whereas the only licit syllabification is .it.bD.rin. The reason for this\nsyllabification is not understood. A directionless theory leaves such cases open for further principles to\ndecide.\n\n14\n\nChapter 2\n\nPrince & Smolensky\n\n(6) DEA in Action\nSteps of the DEA\n\n/ratlult/ ‘you will be born’\n\nSeek [X][+low, !cns]\n\n& Build\n\n(ra)tlult\n\nSeek [X][!low,!cns]\n\n& Build\n\n(ra)t(lu)lt\n\nSeek [X][+cns,+son,!nas]\n\n!blocked by FEC!\n\nSeek [X][+cns,+son,+nas]\n\n—\n\nSeek [X][!son, +cnt, +voi]\n\n—\n\nSeek [X][!son, +cnt, !voi]\n\n—\n\nSeek [X][!son,!cnt,+voi]\n\n—\n\nSeek [X][!son,!cnt,!voi]\n\n& Build\n\n(ra)t(lu)(lT)7\n\n(7) DEA in Action\nSteps of the DEA\n\n/txznt/ ‘you sg.stored’\n\nSeek [X][+low,!cns]\n\n—\n\nSeek [X][!low,!cns]\n\n—\n\nSeek [X][+cns,+son,!nas]\n\n—\n\nSeek [X][+cns,+son,+nas]\n\n& Build\n\nSeek [X][!son, +cnt, +voi]\nSeek [X][!son, +cnt, !voi] & Build\n\n7\n\ntx(zN)t\n—\n(tX)(zN)t\n\nSeek [X][!son,!cnt,+voi]\n\n—\n\nSeek [X][!son,!cnt,!voi]\n\n—\n\nWe show the form predicted by the DEA. The form is actually pronounced rat.lult. because obstruents\ncannot be nuclear next to phrase boundaries, as mentioned in fn. 5.\n\nOptimality Theory\n\nChapter 2\n\n15\n\n(8) DEA in action\nSteps of the DEA\nSeek [X][+low,!cns]\n\n/txznas/ ‘she stored for him’\n& Build\n\ntxz(na)s\n\nSeek [X][!low,!cns]\n\n—\n\nSeek [X][+cns,+son,!nas]\n\n—\n\nSeek [X][+cns,+son,+nas]\n\n!blocked by FEC!\n\nSeek [X][!son, +cnt, +voi] & Build\n\nt(xZ)(na)s\n\nSeek [X][!son, +cnt, !voi]\n\n!blocked by FEC!\n\nSeek [X][!son,!cnt,+voi]\n\n—\n\nSeek [X][!son,!cnt,!voi]\n\n!blocked by FEC!\n\nThe DEA provides an elegant and straightforward account of the selection of syllable nuclei in the\nlanguage. But it suffers from the formal arbitrariness characteristic of re-writing rules when they are\nput to the task of dealing locally with problems that fall under general principles, particularly\nprinciples of output shape. (By ‘formal arbitrariness’, we mean that a formal system rich enough to\nallow expression of the desired rule will also allow expression of many undesired variations of the\nrule, so that the rule itself appears to be an arbitrary random choice among the universe of\npossibilities.) The key to the success of the DEA is the way that the variable Y scans the input,\nstarting at the top of the sonority scale and descending it step by step as the iterative process unfolds.\nWe must ask, why start at the top? why descend the scale? why not use it in some more elaborate\nor context-dependent fashion? why apply the scale to the nucleus rather than the onset? 8\nThe answers are to be found in the theory of syllable structure markedness, which is part of\nUniversal Grammar. The more sonorous a segment is, the more satisfactory it is as a nucleus.\nConversely, a nucleus is more satisfactory to the degree that it contains a more sonorous segment.\nIt is clear that the DEA is designed to produce syllables with optimal nuclei; to ensure that the\nsyllables it forms are the most harmonic that are available, to use the term introduced in §1. Dell and\nElmedlaoui clearly understand the role of sonority in choosing between competing analyses of a\ngiven input string; they write:\nWhen a string ...PQ... could conceivably be syllabified as ...Pq... or as ...pQ... (i.e.\nwhen either syllabification would involve only syllable types which, when taken\nindividually, are possible in ITB), the only syllabification allowed by ITB is the one that\ntakes as a syllabic peak the more sonorous of the two segments.\n— Dell & Elmedlaoui 1985:109\n8\n\nThese are exactly the sort of questions that were fruitfully asked, for example, of the classic TG rule\nof Passive that moved subject and object, inserted auxiliaries, and formed a PP: why does the post-verbal\nNP move up not down? why does the subject NP move at all? why is by+NP a PP located in a PP position?\nand so on.\n\n16\n\nChapter 2\n\nPrince & Smolensky\n\nBut if phonology is couched in re-writing rules, this insight cannot be cashed in as part of the\nfunction that assigns structural analyses. It remains formally inert. Dell and Elmedlaoui refer to it\nas an “empirical observation,” emphasizing its extra-grammatical status.\nThe DEA itself makes no contact with any principles of well-formedness; it merely scans the\ninput for certain specific configurations, and acts when it finds them. That it descends the sonority\nscale, for example, can have no formal explanation. But the insight behind the DEA can be made\nactive if we re-conceive the process of syllabification as one of choosing the optimal output from\namong the possible analyses rather than algorithmic structure-building. Let us first suppose, with\nDell and Elmedlaoui, that the process of syllabification is serial, affecting one syllable at a time\n(thus, that it operates like Move-\" or more exactly, Move-x of grid theory). At each stage of the\nprocess, let all possible single syllabic augmentations of the input be presented for evaluation. This\nset of candidates is evaluated by principles of syllable well-formedness and the most harmonic\nstructure in the set is selected as the output. We can state the process informally as follows:\n(9) Serial Harmonic Syllabification (informal).\nForm the optimal syllable in the domain.\nIterate until nothing more can be done.\nThis approach depends directly on the principles of well-formedness which define the notion\n‘optimal’. No instructions are issued to the construction process to contemplate only one featurallyspecified niche of the sonority scale. Indeed, the Harmonic syllabification algorithm has no access\nto any information at all about absolute sonority level or the specific featural composition of vowels,\nwhich are essential to the DEA; it needs to know whether segment \" is more sonorous than segment\n$, not what their sonorities or features actually are. All possibilities are entertained simultaneously\nand the choice among them is made on grounds of general principle. That you start at the top of the\nscale, that you descend the scale rather than ascending it or touring it in some more interesting\nfashion, all this follows from the universal principles that define the relative Harmony of nucleussegment pairings. The formal arbitrariness of the DEA syllable-constructing procedure disappears\nbecause the procedure itself (‘make a syllable’) has been stripped of intricacies.9\nThis is an instance of Harmony-increasing processing (Smolensky 1983, 1986; Goldsmith\n1991, 1993). The general rubric is this:\n(10) Harmonic Processing\nGo to the most harmonic available state.\nWe speak not of ‘relative well-formedness’ but rather of relative Harmony: Harmony is a wellformedness scale along which a maximal-Harmony structure is well-formed and all other structures\nare ill-formed.\n\n9\n\nFurther development of this idea could eliminate complications at the level of the general theory; in\nparticular, the appearance of obeying the Free Element Condition during serial building of structure could\nbe seen to follow from the fact that disobeying it inevitably decrements the Harmony of the represention.\n\nOptimality Theory\n\nChapter 2\n\n17\n\nWe conclude that the Dell-Elmedlaoui results establish clearly that harmonic processing is a\ngrammatical mechanism, and that optimality-based analysis gives results in complex cases. Let us\nnow establish a formal platform that can support this finding.\n\n2.2 Optimality Theory\nWhat, then, is the optimal syllable that Harmonic Syllabification seeks? In the core process that we\nare focusing on, two constraints are at play, one ensuring onsets, the other evaluating nuclei. The\nonset constraint can be stated like this (Itô 1986, 1989):\n(11) The Onset Constraint (ONS). Syllables must have onsets (except phrase initially).\nAs promised, we are not going to explicate the parenthesized caveat, which is not really part of the\nbasic constraint (see McCarthy & Prince 1993: §4). The nuclear constraint looks like this:10\n(12) The Nuclear Harmony Constraint (HNUC). A higher sonority nucleus is more harmonic than\none of lower sonority.\nI.e. If *x* > *y* then Nuc/x TM Nuc/y.\nThe formalizing restatement appended to the constraint uses some notation that will prove useful.\nFor ‘x is more harmonic than y’ we write x TM y.\nFor ‘the intrinsic prominence of x’ we write *x*.\n‘A/x’ means ‘x belongs to category A, x is the constituent-structure child of A’\nThe two kinds of order TM and > are distinguished notationally to emphasize their conceptual\ndistinctness. Segments of high sonority are not more harmonic than those of lower sonority. It is only\nwhen segments are contemplated in a structural context that the issue of well-formedness arises.\nIt is necessary to specify not only the relevant constraints, but also the set of candidates to\nbe evaluated. To do this we need to spell out the function Gen that admits to candidacy a specific\nrange of structurings or parses of the input. In the case at hand, we want something roughly like this:\n(13) Gen (inputi): the set of (partial) syllabifications of inputi which differ from inputi in no more\nthan one syllabic adjunction.\nFor any form inputi to undergo Serial Harmonic Syllabification, the candidate set Gen(inputi)\nmust be evaluated with respect to the constraints ONS and HNUC. There would be little to say if\nevaluation were simply a matter of choosing the candidate that satisfies both constraints. Crucially,\n\n10\n\nIt is also possible to conceive of the operative constraint in a kind of ‘contrapositive’ manner. Because\nall underlying segments of ITB are parsed, a segment is a nucleus iff it is not a member of the syllable\nmargin. Consequently, negative constraints identifying the badness of syllable margins can have the same\neffect as positive constraints identifying the goodness of nuclei. We investigate this approach below in\n§8.1.1, §8.3.3, §8.4.2.\n\n18\n\nChapter 2\n\nPrince & Smolensky\n\nand typically, this straightforward approach cannot work. Conflict between the constraints ONS and\nHNUC is unavoidable; there are candidate sets in which no candidate satisfies both constraints.\nConsider, for example, the syllabification of the form /£aul-tn/ ‘make them (m.) plentiful’\n(Dell & Elmedlaoui 1985:110). Both ONS and HNUC agree that the core syllable £a should be\nformed: it has an onset as well as the best possible nucleus. Similarly, we must have a final syllable\ntN. But what of the rest of the string? We have two choices for the sequence /ul/: a superior nucleus\nlacking an onset, as in ul; or an onsetted syllable with an inferior nucleus, as in wL. This situation\ncan be perspicuously displayed in tabular form:11\n(14) Constraint Inconsistency\nCandidates\n/£aul-tn/\n\nONS\n\n*l*\n\n~.wL.~\n~.ul.~\n\nHNUC\n\n*\n\n*u*\n\nThe cells contain information about how each candidate fares on the relevant constraint. A blank cell\nindicates that the constraint is satisfied; a star indicates violation. (In the case of a scalar constraint\nlike HNUC we mention the contents of the evaluated element.) The first form succeeds on ONS, while\nthe second form violates the constraint. The relative performance is exactly the opposite on HNUC:\nbecause *u* > *l*, the second, onsetless form has the better nucleus. The actual output is, of course,\n.£a.wL.tN. The onset requirement, in short, takes priority.\nSuch conflict is ubiquitous, and to deal with it, we propose that a relation of domination, or\npriority-ranking, can be specified to hold between constraints. When we say that one constraint\ndominates another, we mean that when they disagree on the relative status of a pair of candidates,\nthe dominating constraint makes the decision. If the dominating constraint does not decide between\nthe candidates — as when both satisfy or both violate the constraint equally — then the comparison\nis passed to the subordinate constraint. (In the case of a more extensive hierarchy, the same method\nof evaluation can be applied repeatedly.)\nIn the case at hand, it is clear that ONS must dominate HNUC. The top priority is to provide\nsyllables with onsets; the relative Harmony of nuclei is a subordinate concern whose force is felt only\nwhen the ONS issue is out of the way. We will write this relation as ONS >> HNUC. Given such a\nhierarchy, an optimality calculation can be usefully presented in an augmented version of display\n(14) that we will call a constraint tableau:\n\n11\n\nProperly speaking, if we limit our attention to the core syllable stage of the procedure, we should be\ncomparing core .u. with core .wL. But the comparison remains valid even after coda consonants are adjoined\nand we wish to emphasize that the two cited analyses of /£aul-tn/ differ only in treatment of the sequence /ul/.\n\nOptimality Theory\n\nChapter 2\n\n19\n\n(15) Constraint Tableau for partial comparison of candidates from /£aultn/\nCandidates\n\nL\n\nONS\n\n*l*\n\n~.wL.~\n~.ul.~\n\nHNUC\n\n*!\n\n*u*\n\nConstraints are arrayed across the top of the tableau in domination order. As above, constraint\nviolations are recorded with the mark *, and blankness indicates total success on the constraint.\nThese are the theoretically important conventions; in addition, there is some clarificatory typography.\nThe symbol L draws the eye to the optimal candidate; the ! marks the crucial failure for each\nsuboptimal candidate, the exact point where it loses out to other candidates. Cells that do not\nparticipate in the decision are shaded. In the case at hand, the contest is decided by the dominant\nconstraint ONS; HNUC plays no role in the comparison of .wL. and .ul. HNUC is literally irrelevant\nto this particular evaluation, as a consequence of its dominated position — and to emphasize this,\nwe shade its cells. Of course, HNUC is not irrelevant to the analysis of every input; but a precondition\nfor relevance is that there be a set of candidates that tie on ONS, all passing it or all failing it to the\nsame extent.\nIf we were to reverse the domination ranking of the two constraints, the predicted outcome\nwould be changed: now .ul. would be superior to .wL. by virtue of its relative success on HNUC, and\nthe ONS criterion would be submerged. Because of this, the ranking ONS >> HNUC is crucial; it must\nobtain in the grammar of Berber if the actual language is to be generated.\nThe notion of domination shows up from time to time in one form or another in the literature,\nsometimes informally, sometimes as a clause clarifying how a set of constraints is to be interpreted.\nFor example, Dell and Elmedlaoui write, “The prohibition of hiatus...overrides” the nuclear sonority\ncomparison (Dell & Elmedlaoui 1985: 109, emphasis added). For them, this is an extra-grammatical\nobservation, with the real work done by the Structural Descriptions provided by the DEA and the\nordering of application of the subrules. Obviously, though, the insight is clearly present. Our claim\nis that the notion of domination, or ‘over-riding’, is the truly fundamental one. What deserves extragrammatical status is the machinery for constructing elaborately specific Structural Descriptions and\nmodes of rule application.\nTo see how Serial Harmonic Syllabification (9) proceeds, let us examine the first stage of\nsyllabifying the input /txznt/ ‘you sg. stored, pf.’. It is evident that the first syllable constructed must\nbe .zN. — it has an onset, and has the highest sonority nucleus available, so no competing candidate\ncan surpass or even equal it. A more discursive examination of possibilities might be valuable; the\nlarger-scale comparisons are laid out in the constraint tableau below.\nHere are (some of the) leading candidates in the first round of the process:\n\n20\n\nChapter 2\n\nPrince & Smolensky\n\n(16) Constraint Tableau for Serial Syllabification of /txznt/ (partial, first step)\nCandidates\n\nL\n\nONS\n\nComments\n\nHNUC\nn\n\noptimal: onsetted, best available\nnucleus\n\nn\n\nno onset, HNUC irrelevant\n\nt(xZ)nt\n\nz!\n\n* z * < * n*\n\n(tX)znt\n\nx!\n\n* x* < * n*\n\ntxz(nT)\n\nt!\n\n*t* < *n*\n\ntx(zN)t\ntxz(N)t\n\n*!\n\nSyllabic parsing is conceived here as a step-by-step serial process, just as in the DEA. A\ncandidate set is generated, each produced by a single licit change from the input; the relative status\nof the candidates is evaluated, yielding an optimal candidate (the output of the first step); and that\noutput will then be subject to a variety of further single changes, generating a new candidate set to\nbe evaluated; and so on, until there are no bettering changes to be made: the final output has then\nbeen determined.\nThis step-by-step Harmony evaluation is not intrinsic to the method of evaluation, though,\nand, in the more general context, when we discard the restricted definition of Gen in (13), it proves\nnecessary to extend the procedure so that it is capable of evaluating entire parsed strings, and not just\nsingle (new) units of analysis. To do this, we apply the same sort of reasoning used to define\ndomination, but within the constraint categories. To proceed by example, consider the analysis of\n/txznt/ taking for candidates all syllabified strings. We present a sampling of the candidate space.\n(17) Parallel Analysis of Complete Syllabification of /txznt/\nCandidates\n\nComments\n\nHNUC\n\nONS\n\nL .tX.zNt.\n\nn\n\nx\n\noptimal\n\n.Tx.zNt.\n\nn\n\nt!\n\n*n* = *n*, *t* < *x*\n\n.tXz.nT.\n\nx!\n\nt\n\n*x* < *n*, t irrelevant\n\nn\n\nz\n\nHNUC irrelevant\n\n.txZ.Nt.\n\n*!\n\n.T.X.Z.N.T.\n\n* ! ***\n\nnzxtt\n\nHNUC irrelevant\n\nIn evaluating the candidates we have kept to the specific assumptions mentioned above: the\nonset requirement is suspended phrase-initially, and the nonnuclear status of peripheral obstruents\nis, as in the DEA itself, put aside (see fn. 5).\n\nOptimality Theory\n\nChapter 2\n\n21\n\nIn this tableau, all the relevant information for harmonic evaluation of the parse of the whole\nstring is present. We start by examining the first column, corresponding to the dominant constraint\nONS. Only the candidates which fare best on this constraint survive for further consideration. The\nfirst three candidates all have syllables with onsets; the last two do not (to varying degrees). Lack\nof onset in even a single non-initial syllable is immediately fatal, because of the competing\ncandidates which satisfy ONS.\nThe remaining three parses are not distinguished by ONS, and so HNUC, the next constraint\ndown the hierarchy, becomes relevant. These three parses are compared by HNUC as follows. The\nmost sonorous nucleus of each parse is examined: these are the most harmonic nuclei according to\nHNUC. For each of the first two candidates the most sonorous nucleus is n. For the last candidate,\nthe most sonorous nucleus is x, and it drops out of the competition since n is more sonorous than x.\nWe are left with the first two candidates, so far tied on all comparisons. The HNUC evaluation\ncontinues now to the next-most-harmonic nuclei, where the competition is finally settled in favor\nof the first candidate .tX.zNt.\nWhat we have done, in essence, is to replace the iterative procedure (act/evaluate,\nact/evaluate,...) with a recursive scheme: collect the results of all possible actions, then sort\nrecursively. Rather than producing and pruning a candidate set at each step of sequential processing,\nstriving to select at each step the action which will take us eventually to the correct output, the whole\nset of possible parses is defined and harmonically evaluated. The correct output is the candidate\nwhose complete structure best satisfies the constraint hierarchy. And ‘best satisfies’ can be\nrecursively defined by descending the hierarchy, discarding all but the best possibilities according\nto each constraint before moving on to consider lower-ranked constraints.\nThe great majority of analyses presented here will use the parallel method of evaluation. A\ndistinctive prediction of the parallel approach is that there can be significant interactions of the topdown variety between aspects of structure that are present in the final parse. In §3, §4 and §7 we will\nsee a number of cases where this is borne out, so that parallelism is demonstrably crucial; further\nevidence is presented in McCarthy & Prince 1993. ‘Harmonic serialism’ is worthy of exploration\nas well, and many hybrid theories can and should be imagined; but we will have little more to say\nabout it. (But see fn. 49 below on Berber syllabification.)\nThe notion of parallel analysis of complete parses in the discussion of constraint tableau (17) is the\ncrucial technical idea on which many of our arguments will rest. It is a means for determining the\nrelative harmonies of entire candidate parses from a set of conflicting constraints. This technique has\nsome subtleties, and is subject to a number of variant developments, so it is worth setting out with\nsome formal precision exactly what we have in mind. A certain level of complexity arises because\nthere are two dimensions of structure to keep track of. On the one hand, each individual constraint\ntypically applies to several substructures in any complete parse, generating a set of evaluations.\n(ONS, for example, examines every syllable, and there are often several of them to examine.) On the\nother hand, every grammar has multiple constraints, generating multiple sets of evaluations.\nRegulating the way these two dimensions of multiplicity interact is a key theoretical commitment.\nOur proposal is that evaluation proceeds by constraint. In the case of the mini-grammar of\nONS and HNUC, entire syllabifications are first compared via ONS alone, which examines each\nsyllable for an onset; should this fail to decide the matter, the entire syllabifications are compared\nvia HNUC alone, which examines each syllable’s nucleus.\n\n22\n\nChapter 2\n\nPrince & Smolensky\n\nAnother way to use the two constraints would be to examine each (completely parsed)\ncandidate syllable-by-syllable, assessing each syllable on the basis of the syllabic mini-grammar. The\nfact that ONS dominates HNUC would then manifest itself in the Harmony assessment of each\nindividual syllable. This is also the approach most closely tied to continuous Harmony evaluation\nduring a step-by-step constructive derivation. Here again, we do not wish to dismiss this conception,\nwhich is surely worthy of development. Crucially, however, this is not how Harmony evaluation\nworks in the present conception (see §5.2.3.1 for further discussion).\nIn order to characterize harmonic comparison of candidate parses with full generality and\nclarity, we need to specify two things: first, a means of comparing entire candidates on the basis of\na single constraint; then, a means of combining the evaluation of these constraints. The result is a\ngeneral definition of Harmonic Ordering of Forms; this is, in its formal essence, our theory of\nconstraint interaction in generative grammar. It is the main topic of §5.\n\n2.3 Summary of discussion to date\nThe core syllabification of Imdlawn Tashlhiyt Berber provides a particularly clear case where the\nfunction assigning structural analyses must be based on the optimality of the output if it is to be\nproperly founded on principle. Once the relevant principles have been moved into grammatical\ntheory, it becomes possible to undertake a radical simplification of the generative procedure that\nadmits candidate syllable structures. The focus shifts away from the effort to construct an algorithm\nthat assembles the correct structure piece-by-piece, an effort that we believe is doomed to severe\nexplanatory shortcomings. Linguistic theory, properly conceived, simply has little to say about such\nconstructional algorithms, which (we claim) are no more than implementations of grammatical\nresults in a particular computational-like framework. The main explanatory burden falls the\nconstraints themselves, and on the apparatus that governs their interactions.\nThe Berber situation is particularly interesting in that core syllabification simply cannot\nproceed without the intervention of two distinct constraints. As with other forms of prosodic\norganization, the most common picture is one in which the structure is built (more-or-less) bottomup, step-by-single-step, with each step falling under the constraints appropriate to it. Taking this\nseriously in the syllable structure domain, this would mean, following Levin [Blevins] (1985) and\nultimately Kahn (1976), that you first locate the nuclei — the heads of syllables; then project higher\norder structure that includes the onsets; then project the structure that includes postnuclear\nconsonantism. In ITB, however, as in many other languages, the availability of nuclei depends on\nthe choice of onsets: an early step in the derivational constructive procedure, working on a low level\nin the structural hierarchy, depends on later steps that deal with the higher levels. Indeed, the higher\nlevel constraint is very much the more forceful. Technical solutions to this conundrum can be found\nin individual cases — Dell and Elmedlaoui’s being a particularly clever one; but the theme will reappear persistently in every domain of prosody, defying a uniform treatment in constructionist terms.\nIn the theory advocated here, where outputs are evaluated, we expect exactly this kind of\ninteraction. The whole output is open to inspection; how we choose to inspect it, or how we are\nforced by UG to inspect it, is not determined by the course that would be taken in bottom-up\nconstruction. The potential force of a constraint is not indexed to the level of structure that it pertains\nto, and under certain circumstances (UG permitting or demanding), constraint domination will be\ninvoked to give higher-level constraints absolute priority over those relevant to the design of lower\nstructural levels.\n\n23\n\n3. Generalization-Forms in Domination Hierarchies I\nBlocking and Triggering: Profuseness and Economy\nTwo patterns of constraint interaction appear repeatedly in modern grammatical work. The first can\nbe informally characterized as Do Something Only When Necessary. Under this rubric, a process of\nwide formal generality, say iÿV, nevertheless applies only in special circumstances, namely those\nin which it is necessary for well-formedness. The default is not to do; the process is triggered by the\nconstraint or constraints that it subserves. In operational phonology, a ‘repair strategy’ is exactly a\nprocess which applies only when it leads to satisfaction of otherwise-violated constraints (Singh\n1987, Paradis 1988ab). Epenthesis is a typical example; it is so closely tied to syllable-structure and\nword-structure constraints that the process itself can be given an entirely general formulation (e.g.\niÿV), with no limiting environmental restrictions, so long as it is understood to apply only when\nneeded. (This notion appears in Sommerstein 1972 and is closely related to the proposals of\nKisseberth 1970ab, 1972). There is a considerable body of work on the idea, including Singh,\nParadis, Prunet, Myers, McCarthy, Itô, Mester, Yip, Goldsmith, though we believe it is fair to say\nthat no consensus has emerged on how the rule-constraint interaction is to be understood; that is,\nhow and when the rule is to be triggered by the constraint(s). In syntax the notion Do Something\nOnly When Necessary appears under the heading of ‘movement as a last resort’ or, more generally,\n‘Economy of Derivation’ (Chomsky 1989).\nThe second common pattern can be characterized as Do Something Except When Banned.\nThis is the original Rossian and Kisseberthian style of rule/constraint interaction, in which the\nconstraint blocks the rule: front a wh-phrase except when such & such conditions prevail. Here the\ndefault is to do; the process is inhibited under narrowly specifiable conditions. In operational\nphonology, deletion rules are often stated this way: delete a certain vowel everywhere, except when\nit leads to ill-formed syllable-structure, stress-clash, or violations of the OCP (Kisseberth 1970ab,\n1972; Hammond 1984; McCarthy 1986). This phenomenon we might call ‘Profuseness of\nDerivation’.\nBoth patterns emerge from strict domination, where the basic fact of life is that a higherranked constraint forces violations of a lower-ranked constraint. How this looks to the operational\ndescriber depends on the character of the lower-ranked constraint. The economy or triggering class\n(Do Something Only When) emerges when the lower-ranked constraint bans some structural option;\nwhen the dominating constraint is at stake, the banned option will be taken — and only then. The\nprofuseness or blocking class (Do Something Except When) emerges when the lower-ranked\nconstraint favors some option — perhaps by blocking its blocking by a yet-lower-ranked constraint;\nnow the high-ranked constraint can force rejection of the otherwise-favored option.\nWe now turn to the analysis of a range of interactions exhibiting the descriptive characters\nof Economy and Profuseness. We will see that constraint-domination theory exposes the common\nconceptual core of a number of different-seeming phenomena, leading to a deeper understanding of\nsome poorly-resolved issues in phonological theory and practice.\n\n24\n\nChapter 3\n\nPrince & Smolensky\n\nDo Something Only When: Triggering, or The Theory of Economy\n3.1 Epenthetic Structure\nNothing ain’t worth nothing, but it’s free.\n— Common Misconception\nTo illustrate the characteristic form of the economic interaction, let us consider a pattern of\nepenthesis in the phonology of (Classical) Arabic. Simplifying for purposes of exposition, let us\nfocus entirely on C-epenthesis, which supplies a glottal stop in certain environments. From an input\n/al-qalam+u/ ‘the-pen (+nom.)’, we get an output §alqalamu. Arabic syllables must be of the form\nCV(X); epenthesis ensures that the obligatory onset is present, whatever the input configuration.\nHowever, if the rule is stated with maximal generality, context-free, as iÿC, we must ask why we\ndon’t get such forms as these, which are all in fine accord with the Arabic syllable canon:\n(18) Free Epenthesis into /al-qalamu/ (all ungrammatical)\na. §alqa§lamu\nb. §alqal§amu\nc. §alqalam§u\nd. §alqa§la§mu\ne. §alqa§lamu§\nf. §alqal§amu§\ng. §alqal§a§mu\nh. §alqa§la§mu§\ni. §alqal§a§mu§\nLet us suppose, following Selkirk 1981, Broselow 1982, Piggott & Singh 1985, and Itô 1986, 1989\nquite closely, that the site of epenthesis is an empty syllabic position that arises during the course of\nsyllabification. The phonetic value of the epenthetic item is filled in by interpretive principles that\nread the output of the level of structure we are concerned with. On this view, the basic principles of\nsyllable structure assignment already have within them all that is required to produce the correct\noutput forms. An epenthetic structure is simply a licit syllable form that contains structure not\nmotivated by the presence of a segment. There are no additional specialized operations of repair\nrecapitulating aspects of parsing itself; no rule “insert Onset” or the like, since that is part of what\nsyllabification does in the first place. The candidate set of possible analyses already contains the\ncorrect output; the constraint system will locate it. We believe this is a major insight into the way\ngrammar works.\nWhat is called epenthesis, then, is a by-product of the syllable parse, which must therefore\ncontemplate candidates that have empty structure in them. Empty structure is avoided, obviously,\nas indeed is anything that would lead to structural complexity in the relationship between base and\nsurface forms. We therefore hypothesize that there is a system of constraints that deals with sources\nof such complexity; call these the ‘faithfulness’ constraints. Itô’s Prosodic Licensing, which requires\nthat realized segments belong to syllables, is clearly among these (Itô 1986, 1989; Goldsmith 1990;\nItô & Mester 1993), as is the Melody Integrity of Borowsky 1986. Prosodic Licensing looks up from\nthe segment, and more generally up from any node, to check that it has a parent, and an appropriate\n\nOptimality Theory\n\nChapter 3\n\n25\n\none. We will call this family of constraints by the name PARSE; several members of the family will\nbe encountered below. (Unparsed elements are denied phonetic realization, in accord with the notion\nof ‘Stray Erasure’ familiar from McCarthy 1979, Steriade 1982, Itô 1986, 1989.) We also need the\ncounterpart of Prosodic Licensing that looks down from a given node to be sure that its immediate\ncontents are appropriate. Let’s call this family of constraints FILL, the idea being that every node\nmust be filled properly; the idea dates back to Emonds 1970.12 In the case at hand, we are interested\nin syllable structure, and the constraint can be stated like this:\n(19) FILL\nSyllable positions are filled with segmental material.\nArabic unmistakably exhibits the ONS constraint, which we state as follows:\n(20) ONS\nEvery syllable has an Onset.\nFor concreteness, let us assume that Onset is an actual node in the syllable tree; the ONS constraint\nlooks at structure to see whether the node F dominates the node Onset. This provides us with the\nsimplest formal interpretation of FILL as banning empty nodes.13\nThe function Gen produces candidates that meet these requirements:\n\n12\n\nPARSE and FILL are conceived here in simple constituent structure terms. This suits the\nstraightforwardly monotonic relation we assume throughout this work between input and output, and allows\nclean technical development of the leading ideas. The ideas themselves, of course, admit extension to the\n“feature-changing” arena, which shows other kinds of breaches of faithfulness to input forms. Generally\nconceived, the PARSE family militates against any kind of failure of underlying material to be structurally\nanalyzed (‘loss’) and the FILL family against any kind of structure that is not strictly based on underlying\nmaterial (‘gain’).\n13\n\nA more general view of the matter would see FILL as a specialized member of a broad family of\nconstraints that ban structure altogether: *STRUC. See Zoll (1992b) for discussion of this notion. Constraints\nof the *STRUC family ensure that structure is constructed minimally: a notion useful in syntax as well as\nphonology, where undesirable options (move-\"; non-branching nonterminal nodes) typically involve extra\nstructure. For example, the suggestion in Chomsky 1986:4 that nonbranching N( (no specifier) is disallowed,\nwith NP directly dominating N in such cases, would be a reflex of *STRUC, as would Grimshaw’s proposal\nthat extended projections are minimal in extent (Grimshaw 1993). XN-theory then reduces entirely to the\nprinciple that a syntactic category has a head of the same category, [X] ÿ ...[X]... . Pointless nonbranching\nrecursion is ruled out by *STRUC, and bar-level can be projected entirely from functional information\n(argument, adjunct, specifier). In economy of derivation arguments, there is frequently a confound between\nshortness of derivation and structural complexity, since each step of the derivation typically contributes\nsomething to the structure. In the original case discussed in Chomsky 1989, we have for example a contrast\nbetween isn’t and doesn’t be; the presence of DO is a kind of FILL violation.\n\n26\n\nChapter 3\n\nPrince & Smolensky\n\n(21) Assumed Syllable Structures\na. F ÿ (Ons) Nuc (Coda)\n‘if an analysis contains a node F, it must dominate Nuc and may dominate Ons and Coda.\nb. Ons, Coda ÿ (consonant)\n‘if an analysis contains a node Ons or Coda, it may dominate a consonant.\nc. Nuc ÿ (vowel)\n‘if an analysis contains a node Nuc, it may dominate a vowel.\nAny parse at all of the input string is admitted by Gen, so long as any structure in it accords with the\nprescriptions of (21).14\nThe constraint ONS is never violated in Arabic. FILL is violated, but only to provide onsets.\nThis establishes the domination relation ONS >> FILL.\nThe Gen function for syllable structure should admit every conceivable structure, with every\nconceivable array of affiliations and empty and filled nodes. In order to retain focus on the issue at\nhand, let’s admit every structure that allows empty onsets and empty codas, deferring till §6-8 a more\nambitious investigation of syllable theory.\nTo establish that §alqalamu is the optimal outcome, we examine here a (sampling of) the\ncandidate set, in which the forms are fully parsed syllabically:\n(22) Syllabification under ONS >> FILL, fully parsed forms\nCandidates\n\nL\n\nONS\n\n*\n\n.Gal.qa.la.mu.\n.al.qa.la.mu.\n\nFILL\n\n*!\n\n.Gal.qaG.la.mu.\n\n** !\n\n.Gal.qal.Ga.mu.\n\n** !\n\n.Gal.qaG.laG.mu.\n\n** ! *\n\n.Gal.qaG.laG.muG.\n\n** ! **\n\nThe symbol G notates an empty position, a nonterminal node, daughter of F. Periods mark syllableedges.\nIt is evident that any form violating ONS will be excluded, since there will always be\ncompetitors that meet the constraint by virtue of empty Onset nodes. Violations of FILL are therefore\ncompelled. What then of the competition among the FILL violators? The evaluation of candidates\n\n14\n\nWe do not urge this as the ultimate theory of syllable structure; what is important for the argument is\nthat the distinctions that it makes will be inevitably reflected in other theories. Other assumptions, for\nexample those in McCarthy & Prince 1986 or Itô 1986, require technical re-formulation of FILL. See Hung\n1992, Kirchner 1992, Samek-Lodovici 1992, 1993, McCarthy & Prince 1993.\n\nOptimality Theory\n\nChapter 3\n\n27\n\nwith respect to a constraint hierarchy is to be handled by a principle of Harmonic Ordering of Forms\n(HOF), mentioned in §2 and treated formally below in §5. Let us suppose that HOF works to\ncompare two candidates by examining the set of marks that they incur. The ‘First Member’ of a\ncollection of violation-marks for a given form is the most significant mark in its collection, where\nthe significance of a mark is determined in the obvious way by the rank of the constraint whose\nviolation it records. The comparison of two competitors proceeds by comparing the ‘First Member’\nof each competitor’s mark collection. When there is a tie, the ‘First Members’ of each collection are\nthrown away, until one of the competitors has none left. By the very definition of constraint\nviolation, we have i TM {*}, meaning that it is better to pass a constraint than to fail it. Therefore,\nunder this conception of evaluation, the competitor with the least number of violations is the victor\nin the comparison.\nAt this point, it might be objected that we have introduced counting into the reckoning of\noptimality, contrary to our explicit assertion above. HOF does not count, however — not even to one.\nTo see this, observe that no effect can ever be arranged to occur if and only if there is exactly one\nviolation of a certain constraint. (Why? Suppose that we altered every constraint so as to add one\nadditional violation to every candidate it assesses. The HOF is completely unaffected, and the theory\noperates exactly as before, even though the candidates with exactly one violation have all changed.)\nHOF merely distinguishes more from less, presence from absence, the empty set from all others. In\nparticular, HOF can never determine the absolute number of violations; that is, count them.15 HOF\ndeals not in quantities but in comparisons, and establishes only relative rankings, not positions on\nany fixed absolute scale.16\nThis observation leads to an important result, worthy of separate statement.\n(23) Economy Property of Optimality Theory\nBanned options are available only to avoid violations of higher-ranked constraints and can\nonly be used minimally.\nIn constraint-domination grammars, the ‘economy of derivation’ pattern emerges because violations\nare always minimized.\nSince we have ranked ONS above FILL for one particular language, it is reasonable to ask\nwhat happens when the ranking is reversed, with FILL >> ONS. In this situation, any violation of FILL\nwill rule a candidate out; so the ONS constraint must simply give way when there is no consonant\naround to fill the Onset node. We will have e.g. .a.TM.Ga., the onsetless syllable rated as better than\none that is onset-containing by virtue of empty structure. This gives us a different type of language,\nbut still a natural language, and shows that re-ranking of constraints yields a typology of admissible\nsystems. The set of all possible rankings generates what we can call a factorial typology of the\n\n15\n\nThere a parallel here to the analysis of Imdlawn Tashlhiyt Berber nucleus choice in the conception of\n§2, where evaluation never knows what features are involved, just whether a candidate nucleus is more or\nless harmonic than its competitors. In §§8.1.1, 8.3.3, 8.4.2 below we show how to treat the ITB system in a\nstrictly mark-sensitive way, in full accord with the HOF as described here.\n16\n\nThe same is of course true of the misnamed ‘feature-counting’ evaluation metric, which was\nhypothesized to select the optimal grammar from among a candidate set of grammars.\n\n28\n\nChapter 3\n\nPrince & Smolensky\n\ndomain to which the constraints are relevant. Below in §6 we explore a factorial typology of syllable\nstructure, based on the interaction of FILL, PARSE, ONS, and other relevant constraints.17\n\n3.2 Do Something Only When:\nThe Failure of Bottom-up Constructionism\n“... piled buildung supra buildung pon the banks for the livers by the Soangso.”\n– Finnegans Wake, 4.\n\nTongan, a language of the Pacific, shows an interaction between stress and syllable structure which\nraises interesting issues for prosodic theory. Poser (1985), following Churchward 1953, provides the\noriginal generative discussion. Mester (1991), improving on Poser, proposes a line of analysis that\ncan be illuminatingly pursued within constraint domination theory.\nSyllables in Tongan are always open, and all heavy syllables are stressed. Since there are no\nsyllable-closing consonants, the weight contrast is necessarily based on the distinction between short\nvowels (V) and long vowels or diphthongs (VV). Main-stress falls on the penultimate mora (V) of\nthe word. This suggests that the pattern is established by bimoraic trochees, with a right-to-left\ndirectionality.\nProsodic systems of this sort inevitably face a conflict between the demands of syllabification\nand the demands of foot structure. Unless other constraints impinge, any sequence CVV is optimally\nsyllabified as .CVV., avoiding a violation of ONS. But if footing is to start immediately at the right\nedge of the word, forms /~CVVCV/ would have to suffer splitting of the VV sequence in two,\nyielding .CV.(V.CV)#. In many familiar languages, e.g. Latin (Hayes 1987), the foot-parse begins\none mora over in such forms, yielding ~(.CVV).CV., where the last foot does not sit at the right edge\nof the word. Stress settles on the penultimate syllable and therefore (prominence falling on the peak\nthereof) on the antepenultimate mora. This effect has been charged to a Principle of Syllabic\nIntegrity (e.g. Prince 1976), which holds that foot-parsing may not dissect syllables.\nTongan, however, requires strict penultimacy of main-stress, and syllabification is not\nallowed to stand in its way. The word /ma+ma/ ‘world’ is parsed ma.á.ma not *má+.ma. Churchward\n17\n\nTo complete the argument about epenthesis, we must consider a larger range of candidates than we have\nexamined so far. In particular, Gen freely admits analyses in which segments are left out of syllable structure,\nand these analyses must be disposed of. Such ‘underparsing’ analyses violate the constraint PARSE. As will\nbe shown in §6, the domination relation PARSE>>FILL eliminates them. To preview, observe that\nunderparsing can lead to satisfaction of ONS, as in output +V,.CV. from input /VCV/. (We write +X, for\nstray X with no parent node.). With ONS out of the way, PARSE and FILL are brought into direct conflict,\nresolved in Arabic in favor of PARSE (nothing left out), as the following tableau illustrates:\nCandidates\n\nL\n\nONS\n\nPARSE\n\n*\n\n.GV.CV.\n\n+V,.CV.\n\nFILL\n\n*!\n\n(The dotted vertical line indicates that Ons and Parse are not crucially ranked with respect to each other.) The\ninvestigation in §6 of the ONS-PARSE-FILL ranking typology resolves issues of exactly this character.\n\nOptimality Theory\n\nChapter 3\n\n29\n\nprovides the useful contrast hú+ ‘go in’ (monosyllabic) versus hu.ú.fi ‘open officially’ (trisyllabic),\nboth involving the stem /hu+/. Mester observes that the last foot must be strictly final, with exact\ncoincidence of foot-edge and word-edge. He proposes a rule he calls Edge-Foot which builds a foot\nat the right edge, disturbing syllable structure if necessary. Mester notes that although the rule of\nEdge-Foot violates Syllabic Integrity in one sense, the actual output (with resyllabification)\nultimately meets the constraint, since no foot edge falls in the middle of a syllable.\nThis apparent conundrum vanishes when the interaction is understood in terms of constraint\ndomination. Mester’s insight into strict edgmostness can be brought into direct confrontation with\nthe principles of syllabification. Both syllabic and stress-pattern considerations will bear\nsimultaneously on establishing the optimal prosodic parse. Two constraints are centrally involved:\nONS, and something that does the work of Mester’s Edge-Foot. Note that along with Edge-Foot, the\nsystem requires a statement to the effect that the last foot bears main stress: Mester calls on the EndRule (Right) to accomplish this. We suggest that the most promising line of attack on the whole\nproblem is to generalize the notion of End-Rule so that it can carry the entire burden, forcing\npenultimate ‘breaking’ as well as final prominence. Instead of demanding that prominence fall on\nan element in absolute edgemost position, suppose we pursue the scalar logic made usable by the\npresent theory and demand instead that the prominence fall on the position nearest to the edge,\ncomparing across candidates. In the more familiar parsing mode of #(CVV)CV#, the foot is as near\nto the edge as it can be while upholding the canons of syllable form, ONS in particular. In Tongan,\nby constrast, the heterosyllabic parse of the vowel sequence in ~CVVCV# words successfully puts\nthe main-stress foot as far right as can be — in absolute edge position. The actual statement of the\nrevised End-Rule is the same as before:\n(24) EDGEMOST position of head foot in word\nThe most prominent foot in the word is at the right edge.\nThe difference is one of interpretation. We now have the means to deal with gradient or multiple\nviolations of the constraint, in terms of a measure of distance from the edge, say syllables. Each\nelement that intervenes between the last foot and the edge counts as a separate violation; the\neconomy property of the theory ensures that any such violations will be minimal in all optimal forms.\nFor the candidate set, let us consider only those parses that are properly bracketed. In this way\nGen encodes those aspects of the Principle of Syllabic Integrity that are empirically supportable.\nBecause syllable well-formedness gives way to the edgemostness requirement, we must have\nEDGEMOST >> ONS. Since EDGEMOST is the only foot constraint that dominates any syllabic criteria,\nit follows that VV sequences elsewhere in the word will never split, regardless of their position.\nThe comparison of alternatives runs like this:\n(25) Tongan Penultimacy, from /huu+fi/ ‘open officially’\nEDGEMOST\n\nONS\n\nhu.(ú.fi)\n\ni\n\n*\n\n(húu).fi\n\nF!\n\nCandidates\n\nL\n\n30\n\nChapter 3\n\nPrince & Smolensky\n\nThe cells in the EDGEMOST column of the tableau indicate the degree of concordance with the\nconstraint by mentioning the string intervening between the main foot and word-edge. If the order\nof domination is reversed, the second candidate becomes optimal and we get the more familiar\npattern of stressing.\nAs for the observed stressing of heavy syllables throughout the word, there are a number of\ndescriptive options. One could assume that feet are distributed throughout the word, but that (aside\nfrom main-stress) only heavy syllable foot-heads are interpreted as especially prominent, or\n‘stressed’. Or one could assume with Mester that feet are not assigned generally but only to heavy\nsyllables. Or one could assume that it’s not footing at all, but merely the intrinsic prominence of\nheavy syllables that observers of the language are reporting (Prince 1983, Hayes 1991/1995). Such\nissues can only be decided at the level of general prosodic theory, and we leave the matter open.\nIt is instructive to compare the constraint-domination solution with that offered by Poser\n(1990) in the spirit of what we might call Bottom-Up Constructionism: the view that structures are\nliterally built by re-write rules in a strictly bottom-up fashion, constructing layer upon layer. Poser\ndistinguishes an initial round of syllabification, the first step of construction, from a later readjustment stage. At first, all VV sequences throughout the entire word are parsed as bisyllabic V.V.,\nthe idea being that moras are independent of syllables. Feet are then built on the syllables thus\nobtained, and main-stress is determined from the feet. When all prosodic structure has been built,\nthere is a final round of syllabic processing (post-lexical?) in which the sequence V.V coalesces\neverywhere except when the second mora bears main-stress.\nThe analytical strategy is to build structure bottom-up and then to do such repairs as are\nnecessary. Under this approach, the unusual word-final situation (V.V before CV#) must be extended\nto the entire word. This is no quirk of Poser’s particular proposal; Bottom-up Constructionism leaves\nlittle choice in the matter. If syllabification is to be done with more-or-less familiar and uniform\nmechanisms, then there is no way to anticipate the specific demands of main-stressing when the\nsyllable level is being constructed. Consequently, there will be levels of derivation in which the\nsyllabification of words is highly marked, perhaps even impossible, with heterosyllabic sequences\nof identical vowels. No known phenomena of Tongan, however, are sensitive to the postulated V.V\nsyllables.\nPoser’s analysis shows that Bottom-Up Constructionism is empirically inconsistent with the\nappealing and often-assumed idea that initial syllabification is governed by markedness\nconsiderations. By this, only the least marked options are initially available to syllabify underlying\nforms. Indeed, we might argue that Bottom-Up Constructionism is antithetical to the idea. Since the\nburden of establishing well-formedness falls on the later rules that function as repair strategies, it is\nalways possible to allow great divergences from well-formedness at earlier stages. It becomes\nnecessary to do so in cases like Tongan, where the generality of early rules of construction can be\nmaintained only by letting them ignore basic markedness principles.\nIn the present theory, divergences from the locally unmarked state of affairs are allowed at\nany level of structure, but only when compelled. The Tongan ranking of EDGEMOST above syllabic\nHarmony promotes an alternative (V.V) that is usually suppressed, but promotes it only in those\ncircumstances where it makes a difference. Bottom-Up Constructionism has no way to express this\nkind of dependency. The only relevant model of interaction is one in which two general rules happen\nto overlap in territory, with one re-doing part of what the other has done. Here, general coalescence\ncorrects general syllabification. Consequently, the V.V syllabification must be portrayed as general\n\nOptimality Theory\n\nChapter 3\n\n31\n\nin Tongan, and UG must be accordingly distorted to allow it as a real option that is independent of\ncoalescence — an intolerable conclusion.\nBottom-Up Constructionism is suited to a state of affairs in which the package of constraints\nrelevant to syllable structure completely and universally dominates the constraint-package pertaining\nto foot structure: SYLL-FORM >> FOOT-FORM. Tongan shows that this hierarchy is not, in fact, rigidly\nadhered to. Bimoraic trochaic footing at the end of a word necessarily entails a conflict between\nsyllable and foot constraints in words ending Heavy-Light. Some languages resolve the conflict in\nfavor of the syllabic constraints, using the bottom-up domination pattern; others, like Tongan, place\none of the foot constraints in dominant position.18\nWe have classified the Tongan situation as an example of the ‘do something only when’ or\ntriggering pattern. In the operational analysis of Mester 1991, which works bottom-up, the breaking\nof long penultimate vowels occurs at the level of foot-formation, “as a structure-changing imposition\nof the foot, violating syllable integrity” (p.2). Local resyllabification is triggered by the requirement\nof utmost finality on the main foot; breaking is therefore a last resort.19 We take from Mester the idea\nthat foot-form is what’s at stake, but we recognize no operation of breaking as a necessary part of\nthe history of the optimal form. The broken parse is among the many alternatives that are always\navailable to construe any string with a long vowel or VV sequence in it. (There is no ‘violation of\nsyllable integrity’ since there is never a syllable .CVV. whose integrity could be violated.)\nFurthermore, we recognize no special relationship of triggering: there is only constraint domination.\nBecause of the constraint ONS, which it violates, any “broken” parse is going to be suboptimal unless\nONS itself is appropriately dominated. In Tongan, the dominance of EDGEMOST entails that ONS will\nbe violated (once) in the optimal parse of certain words: those ending ~CVVCV.\nTongan provides us with our first case where it is important to have the entire structural\nanalysis present at the time of evaluation. The imposition of prosodic requirements top-down is not\nan isolated peculiarity of one language, however. In prosodic systems, the main stress of a domain\nis often required to meet its edge-location requirements at the expense of other characteristics of the\npattern. In Finnish, for example, the sequence L3 H— stressed light syllable followed by a heavy\nsyllable — is generally avoided (Carlson 1978, Kiparsky 1991), but every polysyllable nevertheless\nbegins with a bisyllabic foot, the strongest in the word, no matter what the composition of the first\ntwo syllables is. The constraint EDGEMOST is crucially involved; specifically, EDGEMOST(Hd-F;\nleft;Wd), the member of the EDGEMOST family which requires the head foot of the prosodic word\nto be placed in initial position (see below §4.1. p.35 for details of formulation). EDGEMOST(HdF;left;Wd) evidently dominates whatever prominential or foot-shape constraint is responsible for the\n\n18\n\nThis situation can also be dealt with by aggressive treatment of the segmental input, as in ‘Trochaic\nShortening’, whereby underlying HL is realized as LL (Prince 1990; Hayes 1991). Fijian provides a clear\nexample (Dixon 1988; Hayes 1991), as does the phenomenon of trisyllabic shortening in English and other\nlanguages (Prince 1990). Here a PARSE-type constraint (PARSE-:) occupies a position inferior to FOOT-FORM\nin the hierarchy, so that a mora in the input will be left unparsed in order to get ~(LL)# out of /~HL/. Similar\nphenomena are discussed in §4.5 below and in Mester (in press).\n19\n\nPoser’s analysis is configured so that coalescence is blocked when the second vowel of a sequence bears\nmain-stress. Triggering and blocking are often interconvertible in this way; it all depends on what you think\nthe ameliorative process is.\n\n32\n\nChapter 3\n\nPrince & Smolensky\n\nLH effect. Among the Yupik languages, it is typically the case that the quantity sensitivity of the\nbasic pattern is restricted to the contrast V vs. VV; but in the f irst foot, arguably the prosodic head,\nCVC will count as heavy. (On this, see Hewitt 1992:§2 for extensive discussion, though from a\nsomewhat different point of view; and Hayes 1991/1995, §6.3.8 for another perspective). Here\nEDGEMOST(Hd-F; left;Wd) dominates the constraint that limits moras to vocalicity; this is not unlike\nTongan, in that the higher-level foot-placement constraint influences the basic interpretation of\nsyllable structure. Similarly, it is often the case that the location of the main-stressed foot has a\ndifferent directional sense from the rest of the foot pattern, a fact whose importance is emphasized\nin the work of Hulst 1984, 1992, which advocates top-down analysis of stress patterns in an\noperational framework. In Garawa, for example, the rhythmic pattern is built from bisyllabic trochees\nand every word begins with the main-stressed foot; but the rest of the word is organized with\nreference to the far end, right-to-left in iterative terms (Hayes 1980 working from Furby 1974). In\nPolish, also syllabic-trochaic, the principal foot lies at the end, but otherwise the pattern has a left-toright orientation (Rubach & Booij 1985). Here again the constraint EDGEMOST(Head-F;rt;Wd),\nwhich governs main-stress distribution, dominates the constraint checking the directional uniformity\nof the pattern, call it SENSE(F), which is concerned with the lower hierarchical level of mere feet.20\nAs we expect in the current context, reversing domination to SENSE(F) >> EDGEMOST(Head-F;rt;Wd)\nis entirely sensible, and defines the class of languages which is in accord with the spirit of Bottom-up\nConstructionism.\n\n20\n\nExact formulation of the directionality-sensitive principle is a matter of interest. One tack, noted by\nGreen 1992 inter alia is to have the constraint sensitive to the location of unfooted material; thus a left-toright operational iteration leaves the stray bits on the right side of the run; sometimes internally, in the case\nof bimoraic feet. It is also possible to deal directly with the matter and define a recursive checking procedure\nwhich is similar in spirit to the original iterative constructional conception (Howard 1973, Johnson 1972).\nLet there be a constraint EDGEMOST* which is just like EDGEMOST except that it operates along these lines:\nstring \" is more harmonic than string $ under EDGEMOST*(F,E,D) if \" is more harmonic than $ under simple\nEDGMOST(F,E,D); but if \" and $ are not distinguished by simple EDGEMOST, because the edgemost foot of\n\", F\", is as well-located as the edgemost foot of $, F$, then resume the evaluation wrt EDGEMOST* — nb.\nrecursive reference — on \"\\F\" and $\\F$, where x\\y means ‘x with y removed’. This method of evaluation,\nwhich is like the Lexicographic Order on Composite Structures (LOCS) of Prince & Smolensky 1991, 1992,\nhas been independently suggested by Itô, Mester, & McCarthy. Zoll 1992 offers yet another approach to\ndirectionality, in which an entire subhierarchy works across the word, in the spirit of Prince 1990. Further\nresearch is required to distinguish among these possibilities.\n\n33\n\n4. Generalization-Forms in Domination Hierarchies II\nDo Something Except When: Blocking, or The Theory of Profuseness\nWhen specific conditions limit the scope of an otherwise broadly- applicable generalization, we have\nthe second major form of constraint interaction. The operational imperative is to do something except\nwhen an adverse condition prevails or an adverse outcome would result. The default is to do; but\nthere may be reasons not to do. In the literature, this is often understood as the blocking of a rule by\na constraint; though the effect is also achieved when a later rule undoes part of what an earlier rule\nhas accomplished, or when the Elsewhere Condition preserves the specific in the face of the general.\nThis generalization structure emerges when a constraint that functions to encourage some easily\nidentifiable state-of-affairs is dominated by another that can force a violation, ruling out the\notherwise desired state-of-affairs in certain circumstances.\nClearly, this pattern of generalization is central to linguistic theory and appears in every\nbranch of it. We will focus our discussion on basic elements of prosodic theory. Here are some\nexamples of phenomena that earn the ‘do something except when’ interpretation:\n(26) Blocking of the Generally Applicable\na. A final syllable is extrametrical except when it is the only syllable in the word.\nb. A certain affix is a prefix except when the base is C-initial/V-initial (in which case, it is\nan infix).\nc. Stress is nonfinal except when the final syllable is the heaviest in the word.\nd. Rhythmic units are iambic except when there are only 2 syllables in the word.\ne. Rhythmic units are trochaic, and never of the form LH except when those are the only two\nsyllables in the word.\nExplicating such patterns via constraint domination will significantly advance the understanding of\nsuch fundamentalia as prosodic minimality, extrametricality, foot-typology, as well as the sometimes\nsubtle interactions between them.\n\n4.1 Edge-Oriented Infixation\nInfixation comes in two varieties, each a mild variant of ordinary suffixation/prefixation, according\nto the typology of McCarthy & Prince 1990a. In both cases, the infix is a suffix/prefix which takes\nas its base not some morphological category (stem, root, etc.) but instead a phonologically-defined\nsubdomain within the morphological category.\nIn one type, the affix attaches to a minimal word (foot-sized unit) that lies at the edge of the\nmorphological base. For McCarthy & Prince 1990, the internal minimal word that forms the actual\nbase of affixation is specified by positive Prosodic Circumscription. Thus, we find in the Nicaraguan\nlanguage Ulwa that the personal possessive affixes are suffixed to the first foot, as in /kuhbil+ka/ ÿ\nkuhkabil ‘his knife’(Hale & Lacayo Blanco 1988). Reduplicative infixation may also follow this\npattern. Samoan ‘partial reduplication’, for example, prefixes a syllable to the last foot, giving\n/F+fa+gota/ ÿ fa+go(góta) ‘fishV pl.’ (Broselow & McCarthy 1983, McCarthy & Prince 1990, Levelt\n1991).\n\n34\n\nChapter 4\n\nPrince & Smolensky\n\nIn the other type, the affix lies near an edge; its location can be determined by subtracting\nsomething (often a consonant or vowel) from the edge and prefixing or suffixing to the remainder.\nCharacteristic instances are displayed below:\n(27) Tagalog Prefixal Infixation\num+tawag\nÿ t-um-awag\num+abot\nÿ um-abot\n\n‘call, pf., actor trigger’\n‘reach for, pf., actor trigger’\n\n(28) Pangasinán Prefixal Reduplicative Infixation\nF+amigo\nÿ a-mi-migo\n‘friend/friends’\nF+libro\nÿ li-libro\n‘book/books’\n(29) Chamorro Suffixal Reduplicative Infixation\nÿ métgo-go-t\n‘strong/very strong’\nmétgot+F\nbuníta+F\nÿ buníta-ta\n‘pretty/very pretty’\nIn each of these examples, exactly one peripheral element is bypassed. For McCarthy & Prince 1990,\nProsodic Circumscription identifies the unit that is subtracted from consideration, and the\nmorphological operation applies to the residue of the form as though to an ordinary base. Ignoring\na single peripheral element is extrametricality, and Prosodic Circumscription successfully formalizes\nextrametricality within a generalized theory of the prosodic conditioning of rules.\nThis approach is beset by a serious shortcoming: it cannot explain the relation between the\nshape of the affix and the manner of its placement. Infixes that go after initial C! are common\nthroughout Austronesian, and they always have the form VC, never CV or V or CVC. Anderson\n(1972) observes that just when the affix is VC, infixation after a word-initial C results in a\nconsiderably more satisfactory syllable structure than prefixation would. The VC.CV entailed by\nsimple prefixation (*um.tawag) is abandoned in favor of CV.CV. (tu.mawag). Of course, in the\ntheory of Anderson’s day, such an observation — concerned with the relative markedness of\ndifferent possible outputs — had to remain grammatically inert, and Anderson offered a 6-term\ntransformational rule to describe the facts. Similarly, the observation plays no role in the Prosodic\nCircumscription account developed by McCarthy & Prince, which accordingly suffers from the same\nkind of formal arbitrariness diagnosed in the Dell-Elmedlaoui Algorithm. Optimality Theory, by\ncontrast, allows us to make this insight the keystone of a significantly improved theory of edgeoriented infixation.\nThe relevant syllabic constraint is the one that discriminates against closed syllables: let us\ncall it &COD and formulate it as follows:\n(30) &COD\nSyllables do not have codas.\nAny closed syllable will violate this constraint, which we assume to be universally present in every\ngrammar. It is often, though not always, in subordinate position in constraint rankings, dominated\nby faithfulness, so that a coda is forced when input like /CVC/ is faithfully parsed. (See §6 below.)\n\nOptimality Theory\n\nChapter 4\n\n35\n\nWe need to generalize the notion prefix so that it can refer to items that are only\napproximately in first position in the string. The standard hard-line assumption is that a prefix always\nfalls completely to the left of its base. Scalar evaluation allows us to soften the demand, using the\nnow-familiar pattern of competition between alternatives that vary in degree of adherence to the\nideal. Consider all possible affix placements: the nearer an affix lies to the left edge of the affix-base\ncollocation, the more prefixal its status. The observed location of any particular affix will be that\nwhich best satisfies the entire set of constraints bearing on it, among them the requirement that it be\na prefix or suffix.\nThe constraint needed to implement this idea is already at hand: it is EDGEMOST, familiar\nfrom the discussion of Tongan above, which we now formulate more precisely. Like the End Rule\nthat it supplants, the predicate EDGEMOST takes several arguments. The relevant domain must be\nspecified, as must the choice of edge (Right, Left), as must the item whose position is being\nevaluated. The schema for the constraint family, then, looks like this:\n(31) EDGEMOST (n; E; D)\nThe item n is situated at the edge E of domain D.\nCrucially, violation of EDGEMOST is reckoned in designated units of measure from the edge E, where\neach intervening unit counts as a separate violation. In Tongan, the constraint comes out as\nEDGEMOST(F);R; Wd), which asserts that the main foot (F)) must be Rightmost in the Word. For\nconciseness, the Domain argument will be suppressed when its content is obvious. With this in hand,\nwe can define the two affixal categories:\n(32) Dfn. Prefix\nA prefix is a morpheme M subject to the constraint EDGEMOST(M; L).\n(33) Dfn. Suffix\nA suffix is a morpheme M subject to the constraint EDGEMOST (M; R).\nTraditional prefixes or suffixes, which always appear strictly at their corresponding edges,\nare morphemes M for which EDGEMOST(M;L*R) dominates other conflicting constraints and thus\nalways prevails. In the case of edge-oriented infixation, prosodic well-formedness constraints\ndominate EDGEMOST, forcing violations, which are minimal as always. For the Austronesian VC\nprefixes, the important interaction is &COD >> EDGEMOST(af; L). Consider the effects on the Tagalog\nprefix /um/, characterized by Schachter 1987 as signaling ‘Actor Trigger’ on the verb.\nLet us examine first the case of a vowel-initial base, say /abot/ ‘reach for’. For purposes of\nthis discussion, we assume that the candidate set produced by Gen will consist of all forms in which\n(1) the linear order of tautomorphemic segments is preserved, and (2) the segments of the affix are\ncontiguous. We will also assume, following the general view of scholarship in the area, that there\nare vowel-initial syllables at the level of analysis we are concerned with, even though all surface\nsyllables have onsets, glottal stop being the default filler. The following constraint tableau lays out\nthe results.\n\n36\n\nChapter 4\n\nPrince & Smolensky\n\n(34) Analyses of /um/ + /abot/\nCandidates\n\n&COD\n\nEDGEMOST(um; L)\n\n.u.ma.bot.\n\n*\n\n#i\n\nb.\n\n.a.um.bot.\n\n* *!\n\n#a\n\nc.\n\n.a.bu.mot.\n\n*\n\n#ab !\n\nd.\n\n.a.bo.umt.\n\n*\n\n#abo !\n\ne.\n\n.a.bo.tum.\n\n*\n\n#abot !\n\na.\n\nL\n\nThe degree of violation of EDGEMOST is indicated informally by listing the string that separates um\nfrom the beginning of the word. The sign ‘#’ is included merely as a visual clue. The symbol i refers\nto the empty string. The syllabically-illicit form *aboumt would of course be defeated on other\ngrounds as well: it is included to emphasize the generality of the candidate set.\nThe form umabot is more harmonic than any competitor. Like all the best candidates, it has\none &COD violation. (It is a fact of the language that this one violation cannot be circumvented by\ndeletion or by epenthesis; this shows that !COD is dominated by both FILL and PARSE, as detailed\nin §6 below.) All ties on &COD are adjudicated by EDGEMOST. In the optimal form, the affix lies\nnearest to the beginning of the word: in this case, right at the beginning.\nConsonant-initial bases provide the more interesting challenge. Consider the richest possible\ncase, with an initial C-sequence, as in /um+gradwet/. (This datum is from French 1988.)\n(35) Analyses of /um + gradwet/\nCandidates\n\n&COD\n\nEDGEMOST(um, L)\n\na.\n\n.um.grad.wet.\n\n*** !\n\n#i\n\nb.\n\n.gum.rad.wet.\n\n*** !\n\n#g\n\n.gru.mad.wet.\n\n**\n\n#gr\n\nd.\n\n.gra.um.dwet.\n\n**\n\n#gra !\n\ne.\n\n.gra.dum.wet.\n\n**\n\n#gra ! d\n\nf.\n\n.grad.w...um...\n\n**\n\n#gra ! dw ...\n\nc.\n\nL\n\nAgain, for completeness, we include graumdwet as a representative of the horde of syllabically\ndisastrous candidates — including still more hopeless contenders such as .u.mgra.dwet. and\n.u.m.gra.dwet. — which are all rendered sub-optimal by constraints dominating &COD but of no\nrelevance to the present discussion.\n\nOptimality Theory\n\n37\n\nChapter 4\n\nHere all the best competitors tie at two &COD violations each; these violations are due to\nintrinsic stem structure and cannot be evaded. Prefixing um to the whole base, as in (35.a), or after\nthe initial C, as in (35.b), induces a third, fatal violation. Among the surviving forms, grumadwet\nwins on the grounds of superior affix position.\nWe have shown that certain prefixes are minimally infixed when prosodic constraints\ndominate the basic morphological principle of affix placement. McCarthy & Prince 1991, 1993,\nextending the present account, observe that the same explanation holds for edge-oriented\nreduplicative infixation. As an instance of suffixal F, Chamorro met.go-go-t. is prosodically superior\nto *met.got.-got. in that it more successfully avoids closed syllables; exactly the same reason that\nt-u.m-a.wag bests um.-ta.wag.\n(36) Suffixal Reduplication under Prosodic Domination\n\n&COD\n\nEDGEMOST(Faff;R)\n\n.met.go.got.\n\n**\n\nt#\n\n.met.got.got.\n\n*** !\n\ni#\n\nCandidates\n\nL\n\nThe widely-attested Pangasinán type lilibro / amimigo, in which the reduplicative prefix skips\nover an onsetless initial syllable, falls under the prosodic compulsion account as well. Here\ninfixation — a.mi.migo vs. *.a.amigo – avoids the V-V hiatus which straightforward prefixation\nwould entail (cf. McCarthy & Prince 1986: 90). The active constraint is ONS, which discriminates\nagainst onsetless syllables.\nThe theory has a subtle and important range of consequences, whose existence was brought\nto our attention by John McCarthy: certain types of infixation can only be reduplicative. Under\nprosodic forcing, no phonemically-specified prefix can ever be placed after an initial onsetless\nsyllable; the advantage of avoiding absolute initial position only accrues when reduplication is\ninvolved. To get a sense of this, note that under reduplication the failed candidate $a$a.migo, with\npure prefixation, incurs two ONS violations, and the successful candidate $a.mi.migo but one. (The\nad hoc siglum $ marks a missing Onset.) Reduplication has the unique pathology of copying an onset\nviolation. By contrast, a fixed-content affix like (fictive) /ta/ leads to just one ONS violation wherever\nit is placed: pseudo-Pangasinán ta$amigo is not ONS-distinct from $a.ta.migo. Since ONS is\nindifferent, EDGEMOST will demand full left-placement. Since all the known cases of post-onsetless\nsyllable infixation are in fact reduplicative, we have a striking argument in favor of the present\napproach. The argument applies in a kind of mirror-image or dual form to suffixal infixation as well.\nThe Chamorro metgogot type can only be reduplicative. Consider, for example, the effects of placing\nan imaginary affix /ta/ in and around a form like metgot: met.got.ta., metgo.tat. All such candidates\nagree on the extent of &COD violation, as the reader may verify; therefore EDGEMOST(ta;R) compels\n\n38\n\nChapter 4\n\nPrince & Smolensky\n\nexterior suffixation.21 To firmly establish the claim that fixed-content morphemes cannot be forced\ninto infixation after initial onsetless syllables or before final C, more must be done: one needs to run\nthrough all relevant affix patterns, checking the effects of contact between the edges of the affix with\nthe base. In addition, the reduplicative pattern must be nailed down. Detailed analysis is undertaken\nin McCarthy & Prince 1993: §7, to which the reader is referred.\nWe have, then, the beginnings of a substantive theory of infixability, a theory in which\nprosodic shape modulates the placement of morphemes. Edge-oriented infixation arises from the\ninteraction of prosodic and morphological constraints. The principal effect — interior placement —\ncomes about because EDGEMOSTness is a gradient property, not an absolute one, and violations can\nbe forced. It follows from the principles of the harmonic ordering of forms that violations in the\noutput are minimal. Consequently, such infixes fall near the edge, as near as possible given the\ndominant constraints. Edge-oriented infixation can be construed in the ‘Do-Something-ExceptWhen’ style of descriptive language, should that prove illuminating: the affix falls at the edge except\nwhen a prosodic constraint can be better met inside. The theory, of course, recognizes no distinction\nbetween ‘except when’ and ‘only when’ — blocking and triggering — but deals only in the single\nnotion of constraint domination.\nThe internalizing effects attributed to extrametricality follow, on this view, from constraint\ninteraction and from the way that constraints are defined. There is no formal mechanism called\nExtrametricality or (negative) Prosodic Circumscription to which the analysis appeals. This suggests\nthe general hypothesis, natural within the context of Optimality Theory, that what we call\nExtrametricality is no more than the name for a family of effects in which Edgemostness interacts\nwith other prosodic constraints. We pursue this line in the following two sections as we explore more\ninstances of the except when configuration, showing that key properties of extrametricality, thought\nto be axiomatic, follow from this re-conception.\n\n4.2 Interaction of Weight Effects with Extrametricality\nCertain varieties of Hindi show an interaction between weight and nonfinal placement of stress\nwhich sheds further light on the interaction of gradient edgmostness and other factors operative in\nprosodic patterning. First, we provide some background on “unbounded” “stress” systems; then we\nturn to the revelatory twists of Hindi prosody.\n\n4.2.1 Background: Prominence-Driven Stress Systems\nStress systems typically reckon main-stress from a domain edge, often enhancing an edgemost or\nnear-edgemost syllable or foot. There are also stress systems that call on EDGEMOST but make no use\nof binary structure to define the position of main word-stress: instead the additional determining\n\n21\n\nObserve that in all the cases discussed we can assume that the entire package of syllabic constraints,\nincluding both ONS and &COD, dominates the morphological conditions on affixation; one or the other\nmember of the package turns out to be relevant depending on what the content of the affix is and whether\nit is a prefix or stem. This idea figures centrally in McCarthy & Prince 1993, where the Optimality theoretic\nscheme “prosody dominates morphology” is proposed as the account of what makes morphology prosodic.\n\nOptimality Theory\n\nChapter 4\n\n39\n\nfactor is syllable weight. In the canonical cases, main stress falls on the leftmost/rightmost heavy\nsyllable (pick one); elsewise, lacking heavies in the word, on the leftmost/rightmost syllable (pick\none). Systems like these have been called “unbounded” because the distance between the edge and\nthe main-stress knows no principled limits and because metrical analysis has occasionally reified\nthese unbounded spans as feet (Prince 1976, 1980; Halle & Vergnaud 1987; Hayes 1980,1991/1995).\nThe best current understanding, however, is that what’s involved is not a foot of unbounded\nmagnitude (presumed nonexistent), but a kind of prominential enhancement that calls directly on\ncontrasts in the intrinsic prominence of syllables. These then are prominence-driven systems, in\nwhich a word’s binary rhythmic structure is decoupled from the location of main word-stress. (For\ndiscussion, see Prince 1983, 1990; Hayes 1991/1995.)\nTwo basic constraints are involved. First, it is necessary to establish the relation between the\nintrinsic prominence of syllables and the kind of elevated prominence known as stress. There are a\nnumber of ideas in the literature as to how this is to be done (Prince 1983, 1990, McCarthy & Prince\n1986, Davis 1988ab, Everett 1988, Zec 1988, Goldsmith & Larson 1990, Hayes 1991/1995,\nGoldsmith 1992, Larson 1992), none perhaps entirely satisfactory. Generalizing over particular\nrepresentational assumptions, we can write, following essentially McCarthy & Prince 1986:9,\n(37) Peak-Prominence (PK-PROM)\nPeak(x)TMPeak(y) if *x* >*y*.\nBy PK-PROM, the element x is a better peak than y if the instrinsic prominence of x is greater than\nthat of y. This is the same as the nuclear-Harmony constraint HNUC formulated above, which holds\nthat higher sonority elements make better syllable peaks.\nThe second relevant constraint determines the favored position of the prominence-peak or\nmain stress of the word. It is nothing other than the familiar EDGEMOSTness.\n(38) EDGEMOST(pk; L*R; Word)\nA peak of prominence lies at the L*R edge of the Word.\nWe use ‘Word’ loosely to refer to any stress domain; as before, EDGEMOST is subject to gradient\nviolation, determined by the distance of the designated item from the designated edge.\nTo see how these constraints play out, let us consider a simple prominence-driven system\nsuch as “stress the rightmost heavy syllable, else the rightmost syllable.” Here we have\n(39) PK-PROM >> EDGEMOST(pk;R)\nIf there are no heavy syllables in the word, the rightmost syllable faces no competition and gains the\npeak. The results are portrayed in the following tableau:\n\n40\n\nChapter 4\n\nPrince & Smolensky\n\n(40) Right-Oriented Prominence System. No Heavy Syllables:\nCandidates\n\nL\n\nPK-PROM\n\nEDGEMOST(pk;R)\n\nL L L L3\n\ni#\n\nL L L3 L\n\nF# !\n\nL L3 L L\n\nFF# !\n\nL3 L L L\n\nFFF# !\n\nHere PK-PROM plays no role in the decision, since all candidates fare equally on the constraint. This\nkind of data provides no argument for ranking the constraints; either ranking will do. With heavy\nsyllables in the string, the force of constraint PK-PROM becomes evident:\n(41) Right-Oriented Prominence System, with heavy syllables.\nCandidates\n\nPK-P\nROM\n\nL\n\nEDGEMOST(pk;\nR)\n\nL H H L3\n\nL3\n\nL H H3 L\n\nH3\n\nF#\n\nL H3 H L\n\nH3\n\nFF# !\n\nL3 H H L\n\nL3 !\n\nFFF#\n\nWith the other domination order, a strictly final stress location would always win. With PK-PROM\ndominant, candidates in which a heavy syllable is peak-stressed will eclipse all those where a light\nsyllable is the peak. When several potential peaks are equivalent in weight, or in intrinsic\nprominence construed more generally, the decision is passed to EDGEMOST, and the surviving\ncandidate containing the peak nearest the relevant edge is evaluated as optimal; exactly the\ngeneralization at hand.\n\nOptimality Theory\n\n41\n\nChapter 4\n\n4.2.2 The Interaction of Weight and Extrametricality: Kelkar’s Hindi\nCertain dialects of Hindi/Urdu display an interesting variant of the prominence-driven pattern of\nedgemostness.22 From the work of Kelkar (1968), Hayes (1991/1995:276-278) has constructed the\nfollowing generalization:\n(42) Kelkar’s Hindi\n“Stress falls on the heaviest available syllable, and in the event of a tie, the rightmost\nnonfinal candidate wins.”\n(Hayes 1991/1995:276)\nThe first complication is that this variety of Hindi (or Urdu) recognizes three degrees of\nsyllable weight or intrinsic prominence; hence Hayes’s ‘heaviest’ holding the place of the usual\n‘heavy’. The ordering of weight-classes is as follows:\n(43) Heaviness Scale\n\n|CVVC,CVCC| > |CVV,CVC| > |CV|\n\nHayes suggests that the superheavy syllables are trimoraic, yielding the scale *:::* > *::* > *:*.\nWhatever the proper interpretation may be, the heaviness scale fits directly into the constraint PKPROM.\nThe effects of PK-PROM may be seen directly in forms which contain one syllable that is\nheavier than all others:\n(44) Heaviest wins\na. .ki.dhár.\nb. .ja.náab.\nc. .as.báab.\nd. .ru.pi.áa.\ne. .réez.ga.rii.\n\n.:' :. TM .:' .\n.:' ::. TM .:' .\n.:' ::. TM .:' :.\n.:' :. TM .:' .\n.:' ::. TM .:' :.\n\n‘which way’\n‘sir’\n‘goods’\n‘rupee’\n‘small change’\n\n(All examples here and below are from Hayes 1991/1995.)\nThe second complication in the Hindi pattern is the avoidance of stress on final syllables.\nThis is a very commonly encountered phenomenon in stress systems of all kinds, typically attributed\nto various forms of extrametricality, stress-shift, and de-stressing. We formulate the basic constraint\nas NONFINALITY as follows:\n\n22\n\nJudgments of stress in Hindi are notoriously delicate and unstable, a consequence of dialectal variation\nand the non-obviousness of whatever events and contrasts the term ‘stress’ actually refers to in the language.\nTherefore it is essential to distinguish the observations of distinct individuals and to seek non-impressionistic\nsupport for the claims involved. Hayes (1991: 133-137, 236-237) provides careful analysis along these lines.\n\n42\n\nChapter 4\n\nPrince & Smolensky\n\n(45) NONFINALITY\nThe prosodic head of the word does not fall on the word-final syllable.\nBy ‘prosodic head’ we mean the prosodically most prominent element, here the main stress.\nNONFINALITY is quite different in character from extrametricality; it focuses on the well-formedness\nof the stress peak, not on the parsability of the final syllable.23 Furthermore, it is a substantive stressspecific constraint, not a general mechanism for achieving descriptive ‘invisibility’ (Poser 1986).\nWhen heaviness alone does not decide between candidates, the position of the peak is\ndetermined by the relation NONFINALITY >> EDGEMOST. It is more important for the peak to be\nnonfinal than for it to be maximally near the edge. Exactly as in the simple prominence-driven\nsystems, however, the package of positional constraints is completely dominated by the weightmeasuring PK-PROM. Here are some examples illustrating the positional effects (syllables of the\nheaviest weight class in a word are in roman type):\n(46) Positional Adjudication among Equals\na.\n:\n.sa.mí.ti.\n\n‘committee’\n\nb.\n\n::\n\n.ru.káa.yaa.\n.pús.ta.kee.\n.roo.záa.naa.\n\n‘stopped (trans.)’\n‘books’\n‘daily’\n\nc.\n\n:::\n\n.áas.mãã.jaah.\n.aas.máan.jaah.\n\n‘highly placed’\n‘highly placed (var.)’\n\nThe full constraint hierarchy runs PK-PROM >> NONFINALITY >> EDGEMOST. The following tableaux\nshow how evaluation proceeds over some typical examples.\n\n23\n\nNONFINALITY does not even imply by itself that the literally last syllable is unstressed. Representational\nnonfinality can be achieved in the manner of Kiparsky 1992 by positing an empty metrical node or gridposition (analogous to the ‘silent demi-beat’ of Selkirk 1984) after the final syllable within the stress domain.\nUse of empty structure is proposed in Giegerich 1985 and Burzio 1987 for various purposes, and is explored\nin Kiparsky 1992 under the name of ‘catalexis’, in connection with preserving Foot Binarity (q.v.inf.). Here\nwe want empty metrical positions to be unavailable; clearly, they are proscribed by a constraint of the FILL\nfamily, and we will tacitly assume that this constraint is undominated in the grammars under discussion.\n\nOptimality Theory\n\n43\n\nChapter 4\n\n(47) Light vs. Light: /samiti/\nCandidates\n\nL\n\nPK-PROM\n\nPosition\nNONFINALITY\n\nEDGEMOST\n\n*!\n\ni#\n\n.sa.mi.tí.\n\n.:' .\n\n.sa.mí.ti.\n\n.:' .\n\nF#\n\n.sá.mi.ti.\n\n.:' .\n\nFF# !\n\nThe form .sa.mí.ti. is optimal because it has a nonfinal peak that is nearest the end of the word.\n(48) Heavy vs. Light: /kidhar/\nCandidates\n\nPK-PROM\n\nPosition\nNONFINALITY\n\nL\n\n.ki.dhár.\n\n.:' :.\n\n.kí.dhar.\n\n.:' . !\n\nEDGEMOST\n\ni#\n\n*\n\nF#\n\nThe optimal form .ki.dhár. violates NONFINALITY, but it wins on PK-PROM, which is superordinate.\n(49) Heavy vs. Heavy vs. Light: /pustakee/\nCandidates\n\nPK-PROM\n\nPosition\nNONFINALITY\n\nEDGEMOST\n\n.pus.ta.kée.\n\n.:' :.\n\n.pus.tá.kee.\n\n.:' . !\n\nF#\n\nL .pús.ta.kee.\n\n.:' :.\n\nFF#\n\n*!\n\ni#\n\nThe form .pús.ta.kee. is the worst violator of EDGEMOSTness among the candidates, but it bests each\nrival on a higher-ranked constraint.\n\n44\n\nChapter 4\n\nPrince & Smolensky\n\n(50) Contest of the Superheavies: /aasmããjaah/\nCandidates\n\nPK-PROM\n\nPosition\nNONFINALITY\n\nL\n\nEDGEMOST\n\naas.mãã.jáah\n\n:' ::\n\naas.mã3 ã.jaah\n\n:' : !\n\nF#\n\náas.mãã.jaah\n\n:' ::\n\nFF#\n\n*!\n\ni#\n\nHere again, the optimal candidate is the worst violator of edgemostness, but its status is assured by\nsuccess in the more important confrontations over weight and nonfinality.\nThe stress pattern of Kelkar’s Hindi shows that extrametricality can be ‘canceled’ when it\ninterferes with other prosodic constraints. It is rarely if ever the case that final syllables are\ncategorically extrametrical in a language; rather, prominence is nonfinal except when being so entails\nfatal violation of higher-ranked constraints. This behavior is exactly what we expect under\nOptimality Theory. In the familiar view, of course, such behavior is a total mystery and the source\nof numerous condundra, to be resolved by special stipulation; for if extrametricality is truly a rule\nassigning a certain feature, there can be no explanation for why it fails to apply when its structural\ndescription is met.\n\n4.3 Nonfinality and Nonexhaustiveness\nThe exclusion of word-final syllables from prosodic structure is the prototypical extrametricality\neffect. Latin provides the touchstone example, and parallels can be multiplied easily.24 Writing the\nextrametricality rule to apply word-finally leads immediately to the basic quirk of the theory:\nmonosyllabic content words receive stress without apparent difficulty. Since the unique syllable of\nthe monosyllable is indubitably final, it should by all rights be extrametrical. Why is this syllable\ndifferent from all others? The following examples illustrate the situation, where +..., encloses the\nextrametrical material:\n(51) Extrametricality in Latin\na. cór+pus,\n*corpús\nb. méns\n*+mens,\n\n24\n\nIn words of length two syllables or longer, Latin places main word-stress on the penult if it is heavy or\nif it is the first syllable in the word, otherwise on the antepenult. This array of facts is standardly interpreted\nto mean that final syllables are completely extrametrical — outside foot structure. Bimoraic trochees are\napplied from left to right on the residue of extrametricality; the last foot is the strongest (Hayes 1980, 1987).\n\nOptimality Theory\n\n45\n\nChapter 4\n\nThis state of affairs arises from an interaction exactly parallel to the one that ‘revokes\nextrametricality’ in Hindi. NONFINALITY is simply not the ne plus ultra of the system; it can be\nviolated.\nThe dominant, violation-forcing constraint is not far to seek. Relations must be established\nbetween the categories of morphology and those of phonology. These take the form of requirements\nthat any member of a certain morphological category (root, stem, word) must be, or correspond to,\na phonological category, typically the prosodic word PrWd. (See Liberman & Prince 1977; Prince\n1983; McCarthy & Prince 1986, 1990, 1991ab, 1993; Nespor & Vogel 1986; Inkelas 1989.) The\nPrWd is composed of feet and syllables; it is the domain in which “main stress” is defined, since\nevery PrWd contains precisely one syllable bearing main stress. As in many languages, Latin requires\nthat the lexical word be a prosodic word as well. Following McCarthy & Prince 1991ab, we can put\nthe morphology/phonology interface constraint like this, with one parameter:\n(52) LX.PR (MCat)\nA member of the morphological category MCat corresponds to a PrWd.\nAnother line of approach is to demand that the left or right edge of a morphological category match\nto the corresponding edge of the relevant phonological category (Selkirk 1986, Chen 1987,\nMcCarthy & Prince 1993). For present purposes it is not necessary to pursue such refinements of\nformulation, although we return in §7, p. 114ff., to the virtues of edge-reference.\nAll words of Latin satisfy LX.PR; not all final syllables are stressless. (Indeed, on the\nstandard view of Latin prosodic structure, a final syllable is included in stress structure only in\nmonosyllables.) NONFINALITY is violated exactly when LX.PR is at stake. We deduce that\nLX.PR >> NONFINALITY. It remains to formulate a satisfactory version of the constraint from the\nNONFINALITY family that is visibly active in Latin. For present purposes, the following will suffice:\n(53) NONFINALITY\nThe head foot of the PrWd must not be final.\nThis is related to NONFINALITY (45) §4.2.2, p.42 , which deals with peaks of stress — syllabic heads\nof PrWd — but not identical with it. We will bring them together shortly, in order to deal with the\nsubtler interactions between nonfinality and foot-form restrictions.\nThe effect of the constraint hierarchy on monosyllables is illustrated in this tableau:\n(54) The Parsed Monosyllable of Latin\nCandidates\n\nL\n\nLX.PR\n\n[ (méns)F ]PrWd\n+mens,\n\nNONFINALITY\n\n*\n*!\n\n46\n\nChapter 4\n\nPrince & Smolensky\n\nThe constraint LX.PR word thus ‘revokes extrametricality’ when content-word monosyllables are\ninvolved.\nIt is instructive to compare the present approach with the standard conception, due to Hayes,\nwhich holds that extrametricality is a feature assigned by rule as part of the bottom-up process of\nbuilding prosodic structure. Under Bottom-up Constructionism, there must be a strict serial order\nof operations:\n1. Extrametricality marking must take place: this prepares the syllabified but footless input\nfor further processing.\n2. Feet are then formed, determining the location of stressed and unstressed syllables.\n3. Higher Order structure is then built on the feet — i.e., the Prosodic Word is formed — and\nthe location of main stress is determined.\nUnder this plan of action, it is essential that extrametricality be assigned correctly at the very\nfirst step. If monosyllabic input is rendered entirely extrametrical at step #1, then Prosodic Word\nFormation (step # 3) will have no feet to work with, and will fail. To avoid this disastrous outcome,\na caveat must be attached to the theory of extrametricality to ensure that the fatal misstep is never\ntaken. Hayes formulates the condition in this way:\n(55) Nonexhaustivity\n“An extrametricality rule is blocked if it would render the entire domain of the stress rules\nextrametrical.” (Hayes 1991/1995: 58)\nIt is an unavoidable consequence of Bottom-up Constructionism that condition (55) must be stated\nas an independent axiom of theory, unrelated to any other constraints that bear on prosodic\nwellformedness. Its existence is entirely due to the theory’s inability to recognize that LX.PR is a\nconstraint on the output of the system, a condition that must be met, and not the result of scanning\ninput for suitable configurations and performing Structural Changes on them. The putative rule\nassigning PrWd status cannot be allowed to fail due to lack of appropriate input.25 The Axiom of\nNonexhaustivity is not motivated by restrictiveness or any other such higher explanatory motive. Its\nmotivation is strictly empirical; remove it and you have an equally restrictive theory, but one which\npredicts the opposite treatment of monosyllables.\nNonexhaustiveness appears not to be part of any general theory of extrametricality. Hewitt\n& Prince (1989), for example, argue that extrametricality with respect to tonal association may\nindeed exclude entire monosyllabic domains. Hayes is careful to refer to the notion “stress domain”\nin his statement of the condition. The proposal offered here makes sense of this: the integrity of the\nstress domain is guaranteed by the theory of the morphology/phonology interface, as encoded in\n25\n\nCompare, in this regard, the discussion of relative clause formation in Chomsky 1965, where it is noted\nthat it is insufficient to say that the rule of relative clause formation is obligatory, because nothing guarantees\nthat it will be able to apply at all (*the man that the house looks nice). Compare also the notion of “positive\nabsolute exception” in Lakoff 1965, a rule whose structural description must be met. These phenomena are\ndiagnostic of deep failure in the simple re-write rule conception of grammar, since remedied. In the case of\nrelative clauses, it is clear that the syntax is entirely free to create structures in which no wh-movement can\napply, because independent principles of interpretation, defined over the output of the syntax, will fail in all\nsuch forms, ruling them out.\n\nOptimality Theory\n\nChapter 4\n\n47\n\nLX.PR. When that particular theory is not involved, as in certain tonal associations, there is no\nreason to expect nonexhaustiveness, and we do find it. Similarly, the end-of-the-word bias of stresspattern extrametricality is not mirrored in other phenomena which ought to fall under the theory of\nextrametricality (were there to be one). For example, tonal extrametricality (Prince 1983, Pulleyblank\n1983) is not restricted to final position; nor is edge-oriented infixation (McCarthy & Prince 1986,\n1990). We expect this: extrametricality is not a unified entity, but rather a diverse family of\nconsequences of the gradience of EDGEMOSTNESS. In the subtheory pertaining to stress,\nNONFINALITY is the principal, perhaps only, constraint interacting with EDGEMOSTNESS. In other\nphenomenal domains besides stress, other constraints are at play, shown above in the case of edgeoriented infixation, §4.1.\nNonexhaustiveness, then, emerges from constraint interaction. What of the other properties\nthat have been ascribed to formal extrametricality? There are four, and in each case, we would argue,\nwhat is correct about them follows from the constraint interaction analysis. Let’s take them in turn.\n(56) Property 1: Constituency\n“Only constituents (e.g. segment, mora, syllable, foot, phonological word) may be marked\nas extrametrical.” (Hayes 1991/1995: 57).\nWe suggest that this property has nothing to do with extrametricality per se but rather with the\nsubstantive constraint that pushes the relevant item off an edge. Constraints on stress, for example,\ndeal in syllables quite independently of extrametricality. When the relevant constraint is from a\ndifferent domain, it may well be that constituency is irrelevant; in edge-oriented infixation, for\nexample, as analyzed above in §4.1, the constraint &COD can force prefixes away from the initial\nedge of the word, over consonant sequences that needn’t be interpreted as unitary constituents\n(“onsets”).\n(57) Property 2: Peripherality\n“A constituent may be extrametrical only if it is at a designated edge (left or right) of its\ndomain.” (Hayes, ibid.).\nThis is because the phenomena gathered under the name of extrametricality have to do with items\nthat are positioned by the constraint EDGEMOST — prominences, feet, tones, affixes. If by\nextrametrical, we mean “unparsed into the relevant structure”, then there are many other situations\nwhere constraints force nonparsing. Hayes’s “weak local parsing”, for example, compels unparsed\nsyllables to separate binary feet (the similarity to extrametricality is recognized in Hammond 1992).\nSyllables may be left unparsed internally as well as peripherally because of restrictions on the\nquantitative shape of feet (the “prosodic trapping” of Mester 1992). Similar observations may be\nmade about segmental parsing. Many kinds of constraints can lead to nonparsing; we assert that there\nis no reason to collect together a subset of them under the name of extrametricality.\n(58) Property 3: Edge Markedness\n“The unmarked edge for extrametricality is the right edge.” (Hayes, ibid.)\n\n48\n\nChapter 4\n\nPrince & Smolensky\n\nAs noted, this is true only for stress, not for tone or affixation. The explanation must lie in the\nproperties of stress, not in a theory of the treatment of edges.\n(59) Property 4: Uniqueness.\nOnly one constituent of any type may be extrametrical.\nThis is a classic case of constraint interaction as we treat it. Extrametricality arises, for example,\nwhen NONFINALITY >> EDGEMOSTNESS. It follows that EDGEMOSTNESS is violated when\nextrametrical material is present. Because of the way Harmony is evaluated (HOF: §5), such\nviolations must be minimal. Under NONFINALITY, this will commonly mean that only one element\nis skipped over or left unparsed, the minimal violation of EDGEMOSTNESS. Thus, in many cases —\nenough to inspire belief that a parochial principle is involved — the unparsed sequence will be a\nconstituent.\nWe conclude that there are strong reasons to believe that extrametricality should be retired\nas a formal device. Since its basic properties submit to explanation in the substantive domain under\nscrutiny here, it is worthwhile to pursue the argument into the other areas where it has proved to be\nsuch a useful tool of analysis. (For further exploration of nonfinality and related edge effects, see\nHung 1993.)\nDemoting nonexhaustivity from clause-of-UG to epiphenomenon of interaction raises an\nimportant issue, however: the universality (or at least generality) of the effect is not directly\naccounted for. What ensures that LX.PR outranks NONFINALITY? Why not have it the other way\naround in the next language over? It may be that some further condition is required, restricting the\nplace of LX.PR in constraint hierarchies. Have we therefore exchanged one stipulation for another,\nfailing to net an overall gain at the bottom line?\nReviewing the spectrum of possible responses, it’s clear that we’re not in a simple tit-for-tat\nsituation. Suppose we straightforwardly call on some principle relevant only to to LX.PR; for\nexample, that it must sit at the top of all hierarchies, undominated. Any such condition fixes the\nrange of relations between LX.PR and many other constraints, not just NONFINALITY, so the cost of\nthe stipulation is amortized over a broad range of consequences having to do with the prosodic status\nof lexical items. Thus, even with the most direct response, we put ourselves in a better position than\nthe adherent of pure axiomatic status for nonexhaustiveness as a property local to extrametricality.26\n\n26\n\nMore optimistically, we can expect to find principles of universal ranking that deal with whole classes\nof constraints; in which desirable case, the nonexhaustiveness effect would fully follow from independent\nconsiderations. Also worth considering is the idea that there are no principles involved at all and the\npredominance of the cited ranking is due to functional factors extrinsic to grammar, e.g. the utility of short\nwords. (This comports as well with the fact that conditions on word minimality can differ in detail from\nlanguage to language, including or excluding various categories from the ‘lexical word’: see the discussion\nof Latin which immediately follows; implying a family of related constraints, rather than a single one.)\nGrammar allows the ranking to be easily learnable from the abundant data that justifies it. On this view,\nnothing says that NONFINALITY must be dominated; but it is easy to observe that it is; and there are\nextragrammatical, functional reasons why it is useful for it to be. Note too that in setting the rank of LX.PR,\nwe construct the needed restriction from UG-building tools already needed; as opposed to tacking\nnonexhaustiveness on as a sui generis codicil to some mechanism.\n\nOptimality Theory\n\nChapter 4\n\n49\n\nIt is useful to compare the kind of ranking argument just given with a familiar form of\nargument for rule ordering in operational theories. One often notes that if Rule A and Rule B were\nto apply simultaneously, then the conditions of Rule A must be written into Rule B; whereas if Rule\nA strictly precedes Rule B, the two can be disentangled, allowing the development of an\nappropriately restrictive theory of type A and type B rules.27\nHere we have seen that the empirical generalization about extrametricality (that it holds\nexcept when it would obliterate a monosyllable) emerges properly from the ranking of independent\nconstraints. The rule-ordering theory of extrametricality, by contrast, exhibits a pathological quirk\nsimilar to the one that affects simple non-ordering operational theories. Information proper to one\nrule must be written into another, solely to get the right outcome: the Nonexhaustivity axiom\nembodies a covert reference to PrWd-formation. A grammar of re-write rules is simply not suited\nto the situation where a rule must apply, where its structural description must be met by all inputs\nso that all outputs conform to its structural change (see fn. 25 above). Inserting special conditions\ninto rules so that this happens to happen is no answer. Rule-ordering must therefore be abandoned\nin favor of constraint ranking, for the same reason that simultaneity was previously abandoned in\nfavor of rule ordering.\n\n4.3.1 Nonfinality and the Laws of Foot Form: Raw Minimality\nLatin displays a typical minimality effect of the type made familiar by work in Prosodic Morphology:\nthe language lacks monomoraic words. Here is a list of typical monosyllabic forms (Mester 1992:1920):\n(60) Latin Monosyllables\nCategory\n\nExempla\n\nGlosses\n\na. N\nb. V\nc. Pron.\nd. Conj.\ne. P\n\nmens, cor, mel, r‘, sp‘, v§\ndÇ, st~, sum, stat\nm‘, s‘, tã, is, id, quis\nn‘, s§, cum, sed\n~, ‘, prÇ, sub, in, ab\n\n‘mind, heart, honey: nom.; thing, hope, force: abl’\n‘I give, stand, am; he stands’\n‘1sg.-acc., 3-refl-acc.; you-sg-nom; he, it, who-nom.’\n‘lest, if, when, but also’\n‘from, out of, in front of, under, in, from’\n\nWe have then cum, mens, re+ and rem (acc.), all bimoraic, but no *re- (Mester 1992, citing\nKury»owicz 1968, Allen 1973:51). A morpheme like -que- ‘and’ can only be enclitic. The standard\naccount points to the prosody-morphology interface constraint LX.PR as the source of the restriction\n(Prince 1980; McCarthy & Prince 1986 et seq.). The PrWd must contain at least one foot; a foot will\ncontain at least two moras; hence, lexical words are minimally bimoraic. The deduction rests on the\n\n27\n\nNotice that the argument has nothing to do with ‘redundancy’, which (here as elsewhere) is nothing\nmore than a diagnostic indication that greater independence could be achieved; and with that, explanation.\n\n50\n\nChapter 4\n\nPrince & Smolensky\n\nprinciple Foot Binarity, which we state in (61), following the formulation of McCarthy & Prince\n1986:28\n(61) Foot Binarity (FTBIN)\nFeet are binary at some level of analysis (:, F).\nFoot Binarity is not itself a direct restriction on minimal foot size; it defines a general property of\nstructure. (Indeed the obvious virtue of the prosodic theory of minimality is that it obviates the need\nfor such a thing as a ‘minimal word constraint’; but see Itô & Mester 1992.) Because syllables\ncontain moras, Foot Binarity entails that the smallest foot is bimoraic.\nOne then argues that the lexicon of Latin cannot contain e.g. a noun /re/ because any such\nitem wouldn’t be assigned foot-structure (assuming FTBIN), and therefore wouldn’t be assigned\nPrWd status. Since (on this view, not ours) a version of the constraint LX.PR holds categorically of\nthe output of the lexicon, rejecting all violators, it happens that a potential lexical form like /re/\nwould underly no well-formed output and is therefore impossible, or at least pointless as a lexical\nentry. On this view, the constraint LX.PR assigns absolute ill-formedness to the output; in\nconsequence, an input form /re/ yields no output at all.\nIn the present theory, failure to satisfy a constraint does not entail ill-formedness, and every\ninput is always paired with an output: whichever analysis best satisfies the constraint hierarchy under\nHOF. We must therefore delve deeper to see how absolute ill-formedness — lack of an effective\noutput — could emerge from a system of interacting constraints which always selects at least one\nanalysis as optimal; this (or these) being by definition the output of the system.\nThe key, we suggest, is that among the analyses to be evaluated is one which assigns no\nstructure at all to the input: the Null Parse, identical to the input. The Null Parse will certainly be\nsuperior to some other possibilities, because it vacuously satisfies any constraint pertaining to\nstructures that it lacks. For example, FTBIN says if there is a foot in the representation, then it must\nbe binary; violations are incurred by the presence by nonbinary feet. The Null Parse therefore\nsatisfies FTBIN, since it contains no feet of any kind. Similar remarks hold for syllable structure\nconstraints such as ONS, because the Null Parse contains no syllables; for structural constraints such\nas FILL, which demands that empty nodes be absent (they are). Of course, the Null Parse grossly fails\nsuch constraints as PARSE, which demands that segments be prosodically licensed, to use Itô’s term,\nbecause the input will always contain segments. The Null Parse will fail LX.PR when the input\n\n28\n\nFoot Binarity is generalized from the account of Estonian foot structure in Prince 1980. The foot of\nEstonian is there defined as F = uu, where u is a variable ranging uniformly over : and F. It is shown that\nthis definition holds of the stress system, and the entailed minimality result — all monosyllables are\nbimoraic, hence overlong — is shown to hold as well. With such a foot, there are parsing ambiguities in\ncertain circumstances — HF may be (H)F or (HF) — and it is proposed that the maximal (bisyllabic) analysis\nis the one taken. The Estonian type of foot has been dubbed the “Generalized Trochee” in Hayes 1991, and\nnew applications of it are reported; cf. Kager 1992abc for further exploration. Since iambic feet also meet\nthe description ‘bimoraic or bisyllabic’, we go beyond the realm of the trochaic and, with McCarthy & Prince\n1986 and Prince 1990, demand that FTBIN hold of all feet, regardless of headedness. Of course, FTBIN\nexcludes the ‘unbounded’ feet of early metrical theory.\n\nOptimality Theory\n\n51\n\nChapter 4\n\nstring is a lexical category, because the constraint applies to all items in the category; it says that all\nsuch items must be parsed as prosodic words.\nA direct phonological assault on the Latin type of minimality would run like this: suppose\nthat FTBIN >> LX.PR, with PARSE the lowest-ranked relevant faithfulness constraint. We have then\nthe following:\n(62) Optimality of the Null Parse\nFTBIN\n\nLX.PR\n\n...\n\nPARSE\n\nre\n\nvacuous\n\n*\n\n...\n\n*\n\n[ ( ré )F ]PrWd\n\n*!\n\nCandidates\n\nL\n\n...\n\nIn the language of actions and exceptions, it would be said that a lexical word becomes a prosodic\nword except when it is monomoraic; the “assignment” of PrWd status to subminimals is blocked by\nFTBIN.29\nClearly, then, there exist constraint hierarchies under which the Null Parse is optimal for\ncertain inputs. The Null Parse, however, is uniquely unsuited to life in the outside world. In the\nphonological realm alone, the principle that unlicensed material is phonetically unrealized (our take\non the “Stray Erasure” of McCarthy 1979, Steriade 1982, Itô 1986, 1989) entails that any item\nreceiving the Null Parse will be entirely silent. In a broad range of circumstances, this would render\nan item useless, and therefore provide the basis for an explanation for its absence from the lexicon.\n(Observe that some similar account is required under any theory, since nothing in the formal nature\nof a lexical entry prevents its from being entirely empty of phonetic content in the first place.)\nA more bracing line of attack on the general problem is disclosed if we broaden our attention\nto include morphology. As with phonology, morphological structure can be understood as something\nthat the input lacks and the output has, the product of parsing. In the simple case of affixation, a\nstructure like [Root Af]Stem is an output possibility, sometimes the best one, related to a hierarchically\nunstructured input {rooti, affixj} which merely collects together the consistuent morphemes. Here\ntoo, though, the Null Parse must be among the options, and will be superior to some others, often\nto all others. For example, if affixj is restricted to combining with a certain subset of the vocabulary,\nand rooti is not in this set, then the noncombination of the morphological Null Parse +rooti, affixj,\nis going to be superior to the parsed miscombination [rooti affixj]Stem. A real-life example is provided\nby English comparative-superlative morphology, which attaches only to (one-foot) Minimal Words:\n\n29\n\nOne looseness of formulation here is the exact category to which ‘LX’in the constraint refers. John\nMcCarthy reminds us that there are no alternations of the form Ø (nom.)~ rem (acc.) from /re+m/, even\nthough the inflected form is legitimately bimoraic. One could argue that the absence of such alternations is\nnot properly grammatical, but functional in origin, considering the serious communicative problems entailed\nby lack of a nominative form. One might also argue that this shows that the Latin constraint must actually\napply to the category (noun) root. There are however a number of further issues concerning how minimality\nplays out over the various morphological categories; see Mester 1992, especially §2.2, for analysis.\n\n52\n\nChapter 4\n\nPrince & Smolensky\n\nthus [violet-er], parsed, is inferior to +violet, er,, which evades the one-foot constraint by evading\nattachment. Similarly, the input {write, ation} is best left untouched, but the analysis of {cite, ation}\nis optimally a parsable word. (For discussion of related cases, see McCarthy & Prince 1990, 1993).\nFailure to achieve morphological parsing is fatal. An unparsed item has no morphological\ncategory, and cannot be interpreted, either semantically or in terms of higher morphological\nstructure. This parallels the phonetic uninterpretability of unparsed segmental material. The\nrequirements of higher order prosody will parallel those of higher order morphology and syntax: a\nphonological Null Parse, which assigns no Prosodic Word node, renders a word unusable as an\nelement in a Phonological Phrase (Selkirk 1980, Nespor & Vogel 1986, Inkelas 1989), which is built\non prosodic words. This is the structural correlate of phonetic invisibility. Members of the ‘PARSE’\nfamily of constraints demand that the links in the prosodic hierarchy be established; let us use ‘MPARSE’ for the constraint which requires the structural realization of morphological properties.\nApplying this reasoning to the Latin case changes the game in certain crucial respects. Above\nwe assumed that a lexical form /re/ inevitably had membership in a lexical category; consequently\nfailure of phonological parsing led inevitably to violation of LX.PR. Now we assume that a form\n“has” a lexical category in the relevant sense only when the morphological parse is accomplished.\nA morphologically unassembled item cannot violate LX.PR, since the phonological string is not in\nthe “is a” relation with a morphological category.\nUnder this assumption, it is not possible to rank FTBIN and LX.PR with respect to each other\nexcept arbitrarily, since they are both satisfied in optimal output. With M-PARSE ranked below them,\nthe optimal output for subminimal input will lack morphological structure. To see how this plays out,\nexamine the following tableau.\n(63) Effect of Morphological Null Parse on {re, N}\nCandidates\n\nFTBIN\n\nLX.PR\n\nM-PARSE\n\na.\n\n[ (ré)F,PrWd ]N\n\n*!\n\nb.\n\n[ re ]N\n\nvac\n\n*!\n\nc.\n\n(ré)F,PrWd , N\n\n*!\n\nvac\n\n*\n\nd. L\n\nre, N\n\nvac\n\nvac\n\n*\n\n(Ph)-PARSE\n\n*\n*\n\nHierarchical morphological structure, when present, is indicated by labeled brackets; phonological\nstructure by labeled parentheses. The ad hoc indication vac marks vacuous satisfaction. Constraints\nwhich are not crucially ranked with respect to each other are separated in the tableau by dotted rather\nthan solid lines. We assume that faithfulness constraints like FILL, which would be violated when\nthe input is augmented to minimality, are ranked above M- and Ph-Parse, and we do not display\naugmented candidates; we consider the reverse ranking below.\nUnder these assumptions, any attempt to give /re, N/ a prosodic analysis violates FTBIN, as\nin (a) and (c). Morphological analysis without phonological analyis violates LX.PR, as in (b). This\nleaves only the Null Parse, phonological and morphological, which satisfies, vacuously, both FTBIN\n\nOptimality Theory\n\n53\n\nChapter 4\n\nand LX.PR. Since the Null Parse +re, N, violates M-PARSE, we want M-PARSE subordinated in the\nhierarchy so that the issue can be decided by FTBIN and LX.PR.\nOn this view, then, the underlying form of an item will consist of a very incompletely\nstructured set of specifications which constrain but do not themselves fully determine even the\nmorphological character of the output form. These specifications must be put in relation, parsed into\nstructure, in order to be interpretable. In mild cases of PARSE violation, bits of underlying form will\nnot correspond to anything in the output: underlying consonants will not be realized, underlying long\nvowels will appear as short due to unparsed moras, and so on. But in the face of a battery of highranking structural constraints which the input is not suited to meet when faithfully mapped to the\noutput, an entire Null Parse can be optimal. In this case, there is no interpretable output from the\ninput form, and we have what amounts to absolute ill-formedness.30\nIt is worth taking a look at another line of attack, developed further in §9, that bears on the\nanalysis of certain kinds of ill-formedness. The Null Parse is a kind of neutralization with i. We can\nalso have neutralization with something tangible. Suppose that we have /A/,/B/ ÿ S for two distinct\ninputs A and B. Suppose further that the input-output pairing (A,S) incurs more serious violations\nthan (B,S) does. Then, under the natural assumption that the lexicon is chosen to minimize\nviolations in the input-output mapping, and assuming that there is no other (e.g. morphological)\nreason to choose violation-prone A, one would be compelled to say that what underlies visible S is\nactually B and not A. For example, in the Latin case, suppose (contrary to the assumptions just\nexplored) that putative /re/ must always parsed be as [re+]. Then, if there are no other relevant\nrepercussions of underlying vowel quantity, the surface form [re+] will be identified as /re+/\nunderlyingly.\nTo implement this approach, assume moraic structure and a correlated structural constraint\nFILL-:. With FILL-: appropriately subordinated in the hierarchy, unfilled moras can be posited in\noptimal forms under the compulsion of higher-ranked constraints. Assume further that unfilled moras\nare interpreted in the output as continuations of a tautosyllabic vowel, phonetically interpreted as\nlength. For input /re/, the analysis r[e]:[]: / [re+] now becomes superior to the Null Parse. The output\n[re+ ] satisfies FTBIN and LX.PR, just like the Null Parse, but has the additional virtue of satisying\nboth the phonological and the morphological versions of the PARSE constraint. This state of affairs\nis portrayed in the following tableau:\n(64) Besting the Null Parse when FILL is low\nCandidates\n\nL\n\nM-PARSE\n\n(Ph-)PARSE\n\n[( r[e]:[ ]: )F ]PrWd , N\nre, N\n\n30\n\nFTBIN,\nLX.PR\n\nFILL-:\n\n*\nvac\n\n*!\n\nThe notion of absolute ill-formedness is taken up again in §9 below.\n\n*!\n\n54\n\nChapter 4\n\nPrince & Smolensky\n\nWe now ask why, given [re+] in the observed world, the abstract learner would bother to posit\nunderlying /re/ in the first place. If there is no adequate response, we can never have /re/ in the\nlexicon. Monomoraic forms are absent from the lexicon on this analysis not because they lead to\nuninterpretable output, but because the output they lead to is better analyzed as coming from\nsomething else. We might call this effect “occultation,” since the possible input /re/ is hidden, as it\nwere, behind /re+/, and therefore inaccessible.\nMester (1992:19-23) provides evidence that this analysis is appropriate for actual Latin. The\nform of argument is due originally, we believe, to D. Stampe (1969, 1973, 1973/79) and has been\nreasserted independently by Dell (1973), Hudson (1974), Myers (1991) and probably others we are\nunaware of. We deal with related matters in the discussion of inventory theory below in §9.\nStampean occultation cannot always be appropriate. One common worry should perhaps be\nset aside: how do we determine what the occulting body actually is in cases with inadequate surface\nclues? For example, in the case at hand, in the absence of further, typically morphophonemic\nevidence, all that’s required is that /re/ come out as bimoraic; many epenthetic pathways are open.\nThis issue can in principle be resolved by markedness theory or perhaps even left unresolved:\nanything, after all, will do. But there are still many circumstances, particularly in morphology, where\nit appears that there is simply no well-formed output from many kinds of input. (See McCarthy &\nPrince 1993:§7 for discussion.) The output from {violet, er} cannot be ‘bluer’ nor can the output\nfrom {write, ation} be ‘inscription’: these combinations yield nothing tout court. For such cases, the\nNull Parse is superior to all alternatives.\n\n4.3.2 Nonfinality and the Laws of Foot Form:\nExtended Minimality Effects\nLike so many languages, Latin bars monomoraic items because it respects both LX.PR, which\ndemands feet, and FTBIN, which bans monomoraic feet. Like many other languages, Latin also keeps\nstress off word-final syllables, by imposing NONFINALITY on its prosodic structure. Parsing of\nbimoraic monosyllables, in outright violation of NONFINALITY, is forced by the dominance of\nLX.PR, as we have seen. In a less obvious class of cases, NONFINALITY also conflicts with FTBIN.\nConsider bisyllabic words shaped LL and LH like áqua and ámo+. Under the standard view\nof extrametricality, these must be analyzed as L+L, and L+H,, that is, as the exact equivalent of #L#.\nThe naive expectation, then, is that such words should be impossible rather than plentiful. Hayes\n(1991/1995) terms this state of affairs ‘the unstressable word syndrome’.\nThe solution to the #LL# case is already at hand, given what has been established above. We\nknow from monosyllable behavior that LX.PR >> NONFINALITY. LX.PR never forces binarity\nviolations, as it would if it were ranked above FTBIN. In any total ranking of the constraints in the\ngrammar, FTBIN must dominate LX.PR, and therefore, by transitivity, it must dominate\n\nOptimality Theory\n\n55\n\nChapter 4\n\nNONFINALITY as well.31 From this it follows that /LL/ will be parsed [(LL)F]PrWd. The following\ntableau should make this clear:\n(65) Best Parse for /LL/\n\nFTBIN, LX.PR >> NONFINALITY\n\nCandidates\na.\n\n.a.qua.\n\nb.\n\n(á.)F qua\n\nc.\n\nL\n\n(á.qua)F\n\nFTBIN\n\nLX.PR\n\nNONFINALITY\n\n*!\n*!\n*\n\nIn short, FTBIN and LX.PR jointly force all bimoraic words to have a complete metrical analysis,32\neliminating extrametricality from both #H# and #LL#.\nThe behavior of words shaped LH is more intriguing. If NONFINALITY could be completely\nignored, as assumed above, we’d expect L(H3 ), and thus e.g. *amó+ with final stress. The candidate\nparse (á)mo+ fails FTBIN, while incorrect *a(mó+) satisfies both FTBIN and LX.PR, running afoul\nonly of low-ranked NONFINALITY.\nForms like ámo+ have two virtues which will allow us to rescue them from the oblivion in\nwhich forms like *á repose. First, such words are bisyllabic: unlike true subminimals, they have\nenough substance to support a binary foot. The foot may not be beautifully formed, since (L3 H) makes\na poor trochee but satisfies FTBIN nonetheless. Second, the exhaustively monopodic (ámo+)\nnonetheless displays a kind of nonfinality: the stress peak is indeed off the final syllable. With the\nnotion of relative Harmony securely in hand, we can take advantage of these partial successes. The\ntrochaic parse (L3 H) is equipped to succeed modestly on the constraints FTBIN and NONFINALITY,\nbesting other analyses which fail them entirely. To implement this program of explanation, we need\nto refine our analyses of nonfinality and foot form.\n\nIn terms of the empirically-necessary domination order, we have LX.PR >> NONFINALITY from (c) vs.\n(a), and FTBIN >> NONFINALITY , from (c) vs. (b). But either ranking between LX.PR and FTBIN will\nproduce the same outcome, since there is a solution, namely (c), that satisfies both of them at the expense\nof NONFINALITY. With a grammar defined as a total ranking of the constraint set, the underlying hypothesis\nis that there is some total ranking which works; there could be (and typically will be) several, because a total\nranking will often impose noncrucial domination relations (noncrucial in the sense that either order will\nwork). It is entirely conceivable that the grammar should recognize nonranking of pairs of constraints, but\nthis opens up the possibility of crucial nonranking (neither can dominate the other; both rankings are\nallowed), for which we have not yet found evidence. Given present understanding, we accept the hypothesis\nthat there is a total order of domination on the constraint set; that is, that all nonrankings are noncrucial.\n31\n\n32\n\nThis contradicts the theory of Steriade 1988, in which the word-final accent that appears in pre-enclitic\nposition is attributed to extrametricality of the final syllable. But Mester 1992 offers good reasons to doubt\nthe Steriade proposal.\n\n56\n\nChapter 4\n\nPrince & Smolensky\n\nThe desired version of nonfinality simply puts together its forms from above in (45) and (53).\n(66) NONFINALITY\nNo head of PrWd is final in PrWd.\nThe head of the PrWd is, immediately, the strongest foot ö dominated by the node PrWd. By\ntransitivity of headship (the head of XNcounting also as the head of XO), the PrWd will also be\nheaded by the strongest syllable in ö. In Latin, then, the PrWd has two heads, one inside the other.\nNONFINALITY is violated when either abuts the trailing edge of the PrWd; we assume that each\nviolation counts separately. The candidate *a(mó+) manages to violate NONFINALITY at both levels:\nthe head foot is final, as is the head syllable. The form (ámo+) is more successful: only the head foot\nis in final position. This is the result we want: the form #(L3 H)# achieves a modest degree of success,\nsince it keeps the main stress — the head of the head foot — out of final position.33\nFoot form is already known to be determined by a composite of various principles. There\nmust be a constraint which sets the rhythmic type at either iambic or trochaic; call this RHTYPE=I/T.\nOther factors regulate the well-formedness of various syllable groups, qua feet and qua bearers of\niambic and trochaic rhythm (Hayes 1985, 1991/1995; McCarthy & Prince 1986; Prince 1990; Kager\n1992abc; Mester 1992). For present purposes, we focus only on candidate principles that are relevant\nto the badness of (LH) as a trochee. One such is the Weight-to-Stress Principle of Prince 1990 (cf.\n‘w-nodes do not branch’ of Hayes 1980).\n(67) Weight-to-Stress Principle (WSP).\nHeavy syllables are prominent in foot structure and on the grid.\nBy the WSP, the trochaic group (L3 H) is subpar because it puts a heavy syllable in a weak position.34\n\nThe contrast with Kelkar’s Hindi, which has #LH3 # and #LL3 L#, admits of several interpretations. The\nrelation PK-PROM >> NONFINALITY yields the first of these without elaboration, but when PK-PROM is not\nat issue, we’d expect the Latin pattern of antepenultimacy. The direct approach would redivide NONFINALITY\ninto NONFIN(FN) (45) and NONFIN(F N)(53), each specifying whether the head syllable or the head foot was\nbeing regulated. The argument also depends on the kind of feet which are present in Hindi; if they are\nfundamentally iambic, then nothing need be said. If they are moraic trochees, we must split NONFINALITY\nand subordinate to EDGEMOST the version that refers to the head foot. Otherwise, we incorrectly predict\nantepenultimate rather than penultimate stress in light-syllabled words. The foot structure of languages like\nHindi is, to say the least, incompletely understood.\n33\n\n34\n\nA different line of attack is also available for exploration, since the WSP is effectively the converse of\na principle that we have seen active above in Berber and Hindi: PK-PROM is repeated here for convenience:\n(i) Peak-Prominence (PK-PROM). Peak(x)TMPeak(y) if *x* > *y*.\nPK-PROM favors analyses in which positions of prominence are occupied by the heaviest syllables. By PKPROM, the (L3 H) trochee is relatively bad because the counter-analysis L(H3 ) has a better (heavier) peak. PKPROM, in contrast to the WSP, says nothing directly about the occurrence of H in nonhead position.\nComplications arise in analyses where L(H3 ) is ruled out by higher-ranking constraints, for example\nNONFINALITY, and we will not pursue this alternative here.\n\nOptimality Theory\n\n57\n\nChapter 4\n\nSince the trochee (L3 H) is inferior with respect to the WSP, it will be avoided in parses of\nsyllable strings in favor of other structures that meet the constraint — ceteris paribus.\nIn Latin, NONFINALITY (66) renders the ceteris imparibus, as it were. We must have\nNONFINALITY >> WSP to force all final syllables to be foot-loose and non-prominent, regardless of\ntheir weight. With all the parts of the argument put together, the best parse [ámo+ ] emerges as in the\nfollowing:\n(68) Treatment of #LH# (Classical Latin) FTBIN, LX.PR >> NONFINALITY >> WSP\nCandidates\n\nFTBIN\n\nLX.PR\n\nNONFINALITY\n\nWSP\n\n[ (ámo+) ]\n\n*\n\n*\n\nb.\n\n[ a (mó+) ]\n\n** !\n\nc.\n\n[ (á) mo+ ]\n\nd.\n\namo+\n\na.\n\nL\n\n*!\n\n*\n*!\n\n*\n\nThe feet considered here are trochaic; it is fatal to advance an iambic parse in violation of the topranking but unmentioned constraint RHTYPE=T, since a better alternative, trochaic not iambic,\nalways exists.\nThe ranking of NONFINALITY above WSP is part of the grammar of Latin. When the ranking\nis permuted, we get a language that looks more like Kelkar’s Hindi, for example English. It is wellknown, due to the work of R.T. Oehrle (1972), that English bisyllabic nouns of the form LH are\nmostly end-stressed (políce) while all others are mostly initially stressed (HH: árgyle; HL: bándit;\nLL: édda). (For some discussion, see Halle, 1973; Zonneveld, 1976; Liberman & Prince 1977; Hayes\n1982, 1991/1995.) When WSP >> NONFINALITY, we get the effect of ‘extrametricality revocation’.\nThe analysis runs exactly parallel to that of ámo+ just presented in Tableau (68). Observe that amó+\nis the local winner under WSP and the local loser under NONFINALITY; were it the case that WSP\ndominated NONFINALITY, *amó+ would defeat ámo+. The amó+-like form políce [phclí+s] therefore\noptimal in the English-like system, as shown in the following tableau:\n(69) Treatment of LH in an English-like system:\nCandidates\na.\nb.\n\nFTBIN\n\n... WSP >> NONFINALITY\n\nLX.PR\n\n[ (pólice) ]\n\nL\n\nWSP\n\nNONFINALITY\n\n*!\n\n*\n\n[ po(líce) ]\n\nc.\n\n[ (pó) lice ]\n\nd.\n\npolice\n\n**\n*!\n\n*\n*!\n\n*\n\n58\n\nChapter 4\n\nPrince & Smolensky\n\nThe Latin-style ranking of NONFINALITY above constraints relevant to foot form can have\neven more radical consequences. In many otherwise iambic languages, NONFINALITY forces\nbisyllables to be trochaic. Familiar examples include Choctaw, Southern Paiute, Ulwa, Axininca\nCampa35. In such cases, we have NONFINALITY >> RHTYPE. In Southern Paiute we find, for example,\nqa(í ‘my necklace’ but kú ‘fire’. (Final syllables are voiceless; examples from Hale (undated).)\nSouthern Paiute phonology is such as to make it clear that the effect occurs in all forms:\nNONFINALITY is therefore not restricted to a single head-foot of the prosodic word but applies to all\nfeet and to their heads.\n(70) Rhythmic Reversal due to NONFINALITY\nSouthern Pauiute /puNpuNkuõwì-taõwa/ ‘our (incl.) horses owned severally’\nCandidates\n\nL\n\nNONFINALITY\n\n(pumpúõ)(kuõwì-)(tàõ\n\n*\n\n)\n\n(pumpúõ)(kuõwì-)(taõwà)\n\nRHTYPE=I\n\n*!\n\nThe consequences are most dramatic in bisyllables, where the placement of the only stress in the\nword is affected:\n(71) Rhythmic Reversal due to NONFINALITY:\nCandidates\n\nL\n\nNONFINALITY\n\nRHTYPE=I\n\n*\n\n(kú )\n(kuná)\n\nSouthern Paiute /kuna/ ‘fire’\n\n*!\n\nWe have only sketched the core of the phenomenon here. For further discussion, see McCarthy &\nPrince 1993:§7;36 detailed further exploration is found in Hung (1993).\n\n35\n\nRelevant references include: Choctaw (Muskogean)— Lombardi & McCarthy 1991; Munsee\n(Algonkian) — Hayes 1985; Southern Paiute (Uto-Aztecan)— Sapir 1930; Ulwa (Misumalpan)— Hale &\nLacayo-Blanco 1988; Axininca (Arawakan) Payne 1981.\n36\n\nMcCarthy & Prince note that in an iambic system operating under the compulsion of exhaustive parsing\n(PARSE-F, i.e. syllables into feet), the appearance of Left-to-Right parsing is a consequence of NONFINALITY.\nIn odd parity strings, NONFINALITY puts the free syllable at the very end, no matter where it is in the ranking,\nabove or below RHTYPE. (In even parity strings, the domination relationship determines whether the iambic\nfoot will be inverted at word-end.) This result holds whether the iamb is sensitive to quantity or not. It may\nbe relevant that almost all iambic systems are Left-to-Right in directional sense (see Kager 1992c for\ndiscussion from a different perspective).\n\nOptimality Theory\n\nChapter 4\n\n59\n\n4.4 Summary of Discussion of the Except When Effect\nExplicating the ‘except when’ or blocking pattern in terms of constraint domination has led to new\nunderstanding of a variety of prosodic phenomena. We have been able to put edge-oriented infixation\non a principled basis, leading to predictions about the kind of affixes liable to such treatment. The\nproperties previously attributed to a formal theory of extrametricality follow from construing\nextrametricality as an interaction effect which arises when items placed by the gradient constraint\nEDGEMOST are subject to higher-ranking substantive constraints such as NONFINALITY or ONS which\nforce violations of EDGEMOST, minimal of course. Effects of ‘extrametricality revocation’, rather\nthan being due to quirks in the formal theory or special re-write rules applying in arbitrary\nenvironments, are seen instead to follow from the dominance of constraints such as FTBIN,\nPK-PROM, and LX.PR, easily recognizable as authentic, independently-required principles of\nprosody and of the prosody/morphology interface.\nThe interaction that ‘revokes extrametricality’ is exactly of the same sort as that which\nintroduces it in the first place — constraint domination. Just as NONFINALITY overrules EDGEMOST\nproducing the appearance of extrametricality, so does FTBIN (for example) overrule NONFINALITY,\ntaking extrametricality away. We have examined a number of such cases, embodying the except\nwhen or blocking form of descriptive generalization.\nCSyllables are descriptively extrametrical everywhere in a language like Latin except when\nnonparsing would leave nothing (monosyllables) or a single mora (bisyllables /LF/).\nCFeet take on their independently favored forms — obeying the WSP and the language’s\nRHTYPE — everywhere except when in bisyllables, where FTBIN is at stake due to the force of\nNONFINALITY.\nCStress falls on an edgemost syllable except when there is a heavy syllable in the word (in\nwhich case it falls on the edgemost such syllable).\nCStress falls on a nonfinal syllable except when it is the heaviest syllable in the word.\nCAffixes are situated at the edge of the {affix, stem} collocation except when stem-internal\npositioning results in more harmonic syllable structure (and even then, given satisfaction of the\nsyllabic requirements, they are positioned at minimal distance from the target edge.)\nThe sometimes intricate patterns of dependency that lie behind descriptive notions like\nminimality and extrametricality thus emerge from the interaction of principles of prosodic form. The\nsuccess of the theory in rationalizing this domain and opening up the way to new forms of\nexplanation stands as a significant argument in its favor.\n\n4.5 Except meets Only: Triggering and Blocking in a Single Grammar37\nTo conclude our overview of generalization patterns, we take on some empirical issues made\naccessible by the results of the preceding discussion. We show how nonfaithful parsing interacts with\nthe kind of minimality, extrametricality, and prominence effects just examined. The empirical focus\nwill be on Latin, viewed with finer resolution of detail, and we will show how a renovated\n37\n\nThanks to Armin Mester for discussing various points with us. Errors are ours, of course.\n\n60\n\nChapter 4\n\nPrince & Smolensky\n\nconception of the language’s prosody is mandated. By its nature, the analysis must reach a fair level\nof complexity, and the reader who wishes to focus on the main line of the argument may wish to\nreturn after examining §6.\nWords ending in difficult-to-foot sequences like LH pose a challenge that is sometimes met quite\naggressively. In the pre-classical Latin of Terence and Plautus — presumably reflecting a less\nnormative interpretation of the actual spoken language — bisyllabic words /LH/ may come out\noptionally as LL, whence ámo instead of ámo+, yielding a far more satisfactory trochee, one that does\nnot violate WSP. This phenomenon goes by the name of ‘iambic shortening’, in reference to the\nquantitative shape of the input, and has recently been examined in number of studies, especially\nMester 1992, whose results have inspired these remarks, but also including Allen 1973; Devine &\nStephens 1980; Kager 1989; Prince 1990; Hayes 1991/1995. Mester 1992 emphasizes, with Devine\n& Stephens, that words shaped /...HLH/ suffer an entirely parallel reduction to ...HLL — also\noptionally, and at the same historical period. Here are some examples involving the 1st person\nsingular present ending -Ç:38\n(72)\n\n/HLH/\nd‘sino7\nnescio7\n\n/LLH/\nstudeÇ\nhabitÇ\n\n/HH/\nlaudÇ\nmandÇ\n\nThis is called ‘cretic shortening’ after the cretic foot of Greek lyric meters (HLH). Mester produces\na wide variety of phenomena of Latin phonology and morphology, including these shortening effects,\nwhich are responsive to constraints demanding exhaustive footing with high-quality trochees. The\nstructure (H)(LL) puts all syllables into bimoraic trochees, where (H)L(H) traps a syllable between\ntwo feet, (H)LH leaves the final two syllables dangling, and (H)(LH) involves a poor final trochee,\nthe very same (LH) that is forced on bisyllables like ámÇ in the classical language. Common to both\niambic and cretic shortening is the interpretation of underlying ...LH# as surface ...LL#, which\nresults in notably improved prosodic organization.\nTaking this explanation seriously will push our understanding of Latin prosodic organization\nwell beyond what can be deduced from the simple facts of main-stress placement. For one thing,\nwords HLL must be structured (H)(LL) not (H)LL, as has been assumed in previous scholarship, and\nwords HH must be structured (H)(H), not (H)H. Mester sees a two-step process: standard footassignment and main-stressing, followed by a stage of repair in the direction of well-formedness,\nwhich incorporates loose syllables into foot structure when possible, with the assistance of a rule\n‘Remove :’. By contrast, and in line with the general thrust of our argument throughout, we wish\nto explore the idea that iambo-cretic shortening is a direct by-product of the one basic parse, in the\nsame way that epenthesis and deletion are by-products of the one syllabic parse (Selkirk 1981, Itô\n\nGlosses are d‘sino7 ‘cease’, studeÇ ‘strive’, laudÇ ‘praise’, nescio7 ‘don’t-know’, habitÇ ‘reside’, mandÇ\n‘entrust’, all 1psg. We have normalized Mester’s example mand~ ‘entrust 2sg. imp.’ to the 1psg. Note that\nin later Latin there is a phenomenon whereby word-final o is often short, regardless of preceding context\n(Mester 1992:31 fn. 43). This phenomenon is irrelevant to the Pre-Classical situation, but could mislead the\ncasual observer.\n38\n\nOptimality Theory\n\nChapter 4\n\n61\n\n1986, 1989). On this view, iambocretically shortened forms are among the many candidate analyses\nthat forms ~HLH# and #LH# are subject to in any language. The constraint system of Pre-Classical\nLatin, at least at its colloquial level, picks them out as optimal.\nBefore grappling with the details of iambocretic shortness, it is useful to map the structure\nof the basic rhythmic system of the language. This involves three components:\na. Positional theory: nonfinality and edgemostness.\nb. Parsing theory: to compel footing of syllables, and syllabification of segments and moras.\nc. Foot theory: of trochees, their shape and proclivities.\nFirst, the positional constraints. Iambo-cretic shortening indicates that Latin final syllables\nare not to be excluded in principle from foot structure; quite the contrary. The doctrine of total\nextraprosodicity is a superficial conclusion drawn from focusing on examples like (spátu)la, where\nthere is simply nothing to be done. We know that /d‘sin-Ç/ will be parsed (d‘)(sino) in the colloquial\nlanguage, and from this we can infer that blandula is parsed (blan)(dula) and that mandÇ is\n(man)(dÇ). Maximality of prosodic organization is not abandoned wholesale just to place the mainstress in the right position. (It is abandoned minimally, as we expect.) There is no law banning feet\nfrom final position; rather it is the prosodic heads of the word — main stress and main foot — that\nare banned. This is exactly what was claimed above in the statement of NONFINALITY for Latin (66),\nwhich we repeat here:\n(73) NONFINALITY\nNo prosodic head of PrWd is final in PrWd.\nThe constraint applies to the main-stressed syllable itself and to the foot in which it is housed.\nDescriptively, one would say that main-stress falls not on the last foot, as in previous analyses, but\non the last nonfinal foot, rather like Palestinian Arabic, Cairene Radio Arabic, and Munsee, among\nothers (Hayes 1991/1995).\nThe constraint of NONFINALITY pushes the main stress off the final syllable, often leaving\nopen a number of possibilities for its location. As usual, the major positioning constraint is\nEDGEMOST: the prosodic heads fall as far to the right as possible. We must have, of course,\nNONFINALITY >> EDGEMOST, otherwise no nonfinality effects would be observable.39 The constraint\nEDGEMOST(n;E) penalizes forms according to the extent that item n is removed from edge E. In\nLatin n = Prosodic head, E = right edge. For purposes of reckoning distance from the edge, we will\ntake the relevant prosodic head to be the main-stressed syllable itself, and the distance from the edge\nwill be measured in syllables.\nTo see the effects of this scheme, consider first forms LLL, which have two reasonable parses\n3\n(LL)L and L(L3 L). For head foot, we write FN, for head syllable of head foot we write FN.\n\nThis is an instance of P~Ãini’s Theorem, §5 below, whereby with relations between constraints A and\nB, the ranking B >> A entails that A has no effect on the grammar. Notice that we are not saying that they\nare ‘ranked by the Elsewhere Condition’: they are ranked by the facts; either ranking is possible.\n39\n\n62\n\nChapter 4\n\nPrince & Smolensky\n\n(74) Nonfinality Effect in trisyllables\nCandidates\n\nL\n\nNONFINALITY(FN,FN)\n\nEDGEMOST(FN;R)\ntula#\n\n(spátu)la\nspa(túla)\n\nla#\n\n*F)\n\nAssumed is the dominance of FTBIN and of LX.PR, which entails that a form must have a least one\nfoot and a binary one at that. In the more general context, the effects of a principle of exhaustive\nmetrical analysis, familiar from the earliest work in the area (Liberman 1975), is visibly at work.\nThis principle is part of the parsing theory, and we will call it PARSE-F, omitting from the name the\ninformation that F is parsed into F. It ensures, for example, that forms shaped HH will be parsed\n(H3 )(H) rather than (H3 )+H,. Both candidates have perfect nonfinality of F) and F) and both agree in\nedgemostness; only PARSE-F dictates that the second foot must be posited. Similarly, forms LLH\nmust be parsed (L3 L)(H). That PARSE-F is relegated to a subordinate role becomes apparent when we\nexamine forms LLLL. Examination of the natural candidates for analysis of LLLL shows that\nEDGEMOST must dominate PARSE-F:\n(75) EDGEMOST >> PARSE-F, from LLLL\nEDGEMOST(F),R)\n\nPARSE-F\n\npa(tríci)a\n\ni.a#\n\n**\n\nb.\n\n(pátri)(ci.a)\n\ntri.ci.a# !\n\nc.\n\n(patri)(cí.a)\n\nCandidates\na.\n\nL\n\nNONFINALITY(F),F))\n\n*F)\n\nThe correct output patrícia (a) is poorly F-parsed, while both of its competitors are perfect on that\nscore. EDGEMOST, however, rules in its favor in the competition with (b) , and so must dominate\nPARSE-F. Note that the pre-antepenultimate form (b) is correct for Palestinian Arabic, suggesting a\ndifferent ranking of the constraints in that language.\nThese considerations give us the core of the system of both Classical and Pre-Classical Latin.\nWe have Position >> Parsing, or, in detail:\n(76) Antepenultimacy\nNONFINALITY(F),F)) >> EDGEMOST(F),R) >> PARSE-F\nThe fundamental constraints LX.PR and FTBIN are of course superordinate.\nOn this account, a word LLL is analyzed (L3 L)L not because the final syllable is marked\nextrametrical, but rather because the main foot stands in a nonfinal position, a pure nonfinality effect.\nThe fate of words LLLL is decided by a combination of NONFINALITY, which winnows the candidate\nset down to L(L3 H)L and (L3 L)(LL), and EDGEMOST, which decides the matter in favor of forms in\nwhich the prosodic head stands nearest to the end of the word.\n\nOptimality Theory\n\nChapter 4\n\n63\n\nThis kind of argument parallels the one given above about prefixing infixation (§4.1), and\ncan only be made in a theory that compares across the set of possible structures. Under Bottom-Up\nConstructionism, which builds structure by deterministic rule, the feet must be fixed in place first,\nand you can only choose the head-foot from among the ones you have before you.\nExactly a single syllable ends up extrametrical here. But this follows from the very\ninteraction of EDGEMOST and NONFINALITY which is necessary to generate the extrametricality effect\nin the first place. There is no special notion [+extrametrical], distinct from ‘unparsed’ or ‘occupying\nweak position in prosodic structure’, conditions which befall many an element, for many reasons.\nConsequently, as argued above in §4.3, there is no theory of extrametricality as a formal device,\nwhich requires among its axioms a principle limiting the scope of the feature [+extrametrical] to a\nsingle constituent. Because violations are always minimal, only the minimal amount of nonedgemostness will be tolerated. This minimum will often turn out to be a single constituent. (But not\nnecessarily so, unless other factors conspire: cf. Tagalog gr-um-adwet, §4.1, where gr need not be\nregarded as constituent for the explanation to go through.)\nThe remaining component of the system is the foot theory. The bedrock constraints are FTBIN\nand RHTYPE=T. These are unviolated in the optimal forms of the language: every foot is binary on\nsyllables or moras, and every foot is trochaic. In addition, universal prosody recognizes the Weightto-Stress Principle WSP, which urges that the intrinsic prominence of heavy syllables be registered\nas prosodic prominence; this discriminates against the quantity-prominence mismatch of trochees\n(L3 H). Feet (H3 L) satisfy all these constraints but are known to be marked or even absent in trochaic\nsystems (Hayes 1987, Prince 1990; Mester 1992); we wish to ban these on grounds of rhythmic\nstructure, which favors length at the end of constituents. Let us call the relevant constraint ‘Rhythmic\nHarmony’(RHHRM); for present purposes we can simplify its formulation to *(HL).\nOf these constraints, only the WSP shows any mobility in the dialects (or register levels) of\nLatin under discussion. In Classical Latin, as shown above in (68), we must have NONFINALITY >>\nWSP, to obtain (ámo+) rather than *a(mó+). Both candidates contain a foot, satisfying the\nmorphology/prosody interface constraint LX.PR; both contain binary feet, satisfying FTBIN; but only\n(ámo:) succeeds in getting the main stress off the last syllable. The cost is violation of the WSP. In\nthe iambocretic-shortening register of Pre-Classical Latin, by contrast, we have (ámo) and no\nviolation of the WSP at all. All four foot-relevant constraints are unviolated, and are therefore not\ndominated crucially by any other constraints in the grammar. These observations are summarized\nin the following table.\n\n64\n\nChapter 4\n\nPrince & Smolensky\n\n(77) Foot Form Constraints\nConstraint\n\nEffect\n\nStatus\n\nFTBIN\n\nF = ::, FF\n\nunviolated\n\nRHTYPE=T\n\n(FF) = (F' F)\n\nunviolated\n\nRHHRM\n\n*(HL)\n\nunviolated\n\nWSP\n\n* H-\n\nViolated in Classical Latin.\nUnviolated in Pre-Classical shortening register.\n\nHaving secured the proper infrastructure, we can approach the issue of iambocretic\nshortening. Mester proposes a special rule of repair, ‘Remove :’, which works in concert with his\nsecond round of footing. Optimality Theory does not recognize repair strategies as distinct from the\nordinary resources available for assigning structure in the first place. Structure is posited freely,\nthough always subject to evaluation. Empty nodes are violations (of the constraint we have called\nFILL), but violation can be forced. Similarly, elements present in the input can remain structurally\nunanalyzed, violating PARSE. Such violations are tolerated in an optimal candidate only when they\nlead to better performance on higher-ranked constraints. In the case at hand, an underlying mora (as\nin the second syllable of /amo+/) is left unparsed — unattached to syllable structure — and hence\nuninterpreted, giving rise to a phonetic short vowel. The resulting structure looks something like this:\n(78) Syllabically Unparsed Mora\n\nF\n:\n\n:\nV\n\nThis is a monomoraic syllable. Failure to construe the second mora is a violation of PARSE,\nspecifically of the constraint PARSE-:, which must be distinguished from the other members of the\nPARSE-element family. In Classical Latin, quantity is stable under prosodic analysis; PARSE-: is\nwidely observed and no constraint discussed here forces it to be violated. Therefore, PARSE-: in\nClassical Latin is undominated by the constraints at hand.40 But in the shortening register of\nPre-Classical Latin, PARSE-: is subordinated in the ranking, leading to the appearance of phonetic\nshort vowels as the globally optimal but locally unfaithful renditions of lexical long vowels.\nFollowing Mester 1992: 33, we want /HLH/ words like /di+cito+/ ‘say, imp. fut.’ to be parsed\n(di+)(cito)++,. Similarly, we want /LH/ words like /amo+/ to be parsed (amo)++,. With the ad hoc\n\n40\n\nBy contrast, numerous violations of PARSE-segment are forced by syllable structure conditions, as in\n/mell/ ÿ mel, /cord/ ÿ cor, /ment+s/ ÿ mens (Steriade 1982). See below §6-8 for further discussion.\n\nOptimality Theory\n\n65\n\nChapter 4\n\nnotation HS used to indicate a potentially heavy syllable parsed as light, as for example in diagram\n(78), the relevant lexical-surface associations can be written as follows:\n(79) PC Latin Parsing of Interesting Strings\nBase\n\na. HH\nb. LH\nc. HLL\nd. HLH\n\n*PARSE-:\n\nFaithful\n(H)(H)\n\n(LHS)\n(H)(LL)\n(H)(LHS)\n\nWhat forces the PARSE-: violations? For bisyllabic words, it is clear that the parse (L3 HS) successfully\navoids the wretched trochee (L3 H), which violates the WSP. Therefore we have WSP >> PARSE-:,\nmeaning that is more important to ensure that all heavy syllables are stressed than to retain\nunderlying vowel length. One way to satisfy the WSP is to omit potential heaviness from syllables\nthat stand in unstressable positions.\nA second constraint that crucially dominates PARSE-: is PARSE-F, which compels exhaustive\nfooting. This relation is manifest in the treatment of forms ending in HLH, which show cretic\nshortening.\n(80) PARSE-F >> PARSE-: from /HLH/\nCandidates\n\nL\n\nPARSE-F\n\n*\n\n(H3 )(LHS)\n(H3 )L(H)\n\nPARSE-:\n\n*!\n\nThe parse *(H3 )L(H) has nothing wrong with it but the ‘trapping’, as Mester puts it, of the middle\nsyllable: it is unaffiliated with F. The counter analysis (H3 )(LHS) is fully F-parsed, but the price is\nleaving the final : out of syllable structure. This shows that PARSE-F is dominant, forcing the\nPARSE-: violation. This ranking recognizes Mester’s basic claim: that exhaustive parsing is the\nmotive force behind the shortness effect.\nWith PARSE-: subordinated in the ranking, feet (HS L) also become significant contenders.\nThey also resolve the parsing problem presented by HLH, leading to *(dési)(no+), for example, in\nplace of actual (dé+)(sino). Both candidates are fully F-parsed; both have nonfinal prosodic heads;\nand they agree on the rightmostness of the mainstress. The only difference is the location of the H\nthat is incompletely parsed as HS. The outcome (HS L)H is witnessed in various languages, famously\nEnglish (Myers 1987; Prince 1990) and Boumaa Fijian (Hayes 1991/1995), but not Latin. What\nmakes the difference in Latin? The plausible candidate is PK-PROM, which we repeat from (37):\n(81) Peak-Prominence (PK-PROM).\nPeak(x)TMPeak(y) if *x* > *y*\n\n66\n\nChapter 4\n\nPrince & Smolensky\n\nIn terms of a two-way H/L contrast, this means that H3 is a better peak than L3 . Because the unparsed\nmora of HS makes it into a light syllable, the foot (HS L) has inferior peak-prominence compared with\n(H3 ). The contrast becomes important in the analysis of HLH, as this tableau demonstrates:\n(82) PK-PROM and PARSE-:\nPK-PROM\n\nPARSE-:\n\n(H3 )(LHS)\n\n*H*\n\n*\n\n(H3 S L)(H)\n\n*HS*=*L* !\n\n*\n\nCandidates\n\nL\n\nThis is not a ranking argument: PARSE-: does not discriminate between these candidates, so the\nconstraints are not in diametric conflict. PK-PROM will decide the issue no matter where it is located\nin the hierarchy.41 In Latin PK-PROM cannot be allowed to play the same role that it does in Hindi,\nsingling out a heavy syllable anywhere among a string of light syllables; the positional constraints\nmust dominate it, EDGEMOST in particular:\n(83) EDGEMOST >> PK-PROM, from HLLL /incipere/ ‘to begin’\nCandidates\n\nL\n\nEDGEMOST\n\nPK-PROM\n\n(in)(cípe)re\n\npe.re#\n\n*L*\n\n(ín)(cipe)re\n\nci.pe.re# !\n\n*H*\n\nThis relation also holds in the grammar of Classical Latin, where PK-PROM has no visible effects.\nIt is worth emphasizing that PK-PROM is quite distinct notionally from the WSP. The WSP goes from\nweight to stress: ‘if heavy then stressed’ (equivalently, ‘if unstressed then light’). PK-PROM\nessentially goes the other way: ‘if stressed then heavy’ (contrapositively and equivalently: ‘if light\nthen unstressed’). To see this, imagine PK-PROM playing out over a binary weight contrast; it says\nH3 TML3 or in the language of violations, *L3 . The WSP has nothing to say about this configuration.\nThese two halves of the purported biconditional ‘heavy iff stressed’ have very different status in\nstress systems, as Prince 1990 observes; the present case is a further demonstration of this fact.\nWe have now established the form of the constraint system. For convenience of reference,\nthe rationale for the crucial rankings is summarized in the following table:\n\n41\n\nObserve that PK-PROM as stated deals only with the main stress, the peak of the PrWd. Feet (HSL) are\nbanned everywhere in the word, and so the explanation must be extended to these cases. The issue does not\narise to the right of the main stress, and we will return to it only after the main argument is laid out.\n\nOptimality Theory\n\n67\n\nChapter 4\n\n(84) Support for Rankings\nRanking\n\nBecause:\n\nRemarks\n\nNONFINALITY(F),F)) >> EDGEMOST(F);R)\n\n(L3 L)L ] TM\n\nL(L3 L) ]\n\nEDGEMOST(F);R) >> PARSE-F\n\nL(L3 L)L ] TM\n\n(L3 L)(LL) ]\n\nEDGEMOST(F);R) >> PK-PROM\n\nHL3 LL ] TM\n\nH3 LLL ]\n\nWSP >> PARSE-:\n\n[(L3 HS) ] TM\n(H3 )(LHS) ] TM\n\n[(L3 H) ]\n3\n(H)(LH) ]\n\nPARSE-F >> PARSE-:\n\n(H3 )(LHS) ] TM\n\n(H3 )L(H) ]\n\nShared, all Registers\nPosition of main\nstress\n\nShortening Register:\nIambocretic effect\n\nObserve that the three relations above the double line are shared in all dialects or speech-levels; those\nbelow it delimit the characteristics of iambocretic shortening.\nTo conclude this discussion, we assemble the constraint relations established for Latin and\ngo on to demonstrate the efficacy of the constraint system in dealing with the key examples.\n(85) Constraint Structure of PC Latin Shortening Grammar\na. Undominated\nWSP, RHHRM, FTBIN, RHTYPE=T, LX.PR\nb. Main Sequence\nLX.PR, FTBIN >> NONFINALITY(F),F)) >> EDGEMOST(F);R) >> PARSE-F >> PARSE-:\nc. Weight Effect\nWSP >> PARSE-:\nd. Bounding\nEDGEMOST(F);R) >> PK-PROM\nEmpirical considerations do not force a total order on the set of constraints. Any total order\nconsistent with the partial order will yield equivalent results. Without violating the crucial rankings\nwe can place all four of the foot-relevant constraints WSP, RHHRM, FTBIN, and RHTYPE=T in a\nsingle package at the top of the hierarchy, which we will label ‘foot form’. More arbitrarily, under\nthe compulsion of the planar format of the tableau, we will list PK-PROM at the very bottom. This\ndivides the constraint system into four blocks:\n(86) Block Structure of the Constraint system, in domination order\na. Foot Form\nb. Position\nc. Parsing\nd. Prominence\nTo simplify the presentation, all candidate parses that fail to satisfy LX.PR and FTBIN will be\nomitted from consideration, since violation is obvious and inevitably fatal.\n\n68\n\nChapter 4\n\nPrince & Smolensky\n\nFirst, let us contrast the treatment of bisyllables LH and HH.\n(87) Parsing of LH\nCandidates\n\nFoot Form\n\n/LH/\na.\n\nL\n\n(L3 HS)\n\nb.\n\n(L3 H)\n\nc.\n\nL (H3 )\n\n*WSP !\n\nPosition\n\nParsing\n\nNONFINAL\n\nEDGEM\n\n*FN\n\nF#\n\n*FN\n\nF#\n\n*FN *FN !\n\ni#\n\nPARSE-F\n\nPARSE-:\n\nPK-PROM\n\n*\n\n*L*\n*L*\n*H*\n\n*\n\nHere the parse (LHS) is optimal because (LH) is a poor foot violating WSP, and because (LH3 )\nviolates both requirements on the nonfinality of heads. This shows that we have ‘iambic shortening’.\n(88) Parsing of HH\nCandidates\n\nFoot Form\n\nNONFINAL\n\n/HH/\na.\n\nL\n\n(H3 ) H\n\nc.\n\n(H3 ) HS\n\nParsing\n\nEDGEM\n\nPARSE-F\n\nPARSE-:\n\nF#\n\n(H3 )(H)\n\nb.\n\nPosition\n\n*WSP !\n\nPK-PROM\n\n*H*\n\nF#\n\n*\n\nF#\n\n*!\n\n*H*\n\n*\n\n*H*\n\nThe form (H3 )(H) satisfies all constraints maximally well and its rivals must all do something worse.\n\nOptimality Theory\n\n69\n\nChapter 4\n\n(89) Parsing of HLH\nCandidates\n\nFoot Form\n\nPosition\n\nNONFINAL\n\n/HLH/\n\nParsing\n\nEDGEM\n\nPARSE-F\n\nPARSE-:\n\na.\n\nL (H3 )(LHS)\n\nFF#\n\n*\n\nb.\n\n(H3 SL)(H)\n\nFF#\n\n*\n\nc.\n\n(H3 )L(H)\n\nFF#\n\nd.\n\n(H3 )(LH)\n\n*WSP !\n\nFF#\n\n(H3 L)(H)\n\n*RHHRM !\n\nFF#\n\nPK-PROM\n\n*!\n\n*!\n\nPerhaps the most interesting comparison is between (H3 )(LHS) and (H3 )L(H). It’s decided by PARSE-F,\nwhich forces the inclusion of syllables in foot structure, at the expense of an unfaithful rendering of\nthe underlying moraic structure.\n(90) Parsing of HLL\nCandidates\n\nFoot Form\n\nNONFINAL\n\n/HLL/\na.\n\nL (H3 )(LL)\n\nb.\n\n(H3 L) L\n\nc.\n\n(H)(L3 L)\n\nPosition\n\nParse\n\nEDGEM\n\nPARSE-F\n\nPARSE-:\n\nPK-PROM\n\nFF#\nFF#\n\n*RHHRM !\n\n*\n\n*FN !\n\nLike its moraic parallel HH, the wordform HLL has the near-perfect parse (H3 )(LL), with only\nEDGEMOST being violated, a necessary infraction. Its rivals must all incur more serious violations.\nThis completes our review of the basic patterns. A couple of further subtleties deserve\nmention. Iambocretic shortening not only affects long vowels, it also treats closed syllables as light,\nas evidenced by versification practice (Allen 1973, Kager 1989, Mester 1992). We have quantitative\nanalyses like these:42\n(91) Light Closed Syllables\n\n42\n\nBase\n\nAnalysis\n\na. /kanis/\nb. /volupta+te+s/\nc. /ve+nerant/\n\n(.ka.nis.):.:\n(.vo.lup.):.: (ta+):: (te+s)::\n(ve+):: (.ne.rant.):.:\n\nPattern\n(LHS)\n(LHS) (H) (H)\n(H) (LHS)\n\nGlosses: ‘dog’; ‘desires’; ‘come’ 3pl.fut.pf. Examples from Mester 1992:12;31.\n\n70\n\nChapter 4\n\nPrince & Smolensky\n\nIn such cases, the syllable-closing consonant is analyzed as nonmoraic, merely adjoined to the\nsyllable, so that .nis. = .n[i]:s, for example (cf. Kager 1989). What is ineffective, here, is the parsing\nprinciple requiring that a syllable-final consonant (sequence) correspond to a heaviness-inducing\nweak mora. To ensure the parallelism with long-vowel shortening, we can assume that moraic\nparsing is not itself violated, but rather that the mora it licenses remains unparsed syllabically. The\nstructure looks like this:\n(92) Unparsed Syllable-Closing Mora\n\nF\n:\n\n:\n\nV C\nIf this kind of structure is admitted, both kinds of lightness effects of iambo-cretic shortening show\nup as PARSE-: violations.43\nIambic shortening also shows up in non-final position, as example (91b) illustrates.44 The\nfollowing tableau demonstrates that the constraint hierarchy already predicts this outcome:\n\n43\n\nThese phenomena can also be construed in metrical rather than syllabic terms, perhaps more\ninterestingly. Suppose that the actual terminal nodes of metrical structure are the positions on the first grid\nrow (Prince 1983, Halle & Vergnaud 1987). (Bracketing of syllable strings is derivative from this in the\nobvious way.) Mapping syllable structure to the grid is what’s at issue. In general, : 2 x. But we can also\nhave [::]F 2 x, “compression” in the manner of Yupik (Woodbury 1981, Hewitt 1992), somewhat like the\n“mora sluicing” of Prince 1983. The constraint that’s being violated is not PARSE-:-to-F but rather PARSE:-to-x. To make it perfectly parallel to discussion in the text, instead of :i:j 2 xixj, we get :i:j 2 xi, with\n:j unassociated. Thus both V+ and VC violate PARSE-:-to-x equally. Compressed V+ is interpreted as\nequivalent to a short vowel; that is, quantity is read off the first layer of the grid. Evidence for this view\ncomes from the fact that geminates may suffer iambic shortening, e.g. supellectilis ‘utensils’ without\napparently being literally degeminated (Mester 1992: 17n).\n44\n\nMester (1992: 17n) points to a number of other subtleties, such as the fact that the vowel-shortening\nwing of the phenomenon applies only sporadically to internal long vowels. He suggests that preserving\nlexical (distinctive) quantity may drive this difference in behavior. We refer the reader to Mester’s\ndiscussion.\n\nOptimality Theory\n\n71\n\nChapter 4\n\n(93) Internal Nonparsing of Moras\nCandidates\nLHHH\n\nFoot\nForm\n\nPosition\n\nNONFINAL\n\nParsing\n\nEDGEM\n\na.\n\nL (LHS)(H3 )(H)\n\nF#\n\nb.\n\nL(H)(H3 )(H)\n\nF#\n\nPARSE-F\n\n*!\n\nPARSE-:\n\nPK-PROM\n\n*\n\n*H*\n*H*\n\nAn interesting issue arises in longer words which have the potential for feet (HSL) before the\nmain stress, for example HLHH. As noted in fn. 41, p. 66 above, if PK-PROM is stated so as to apply\nonly to the peak or main stress of the PrWd, it will have no consequences outside the head foot.\nWithout further remark, we expect (HSL)(H3 )(H) from HLHH. This avoids the Foot Form violation\n(HL), which we know to be avoided in the parse of /HLH/, shown in (89); and it achieves complete\nfoot-parsing at the expense of PARSE-:, which is well-motivated in the grammar. We suggest that\nPK-PROM in fact applies to all “peaks” or heads, both of PrWd and of F. But within this subsystem,\nthere is also a ranking of priorities: evaluation of the head of PrWd takes priority over evaluation of\nfoot-heads. To see this, consider the rival parses *(H3 SL)(H) and (H3 )(LHS). At the foot level each\nsports one heavy head and one light head, since *HS*=*L*. It is only at the PrWd level that the\ndecision can be made in favor of the correct form, which has a heavy main peak. In §8, we provide\na general mechanism for constructing complex constraints like PK-PROM from the coordination of\ntwo distinct scales of relative prominence, here (1) head of PrWd vs. foot-head and (2) heavy syllable\nvs. light syllable.\nA final, fundamental question raised by the analysis concerns the relation between Classical\nLatin and Pre-Classical Latin, or, more precisely, between the formal register and the informal\nshortening register of the Pre-Classical language. The shortening register is derived by two rerankings: PARSE-: is made subordinate and the WSP rises to the top. It might be objected, on\naesthetic grounds, that one should aim to get the difference out of a single re-ranking. This seems\nto us too superficial a judgment. The notion of colloquial register surely has a substantive\ncharacterization which is not even approximated by counting changes in a constraint or rule system;\ncertain single re-rankings will massively alter the surface appearance of the system. In Latin, the\neffect of the re-ranking is to render the foot-defining block of constraints entirely transparent, at the\ncost of some failures to realize underlying quantity. This is consistent with the general sense that\ncolloquial language simplifies prosodic structures, rendering them in closer accord with universal\nstructural markedness constraints, while subordinating Faithfulness.\n\n72\n\nChapter 4\n\nPrince & Smolensky\n\n73\n\n5. The Construction of Grammar in Optimality Theory\nPhonological theory contains two parts: a theory of substantive universals of phonological wellformedness and a theory of formal universals of constraint interaction. These two components are\nrespectively the topics of §5.1 and §5.2. Since much of this work concerns the first topic, the\ndiscussion here will be limited to a few brief remarks. In §5.3, we give P~Ãini’s Theorem, a theorem\nabout the priority of the specific which follows from the basic operation of Optimality Theory as set\nout in §5.2.\n\n5.1 Construction of Harmonic Orderings\nfrom Phonetic and Structural Scales\nTo define grammars from hierarchies of well-formedness constraints, we need two distinct\nconstructions: one that takes given constraints and defines their interactions, another that pertains\nto the constraints themselves. The first will be discussed at some length in §5.2; we now take up the\nsecond briefly.\nConstruction of constraints amounts in many ways to a theory of contextual markedness\n(Chomsky & Halle 1968: ch. 9, Kean 1974, Cairns & Feinstein 1982, Cairns 1988, Archangeli &\nPulleyblank 1992). Linguistic phonetics gives a set of scales on phonetic dimensions; these are not\nwell-formedness ratings, but simply the analyses of phonetic space that are primitive from the\nviewpoint of linguistic theory. (We use the term ‘scale’ in the loosest possible sense, to encompass\neverything from unary features to n-ary orderings.)\nIssues of relative well-formedness, or markedness, arise principally when elements from the\ndifferent dimensions are combined into interpretable representations. High sonority, for example,\ndoes not by itself entail high (or low) Harmony; but when a segment occurs in a structural position\nsuch as nucleus, onset, or coda, its intrinsic sonority in combination with the character of its position\ngives rise to markedness-evaluating constraints such as HNUC above. Similarly, tongue-height in\nvowels is neither harmonic nor disharmonic in isolation, but when the dimension of ATR is brought\nin, clear patterns of relative well-formedness or Harmony emerge, as has been emphasized in the\nwork of Archangeli & Pulleyblank (1992). These Harmony scales are intimately tied to the repertory\nof constraints that grammars draw on. Inasmuch as there are principled harmonic concomitants of\ndimensional combination, we need ways of deriving Harmony scales from phonetic scales.\nSymbolically, we have\n(94) Harmony Scale from Interaction of Phonetic Scales\n{a > b ...} q { x > y >...} = ax TM...\nThe goal of contextual markedness theory is to give content to the operator q. Below in §8.2 we\nintroduce a formal mechanism of Prominence Alignment which generates constraint rankings from\npaired phonetic scales, yielding a Harmony scale on their combination. In the syllable structure\napplication of §8.2, the two phonetic scales which are aligned are segmental prominence (the\n\n74\n\nChapter 5\n\nPrince & Smolensky\n\nsonority dimension) and syllable position prominence (Peak is a more prominent position than\nMargin). The result is a Harmony scale on associations of segments to syllable positions.\nIt is important to distinguish the three kinds of scales or hierarchies which figure in Optimality\nTheory. To minimize confusions, we have given each its own distinctive comparison symbol. Two\nof these figure in (94): elements are ordered on a phonetic scale by the relation ‘>’, and on a\nHarmony scale according to ‘TM’. The third type of hierarchy in the theory is the domination\nhierarchy, along which constraints are ranked by the relation ‘>>’. These different types of scales are\nenumerated and exemplified in the following table:\n(95) Three Different Scales in Optimality Theory\nType of scale\nor hierarchy\n\nRelates\n\nSymbol\n\nExample\n\nPhonetic\nScale\n\nPoints along\nelementary\nrepresentational\ndimensions\n\n>\n\na>l\n\na is more sonorous\nthan l\n\nHarmony\nScale\n\nWell-formedness of\nstructural\nconfigurations built\nfrom elementary\ndimensions\n\nTM\n\náTM3\n\na nucleus filled by a is\nmore harmonic than a\nnucleus filled by l\n\nDomination\nHierarchy\n\nRelative priority of\nwell-formedness\n\nONS>>HNUC\n\nthe constraint ONS\nstrictly dominates the\nconstraint HNUC\n\n>>\n\nMeaning\n\n5.2 The Theory of Constraint Interaction\nIn order to define harmonic comparison of candidates consisting of entire parses, we will proceed\nin two steps. First, we get clear about comparing entire candidates on the basis of a single constraint,\nusing ONS and HNUC from the Berber analysis in §2 as our examples. Then we show how to\ncombine the evaluation of these constraints using a dominance hierarchy.\n\n5.2.1 Comparison of Entire Candidates by a Single Constraint\nThe first order of business is a precise definition of how a single constraint ranks entire parses. We\nstart with the simpler case of a single binary constraint, and then generalize the definition to nonbinary constraints.\n\nOptimality Theory\n\nChapter 5\n\n75\n\n5.2.1.1 ONS: Binary constraints\nIt is useful to think of ONS as examining a syllable to see if it has an onset; if it does not, we think\nof ONS as assessing a mark of violation, *ONS. ONS is an example of a binary constraint; a given\nsyllable either satisfies or violates the constraint entirely. The marks ONS generates are all of the\nsame type: *ONS. For the moment, all the marks under consideration are identical. Later, when we\nconsider the interaction of multiple binary constraints, there will be different types of marks to\ndistinguish; each binary constraint ÷ generates marks of its own characteristic type, *÷. Furthermore,\nsome constraints will be non-binary, and will generate marks of different types representing different\ndegrees of violation of the constraint: the next constraint we examine, HNUC, will illustrate this.\nWhen assessing the entire parse of a string, ONS examines each F node in the parse and\nassesses one mark *ONS for each such node which lacks an onset. Introducing a bit of useful\nnotation, let A be a prosodic parse of an input string, and let ONS(A) = ( *ONS, *ONS, þ ) be a list\ncontaining one mark *ONS for each onsetless syllable in A. Thus for example ONS(.txï.1⁄2t.) = (*ONS):\nthe second, onsetless, syllable earns the parse .txï.1⁄2t. its sole *ONS mark. (Here we use ï to indicate\nthat z is parsed as a nucleus.)\nONS provides a criterion for comparing the Harmony of two parses A and B; we determine\nwhich of A or B is more harmonic (‘less marked’) by comparing ONS(A) and ONS(B) to see which\ncontains fewer *ONS marks. We can notate this as follows:\nA TMONSparse B iff ONS(A) TM(*) ONS(B)\nwhere ‘TMONSparse’ denotes comparison of entire parses and ‘ONS(A) TM(*) ONS(B)’ means ‘the list\nONS(A) contains fewer marks *ONS than the list ONS(B)’. (We will use the notation ‘(*)’ as a\nmnemonic for ‘list of marks’.) If the lists are the same length, then we write45\nA .ONSparse B iff ONS(A) .(*) ONS(B).\nIt is extremely important to realize that what is crucial to TM(*) is not numerical counting, but\nsimply comparisons of more or less. This can be emphasized through a recursive definition of TM(*),\na definition which turns out to provide the basis for the entire Optimality Theory formalism for\nHarmony evaluation. The intuition behind this recursive definition is very simple.\n\n45\n\nIn §5.1 we define several formally distinct orders in terms of one another. At the risk of overburdening\nthe notation, we use superscripts like parse and (*) to keep all these orders distinct. We prefer to resist the\ntemptation to sweep conceptual subtleties under the rug by using extremely concise notation in which many\nformally distinct relations are denoted by the same symbol. It is important to remember, however, that the\nsymbols ‘TM’ and ‘.’ — no matter what their subscripts and superscripts — always mean ‘more harmonic’\nand ‘equally harmonic’. We need to compare the Harmonies of many different kinds of elements, and for\nclarity while setting up the fundamental definitions of the theory, we distinguish these different Harmony\ncomparison operators. Once the definitions are grasped, however, there is no risk of confusion in dropping\nsuperscripts and subscripts, which we will indeed do. The superscripts and subscripts can always be inferred\nfrom context — once the whole system is understood.\n\n76\n\nChapter 5\n\nPrince & Smolensky\n\nSuppose we are given two lists of identical marks *÷; we need to determine which list is\nshorter, and we can’t count. Here’s what we do. First, we check to see if either list is empty. If both\nare, the conclusion is that neither list is shorter. If one list is empty and the other isn’t, the empty one\nis shorter. If neither is empty, then we remove one mark *÷ from each list, and start all over. The\nprocess will eventually terminate with a correct conclusion about which list is the shorter — but with\nno information about the numerical lengths of the lists.\nFormalizing this recursive definition is straightforward; it is also worthwhile, since the\ndefinition will be needed anyway to characterize the full means of evaluating the relative harmonies\nof two candidate parses.\nWe assume two simple operations for manipulating lists. The operation we’ll call FM\nextracts the First Member (or ForeMost element) of a list; this is what we use to extract the First\nMark *÷ from each list. The other operation Rest takes a list, throws away its First Member, and\nreturns the rest of the list; we use this for the recursive step of ‘starting over’, asking which list is\nshorter after the first *÷ has been thrown out of each.\nSince we keep throwing out marks until none are left, it’s also important to deal with the case\nof empty lists. We let ( ) denote an empty list, and we define FM so that when it operates on ( ), its\nvalue is i, the null element.\nNow let \" and $ be two lists of marks. We write \" TM(*) $ for ‘\" is more harmonic than $’,\nwhich in the current context means ‘\" is shorter than $’, since marks are anti-harmonic. To express\nthe fact that an empty list of marks is more harmonic than a non-empty list, or equivalently that a\nnull first element indicates a more harmonic list than does a non-null first element *÷, we adopt the\nfollowing relation between single marks:\n(96) Marks are anti-harmonic:\n\ni TM * *÷\n\nRemembering that . denotes ‘equally harmonic’ (or ‘equally marked’), we also note the obvious\nfacts about identical single marks:\n\ni .* i and *÷ .* *÷\nOur recursive definition of TM(*) can now be given as follows, where \" and $ denote two lists\nof identical marks:\n(97) Harmonic ordering — lists of identical marks\n\" TM(*) $ iff either:\n(i)\nFM(\") TM* FM($)\nor\n(ii)\nFM(\") .* FM($) and Rest(\") TM(*) Rest($)\n‘$ —(*) \"’ is equivalent to ‘\" TM(*) $’; ‘\" .(*) $’ is equivalent to ‘neither \" TM(*) $ nor $ TM(*) \"’.\n(In subsequent order definitions, we will omit the obvious counterparts of the final sentence defining\n—(*) and .(*) in terms of TM(*).)\n\nOptimality Theory\n\nChapter 5\n\n77\n\nTo repeat the basic idea of the definition one more time in English: \" is shorter than $ iff (if and only\nif) one of the following is true: (i) the first member of \" is null and the first member of $ is not (i.e.,\n\" is empty and $ is not), or (ii) the list left over after removing the first member of \" is shorter than\nthe list left over after removing the first member of $.46\nNow we can say precisely how ONS assesses the relative Harmony of two candidate parses, say\n.tx' .z1⁄2t. and .txï.1⁄2t. ONS assesses the first as more harmonic than the second, because the second has\nan onsetless syllable and the first does not. We write this as follows:\n.tx' .z1⁄2t. TMONSparse .txï.1⁄2t. because ONS(.tx' .z1⁄2t.) = ( ) TM(*) ( *ONS ) = ONS(.txï.1⁄2t.)\nwhere TM(*) is defined in (97).\nAs another example:\n.tx' .z1⁄2t. .ONSparse .txz'.n't . because ONS(.tx' .z1⁄2t.) = ( ) .(*) ( ) = ONS(.txz'.n't .)\nIn general, for any binary constraint ÷, the harmonic ordering of entire parses which it\ndetermines, TM÷parse, is defined as follows, where A and B are candidate parses:\n(98) Harmonic ordering of forms — entire parses, single constraint ÷\nA TM÷parse B iff ÷(A) TM(*) ÷(B)\nwith TM(*) as defined in (97).\nIt turns out that these definitions of TM(*) (97) and TM÷parse (98), which we have developed for binary\nconstraints (like ONS) apply equally to non-binary constraints (like HNUC); in the general case, a\nconstraint’s definition includes a harmonic ordering of the various types of marks it generates. The\nimportance of the definition justifies bringing it all together in self-contained form:\n\n46\n\nA simple example of how this definition (97) works is the following demonstration that\n( * ) TM(*) ( * , * ).\nDefine \" and $ as follows (we use ‘/’ for ‘is defined to be’):\n\"/(* )\n$/(* ,* ).\nThen\n\" TM(*) $ because\n(97.ii) FM(\") = * .* * = FM($) and\nRest(\") = ( ) TM(*) ( * ) = Rest($);\nwhere the last line, ( ) TM ( * ), is in turn demonstrated by letting\n\"N / ( ) $N / (* )\nand noting that\n\"N TM(*) $N because\n(97.i) FM(\"N) = i TM* * = FM($N)\nby (96).\n\n78\n\nChapter 5\n\nPrince & Smolensky\n\n(99)\nHarmonic ordering of forms — entire parse, single constraint\nLet ÷ denote a constraint. Let A,B be two candidate parses, and let \",$ be the lists of\nmarks assigned them by ÷:\n\" / ÷(A), $ / ÷(B)\n÷ by definition provides a Harmony order TM* of the marks it generates. This order is\nextended to a Harmony order TM(*) over lists of marks as follows:\n\" TM(*) $ iff either:\n(i)\nFM(\") TM* FM($)\nor\n(ii)\nFM(\") .* FM($) and Rest(\") TM(*) Rest($)\nThis order TM(*) is in turn extended to a Harmony order over candidate parses (with\nrespect to ÷), TM÷parse, as follows:\nA TM÷parse B iff ÷(A) / \" TM(*) $ / ÷(B)\nThe case we have so far considered, when ÷ is binary, is the simplest precisely because the Harmony\norder over marks which gets the whole definition going, TM*, is so trivial:\ni TM * *÷\n‘a mark absent is more harmonic than one present’ (96). In the case we consider next, however, the\nordering of the marks provided by ÷, TM*, is more interesting.\n\n5.2.1.2 HNUC: Non-binary constraints\nTurn now to HNUC. When it examines a single syllable, HNUC can usefully be thought of as\ngenerating a symbol designating the nucleus of that syllable; if the nucleus is n, then HNUC generates\n1⁄2. HNUC arranges these nucleus symbols in a Harmony order, in which x' TMHNUC ý if and only if x is\nmore sonorous than y: *x* > *y*.\nIf A is an entire prosodic parse, HNUC generates a list of all the nuclei in A. For reasons soon\nto be apparent, it will be convenient to think of HNUC as generating a list of nuclei sorted from most\nto least harmonic, according to HNUC — i.e., from most to least sonorous. So, for example,\nHNUC(.txï.1⁄2t.) = (1⁄2, ï).\nWhen HNUC evaluates the relative harmonies of two entire syllabifications A and B, it first\ncompares the most harmonic nucleus of A with the most harmonic nucleus of B: if that of A is more\nsonorous, then A is the winner without further ado. Since the lists of nuclei HNUC(A) and HNUC(B)\nare assumed sorted from most to least harmonic, this process is simply to compare the First Member\nof HNUC(A) with the First Member of HNUC(B): if one is more harmonic than the other, according\nto HNUC, the more harmonic nucleus wins the competition for its entire parse. If, on the other hand,\nthe two First Members of HNUC(A) and HNUC(B) are equally harmonic according to HNUC (i.e.,\nequally sonorous), then we eject these two First Members from their respective lists and start over,\ncomparing the Rest of the nuclei in exactly the same fashion.\n\nOptimality Theory\n\nChapter 5\n\n79\n\nThis procedure is exactly the one formalized above in (99). We illustrate the formal definition\nby examining how HNUC determines the relative harmonies of\nA / .tx' .z1⁄2t.\nand\nB / .'t x.z1⁄2t.\nFirst, ÷ / HNUC assigns the following:\n\" / ÷(A) = (1⁄2, x' )\n$ / ÷(B) = (1⁄2, 't )\nTo rank the parses A and B, i.e., to determine whether\nA TM÷parse B,\nwe must rank their list of marks according to ÷, i.e., determine whether\n÷(A) / \" TM(*) $ / ÷(B).\nTo do this, we examine the First Marks of each list, and determine whether\nFM(\") TM* FM($).\nAs it happens,\nFM(\") . FM($),\nsince both First Marks are 1⁄2, so we must discard the First Marks and examine the Rest, to determine\nwhether\n\"N / Rest(\") TM(*) Rest($) / $N.\nHere,\n\"N = ( x' ); $N = ( 't ).\nSo again we consider First Marks, to determine whether\nFM(\"N) TM* FM($N).\nIndeed this is the case:\nFM(\"N) = x' TM* 't = FM($N)\nsince *x* > *t*. Thus we finally conclude that\n.tx' .z1⁄2t. TMHNUCparse .'t x.z1⁄2t.\nHNUC assesses nuclei x' from most to least harmonic, and that is how they are ordered in the\nlists HNUC generates for Harmony evaluation. HNUC is an unusual constraint in this regard; the other\nnon-binary constraints we consider in this book will compare their worst marks first; the mark lists\nthey generate are ordered from least- to most-harmonic. Both kinds of constraints are treated by the\nsame definition (99). The issue of whether mark lists should be generated worst- or best-first will\noften not arise, for one of two reasons. First, if a constraint ÷ is binary, the question is meaningless\nbecause all the marks it generates are identical: *÷. Alternatively, if a constraint applies only once\nto an entire parse, then it will generate only one mark per candidate, and the issue of ordering\nmultiple marks does not even arise. (Several examples of such constraints, including edgemostness\nof main stress, or edgemostness of an infix, are discussed in §4.) But for constraints like HNUC which\nare non-binary and which apply multiply in a candidate parse, part of the definition of the constraint\nmust be whether it lists worst- or best-marks first.\n\n5.2.2 Comparison of Entire Candidates by an Entire Constraint Hierarchy\nWe have now defined how a single constraint evaluates the relative Harmonies of entire candidate\nparses (99). It remains to show how a collection of such constraints, arranged in a strict domination\nhierarchy [÷1 >> ÷2 >> þ], together perform such an evaluation: that is, how constraints interact.\n\n80\n\nChapter 5\n\nPrince & Smolensky\n\nConsider the part of the Berber constraint hierarchy we have so far developed: [ONS >>\nHNUC]. The entire hierarchy can be regarded as assigning to a complete parse such as .txï.1⁄2t. the\nfollowing list of lists of marks:\n[ONS >> HNUC](.txï.1⁄2t.) = [ ONS(.txï.1⁄2t.), HNUC(.txï.1⁄2t.) ] = [ (*ONS), (1⁄2, ï) ]\n\n(100.a)\n\nThe First Member here is the list of marks assigned by the dominant constraint: (*ONS). Following\nare the lists produced by successive constraints down the domination hierarchy; in this case, there\nis just the one other list assigned by HNUC. As always, the nuclei are ordered from most- to leastharmonic by HNUC.\nWe use square brackets to delimit this list of lists, but this is only to aid the eye, and to\nsuggest the connection with constraint hierarchies, which we also enclose in square brackets. Square\nand round brackets are formally equivalent here, in the sense that they are treated identically by the\nlist-manipulating operations FM and Rest.\nThe general definition of the list of lists of marks assigned by a constraint hierarchy is simply:\n(101) Marks Assigned by an Entire Constraint Hierarchy\nThe marks assigned to an entire parse A by a constraint hierarchy [\nfollowing list of lists of marks:\n[ >>\n>> þ](A) / [ (A), (A), þ ]\n\n>>\n\n>> þ] is the\n\nConsider a second example, .tx' .z1⁄2t.:\n(100.b)\n\n[ONS >> HNUC](.tx' .z1⁄2t.) = [ ONS(.tx' .z1⁄2t.), HNUC(.tx' .z1⁄2t.) ] = [ ( ), (1⁄2, x' ) ]\n\nSince there are no onsetless syllables in this parse, ONS(.tx' .z1⁄2t.) = ( ), the empty list. A third example\nis:\n(100.c)\n\n[ONS >> HNUC](.'t x.z1⁄2t.) = [ ( ), (1⁄2, 't ) ]\n\nAs always in Berber, the ONS constraint is lifted phrase-initially, so this parse incurs no marks *ONS.\nNow we are ready to harmonically rank these three parses. Corresponding directly to the\nexample tableau (17) of §2, p.20, repeated here:\n(102) Constraint Tableau for three parses of /txznt/\nCandidates\n\nL\n\nONS\n\nHNUC\n\n.tx.z\n' 1⁄2t.\n\n1⁄2 x'\n\n.t3 x.z1⁄2t.\n\n1⁄2 3t !\n\n.txï.1⁄2t.\n\n*!\n\n1⁄2 ï\n\nOptimality Theory\n\n81\n\nChapter 5\n\nwe have, from (100.a!c):\n(103) Marks Assessed by the Constraint Hierarchy on three parses of /txznt/\nA\n\n[ONS >> HNUC] (A)\n\n.tx.z\n' 1⁄2t.\n\n[\n\n()\n\n,\n\n( 1⁄2 x' )\n\n]\n\n.t3 x.z1⁄2t.\n\n[\n\n()\n\n,\n\n( 1⁄2 3t )\n\n]\n\n.txï.1⁄2t.\n\n[\n\n( *ONS )\n\n,\n\n(1⁄2 ï)\n\n]\n\nTo see how to define the Harmony order TM[ONS >> HNUC] that the constraint hierarchy imposes on the\ncandidate parses, let’s first review how Harmony comparisons are performed with the tableau (102).\nWe start by examining the marks in the first, ONS, column. Only the candidates which fare best by\nthese marks survive for further consideration. In this case, one candidate, .txï.1⁄2t., is ruled out\nbecause it has a mark *ONS while the other two do not. That is, this candidate is less harmonic than\nthe other two with respect to the hierarchy [ONS >> HNUC] because it is less harmonic than the other\ntwo with respect to the dominant individual constraint ONS. The remaining two parses .tx' .z1⁄2t. and\n.'t x.z1⁄2t. are equally harmonic with respect to ONS, and so to determine their relative Harmonies with\nrespect to [ONS >> HNUC] we must continue by comparing them with respect to the next constraint\ndown the hierarchy, HNUC. These two parses are compared by the individual constraint HNUC in just\nthe way we have already defined: the most harmonic nuclei are compared first, and since this fails\nto determine a winner, the next-most harmonic nuclei are compared, yielding the final determination\nthat .tx' .z1⁄2t. TM[ONS >> HNUC] .'t x.z1⁄2t.\nFor the case of [ONS >> HNUC], the definition should now be clear:\n(104) Harmonic ordering of forms — entire parses by [ONS >> HNUC].\nA TM[ONS >> HNUC] B iff either\n(i)\nA TMONS B\nor\n(ii)\nA .ONS B and A TMHNUC B\nFor a general constraint hierarchy, we have the following recursive definition:\n(105)\nHarmonic ordering of forms — entire parse, entire constraint hierarchy\nA TM[\n\n>>\n\n>> þ]\n\nB iff either\n(i)\nATM B\n\nor\n(ii)\n\nA . B and A TM[\n\n>> þ]\n\nB\n\n82\n\nChapter 5\n\nPrince & Smolensky\n\nAll the orderings in (104) and (105) are of complete parses, and we have therefore omitted the\nsuperscript parse. The Harmony order presupposed by this definition, TM parse, the order on entire parses\ndetermined by the single constraint , is defined in (99).\nIt is worth showing that the definitions of whole-parse Harmony orderings by a single constraint TM÷\n(99) and by a constraint hierarchy TM[ >> >> þ] (105) are essentially identical. To see this, we need\nonly bring in FM and Rest explicitly, and insert them into (105); the result is the following:\n(106) Harmonic ordering of forms — entire parses, entire constraint hierarchy (opaque\nversion).\n/ [ >>\n>> þ] be a constraint hierarchy and let A,B be two candidate parses. Let\nLet\n!,\" be the two lists of lists of marks assigned to these parses by the hierarchy:\n!/\n(A), \" /\n(B)\nIt follows that:\nRest(!) = [ >> þ](A);\nFM(!) = (A),\nFM(\") = (B),\nRest(\") = [ >> þ](B)\nThe hierarchy\ndetermines a harmonic ordering over lists of lists of marks as follows:\n! TM[(*)] \" iff either\n(i)\nFM(!) TM(*) FM(\") (i.e., (A) TM(*) (B), i.e., A TM B)\nor\n(ii)\nFM(!) .(*) FM(\") (i.e., A . B)\nand\nRest(!) TM[(*)] Rest(\")\nis then defined by:\nThe harmonic ordering over candidate parses determined by\nA TM parse B iff\n(A) / ! TM[(*)] \" /\n(B)\nThis definition of TM parse is identical to the definition of TM÷parse (99) except for the inevitable\nsubstitutions: the single constraint ÷ of (99) has been replaced with a constraint hierarchy\nin\n(106), and, accordingly, one additional level has been added to the collections of marks.\nThe conclusion, then, is that whole-parse Harmony ordering by constraint hierarchies is\ndefined just like whole-parse Harmony ordering by individual constraints. To compare parses, we\ncompare the marks assigned them by the constraint hierarchy. This we do by first examining the First\nMarks — those assigned by the dominant constraint. If this fails to decide the matter, we discard the\nFirst Marks, take the Rest of the marks (those assigned by the remaining constraints in the hierarchy)\nand start over with them.\nThus, there is really only one definition for harmonic ordering in Optimality Theory; we can\ntake it to be (99). The case of binary marks (§5.2.1.1) is a simple special case, where ‘less marked’\nreduces to ‘fewer (identical) marks’; the case of constraint hierarchies (106) is a mechanical\ngeneralization gotten by making obvious substitutions.\n\nOptimality Theory\n\nChapter 5\n\n83\n\n5.2.3 Discussion\n5.2.3.1 Non-locality of interaction\nAs mentioned at the end of §2, the way that constraints interact to determine the Harmony ordering\nof an entire parse is somewhat counter-intuitive. In the Berber hierarchy [ONS >> HNUC], for\nexample, perhaps the most obvious way of ordering two parses is to compare the parses syllable-bysyllable, assessing each syllable independently first on whether it meets ONS, and then on how well\nit fares with HNUC. As it happens, this can be made to work for the special case of [ONS >> HNUC]\nif we evaluate syllables in the correct order: from most- to least-harmonic. This procedure can be\nshown to more-or-less determine the same optimal parses as the different harmonic ordering\nprocedure we have defined above, but only because some very special conditions obtain: first, there\nare only two constraints, and second, the dominant one is never violated in optimal parses.47 Failing\n\n47\n\nThe argument goes as follows. Suppose A is the optimal parse of an input I according to harmonic\nordering, so that A TM B for any other parse B of I. We need to show that A beats B in the following syllableby-syllable comparison: compare the most harmonic syllable in A with the most harmonic syllable in B; if\none is more harmonic than the other, its parse wins; if they are equally harmonic, discard these two best\nsyllables and recursively evaluate the remaining ones. To determine which of two syllables is the more\nharmonic, evaluate them by [ONS >> HNUC]; that is, compare them against each other on ONS and if that fails\nto pick a winner, compare them on HNUC.\nHere’s the argument. Every input has parses which do not violate the dominant constraint ONS, so\nparses judged optimal by harmonic ordering never violate ONS. Since A is optimal, none of its syllables\nviolates ONS. Thus, in comparing any syllable FA of A with a syllable FB of B, A will win if FB violates ONS.\nSo the only competitors B which could possibly beat A are those with no onsetless syllables. But in that case,\nONS is irrelevant to the comparison of A and B: the syllable-by-syllable comparison will compare syllables\nfrom most- to least-harmonic based solely on HNUC. But this is exactly how the comparison goes according\nto harmonic ordering when both candidates have no violations of ONS. So the two methods must give the\nsame result.\nIn short: ONS in either case serves to knock out all parses which violate it at all, and of the remaining\nparses the same one is picked out as optimal by the two methods because they both degenerate to the single\nremaining constraint HNUC.\nThis argument is correct regarding the core of the matter, but fails on a subtle issue: comparisons\nof parses with different numbers of syllables. In this case it can happen that the comparison has not yet been\nsettled when one parse runs out of syllables and the other still has some remaining (which may or may not\nviolate ONS). A definite procedure is required to handle the comparison of the null syllable i and a non-null\nsyllable F. And indeed here syllable-by-syllable comparison (but not harmonic ordering) fails: neither i TM\nF nor F TM i will work. To minimize distractions, consider the two hypothetical Berber inputs /tat/ and /tnmn/.\nThe Dell-Elmedlaoui algorithm (and harmonic ordering) determine the corresponding outputs to be .tát. and\n.t1⁄2.m1⁄2. Now in order that .tát. beat .tá.'t . in the syllable-by-syllable comparison, we must assume i TM F,\nbecause after the two best syllables (.tát. and .tá.) tie, the correct parse has no more syllables while the\nincorrect parse has the remaining (miserable) syllable .'t . On the other hand, in order that the correct parse\n.t1⁄2.m1⁄2. beat .tnmn.,\n' we must assume F TM i; for now, after the two best syllables (say .t1⁄2. [which . .m1⁄2.], and\n.tnmn.)\n' tie, the competitor has no more syllables while the correct parse still has one left (.m1⁄2.).\n(continued...)\n\n84\n\nChapter 5\n\nPrince & Smolensky\n\nsuch special conditions, however, harmonic ordering as defined above and as used in the remainder\nof this book gives results which, as far as we know, cannot be duplicated or even approximated using\nthe more obvious scheme of syllable-by-syllable evaluation. Indeed, when we extend our analysis\nof Berber even one step beyond the simple pair of constraints ONS and HNUC (see §8), harmonic\nordering clearly becomes required to get the correct results.48\n\n47\n\n(...continued)\nThe intuition evoked here is that really i is better than a syllable which violates ONS but worse than\none which satisfies ONS. What this intuition really amounts to, we claim, is that ONS-violating syllables\nshould lose the competition for their parses, and that this should have priority over trying to maximize\nnuclear Harmony — exactly as formalized in harmonic ordering. It is precisely because the ONS-violating\nsyllable .'t . in .tá.'t . is so bad that it ends up being considered too late to clearly lose against a proper syllable\nin the correct parse. That is, postponing consideration of ONS-violating syllables until after considering better\nONS-satisfying ones is exactly backwards — yet this is what the syllable-by-syllable method requires. Our\ndiagnosis is that correctly handling ONS requires considering first those syllables that violate it — the worst\nsyllables, according to ONS; whereas correctly handling HNUC requires considering first the syllables it rates\nthe best. This is just what harmonic ordering does, by virtue of having separate passes over the parse for ONS\nand later for HNUC. Syllable-by-syllable evaluation is fundamentally incorrect in forcing one pass through\nthe parse, evaluating each syllable according to both constraints and then discarding it. It is fortuitous that\nin the case of [ONS >> HNUC], in the majority of cases, best-first syllable comparison gives the correct\nanswer: as long as a competitor has the same number of syllables as the optimal parse, an ONS violation will\neventually get caught — even though such violations should really be handled first rather than last. Such\npostponement is revealed for the mistake it really is when parses with different numbers of syllables are\nexamined.\nOur more complete analysis of Berber will include, among others, a universal constraint !COD which\nstates that syllables must not have codas (this constraint is introduced in §4.1). This constraint is lowerranked in the Berber hierarchy than HNUC, so a slightly more complete Berber hierarchy is [ONS >> HNUC\n>> !COD]. Now consider the input /ratlult/; the Dell-Elmedlaoui algorithm (and harmonic ordering) parses\nthis as .rát.lú.l't . (the final stop desyllabifies in a subsequent process which as promised we ignore here). Note\nthat the most harmonic syllable in this correct parse, .rát., has a coda, violating !COD. Note further that there\nis a competing parse without the coda (which also respects ONS): .rá.t3.u3t. Since HNUC >> !COD, the most\nharmonic syllable in this competing parse is also the one with the most sonorous nucleus, .rá. Now if we\ncompare the most harmonic syllables of these two parses, we see that the correct parse loses because of its\nviolation of !COD. (In case it is unclear whether comparing least harmonic syllables first might work, note\nthat this also gives the wrong result here, since of the two parses being compared here, the correct parse\ncontains the worst syllable: .l't .)\nAgain, harmonic ordering gets the correct result in comparing these two parses. First, ONS is checked\nthroughout the parses; both respect it so the next constraint is considered. HNUC now declares the correct\nparse the winner, since its nuclei are more harmonic than those of its competitor: (á, ú, 't ) TM (á, 3, 3). The\ncompetition is correctly resolved without ever consulting the lowest constraint !COD, which in this case can\nonly lead the evaluation astray.\nThis example illustrates a kind of non-local constraint interaction captured by harmonic ordering but\nmissed in the syllable-by-syllable approach. In order for the second syllable of the correct parse .rát.lú.l't . to\noptimize its nucleus (ú), the first syllable pays with a coda. (The parse .rá.tlú.l't . is blocked by a high-ranking\n(continued...)\n48\n\nOptimality Theory\n\nChapter 5\n\n85\n\nIt is important to note also that harmonic ordering completely finesses a nasty conceptual\nproblem which faces a syllable-by-syllable approach as soon as we expand our horizons even\nslightly. For in general we need to rank complex parses which contain much more structure than\nmere syllables. The ‘syllable-by-syllable’ approach is conceptually really a ‘constituent-byconstituent’ approach, and in the general case there are many kinds and levels of constituents in the\nparse. Harmonic ordering completely avoids the need to decide in the general case how to correctly\nbreak structures into parts for Harmony evaluation so that, in part-by-part evaluation, all the relevant\nconstraints have the proper domains for their evaluation. In harmonic ordering, each constraint ÷\nindependently generates its own list of marks ÷(A) for evaluating a parse A, considering whatever\ndomains within A are appropriate to that constraint. In comparing A with parse B, the marks ÷(A)\nare compared with the marks ÷(B); implicitly, this amounts to comparing A and B with respect to\nthe domain structure peculiar to ÷. This comparison is decoupled from that based on other\nconstraints which may have quite different domain structure.\nThe interaction of constraints in a constituent-by-constituent approach is in a sense limited\nto interactions within a constituent: for ultimately the comparison of competing parses rests on the\nassessment of the Harmony of individual constituents as evaluated by the set of constraints.\nOptimality Theory is not limited to constraint interactions which are local in this sense, as a number\nof the subsequent analyses will illustrate (see also fn. 48).\n\n5.2.3.2 Strictness of domination\nOur expository example [ONS >> HNUC] in Berber may fail to convey just how strong a theory of\nconstraint interaction is embodied in harmonic ordering. In determining the correct — optimal —\nparse of an input, as the constraint hierarchy is descended, each constraint acts to disqualify\nremaining competitors with absolute independence from all other constraints. A parse found wanting\non one constraint has absolutely no hope of redeeming itself by faring well on any or even all lowerranking constraints. It is remarkable that such an extremely severe theory of constraint interaction\nhas the descriptive power it turns out to possess.\nSuch strict domination of constraints is less striking in the Berber example we have\nconsidered than it will be in most subsequent examples. This is because the dominant constraint is\nnever violated in the forms of the language; it is hardly surprising then that it has strict veto power\nover the lower constraint. In the general case, however, most of the constraints in the hierarchy will\nnot be unviolated like ONS is in Berber. Nonetheless, all constraints in Optimality Theory, whether\nviolated or not in the forms of the language, have the same strict veto power over lower constraints\nthat ONS has in Berber.\n\n48\n\n(...continued)\nconstraint which limits onsets to one segment, except phrase-initially; this is part of our fuller account of\nBerber in §8.) Raising the Harmony of the second syllable w.r.t HNUC at the cost of lowering the Harmony\nof the first w.r.t. !COD is in this case optimal because HNUC >> !COD. However, HNUC and !COD interact\nhere across syllables; and, in fact, the best syllable must pay to improve the less-good syllable. The syllableby-syllable theory cannot correctly handle this non-local interaction, as we have seen; it wrongly rules against\nthe correct parse because its best syllable has sacrificed Harmony (on a low-ranked constraint), never getting\nto the next-best syllable to see that it has improved Harmony (on a higher-ranked constraint).\n\n86\n\nChapter 5\n\nPrince & Smolensky\n\n5.2.3.3 Serial vs. Parallel Harmony Evaluation and Gen\nUniversal grammar must also provide a function Gen that admits the candidates to be evaluated. In\nthe discussion in §2 we have entertained two different conceptions of Gen. The first, closer to\nstandard generative theory, is based on serial or derivational processing; some general procedure\n(Do-\") is allowed to make a certain single modification to the input, producing the candidate set of\nall possible outcomes of such modification. This is then evaluated; and the process continues with\nthe output so determined. In this serial version of grammar, the theory of rules is narrowly\ncircumscribed, but it is inaccurate to think of it as trivial. There are constraints inherent in the\nlimitation to a single operation; and in the requirement that each individual operation in the sequence\nimprove Harmony. (An example that springs to mind is the Move-x theory of rhythmic adjustments\nin Prince 1983; it is argued for precisely on the basis of entailments that follow from these two\nconditions, pp. 31-43.)\nIn the second, parallel-processing conception of Gen, all possible ultimate outputs are\ncontemplated at once. Here the theory of operations is indeed rendered trivial; all that matters is what\nstructures are admitted. Much of the analysis given in this book will be in the parallel mode, and\nsome of the results will absolutely require it. But it is important to keep in mind that the\nserial/parallel distinction pertains to Gen and not to the issue of harmonic evaluation per se. It is an\nempirical question of no little interest how Gen is to be construed, and one to which the answer will\nbecome clear only as the characteristics of harmonic evaluation emerge in the context of detailed,\nfull-scale, depth-plumbing, scholarly, and responsible analyses.49\n49\n\nA faithful reconstruction of the sequential parsing process of the Dell-Elmedlaoui algorithm seems to\nbe possible within the harmonic serial approach. Here is a quick sketch; the analysis has not been well\ndeveloped. Many ideas are imported which will later be developed in the text in the context of the parallel\napproach. It seems highly unlikely that the sequential approach presented here for Berber can be extended\nto a sequential account of syllabification more generally.\nThe process starts with an input. Gen then generates a set of alternatives which are ‘one change\naway’ from the input. We let Gen perform any one of the following ‘changes’:\n(a) build a new syllable from free segments;\n(b) adjoin a free element to an existing syllable;\n(c) mark a segment x as surface-free: +x,.\nA surface-free segment is not phonetically realized in the surface form, as though deleted by Stray Erasure.\nOnce a segment has been marked as surface-free it no longer counts as ‘free’; it is no longer available to Gen\nfor operations (a!c). Berber never chooses to exercise the surface-free option, but we will derive this as a\nresult rather than assuming it. The syllables constructed in (a) may include empty syllable positions which\ndenote epenthetic elements; again, an option we show Berber not to exercise.\nNow initially all segments in the input are free. Gen produces a set of candidates each of which is\ngenerated from the input by applying one of the ‘changes’ (a!c). The most harmonic of these is chosen as\nthe next representation in the derivation. At each step at least one segment which was free becomes no longer\nfree. The process is repeated until no free elements remain; this is the output.\nAt each step of the derivation, the candidates generated by Gen each contain one ‘changed’ element;\nfor (a), it is a newly constructed syllable; for (b), a syllable with a segment newly adjoined; for (c), a segment\nmarked surface-free. To compare the Harmonies of two such candidates, we simply compare the one changed\n(continued...)\n\nOptimality Theory\n\n49\n\nChapter 5\n\n87\n\n(...continued)\nelement of each candidate; the remaining parts of the two candidates are identical. If both candidates are\ngenerated by either (a) or (b), then we are comparing two syllables. This we can do using a constraint\nhierarchy, as previously explained in the text. The hierarchy we assume for Berber is as follows:\nNUC >> *COMPLEX >> PARSE >> FILL >> ONS >> !COD >> HNUC\nThis is virtually identical to the hierarchy of the parallel analysis we develop in §8.1.1 (ignoring exceptional\nepenthesis), except that !COD is higher-ranked in this sequential analysis, for reasons to be discussed. The\nconstraints are more fully developed in the text; here is a quick summary. NUC requires nuclei; *COMPLEX\nforbids more than one segment in onset, nucleus, or coda; PARSE forbids surface-free segments; FILL forbids\nempty (epenthetic) syllable positions; !COD forbids codas.\nAt each step Gen generates via (a) candidates each with a new syllable. When these are compared\nusing the constraint hierarchy, the most harmonic such new syllables will always have a single segment onset\nand a single segment nucleus, with no epenthetic positions and no coda. That is, they will always be core\nsyllables. Gen generates all sorts of new syllables, but the most harmonic will always be those built as xy\nÿ {xY}, for only these satisfy all of the top six constraints. Of these, the most harmonic will be determined\nby the seventh constraint, HNUC. As long as there is a free pair of adjacent segments xy, a candidate\ngenerated from xy ÿ {xY} via (a) will be more harmonic than all candidates generated via adjunction (b)\nor surface-free marking (c); for adjunction to a core syllable already built (b) will violate *COMPLEX unless\nthe adjunction is to coda position, in which case it will violate !COD; and a surface-free marking (c) violates\nPARSE. No such violations occur with {xY}. Thus, as long as free pairs xy exist, the most harmonic candidate\ngenerated by Gen will always be the one which performs xy ÿ {xY} where Y is the most sonorous available\nsuch segment. This is of course exactly the principal step of the Dell-Elmedlaoui algorithm.\nThe final part of the Dell-Elmedlaoui algorithm takes place when there are no longer any free pairs\nxy. Then free singleton segments are adjoined as codas to the preceding already-built core syllable. This too\nis reconstructed by harmonic sequential parsing. For when there are no longer free pairs xy, any new\nsyllables generated via (a) by Gen are no longer the most harmonic changes. Such a new syllable must be\nerected over a single underlying segment x (or be totally epenthetic), and this syllable must therefore violate\nat least one of the constraints NUC, FILL, or ONS. These constraints are all higher ranked than !COD, which\nis the only constraint violated by the changed element in candidates generated via (b) by adjoining x as the\ncoda of an existing core syllable. The other candidates are generated via (c) by marking x as surface-free;\nthe changed element in such candidates, +x,, violates PARSE, which dominates !COD, so surface-free\ncandidates (c) are less harmonic than coda-adjoined ones (b). At each step in this last phase of parsing, then,\none free singleton segment will be coda-adjoined, until finally there are no free segments left and parsing\nis complete.\nFor this sequential approach to work, it is crucial that !COD >> HNUC — although in the parallel\napproach developed in the text, it is equally crucial that HNUC >> !COD. The sequential parsing algorithm\nmust build all possible core syllables before creating any codas; the location of codas in the correct parse can\nonly be determined after the nuclei have been taken in descending sonority order. !COD >> HNUC ensures\nthat a newly-closed syllable will be sub-optimal as long as new core syllables exist in the candidate set. To\nsee what would happen if HNUC >> !COD, consider the example input /ratlult/, considered in (6), p.14, §2.1.\nThe most harmonic first step is {ra}tlult. Now the next step should be to {ra}t{lu}lt, with changed element\n{lu}. But consider the adjunction (b) candidate {rat}lult, with changed element {rat}. On HNUC, {rat} bests\n{lu}, while on !COD, {lu} is preferred. Thus the right choice will only be made if !COD >> HNUC.\nTo most clearly see why the parallel approach requires HNUC >> !COD, consider the hypothetical\ninput /tat/, which the Dell-Elmedlaoui algorithm parses as {tat}, a closed syllable. An alternative complete\n(continued...)\n\n88\n\nChapter 5\n\nPrince & Smolensky\n\nMany different theories of the structure of phonological outputs can be equally well accommodated\nin Gen, and the framework of Optimality Theory per se involves no commitment to any set of such\nassumptions. Of course, different structural assumptions can suggest or force different formal\napproaches to the way that Optimality theoretic constraints work. In this work, to implement\nfaithfulness straightforwardly, we entertain a non-obvious assumption about Gen which will be\nuseful in implementing the parallel conception of the theory: we will assume, following the lead of\nMcCarthy 1979 and Itô 1986, 1989, that every output for an input In – every member of Gen(In) –\nincludes In as an identifiable substructure. In the theory of syllable structure developed in Part II,\nGen(/txznt/) will be a set of possible syllabifications of /txznt/ all of which contain the input string\n/txznt/, with each underlying segment either associated to syllable structure or left unassociated. We\nwill interpret unassociated underlying segments as phonetically unrealized (cf. ‘Stray Erasure’); thus\non this conception, input segments are never ‘deleted’ in the sense of disappearing from the\nstructural description; rather, they may simply be left free — unparsed. Our discussion of Berber in\nthis section has focused on a fairly restricted subset of the full candidate set we will subsequently\nconsider; we have considered only syllabifications in which underlying segments are in one-to-one\ncorrespondence with syllable positions. In following chapters, we turn to languages which, unlike\nBerber, exhibit syllabifications manifesting deletion and/or epenthesis.\n\n5.2.3.4 Binary vs. Non-binary constraints\nAs might be suspected, it will turn out that the work done by a single non-binary constraint like\nHNUC can also be done by a set (indeed a sub-hierarchy) of binary constraints. This will prove\nfundamental for the construction of the Basic Segmental Syllable Theory in §8, and we postpone\ntreatment of the issue until then. For now it suffices simply to remark that the division of constraints\ninto those which are binary and those which are not, a division which we have adopted earlier in this\nsection, is not in fact as theoretically fundamental as it may at this point appear.\n\n5.3 P~Ãini’s Theorem on Constraint Ranking\nOne consequence of the definition of harmonic ordering is that there are conditions under which the\npresence of a more general constraint in a superordinate position in a hierarchy will eliminate all\nopportunities for a more specialized constraint in a subordinate position to have any effects in the\ngrammar. The theorem states, roughly, that if one constraint is more general than another in the sense\nthat the set of inputs to which one constraint applies nonvacuously includes the other’s nonvacuous\ninput set, and if the two constraints conflict on inputs to which the more specific applies nonvacuously, then the more specific constraint must dominate the more general one in order for its\neffects to be visible in the grammar. (This is an oversimplified first cut at the true result; such claims\n49\n\n(...continued)\nparse with only open syllables is {T}{aT}. In the parallel approach, we first scan the complete parse for\nviolations of the top-ranked constraint; if this were !COD, then the correct parse would lose immediately,\nand its redeeming qualities with respect to lower-ranked HNUC would be irrelevant.\n\nOptimality Theory\n\nChapter 5\n\n89\n\nmust be stated carefully.) Intuitively, the idea is that if the more specific constraint were lowerranked, then for any input to which it applies non-vacuously, its effects would be over-ruled by the\nhigher-ranked constraint with which it conflicts. The utility of the result is that it allows the analyst\nto spot certain easy ranking arguments.\nWe call this P~Ãini’s Theorem on Constraint-ranking, in honor of the first known investigator\nin the area; in §7.2.1, we discuss some relations to the Elsewhere Condition of Anderson 1969 and\nKiparsky 1973b. In this section we introduce some concepts necessary to develop a result; the proof\nis relegated to the Appendix. The result we state is undoubtedly but one of a family of related\ntheorems which cover cases in which one constraint hides another.\nDue to the complexities surrounding this issue, we will formally state and prove the result only in\nthe case of constraints which are Boolean at the whole-parse level: constraints which assign a single\nmark to an entire parse when they are violated, and no mark when they are satisfied.\n(107) Dfn. Separation. A constraint ÷ separates a set of structures if it is satisfied by some\nmembers of the set and violated by others.\n(108) Dfn. Non-vacuous application. A constraint ÷ applies non-vacuously to an input i if it\nseparates Gen(i), the set of candidate parses of i admitted by Universal Grammar.\nA constraint may sometimes apply vacuously to an input, in that every possible parse of i satisfies\nthe constraint. For example, in §7 we will introduce a constraint FREE-V which requires that stemfinal vowels not be parsed into syllable structure. Clearly, this constraint is vacuously satisfied for\na stem which is not vowel-final; all the parses of such an input meet the constraint since none of\nthem have a stem-final vowel which is parsed!\n(109) Dfn. Accepts. A constraint hierarchy\nparse of i.\n\naccepts a parse P of an input i if P is an optimal\n\nis the entire constraint hierarchy of a grammar, it is normally the case that only one parse\nWhen\nP of an input i is optimal: the constraint set is sufficient to winnow the candidate set down to a single\noutput. In this section we will need to consider, more generally, initial portions of the constraint\nhierarchy of a grammar, i.e., all the constraints from the highest-ranked down to some constraint\nwhich may not be the lowest-ranked. In these cases,\nwill often consist of just a few constraints,\ninsufficient to winnow the candidate set down to a single parse; in that case,\nwill accept an entire\n.\nset of parses, all equally harmonic, and all more harmonic than the competitors filtered out by\n(110) Dfn. Active. Let ÷ be a constraint in a constraint hierarchy\nand let i be an input. ÷ is\nif ÷ separates the candidates in Gen(i) which are admitted by the portion\nactive on i in\nof\nwhich dominates ÷.\nwhich dominates ÷ filters the set of candidate parses of i to some\nIn other words, the portion of\ndegree, and then ÷ filters it further. When ÷ is not active for an input i in\n, the result of parsing\ni is not at all affected by the presence of ÷ in the hierarchy.\n\n90\n\nChapter 5\n\nPrince & Smolensky\n\n(111) Dfn. P~Ãinian Constraint Relation. Let and be two constraints. stands to as special\nto general in a P~Ãinian relation if, for any input i to which applies non-vacuously, any\nparse of i which satisfies fails .\nFor example, the constraint FREE-V stands to PARSE as special to general in a P~Ãinian relation: for\nany input to which FREE-V applies non-vacuously (that is, to any input with a stem-final vowel V),\nany parse which satisfies FREE-V (that is, which leaves V unparsed) must violate PARSE (in virtue\nof leaving V unparsed). For inputs to which the more specialized constraint FREE-V does not apply\nnon-vacuously (C-final stems), the more general constraint PARSE need not conflict with the more\nspecific one (for C-final stems, FREE-V is vacuously satisfied, but PARSE is violated in some parses\nand satisfied in others).\nNow we are finally set to state the theorem:\n(112) P~Ãini’s Theorem on Constraint-ranking. Let and stand as specific to general in a\n,\nP~Ãinian constraint relation. Suppose these constraints are part of a constraint hierarchy\nand that is active in\non some input i. Then if >> , is not active on i.\nIn §7, we will use this theorem to conclude that in the grammar of Lardil, the more specific\nconstraint FREE-V must dominate the more general constraint PARSE with which it conflicts.\n\nPART II\nSyllable Theory\n\n92\n\nPrince & Smolensky\n\nOverview of Part II\nThe typology of syllable structure systems has been the object of a successful research effort over\nthe last century and is fairly well understood empirically.50 Basic theoretical questions remain open\nor undecided, of course, depite (or because of) the body of modern work in the area. Here we aim\nto show that the fundamental typological generalizations receive principled explication through the\nnotion of Factorial Typology. The idea is that Universal Grammar provides a set of violable\nconstraints on syllable structure, and individual grammars fix the relative ranking of these\nconstraints. The typology of possible languages is then given by the set of all possible rankings.\nBecause of the considerable complexity that inheres in this domain, it is appropriate to\napproach it via the strategies of Galilean science, sometimes referred to as Rational Inquiry in the\nlinguistic literature. Our discussion will therefore proceed through three degrees of decreasing\nidealization. First, in §6, we examine a kind of C/V theory: the key simplifying assumption being\nthat the terminal nodes (segments) are pre-sorted binarily as to their suitability for peak (V) and\nmargin (C) positions (cf. McCarthy 1979, Clements & Keyser 1983). Further, we consider only\nsyllables with at most one symbol C or V in any syllabic position. Under this restrictions, the basic\nstructural constraints are introduced and the ranking-induced typology is explored. Then, still within\nCV theory, we examine the finer grain of interactions between the structural constraints and various\nmethods of enforcing them upon recalcitrant inputs.\nNext, in §7, we show how the theory allows a rich set of alternations in Lardil to be\nexplicated strictly in terms of the interactions of constraints on prosodic structure. In §8, we extend\nthe CV theory, taking up the more ambitious task of constructing syllables from segments classified\ninto a multi-degree sonority scale. We show how simple assumptions in Universal Grammar explain\na universal typology of inventories of onset, nucleus, and coda segments. A licensing asymmetry\nbetween onsets and codas is derived from the structural asymmetry in the basic theory: wellstructured syllables possess onsets but lack codas. In the course of extracting these typological\nconsequences, a number of general analytical techniques are developed.\n\n50\n\nWe do not pretend to cite this veritably oceanic body of work. The interested reader should refer to such\nworks as Bell & Hooper 1978 and, say, the references in the references of Goldsmith 1990.\n\nOptimality Theory\n\nChapter 6\n\n93\n\n6. Syllable Structure Typology I: the CV Theory\n\n6.1 The Jakobson Typology\nIt is well-known that every language admits consonant-initial syllables .CV~., and that some\nlanguages allow no others; that every language admits open syllables .~V. and that some admit only\nthose. Jakobson puts it this way:\n“There are languages lacking syllables with initial vowels and/or syllables with final\nconsonants, but there are no languages devoid of syllables with initial consonants or of\nsyllables with final vowels.” (Jakobson 1962:526: Clements & Keyser 1983:29.)\nAs noted in the fundamental work of Clements & Keyser 1983, whence the quotation was cadged,\nthese observations yield exactly four possible inventories. With the notation GXYZ to denote the\nlanguage whose syllables fit the pattern XYZ, the Jakobson typology can be laid out as follows, in\nterms of whether onsets and codas are obligatory, forbidden, or neither:\n(113) CV Syllable Structure Typology\nonsets\nrequired\n\nnot required\n\nforbidden\n\n3CV\n\n3(C)V\n\nallowed\n\n3CV(C)\n\n3(C)V(C)\n\ncodas\n\nThere are two independent dimensions of choice: whether onsets are required (first column) or not\n(second column); whether codas are forbidden (row one) or allowed (row two).\nThe Basic Syllable Structure Constraints, which generate this typology, divide notionally into two\ngroups. First, the structural or ‘markedness’ constraints – those that enforce the universally unmarked\ncharacteristics of the structures involved:\n(114) ONS\nA syllable must have an onset.\n(115) !COD\nA syllable must not have a coda.\n\n94\n\nChapter 6\n\nPrince & Smolensky\n\nSecond, those that constrain the relation between output structure and input:\n(116) PARSE\nUnderlying segments must be parsed into syllable structure.\n(117) FILL\nSyllable positions must be filled with underlying segments.\nPARSE and FILL are Faithfulness constraints: they declare that perfectly well-formed syllable\nstructures are those in which input segments are in one-to-one correspondence with syllable\npositions.51 Given an interpretive phonetic component that omits unparsed material and supplies\nsegmental values for empty nodes, the ultimate force of PARSE is to forbid deletion; of FILL, to forbid\ninsertion.\nIt is relatively straightforward to show that the Factorial Typology on the Basic Syllable Structure\nConstraints produces just the Jakobson Typology. Suppose Faithfulness dominates both structural\nconstraints. Then the primacy of respecting the input will be able to force violations of both ONS and\n!COD. The string /V/ will be parsed as an onsetless syllable, violating ONS; the string /CVC/ will\nbe parsed as a closed syllable, violating !COD: this gives the language G(C)V(C).\nWhen a member of the Faithfulness family is dominated by one or the other or both of the\nstructural constraints, a more aggressive parsing of the input will result. In those rankings where ONS\ndominates a Faithfulness constraint, every syllable must absolutely have an onset. Input /V/ cannot\nbe given its faithful parse as an onsetless syllable; it can either remain completely unsyllabified,\nviolating PARSE, or it can be parsed as .GV., where ‘G’ refers to an empty structural position,\nviolating FILL.\nThose rankings in which !COD dominates a Faithfulness constraint correspond to languages\nin which codas are forbidden. The imperative to avoid codas must be honored, even at the cost of\nexpanding upon the input (*FILL) or leaving part of it outside of prosodic structure (*PARSE).\nIn the next section, we will explore these observations in detail. The resulting Factorial\nconstrual of the Jakobson Typology looks like this (with ‘ö’ denoting the Faithfulness set and ‘Fi’\na member of it):\n\n51\n\nBoth FILL and PARSE are representative of families of constraints that govern the proper treatment of\nchild nodes and mother nodes, given the representational assumptions made here. As the basic syllable theory\ndevelops, FILL will be articulated into a pair of constraints:\nFILLNuc: Nucleus positions must be filled with underlying segments.\nFILLMar: Margin positions (Ons and Cod) must be filled with underlying segments.\nSince unfilled codas are never optimal under syllable theory alone, shown below in §6.2.3 (141), p.104,\nFILLMar will often be replaced by FILLOns for perspicuity.\n\nOptimality Theory\n\nChapter 6\n\n95\n\n(118) Factorial Jakobson Typology\n\nOnsets\nONS >> Fj\n\nö >> ONS\n\n!COD >> Fi\n\n3CV\n\n3(C)V\n\nö >> !COD\n\n3CV(C)\n\n3(C)V(C)\n\nCodas\n\nAt this point, it is reasonable to ask whether there is any interesting difference between our\nclaim that constraints like ONS and !COD can be violated under domination and the more familiar\nclaim that constraints can be turned off — simply omitted from consideration. The Factorial\nJakobson Typology, as simple as it is, contains a clear case that highlights the distinction. Consider\nthe language 3(C)V(C). Since onsets are not required and codas are not forbidden, the Boolean\ntemptation would be to hold that both ONS and !COD are merely absent. Even in such a language,\nhowever, one can find certain circumstances in which the force of the supposedly nonexistent\nstructural constraints is felt. The string CVCV, for example, would always be parsed .CV.CV. and\nnever .CVC.V. Yet both parses consist of licit syllables; both are entirely faithful to the input. The\ndifference is that .CV.CV. satisfies ONS and !COD while .CVC.V. violates both of them. We are\nforced to conclude that (at least) one of them is still active in the language, even though roundly\nviolated in many circumstances. This is the basic prediction of ranking theory: when all else is equal,\na subordinate constraint can emerge decisively. In the end, summary global statements about\ninventory, like Jakobson’s, emerge through the cumulative effects of the actual parsing of individual\nitems.\n\n6.2 The Faithfulness Interactions\nFaithfulness involves more than one type of constraint. Ranking members of the Faithfulness family\nwith respect to each other and with respect to the structural markedness constraints ONS and !COD\nyields a typology of the ways that languages can enforce (and fail to enforce) those constraints. We\nwill consider only the Faithfulness constraints PARSE and FILL (the latter to be distinguished by\nsensitivity to Nucleus or Ons); these are the bare minimum required to obtain a contentful, usable\ntheory, and we will accordingly abstract away from distinctions that they do not make, such as\nbetween deleting the first or second element of a cluster, or between forms involving metathesis,\nvocalization of consonants, de-vocalization of vowels, and so on, all of which involve further\nFaithfulness constraints, whose interactions with each other and with the markedness constraints will\nbe entirely parallel to those discussed here.\n\n6.2.1 Groundwork\nTo make clear the content of the Basic Syllable Structure Constraints ONS, !COD, PARSE, and FILL,\nit is useful to lay out the Galilean arena in which they play. The inputs we will be considering are\n\n96\n\nChapter 6\n\nPrince & Smolensky\n\nCV sequences like CVVCC; that is, any and all strings of the language {C,V}*. The grammar must\nbe able to contend with any input from this set: we do not assume an additional component of\nlanguage-particular input-defining conditions; the universal constraints and their ranking must do\nall the work (see §9.3 for further discussion).The possible structures which may be assigned to an\ninput are all those which parse it into syllables; more precisely, into zero or more syllables. There\nis no insertion or deletion of segments C, V.\nWhat is a syllable? To avoid irrelevant distractions, we adopt the simple analysis that the\nsyllable node F must have a daughter Nuc and may have as leftmost and rightmost daughters\nrespectively the nodes Ons and Cod.52 The nodes Ons, Nuc, and Cod, in turn, may each dominate\nC’s and V’s, or they may be empty. Each Ons, Nuc, or Cod node may dominate at most one terminal\nelement C or V.\nThese assumptions delimit the set of candidate analyses. Here we list and name some of the\nmore salient of the mentioned constraints. By our simplifying assumptions, they will stand at the top\nof the hierarchy and will be therefore unviolated in every system under discussion:\n\nSyllable form:\n(119) NUC\nSyllables must have nuclei.\n(120) *COMPLEX\nNo more than one C or V may associate to any syllable position node.53\nDefinition of C and V, using M(argin) for Ons and Cod and P(eak) for Nuc:\n(121) *M/V\nV may not associate to Margin nodes (Ons and Cod).\n(122) *P/C\nC may not associate to Peak (Nuc) nodes.\nThe theory we examine is this:\n(123) Basic CV Syllable Theory\nCSyllable structure is governed by the Basic Syllable Structure constraints\nONS, !COD, NUC; *COMPLEX, *M/V, *P/C; PARSE, and FILL.\n\n52\n\nFor versions of the structural constraints within the perhaps more plausible moraic theory of syllable\nstructure see Kirchner 1992bc, Hung 1992, Samek-Lodovici 1992, 1993, Zoll 1992, 1993, McCarthy &\nPrince 1993.\n53\n\nOn complex margins, see Bell 1971, a valuable typological study. Clements 1990 develops a promising\nquantitative theory of cross-linguistic margin-cluster generalizations in what can be seen as harmonic terms.\nThe constraint *COMPLEX is intended as no more than a cover term for the interacting factors that determine\nthe structure of syllable margins. For a demonstration of how a conceptually similar complex vs. simple\ndistinction derives from constraint interaction, see §9.1-2 below.\n\nOptimality Theory\n\nChapter 6\n\n97\n\nCOf these, ONS, !COD, PARSE, and FILL may be relatively ranked in any domination order\nin a particular language, while the others are fixed in superordinate position.\nCThe Basic Syllable Structure Constraints, ranked in a language-particular hierarchy, will\nassign to each input its optimal structure, which is the output of the phonology.\nThe output of the phonology is subject to phonetic interpretation, about which we will here make two\nassumptions, following familiar proposals in the literature:\n(124) Underparsing Phonetically Realized as Deletion\nAn input segment unassociated to a syllable position (‘underparsing’) is not phonetically\nrealized.\nThis amounts to ‘Stray Erasure’ (McCarthy 1979, Steriade 1982, Itô 1986, 1989). Epenthesis is\nhandled in the inverse fashion:\n(125) Overparsing Phonetically Realized as Epenthesis\nA syllable position node unassociated to an input segment (‘overparsing’) is phonetically\nrealized through some process of filling in default featural values.\nThis is the treatment of epenthesis established in such works as Selkirk 1981, LaPointe & Feinstein\n1982, Broselow 1982, Archangeli 1984, Kaye & Lowenstamm 1984, Piggott & Singh 1985, and Itô\n1986, 1989.\nThe terms ‘underparsing’ and ‘overparsing’ are convenient for referring to parses that violate\nFaithfulness. If an input segment is not parsed in a given structure (not associated to any syllable\nposition nodes), we will often describe this as ‘underparsing’ rather than ‘deletion’ to emphasize the\ncharacter of our assumptions. For the same reason, if a structure contains an empty syllable structure\nnode (one not associated to an input segment), we will usually speak of ‘overparsing’ the input rather\nthan ‘epenthesis’.\nSuppose the phonology assigns to the input /CVVCC/ the following bisyllabic structure,\nwhich we write in three equivalent notations:\n(126) Transcription of Syllabic Constituency Relations, from /CVVCC/\n\nF\n\na.\n\nF\n\nOns\n\nNuc\n\nOns Nuc Cod\n\nC\n\nV\n\nV\n\nb.\n\n[F [Ons C] [Nuc V]]\n\nc.\n\n.CV! .~V! C.+C,\n\nC\n\nC\n\n[F [Ons ] [Nuc V] [Cod C]] C\n\n98\n\nChapter 6\n\nPrince & Smolensky\n\nPhonetic interpretation ignores the final C, and supplies featural structure for a consonant to fill the\nonset of the second syllable.\nThe dot notation (126c) is the most concise and readable; we will use it throughout. The\ninterpretation is as follows:\n(127) Notation\na. .X.\nb. +x,\nc. G\nd. x'\n\n‘the string X is a syllable’\n‘the element x has no parent node; is free (unparsed)’\n‘a node Ons, Nuc, or Cod is empty’\n‘the element x is a Nuc’\n\nIn the CV theory, we will drop the redundant nucleus-marking accent on V! . Observe that this is a\n‘notation’ in the most inert and de-ontologized sense of the term: a set of typographical conventions\nused to refer to well-defined formal objects. The objects of linguistic theory — syllables here — are\nnot to be confused with the literal characters that depict them. Linguistic operations and assessments\napply to structure, not to typography.\nWe will say a syllable ‘has an onset’ if, like both syllables in the example (126), it has an Ons\nnode, whether or not that node is associated to an underlying C; similarly with nuclei and codas.\nThe technical content of the Basic Syllable Structure Constraints (114!117) above can now be\nspecified. The constraint ONS (114) requires that a syllable node F have as its leftmost child an Ons\nnode; the presence of the Ons node satisfies ONS whether empty or filled. The constraint !COD (115)\nrequires that syllable nodes have no Cod child; the presence of a Cod node violates !COD whether\nor not that node is filled. Equivalently, any syllable which does not contain an onset in this sense\nearns its structure a mark of violation *ONS; a syllable which does contain a coda earns the mark\n*!COD.\nThe PARSE constraint is met by structures in which all underlying segments are associated\nto syllable positions; each unassociated or free segment earns a mark *PARSE. This is the penalty\nfor deletion. FILL provides the penalty for epenthesis: each unfilled syllable position node earns a\nmark *FILL, penalizing insertion. Together, PARSE and FILL urge that the assigned syllable structure\nbe faithful to the input string, in the sense of a one-to-one correspondence between syllable positions\nand segments. This is Faithfulness in the basic theory.\n\n6.2.2 Basic CV Syllable Theory\nWe now pursue the consequences of our assumptions. One important aspect of the Jakobson\nTypology (113) follows immediately:\n(128) THM. Universally Optimal Syllables\nNo language may prohibit the syllable .CV. Thus, no language prohibits onsets or requires\ncodas.\n\nOptimality Theory\n\nChapter 6\n\n99\n\nTo see this, consider the input /CV/. The obvious analysis .CV. (i.e., [F [Ons C] [Nuc V]]) is universally\noptimal in that it violates none of the universal constraints of the Basic CV Syllable Theory (123).\nNo alternative analysis, therefore, can be more harmonic. At worst, another analysis can be equally\ngood, but inspection of the alternatives quickly rules out this possibility.\nFor example, the analysis .CVG. violates !COD and FILL. The analysis .C~3 .V. violates ONS\nin the second syllable and FILL in the first. And so on, through the infinite set of possible analyses–\n[.+C,V.], [.C~3 .+V,.], [.~3 .C ~3 .~V.], etc. ad inf. No matter what the ranking of constraints is, a form\nthat violates even one of them can never be better than a form, like .CV., with no violations at all.\nBecause every language has /CV/ input, according to our assumption that every language has\nthe same set of possible inputs, it follows that .CV. can never be prohibited under the Basic Theory.\n\n6.2.2.1 Onsets\nOur major goal is to explicate the interaction of the structural constraints ONS and !COD with\nFaithfulness. We begin with onsets, studying the interaction of ONS with PARSE and FILL, ignoring\n!COD for the moment. The simplest interesting input is /V/. All analyses will contain violations;\nthere are three possible one-mark analyses:\n(129)\n\n/V/ ÿ\na.\nb.\nc.\n\n.V.\n+V,\n.~V.\n\ni.e., [F [Nuc V]]\ni.e., no syllable structure\ni.e., [F [Ons ] [Nuc V]]\n\nEach of these alternatives violates exactly one of the Basic Syllable Structure Constraints (114!117).\n(130) Best Analyses of /V/\nAnalysis\n\nInterpretation\n\nViolation\n\nRemarks\n\n.V.\n\nF lacks Ons\n\n*ONS\n\nsatisfies FILL, PARSE\n\n+V,\n\nnull parse\n\n*PARSE\n\nsatisfies ONS, FILL\n\n.GV.\n\nOns is empty\n\n*FILL\n\nsatisfies ONS, PARSE\n\nEvery language must evaluate all three analyses. Since the three candidates violate one constraint\neach, any comparison between them will involve weighing the importance of different violations.\nThe optimal analysis for a given language is determined precisely by whichever of the constraints\nONS, PARSE, and FILL is lowest in the constraint hierarchy of that language. The lowest constraint\nincurs the least important violation.\nSuppose .V. is the optimal parse of /V/. We have the following tableau:\n\n100\n\nChapter 6\n\nPrince & Smolensky\n\n(131) Onset Not Required\n/V/\n\nL\n\nFILL\n\nPARSE\n\n*\n\n.V.\n\n+V,\n.~V.\n\nONS\n\n*!\n*!\n\nThe relative ranking of FILL and PARSE has no effect on the outcome. The violations of PARSE and\nFILL are fatal because the alternative candidate .V. satisfies both constraints.\nOf interest here is the fact that the analysis .V. involves an onsetless syllable. When this\nanalysis is optimal, then the language at hand, by this very fact, does not absolutely require onsets.\nThe other two inferior analyses do succeed in satisfying ONS: +V, achieves this vacuously, creating\nno syllable at all; .GV. creates an onsetful syllable by positing an empty Ons node, leading to\nepenthesis. So if .V. is best, it is because ONS is the lowest of the three constraints, and we conclude\nthat the language does not require onsets. We already know from the previous section, Thm. (128),\nthat onsets can never be forbidden. This means the following condition holds:\n(132) If PARSE, FILL >> ONS, then onsets are not required.\n(The comma’d grouping indicates that PARSE and FILL each dominate ONS, but that there is no\nimplication about their own relative ranking.)\nOn the other hand, if ONS is not the lowest ranking constraint, — if either PARSE or FILL is\nlowest — then the structure assigned to /V/ will be consistent with the language requiring onsets.\nThe following two tableaux lay this out:\n(133) Enforcement by Overparsing (Epenthesis)\n/V/\n\nONS\n.V.\n\n+V,\n\nL .~V.\n\nPARSE\n\nFILL\n\n*!\n*!\n*\n\nOptimality Theory\n\nChapter 6\n\n101\n\n(134) Enforcement by Underparsing (Deletion)\n/V/\n\nFILL\n.V.\n\nL\n\nONS\n\nPARSE\n\n*!\n*\n\n+V,\n.~V.\n\n*!\n\nThese lucubrations lead to the converse of (132):\n(135) If ONS dominates either PARSE or FILL, then onsets are required.\nThere is an important difference in status between the two ONS-related implications. To prove that\nsomething is optional, in the sense of ‘not forbidden’ or ‘not required’ in the inventory, one need\nmerely exhibit one case in which it is observed and one in which it isn’t. To prove that something\nis required, one most show that everything in the universe observes it. Thus, formal proof of (135)\nrequires considering not just one trial input, as we have done, but the whole (infinite) class of strings\non {C,V}* which we are taking to define the universal set of possible inputs for the Basic Theory.\nWe postpone this exercise until the appendix; in §8 we will develop general techniques which will\nenable us to extend the above analysis to arbitrary strings, showing that what is true of /V/ and /CV/\nis true of all inputs.\nThe results of this discussion can be summarized as follows:\n(136) Onset Theorem.\nOnsets are not required in a language if ONS is dominated by both PARSE and FILL.\nOtherwise, onsets are required.\nIn the latter case, ONS is enforced by underparsing (phonetic deletion)\nif PARSE is the lowest ranking of the three constraints; and by\noverparsing (phonetic epenthesis) if FILL is lowest.\nIf FILL is to be articulated into a family of node-specific constraints, then the version of FILL that is\nrelevant here is FILLOns. With this in mind, the onset finding may be recorded as follows:\nLowest\nconstraint\n\nOnsets are ...\n\nEnforced by ...\n\nONS\n\nNot required\n\nN/A\n\nPARSE\n\nRequired\n\nV ‘Deletion’\n\nFILLOns\n\nRequired\n\nC ‘Epenthesis’\n\n102\n\nChapter 6\n\nPrince & Smolensky\n\n6.2.2.2 Codas\nThe analysis of onsets has a direct parallel for codas. We consider the input /CVC/ this time; the\ninitial CV provides an onset and nucleus to meet the ONS and NUC constraints, thereby avoiding any\nextraneous constraint violations. The final C induces the conflict between !COD, which prohibits\nthe Cod node, and Faithfulness, which has the effect of requiring just such a node. As in the\ncorresponding onset situation (130), the parses which violate only one of the basic syllable structure\nconstraints are three in number:\n(137) Best Analyses of /CVC/\nAnalysis\n\nInterpretation\n\nViolation\n\nRemarks\n\n.CVC.\n\nF has Cod\n\n*!COD\n\nsatisfies FILL, PARSE\n\n.CV+C,.\n\nNo parse of 2nd C\n\n*PARSE\n\nsatisfies ONS, FILL\n\n.CV.C~3 .\n\n2nd Nuc is empty\n\n*FILL\n\nsatisfies ONS, PARSE\n\nThe optimal analysis of /CVC/ in a given language depends on which of the three constraints is\nlowest in the domination hierarchy. If .CVC. wins, then the language must allow codas; !COD ranks\nlowest and violation can be compelled. If .CVC. loses, the optimal analysis must involve open\n(codaless) syllables; in this case !COD is enforced through empty nuclear structure (phonetic Vepenthesis) if FILL is lowest, and through non-parsing (phonetic deletion of C) if PARSE is the lowest,\nmost violable constraint. In either case, the result is that open syllables are required. This is a claim\nabout the optimal parse in the language of every string, and not just about /CVC/, and formal proof\nis necessary; see the appendix.\nThe conclusion, parallel to (136), is this:\n(138) Coda Theorem.\nCodas are allowed in a language if !COD is dominated by both PARSE and FILLNuc.\nOtherwise, codas are forbidden.\nIn the latter case, !COD is enforced by underparsing (phonetic deletion) if\nPARSE is the lowest ranking of the three constraints; and by overparsing\n(epenthesis) if FILLNuc is the lowest.\nThe result can be tabulated like this:\n\nOptimality Theory\n\nChapter 6\n\n103\n\nLowest\nconstraint\n\nCodas are ...\n\n!COD\n\nAllowed\n\nN/A\n\nPARSE\n\nForbidden\n\nC ‘Deletion’\n\nFILLNuc\n\nForbidden\n\nV ‘Epenthesis’\n\nEnforced by ...\n\nMotivation for distinguishing the constraints FILLOns and FILLNuc is now available. Consider\nthe languages 3CV in which only CV syllables are allowed. Here ONS and !COD each dominate a\nmember of Faithfulness group. Enforcement of the dominant constraints will be required. Suppose\nthere is only one FILL constraint, holding over all kinds of nodes. If FILL is the lowest-ranked of the\nthree constraints, we have the following situation:\n(139) Triumph of Epenthesis\nInput\n\nOptimal Analysis\n\nPhonetic\n\n/V/\n\n.GV.\n\n. V.\n\n/CVC/\n\n.CV.C~3 .\n\n.CV.C .\n\nThe single uniform FILL constraint yokes together the methods of enforcing the onset requirement\n(‘C-epenthesis’) and the coda prohibition (‘V-epenthesis’). There is no reason to believe that\nlanguages 3CV are obligated to behave in this way; nothing that we know of in the linguistic\nliterature suggests that the appearance of epenthetic onsets requires the appearance of epenthetic\nnuclei in other circumstances. This infelicitous yoking is avoided by the natural assumption that FILL\ntakes individual node-classes as an argument, yielding FILLNuc and FILLOns as the actual constraints.\nIn this way, the priority assigned to filling Ons nodes may be different from that for filling Nuc\nnodes.54\nIt is important to note that onset and coda distributions are completely independent in this\ntheory. Any ranking of the onset-governing constraints {ONS, FILLOns, PARSE} may coexist with any\nranking of coda-governing constraints {!COD, FILLNuc, PARSE}, because they have only one\nconstraint, PARSE, in common. The universal factorial typology allows all nine combinations of the\nthree onset patterns given in (136) and the three coda patterns in (138). The full typology of\ninteractions is portrayed in the table below. We use subcripted del and ep to indicate the phonetic\nconsequences of enforcement; when both are involved, the onset-relevant mode comes first.\n\n54\n\nIt would also be possible to break this yoke by having two separate PARSE constraints, one that applies\nto C and another to V. Basic syllable structure constraints that presuppose a C/V distinction, however, would\nnot support the further development of the theory in §8, where the segment classes are derived from\nconstraint interactions.\n\n104\n\nChapter 6\n\nPrince & Smolensky\n\n(140) Extended CV Syllable Structure Typology\n\nOnsets\nrequired\n\nforbidden\n\nCodas\nallowed\n\nnot required\n\nONS, FILLOns\n>> PARSE\n\nONS, PARSE\n>> FILLOns\n\nPARSE, FILLOns\n>> ONS\n\n!COD, FILLNuc\n>> PARSE\n\n3CVdel,del\n\n3CVep,del\n\n3(C)Vdel\n\n!COD, PARSE\n>> FILLNuc\n\n3CVdel,ep\n\n3CVep,ep\n\n3(C)Vep\n\nPARSE, FILLNuc\n>> !COD\n\n3CV(C)del\n\n3CV(C)ep\n\n3(C)V(C)\n\nIf we decline to distinguish between the Faithfulness constraint rankings, this simplifies to the\nJakobson Typology of (118).\n\n6.2.3 The Theory of Epenthesis Sites\nThe chief goal of syllabification-driven theories of epenthesis is to provide a principled account of\nthe location of epenthetic elements (Selkirk 1981, Broselow 1982, Lapointe and Feinstein 1982, Itô\n1986, 1989). Theories based on manipulation of the segmental string are capable of little more than\nsummary stipulation on this point (e.g. Levin 1985:331; see Itô 1986:159, 1989 for discussion). The\ntheory developed here entails tight restrictions on the distribution of empty nodes in optimal syllabic\nparses, and therefore meets this goal. We confine attention to the premises of the Basic CV syllable\nstructure theory, which serves as the foundation for investigation of the theory of epenthesis, which\nultimately involves segmental and prosodic factors as well.\nThere are a few fundamental observations to make, from which a full positive characterization of\nsyllabically-motivated epenthesis emerges straightaway.\n(141) Prop. 1. *[ ]Cod\nCoda nodes are never empty in any optimal parse.\nStructures with unfilled Cod can never be optimal; there is always something better. To see this, take\na candidate with an unfilled Cod and simply remove that one node. This gives another candidate\nwhich has one less violation of !COD and one less violation of FILL. Since removing the node has\nno other effects on the evaluation, the second candidate must be superior to the first. (To show that\nsomething is non-optimal, we need merely find something better: we don’t have to display the best.)\n\nOptimality Theory\n\nChapter 6\n\n105\n\nWe know from the earlier discussion that Ons and Nuc must be optimally unfilled in certain parses\nunder certain grammars. So the remaining task is to determine the conditions under which these\nnodes must be posited and left empty.\n(142) Prop. 2. *.(~)~3 .\nA whole syllable is never empty in any optimal parse.\nThe same style of argument applies. Consider a parse that has an entirely empty syllable. Remove\nthat syllable. The alternative candidate thereby generated is superior to the original because it has\n(at least) one less FILLNuc violation and no new marks. The empty syllable parse can always be bested\nand is therefore never optimal.\nOf course, in the larger scheme of things, whole syllables can be epenthesized, the canonical\nexamples being Lardil and Axininca Campa (Hale 1973, Klokeid 1976, Itô 1986, Wilkinson 1988,\nKirchner 1992a; Payne 1981, 1982, Spring 1990, Black 1991, McCarthy & Prince 1993). In all such\ncases, it is the impact of additional constraints that forces whole-syllable epenthesis. In particular,\nwhen the prosody/morphology interface constraints like LX.PR are taken into account, prosodic\nminimality requirements can force syllabic epenthesis, as we will see for Lardil in §7 below.\n(143) Prop. 3. *.(~)~3 C.\nNo syllable can have Cod as its only filled position.\nAny analysis containing such a syllable is bested by the alternative in which the content of this one\nsyllable (namely ‘C’) is parsed instead as .C~3 . . This alternative incurs only the single mark *FILLNuc,\nbut the closed-syllable parse .(~)~3 C. shares this mark and violates !COD as well. (In addition, the\nclosed-syllable parse must also violate either ONS or FILLOns.)\nSuch epentheses are not unknown: think of Spanish /slavo/ ÿ eslavo and Arabic /£marar/\nÿ §i£marar. We must argue, as indeed must all syllable theorists, that other constraints are involved\n(for Arabic, see McCarthy & Prince 1990b).\n(144) Prop. 4. *[ ][ ]\nAdjacent empty nodes cannot occur in an optimal parse.\nPropositions 1, 2 and 3 entail that [ ][ ] cannot occur inside a syllable. This leaves only the\nintersyllabic environment .C ~3 .~V~. This bisyllabic string incurs two marks, *FILLNuc and *FILLOns.\nConsider the alternative parse in which the substring /CV/ is analyzed as tautosyllabic .CV~. This\neliminates both marks and incurs no others. It follows that two adjacent epentheses are impossible.\nWe now pull these results together into an omnibus characterization of where empty nodes can be\nfound in optimal parses.\n\n106\n\nChapter 6\n\nPrince & Smolensky\n\n(145) FILL Violation THM. Location of possible Epenthesis Sites.\nUnder the basic syllable structure constraints, epenthesis is limited to the following\nenvironments:\na) Onset, when Nucleus is filled:\n.~V.\n.~VC.\nb) Nucleus, when Onset is filled:\n.C ~3 .\n.C ~3 C.\nFurthermore, two adjacent epentheses are impossible, even across syllable boundaries.\nWe note that this result will carry through in the more complex theory developed below in §8, in\nwhich the primitive C/V distinction is replaced by a graded sonority-dependent scale.\n\n107\n\n7. Constraint Interaction in Lardil Phonology\nThe nominal paradigm of LARDIL, a Pama-Nyungan language of Australia,55 displays a set of\nsometimes dramatic alternations that are responsive to constraints on syllable structure and word\nform. Detailed study and analysis of the language has established not only the facts of the matter, but\nalso uncovered the essential structural factors that drive the phonology (Hale 1973; Klokeid 1976;\nItô 1986; Wilkinson 1988; Kirchner 1992a). Of principal interest, from our point of view, is the\ncoexistence of prosodically-governed augmentation and truncation patterns, competing for the same\nterritory at the end of the word. Short stems are augmented; long stems can be truncated; and nothing\nhappens to stems that are just the right size.\nAccording to a current operational conception, the phonology would have rules of deletion\nand epenthesis that are blocked and triggered by various constraints: deletion of a final vowel except\nwhen the resulting output would be too short (blocking); addition of a vowel (or even consonant and\nvowel) only when the stem is not long enough (triggering); deletion of a final consonant sequence\nwhen unsyllabifiable (deletion triggered when syllabification is blocked). The major problem is to\nmake sure that the right rule is controlled by the right constraint: although vowel-epenthesis is in the\ngrammar, it is not used to save unsyllabified consonants; they delete. A second problem is keeping\nthe rules at bay: excessive application of final V- and C-deletion (both in evidence) would result in\nvery short words indeed.\nIt is important to see through such mechanical challenges to the fundamental insight behind\nthe account: the role of prosodic output constraints in defining the system. Surely the key advance\nin the understanding of Lardil and similar systems was the introduction of analytical techniques that\nallowed many mutations of this sort to be rendered as consequences of syllabification and footformation, as in the work of Selkirk 1981, Broselow 1982, Steriade 1982, Itô 1986, 1989, McCarthy\n& Prince 1986, and for Lardil, Itô 1986 and Wilkinson 1988. The basic idea here is that the\nassignment of prosodic structure is directly responsible for a range of phenomena which early\ngenerative phonology attributed to a battery of structure-modifying re-write rules. Our program is\nto pursue this line of analysis with full vigor; we will argue that the major paradigmatic alternations\nin the Lardil noun are entirely consequent upon the prosodic parse.\n\n7.1 The Constraints\nWe begin in this section by identifying the principal prosodic constraints operative in the language;\nin the next, we proceed to determine their relative ranking. The data are taken from Hale (1973),\nKlokeid (1976), Wilkinson (1988), and Kirchner (1992a). (After glosses we provide page number\nreferences, which are to Hale, except where otherwise noted.)\n55\n\nAccording to Hale, Lardil is “rather distantly related to the other Pama-Nyungan languages.” The\nlanguage is spoken on Mornington Island, one of the Wellesley group at the bottom of the Gulf of\nCarpentaria. Hale notes that it “is closely related to the other language spoken in the Wellesley group and\nadjacent mainland,... [which has] at least three dialects, Yanggal, Yukulta, Gayardilt.” (Hale 1973: 421).\n\n108\n\nChapter 7\n\nPrince & Smolensky\n\nThe phonological action we seek is found in the nominative case.56 To make clear the\ncharacter of the inflections we show some simple, alternation-free forms here:\n(146) Lardil Inflections\na.\nb.\n\nStem\n\nNominative\n\nNonfuture Acc.\n\nFuture Acc.\n\nGloss\n\n/kentapal/\n/pirõen/\n\nkentapal\npirõen\n\nkentapal-in\npirõen-in\n\nkentapal-uÏ\npirõen-uÏ\n\n‘dugong’ 423\n‘woman’ 423\n\nThe nominative ending is null; the nonfuture accusative is -in; the future accusative is -uÏ.\nMost of Lardil syllable structure falls comfortably within the purview of the Basic Theory\nof §6. Lardil admits only syllables CV(C). Onsets are required, and underparsing is evidently used\nto enforce the ONS constraint when morphology puts V against V, as in the following example,\nshowing the nonfuture accusative of /yukaÍpa/ ‘husband’:\n(147) Resolution of V+V\nInput\n\nPhonological Analysis\n\nPhonetic\n\n/yukaÍpa+in/\n\n.yu.kaÍ.pa+i,n.\n*.yu.kaÍ.pa.~in.\n\nyukaÍpan\n*yukaÍpatin\n\n(We will not be concerned with the details of the V+V phenomenon, however.) Lardil thus\nexemplifies the typological family 3CV(C)del, in the terminology of the basic CV syllable structure\ntheory of §6 (140). This means that the Faithfulness constraints dominate &COD, allowing codas\nwhen there is segmental motive for them in the input; and the constraint ONS dominates at least one\nof the Basic Theory’s Faithfulness constraints, disallowing onsetless syllables.\nBoth Onsets and Codas are limited to a single segment, and nuclei consist of either a single\nshort or long vowel. The relevant constraint from the basic theory is *COMPLEX (120), which says\nthat syllable positions are limited to single segments. Long vowels, being monosegmental, satisfy\nthis constraint. The constraint *COMPLEX is unviolated in Lardil, and will be seen to play an\nimportant role in the system.\nFor explicitness, we recall a few other characteristics of the basic theory. The constraint NUC\n(119) requiring syllables to have nuclei is assumed without comment to be undominated; similarly\nfor the constraints *M/V (121) and *P/C (122) which prohibit vowels from being parsed as syllable\n\n56\n\nThere are a number of segmental and allomorphic alternations which will not be treated here, including\nthe lowering of final vowels u,i ÿa,e and the process of sonorization t,ÛÿÍ,Ï/—#, of which the latter may\nbe relevant to a later level of phonology than we discuss (see Hale 1973:426 fn. 32, Klokeid 1976 for details).\nThese can be safely abstracted away from inasmuch as they do not interact with basic syllabification, which\nlies at the center of our concerns. For a different view of the system, the reader is referred to Kirchner 1992a,\nwhere the nominative form is analyzed not as uninflected but as bearing an abstract consonantal affix, one\nwhose featural specification (though ill-formed at the surface) plays into the segmental alternations and\nwhich provides material for the cases that we regard as full syllable augmentation. In our formulations we\nnote, but do not dwell on, Kirchner’s conclusion that truncation is limited to nominals.\n\nOptimality Theory\n\n109\n\nChapter 7\n\nmargins and consonants as being parsed as syllable peaks. These are unviolated in Lardil and\ntherefore cannot be crucially subordinated. (A domination relation will be said to be ‘crucial’ if the\noutput changes when it is reversed. When clear from context, ‘crucial’ will be omitted and, in\nparticular, we will feel free to use ‘undominated’ to mean ‘not crucially dominated’.) The division\nof segments in Lardil into vowels and consonants is uncomplicated: there is, evidently, no need to\nposit segments which alternate between peak and margin positions.\nLooking beyond purely structural concerns, we find that codas in Lardil are subject to further\nstrong limitations of the familiar kind (Steriade 1982, Itô 1986). Adopting Itô’s term, we refer to the\nrelevant constraint as the Coda Condition, CODACOND for short. The generalization offered by\nWilkinson is that Codas may be occupied only by “nonback coronals” and by nasals homorganic\nwith a following (onset) consonant. The consonant inventory of Lardil looks like this, with the\n‘nonback’ coronals boxed:\n(148) Lardil Consonants (Hale 1973)\nlabial\n\nlamino- apico- laminodental alveolar alveolar\n\napicodomal\n\ndorsovelar\n\nobstruent\n\np\n\n=t\n\nt\n\nty\n\nÛ\n\nk\n\nnasal\n\nm\n\nn=\n\nn\n\nny\n\nÃ\n\nõ\n\ny\n\nÏ\n\nlateral\n\nl\n\nflap\n\nÍ\n\napproximant\n\nw\n\nCaveat lector: the Lardil coronals referred to by Wilkinson as back are the farthest forward: the\nlamino-dentals [t= n=]. The feature assignment is due to Stevens, Keyser, & Kawasaki 1986; evidently\nthe lamino-dentals are velarized, so that that they have a Dorsal as well as a Coronal articulation.\nExcluded from syllable final position, then, is any consonant with a noncoronal specification (Labial\nor Dorsal), even secondarily. (On the unmarked status of coronals, see Paradis & Prunet 1991,\nMcCarthy & Taub 1992). When a consonant has no place of its own, such as a linked nasal, it is of\ncourse also allowed in Coda position. Here we will do little more than summarize the effects of the\ncondition, making no serious attempt to provide it or its variants with a proper analysis (for recent\napproaches, see Goldsmith 1990, Itô & Mester 1993, and within the present theory, Kirchner 1992bc,\nZec 1992, and §8 and §9.1.2 below.)\n(149) CODACOND\nA coda consonant can have only Coronal place or place shared with another consonant.\nThe Coda Condition has serious consequences at the end of words, as can be seen in table (150) in\nthe Nominative column.\n\n110\n\nChapter 7\n\n(150) Lardil Paradigms with Truncation\nUnderlying Stem\n•Nominative• Nonfut. Acc.\na. C Loss from Stem\nõalu\nõaluk\nõaluk-in\nwuõkunu\nwuõkunuõ\nwuõkunuõ-in\nwaõal\nwaõalk\nwaõalk-in\n\nPrince & Smolensky\n\nFut. Acc.\n\nGloss\n\nõaluk-uÏ\nwuõkunuõ-kuÏ\nwaõalk-uÏ\n\n‘story’ 438\n‘queen-fish’ 438\n‘boomerang’ 438\n\nb. V Loss from Stem\nyiliyili\nmayaÍa\n\nyiliyil\nmayaÍ\n\nyiliyili-n\nmayaÍa-n\n\nyiliyili-wuÏ\nmayaÍa-Ï\n\n‘oyster sp.’ 424\n‘rainbow’ 424\n\nc. CV Loss from Stem\nyukaÍpa\nwuÛaltyi\nõawuõawu\nmuÍkunima\n\nyukaÍ\nwuÛal\nõawuõa\nmuÍkuni\n\nyukaÍpa-n\nwuÛaltyi-n\nõawuõawu-n\nmuÍkunima-n\n\nyukaÍpa-Ï\nwuÛaltyi-wuÏ\nõawuõawu-Ï\nmuÍkinima-Ï\n\n‘husband’ 424\n‘meat’ 424\n‘termite’ 425\n‘nullah’ 425\n\nmuõkumuõku-n\ntyumputyumpu-n\n\nmuõkumuõku-Ï\ntyumputyumpu-Ï\n\nd. CCV Loss from Stem\nmuõkumuõku muõkumu\ntyumputyumpu tyumputyu\n\n‘wooden axe’ 425\n‘dragonfly’ 425\n\nThese underlying stems show up intact only when suffixed, here by the endings -in and -uÏ.57 In the\nNominative, with null affixation, a considerable amount of word-final material can be left behind.\nIn the simplest case, a single consonant is lost, always one that cannot be syllabified because of the\nnarrowness of the Coda Condition. Violations of CODACOND are avoided by failure to parse\nsegments, as in the following typical example /õaluk/ ‘story, nom.’ (150a).\n(151) Enforcement of CODACOND through underparsing\nStem\n\n/õaluk/\n\nParse\n\n.õa.lu.+k,\n*.õa.lu.k~3 .\n\nPhonetic\n\nõalu\n*õaluka\n\nUnparsed segments occur in Lardil, as in many other languages, in situations where violations\nof ONS and CODACOND are at risk. In addition, word-final vowels are generally left unparsed in the\nnominative. The stem /yiliyili/ is analyzed as .yi.li.yil.+i, when uninflected (150b). There are\nimmediate further consequences: preceding consonants must also be left unparsed if syllabifying\nthem would violate CODACOND. The resulting heavy losses are illustrated in (150c-d).\n\nIn addition to the V-loss mentioned above, the ending -uÏ undergoes various morphophonemic\nmodifications of limited or unclear generality which will not be dealt with here. See Mester 1992 for\ndiscussion of allomorphy within an Optimality Theoretic conception of phonology.\n57\n\nOptimality Theory\n\n111\n\nChapter 7\n\nSince nonparsing violates the prosodic licensing constraint PARSE, it will be avoided unless\nthere is another, higher-ranked constraint that compels it. Wilkinson (1986:10) makes the interesting\nproposal that extrametricality is what’s involved. Following this line, we formulate the relevant\nconstraint so as to require that word-final vowels not be parsed (in the nominative).\n(152) FREE-V\nWord-final vowels must not be parsed (in the nominative).\nAlthough FREE-V takes the bull by the horns, it would not perhaps be put forth as the canonical\nexample of a universal markedness principle. It appears to be a morphologized reflex of the prosodic\nweakness of final open syllables, which are liable to de-stressing, de-voicing, shortening, truncation,\nand so on, under purely phonological conditions. (Estonian morphology has virtually the same\nconstraint, including limitation to the nominative, the null-affixed case.) It also has connection with\nthe commonly encountered constraint to the effect that stems or words must end in a consonant\n(McCarthy & Prince 1990ab, Prince 1990). Any theory must allow latitude for incursions of the\nidiosyncratic into grammar. What is important for our program is that such incursions are best\nexpressible as constraints; that they are (slightly) modified versions of the universal conditions on\nphonological form out of which core grammar is constructed; and that they interact with other\nconstraints in the manner prescribed by the general theory.\nThere is an important class of cases where, despite phonetic appearances, FREE-V is not\nviolated. Since the constraint is phonological and pertains to phonological structure, it is vacuously\nsatisfied in forms like .õa.lu.+k,, because the form has no word-final vowel in the relevant sense, its\nlast vowel being separated from the word-edge by k. And the constraint is actively satisfied in\n.muõ.ku.mu.+õku,, where the word-final vowel is unparsed, even though the phonetic interpretation\nmuõ.ku.mu ends, irrelevantly, in a syllabified vowel. Our analysis crucially rests, then, on the parallel\nsatisfaction of constraints, as opposed to serial application of structure-deforming rules, and on the\nassumption of ‘monotonicity’ in the input/output relation — that the input is literally contained in\nthe output, with no losses (cf. Wheeler 1981, 1988).\nBy contrast, the constraint FREE-V is flagrantly violated in bisyllabic stems, as illustrated in\n(153) by /wiÛe/, which is parsed simply as .wi.Ûe.\n(153) No Truncation in Minimal Words\nStem\n\nNominative\n\nNonfuture\n\nFuture\n\nGloss\n\na.\n\nwiÛe\n\nwiÛe\n\nwiÛe-n\n\nwiÛe-Ï\n\n‘inside’\n\nW326\n\nb.\n\nmela\n\nmela\n\nmela-n\n\nmela-Ï\n\n‘sea’\n\n433\n\nConstruing these as monosyllables to satisfy FREE-V would lead to violation of the strong\nuniversal prosody-morphology interface constraint discussed above in §4.3:\n(154) LX.PR\nEvery Lexical Word must correspond to a Prosodic Word.\n\n112\n\nChapter 7\n\nPrince & Smolensky\n\nSince the phonological category PrWd must dominate a foot, and since Lardil feet are binary by Foot\nBinarity (FTBIN, §4.3), adherence to LX.PR entails bimoraic minimality. As shown in Wilkinson\n1988, the resulting minimal word-size limitation correctly blocks stem-final vowel loss. The actual\nfoot in Lardil may be the bimoraic trochee, with a syllable having one or two moras depending on\nwhether its vowel is short or long, regardless of whether it has a coda. Details of foot form, of\ncourse, do not affect the minimality argument, since moraic binarity is the universal lower limit.\nNot only does LX.PR, in consort with FTBIN, prevent nonparsing of word-final vowels, it\nalso forces the appearance of syllables with empty positions. The mono-moraic stems illustrated in\n(155) all receive syllabic augmentation in the nominative:58\n(155) Lardil Augmentation of Short Stems\nUnderlying Stem\n\nNominative\n\nNonfuture\n\nFuture\n\nGloss\n\nyaka\nÏelka\n\nyak-in\nÏelk-in\n\nyak-uÏ\nÏelk-uÏ\n\n‘fish’ 438\n‘head’ 438\n\nmaÏÛÛa\nÏilta\n\nmaÏ-in\nÏil-in\n\nmaÏ-uÏ\nÏil-uÏ\n\n‘hand’ 427\n‘neck’ 427\n\nkaõka\ntyaõka\n\nkaõ-in\ntyaõ-in\n\nkaõ-kuÏ\ntyaõ-kuÏ\n\n‘speech’ 438\n‘some’ 438\n\na. V Augmentation\n\nyak\nÏelk\nb. CV Augmentation\n\nmaÏ\nÏil\nc. CV Augmentation\n\nkaõ\ntyaõ\n\nThese stems cannot end underlyingly in the -a that shows up in the phonetics. The accusative\nmarkers are -n and -Ï after true vowel-final stems, -in and -uÏ after consonant finals, as seen in (146)\nand (150) above. Nor can the underlying stems in (155b,c) be analyzed as ending in -ta or -ka, or\neven in -t and -k. Were the nominatives taken to reflect underlying consonantism, there would be\nno explanation for the putative disappearance of the additional consonants t and k in the oblique\ncases.\nAll subminimal stems are augmented. Not only are LX.PR and FTBIN unviolated in the\nlanguage, but the Null Parse output is inferior to the augmented forms, even though they violate FILL,\nwhich is therefore well down in the hierarchy.\n\n58\n\nIn addition to the well-populated stem-shape categories exemplified in the table, there are two known\nCV stems: /Ïu/ ‘body fat, grease’, /tya/ ‘foot’(Hale 1973:428, Klokeid 1976:55). These have the following\nforms: Ïuwa, Ïuyin, ÏuuÏ; tya:, tyayin, tyawuÏ. These are of interest for several reasons. Note the blocking of\ntruncation of the affixal vowel, obviously due to the word minimality requirement; note also the use of a\nspreading structure rather than featural epenthesis to fill the Onset. The form ÏuuÏ (unattested: constructed\nfrom Klokeid’s description) raises an issue about VV sequences; perhaps it is really uwu, with the w of low\nperceptibility in the u—u environment. The most serious problem for the analysis we give is the tya+\nnominative from /tya/. We point out the exact problem below, fn. 64, p. 130.\n\nOptimality Theory\n\nChapter 7\n\n113\n\nAugmentation violates FILL, but it does not always do so minimally, contrary to ceteris\nparibus expectation. Although a single empty position — a Nucleus — is sufficient to rescue\nexcessively short stems CVC from Foot Binarity violations, the fact is that the accessory syllable\nmay be entirely empty, with an unfilled Onset as well, as in .maÏ.~~3 . and .kaõ.~~3 . (155b,c). Since\nall consonants of Lardil may stand in onset position, there is no phonological need for this extra FILL\nviolation; the last consonant of the stem could easily fill the required Onset. Whence the\nsupererogatory empty Onset? What’s crucial, as Wilkinson points out (1986:7), is whether or not the\nstem-final consonant can be parsed as a Coda: when it can, it is.59\nThe generalization is clear in table (155). Supererogation is manifest in forms like (a), (b):\n(156) FILL Patterns depending on syllabifiability of stem\nStem\n\na. /maÏ/\nb. /kaõ/\nc. /yak/\n\nAnalysis\n.maÏ.~~3 .\n*.ma.Ï~3 .\n.kaõ.~~3 .\n*.ka.õ~3 .\n\nPhonetic\n\nmaÏÛa\n*maÏa\nkaõka\n*kaõa\n\n.ya.k~3 .\n*.yak.~~3 .\n\nyaka\n*yakta\n\nWhere CODACOND can be met, as in (a) and (b), the stem-final consonant closes the stem syllable.\nWhere it can’t be met, as in (c), augmentation is minimal.60 We propose that this pattern of\ngeneralization reflects another type of constraint on the morphology-phonology interface, one that\nrequires edges of morphological constituents to match up with edges of phonological constituents.\n59\n\nTwo patterns have been observed that indicate the need for refinement: /bit/÷bita, *bitta; and\n/teÍ/ ÷teÍa, *teÍta (Hale 1973, Wilkinson 1988, Kirchner 1992a). In these cases, it appears that an onset [t]\ncannot be epenthesized because of constraints against geminate consonants and against the sequence [Ít]\n(Hale 1973:427; recall the untreated alternation t~ Í, fn. 56, p.108. These constraints are sensitive to the\nphonetic content of the epenthetic onset, and not merely to its presence, yet they bear on syllabification,\ncontrary to the hypothesis that epenthetic structure is nothing more than an empty syllabic node. For a further\ndiscussion of this phenomenon, see immediately below, fn. 60.\nThe fact that the Coda Condition is met in forms like .kaõ.~~\n3 . (phonetic kaõka) requires explication.\nCoda nasals must be homorganic to a following C; here there is no following C, only a syllabic position\n(under the current construal) lacking segmental content. This is a course a typical conundrum encountered\nin underspecification theories, in which the phonetic properties of the to-be-phonetically-filled-in material\nenter into the phonological constraint system of the language (Kiparsky 1968/73, Mohanan 1991, McCarthy\n& Taub 1992, McCarthy to appear). Such phenomena provide compelling evidence that the empty structure\ntechnology used here needs amplification: perhaps, for example, the set of candidates issued by Gen should\ninclude actual featural and segmental insertions, as well as new association lines. In such a theory, the\ncognate of FILL would militate against the presence of material not in the input, an obvious kind of\nunfaithfulness. We postpone consideration of such refinements for future research (see Yip 1993 for some\nsuggestions). For present purposes, let us imagine that a syllable node bears the index of the segments\nassociated with it (Aoun 1979), specifically of the place node of that segment, its head (Itô & Mester 1993);\nassume also that empty nodes can be introduced with indices. A form like .kaõi.~i~3 . is regarded as legitimate\nby CODACOND because the nasal is indexed to a non-coda node. It appears that in Lardil only sonorants may\nbe coindexed in this way. The phonetic interpretation process that fills in values for empty nodes would\nderive place information from coindexation. For deeper exploration of CODACOND-type issues, see\nGoldsmith 1990, Kaye 1990, Itô & Mester 1993 and the references cited therein.\n60\n\n114\n\nChapter 7\n\nPrince & Smolensky\n\nIn the examples of (156), we see that the end of the stem is made to coincide with a syllable edge,\nif that state of affairs can be achieved by epenthesis while still deferring to the general syllable\nstructure restrictions of the language.\nAlthough the phonological integrity of the stem is protected in forms like maÏ.~a , no such\neffect is observed internally at stem+affix junctures. We do not find, for example, maÏ.~in from\n/maÏ+in/ or ken.ta.pal.~in from /kentapal+in/. The morphological category at issue can therefore\nbe determined quite precisely: the phenomenon involves only the final edge of the entire underlying\ncollocation of stem+affixes. Let us call this entity the ‘Morphological Word’, or MWord. We may\nthen state the relevant constraint:\n(157) ALIGN\nThe final edge of a Morphological Word corresponds to the final edge of a syllable.\nALIGN belongs to the family of constraints which govern the relation between prosody and\ngrammatical structure. Considerable further development and investigation of the ALIGN idea is\nfound in McCarthy & Prince 1993a, which posits a general format for alignment constraints:\nALIGN(GCat-edge(L*R), PCat-edge(L*R) ), where GCat denotes a morphological or syntactic\ncategory; PCat denotes a prosodic category; L,R denote ‘left’ and ‘right’. McCarthy & Prince\ndemonstrate the central role of such constraints in a wide range of prosodic-morphological\nphenomena and explore the variety of effects that can be obtained by using them. Of particular\ninterest in the present context is their finding that Axininca Campa right-aligns the Stem itself and\nnot the MWord. (McCarthy & Prince (1993b) show that the Alignment family is instrumental in\nmuch prosodic phonology as well, incorporating and generalizing the EDGEMOST constraints posited\nabove.) The ALIGN pattern is closely analogous to that proposed for the domain of phrasal phonology\nby Chen 1987 and further explored in Selkirk 1986, 1993. Observe that LX.PR really falls into the\nsame family: a lexical word edge is to be aligned with the edge of a Prosodic Word.\nIn the case at hand, the constraint ALIGN is violated unless the MWord’s final segment stands\nas the final segment in a syllable. A consonant-final MWord satisfies ALIGN only if its final C is a\nCoda. A vowel-final MWord satisfies ALIGN only if its final V is parsed as the Nucleus of an open\nsyllable. MWords in which the final segment is not parsed at all will violate ALIGN because the\nmorphological-category edge does not fall at a syllable edge.\nLike Axininca Campa, Lardil evidences both left and right morphology/prosody alignment.\nTruncation and Augmentation lead to frequent violations of final ALIGN (157), which looks at the\nend of the domain. By contrast, ALIGN-L, aimed at the leading edge of the Stem or MWord, is never\nviolated: prosodic structure begins crisply at the beginning of the word, and empty structure never\nappears there. Word minimality considerations alone are insufficient to determine the placement of\nempty material, and languages differ on its location. Shona, Mohawk, and Choctaw, to cite three\ngenetically separated examples, all use prothetic vowels to attain minimality (Myers 1987a, Hewitt\n1992; Michelson, 1988; Lombardi & McCarthy 1991). In Lardil, as in Axininca Campa,\naugmentation is always final, being ruled out initially by ALIGN-L (McCarthy & Prince 1993:§4).\nNote that if LX.PR actually works along Chen-Selkirk lines, as suggested above, then we can\nidentify ALIGN-L with LX.PR. The constraint would be that the initial edge of the lexical word must\nalign with the initial edge of the prosodic word. Let’s tentatively assume this formulation, and speak\nno more of ALIGN-L.\n\nOptimality Theory\n\nChapter 7\n\n115\n\nWe have now surveyed the principal constraints involved in the alternations. The following\nlist summarizes and categorizes the constraint set:\n(158) Principal Lardil Constraints (not yet ranked)\na Basic Syllable Structure\nONS, &COD, FILLOns, FILLNuc, PARSE, *COMPLEX\nb Segmental Association\nCODACOND\nc Foot Structure\nFTBIN\nd Morphology-Phonology Interface\nLX.PR, ALIGN, FREE-V\nOf these constraints, only FREE-V involves a significant degree of language-particular idiosyncrasy.\nThe others are strictly universal; and some, like ALIGN (i.e. ALIGN-R) and LX.PR (qua ALIGN-L)\npoint to the existence of a universal family of constraints whose other members are presumably\navailable but subordinated out of sight in Lardil.\nFor the reader’s convenience, the table on the following page lays out the the alternation system that\nthe constraint set, when ranked, will generate.\nInputs are distinguished first according to whether they are consonant- or vowel-final, and\nthen according to whether they are sub-minimal (one mora), minimal (two moras) or supra-minimal\n(more than two moras). On stems CV, see fn. 58, p. 112 above.\n\n116\n\nChapter 7\n\nPrince & Smolensky\n\nThe table uses the following code:\nT\npure coronal, a possible coda\nC with dorsal or labial articulation, impossible coda\na nasal not pure coronal (a possible coda only when followed by a homorganic onset)\nC that is an impossible coda for any reason. { } = { } c { }\n+\nsequence of one or more elements of type X\nX\n(159) Summary of Lardil Nominative Forms\n\nConsonant-Final Stems\nStem $ ::\n\na.\n\n~T ÿ ~T.\n\nb.\n\n~\n\nÿ ~.+\n\n,\n\nkentapal\n\nÿ .ken.ta.pal.\n\nwaõalk\n\nÿ .wa.õal.+k,\n\nõaluk\n\nÿ .õa.lu.+k,\n\nStem < ::\n\nc.\n\n~T ÿ ~T.~~3 .\n\nmaÏ\n\nÿ .maÏ.~~3 .\n\nd.\n\n~\n\nÿ ~. ~3 .\n\nÏelk\n\nÿ .Ïel.k~3 .\n\nyak\n\nÿ .ya.k~3 .\n\nkaõ\n\nÿ .kaõ.~~3 .\n\ne.\n\n~\n\nÿ ~ .~~3 .\n\nVowel-Final Stems\nStem > ::\n\nf.\n\n~TV ÿ ~T.+V,\n\nyiliyili\n\nÿ .yi.li.yil.+i,\n\ng.\n\n~\n\nV ÿ ~. +\n\nyukaÍpa\n\nÿ .yu.kaÍ.+pa,\n\nõawuõawu\n\nÿ .õa.wu.õa.+wu,\n\nV,\n\nmuõkumuõku ÿ .muõ.ku.mu.+õku,\nStem = ::\n\nh.\n\n~V ÿ ~V.\n\nwiÛe\n\nÿ .wi.Ûe.\n\nOptimality Theory\n\nChapter 7\n\n117\n\n7.2 The Ranking\nTo construct a grammar of Lardil from the assembled constraints, it is necessary to fix their ranking.\nOur basic analytical strategy will be to examine competitions between pairs of candidates, one of\nwhich is desired to be optimal, the other of which provides a serious challenge, because it is favored\nby some constraint or constraints (§7.2.2). Each such competition will turn out to bear on the ranking\nrelations between a small number of conflicting constraints. The end result will be a collection of\nranking conditions, which must hold of any grammar that is successful in generating the desired\nforms. These conditions are combined into an overall ranking (more precisely: class of rankings) for\nthe whole set of constraints.\nWe then go on to show in §7.3 that the posited rankings are not only necessary, but sufficient\nto produce the desired outputs: that a grammar of constraints so ranked will dismiss not just the\nsmall set of losing competitors considered in §7.2.2, but will indeed dismiss every nonattested output\ncandidate as suboptimal.\nBefore we plunge into this task, we offer two remarks on the logic of constraint-ranking\narguments. The first is fundamental to the project of advancing from empirical observations to\nsound conclusions about necessary rankings. The second offers a refinement useful for deducing\nrankings under the particular conditions comprehended by P~Ãini’s Theorem (§5.3 ).\n\n7.2.1 Some Ranking Logic\nThere are risks involved in focussing on only two constraints in a situation where a number of\nconstraints are swarming about, their interactions unresolved. When is it safe to conclude that an\nargument about two constraints can’t be invalidated by the introduction of a third into the\ndiscussion? Fortunately, the issue submits to a simple resolution.\nConsider the basic situation in which two constraints, call them ÷1 and ÷2, are directly\nrankable. For a ranking argument to exist at all, the constraints must conflict. This means that they\ndisagree on the the relative Harmony of competing candidate forms arising from a given input, where\none of the candidates is the true output. Let’s denote the forms on which ÷1 and ÷2 conflict by the\nnames T and z. Suppose T is the empirically correct output, which must be optimal under the\nconstraint hierarchy, if the grammar is to be successful. Suppose further that ÷1 favors T over z, but\nthat the conflicting ÷2 favors z over T.\nIn this situation, it is clear that ÷2 must be subordinated in the ranking to some constraint\nfavoring T over z — otherwise T will not win against z. If the choice between T and z is relevant\nto the ranking of ÷1 and ÷2, then the constraint that grants relative superiority to T — here, ÷1 —\nmust be dominant. A typical conflict situation is shown in the following tableau.\n\n118\n\nChapter 7\n\nPrince & Smolensky\n\n(160) Constraint Conflict and Ranking Argument\n\n÷1\n\nCandidates from\n/inputi/\n\nL\n\n*\n\nT\nz\n\n÷2\n\n*!\n\nThis constitutes a potential empirical argument that ÷1 dominates ÷2. Are we then licensed to\nconclude that the domination relation ÷1 >> ÷2 must be honored by the grammar under investigation?\nCould it be that another constraint in the grammar — call it — is actually responsible for the\nvictory of T over z, mooting the clash of ÷1 and ÷2?\nIndeed it could, but any such spoiler constraint must meet tight conditions. First of all, T and\nz cannot tie on ; for if they do, plays no role in deciding between them. Second, cannot favor\nz over T: no such constraint, disfavoring T, can be responsible for its triumph over a competitor.\nThis leaves only the situation where favors T over z, exactly as ÷1 does. Such constraints\nhave the power to decide the competition in favor of T. These are the ones to watch out for. If there\nare none, or if they have already been shown to be lower-ranked than ÷2 by other considerations,\nthen the ranking argument in (160) goes through and establishes a necessary condition on the\ngrammar.61 (Should such a potential rejector exist, and should we have no reason to believe that it\nmust be ranked below ÷2, we can only conclude that ÷1 or is ranked above ÷2.)\nTo put it another way: a successful direct ranking argument shows that ÷1 is the rejector of\nthe candidate z in its contest against T, i.e. that ÷1 is the very constraint that puts an end to z’s\ncandidacy. The only type of constraint whose presence in the grammar would undermine the\nargument is another potential rejector of z vis-à-vis T.\nAs a second point of useful ranking logic, we review the discussion of P~Ãini’s Theorem on\nConstraint-ranking from §5.3. Intuitively, this theorem says that if a more general and a more\nspecific constraint disagree, then they can only both be active in winnowing the candidate set of an\ninput if the specific constraint dominates the general one. The first relevant case of this theorem in\nLardil involves the more general constraint PARSE and the more specific constraint FREE-V which\ndisagrees with the more general one on its more specialized domain, V-final stems.\nLet us review the relevant definitions from §5.\n\n61\n\nThis argument can be re-phrased in terms of the Cancellation/Domination Lemma below: §8.2.6, (192),\np.142,and (238), p.162. The Cancellation/Domination Lemma holds that each mark incurred by the overall\nwinner T must be canceled or dominated by the marks of any competitor. Let us suppose, without loss of\ngenerality, that we are looking at fully canceled tableaux, in which all common marks have been eliminated.\nThe form T has a mark *÷2; the claim of the comparison in tableau (160) is that ÷1 crucially supplies the\ndominating mark for z. Of course, there might be another constraint around, , which actually supplies the\ndominating mark. To fill this role, would have to give a mark to z and no mark to T, just like ÷1.\n\nOptimality Theory\n\nChapter 7\n\n119\n\n(161) Dfn. P~Ãinian Constraint Relation\nLet and be two constraints. stands to as special to general in a P~Ãinian relation\nif, for any input i to which applies non-vacuously, any parse of i which satisfies fails .\nA constraint applies non-vacuously to an input i if some of the parses of i violate the constraint while\nothers satisfy it.\nFor example, the constraint FREE-V stands to PARSE as special to general in a P~Ãinian\nrelation. Given any input to which FREE-V applies non-vacuously — an input with a stem-final\nvowel V — any parse of it which satisfies FREE-V by leaving V unparsed must for that very reason\nviolate PARSE.\nThe other concept we need is:\n(162) Dfn. Active\nLet ÷ be a constraint in a constraint hierarchy\nand let i be an input. ÷ is active on i in\nif ÷ eliminates from consideration some candidate parses of i.\nThat is, among those candidate parses of i which survive the constraints which dominate ÷ in the\nhierarchy\n, some violate ÷ and others satisfy it, so ÷ eliminates those parses which violate it.\n(Recall that in harmonic ordering, if all the candidates left for consideration by ÷ violate ÷, then ÷\ndoes not eliminate any of these parses.)\nNow the theorem asserts:\n(163) P~Ãini’s Theorem on Constraint-ranking (PTC)\nLet and stand as specific to general in a P~Ãinian constraint relation. Suppose these\nconstraints are part of a constraint hierarchy\n, and that is active in\non some input\ni. Then if >> , is not active on i.\nThus if both the general and specific constraints are active on a common input, the specific must\ndominate the general. We will see shortly how PTC can be used to help deduce the domination\nhierarchy of Lardil. For other examples of PTC and related patterns of argument, see Kirchner\n1992bc and McCarthy & Prince 1993.\nPTC has obvious affinities with the Elsewhere Condition of Anderson 1969 and Kiparsky 1973b,\nwhich has played an important role in enriching and deepening the theory of Lexical Phonology.\nThere is an important difference: PTC is merely a point of logic, but the Elsewhere Condition is\nthought of as a principle specific to UG, responsible for empirical results which could very well be\notherwise. In Kiparsky 1973b, for example, the Elsewhere Condition is written to govern the\nrelationship between rules whose structural changes are the same as well as incompatible (broadly,\n‘conflicting’). This enables him to claim that it is the Elsewhere Condition, rather than the\ninterpretation of parentheses, that is responsible for disjunctive ordering in stress rules. Suppose a\ngrammar has the two (adjacent) rules ‘stress the penult’ and ‘stress the final syllable’. Since every\nword has a final syllable, but not every word a penult, it follows from the Elsewhere Condition that\nin longer words only the penult stress rule applies. It is logically possible that both rules would apply,\nstressing the last two syllables in longer words. Current prosodic theory yields a better understanding\n\n120\n\nChapter 7\n\nPrince & Smolensky\n\nof the phenomenon. In reality, the two stress rules are incompatible: conflicting, not identical in\nstructural change. If main stress is at issue, then the relevant constraints entail that there can be only\none such in word. (Each rule then says “the main-stress is here.”) The ranking decides which position\nis favored; and either is possible. If mere stress vs. unstress is at issue, then Foot Binarity decides\nthe matter (not to mention anti-clash constraints).\nAlong the same lines, the Elsewhere Condition is sometimes said to entail that a given\nmorphological category should have only one marking; double marking of e.g. plural by two\ndifferent affixes, one specialized, the other of more general applicability, is then held to be an\n“exception” to the Elsewhere Condition (Stump 1989). Here again, it should be clear that what’s\nreally at issue is a substantive matter: how morphological categories are expressed. A\nmorphosyntactic feature [+PL] typically has one morpheme in a string devoted to it (Pinker 1984,\nMarcus et al. 1992); thus, different plural morphemes are incompatible. This allows for a specialcase/general-case system, in which the logic of PTC determines the ranking that yields the observed\nfacts. What double marking challenges is the assumption of incompatibility, without which the PTC\nis irrelevant. We conclude that the standard Elsewhere Condition folds together a point of logic\n(PTC) with additional claims about what linguistic phenomena are incompatible. With the\nincompatibility claims properly factored out into substantive constraints of various types, what’s left\nis PTC; that is to say, nothing.\n\n7.2.2 Ranking the Constraints\nLet us now turn to the business at hand. We repeat the constraint list for convenience of\nreference.\n(164) Principal Lardil Constraints (not yet ranked)\na. Basic Syllable Structure\nONS, &COD, FILLOns, FILLNuc, PARSE, *COMPLEX\nb Segmental Association\nCODACOND\nc Foot Structure\nFTBIN\nd Morphology-Phonology Interface Constraints\nLX.PR, ALIGN, FREE-V\nFive of the constraints are never violated in Lardil, and are therefore not crucially dominated. In any\ngiven grammar, which is imposes a total order on the constraint set, all but one will be formally\ndominated; but permuting the ranking relations among the members of this set will have no effect\non the outcome.\n(165) Constraints Not Crucially Dominated\nONS, CODACOND,*COMPLEX, LX.PR, FTBIN\n\nOptimality Theory\n\nChapter 7\n\n121\n\nIt remains to be determined how each of these top-rankable constraints is enforced via domination\nof a relevant faithfulness constraint. We will find direct evidence in the cases of ONS, LX.PR,\nFTBIN. Note that the constraint *COMPLEX, which bans tautosyllabic sequences, is undominated in\nLardil just as it is in the basic syllable structure theory of §6 (123), p. 96.\nLardil is a member of the family 3CV(C)del of CV(C) languages (§6.1), with mandatory onset\nenforced by omitting stranded V’s, as in VV, from syllable structure. From the discussion in §6, we\nknow how to define this family:\n(166) Mandatory Onset Enforced by Failure to Parse\nONS, FILLOns >> PARSE\nInput sequences CVV are resolved as .CV.+V,, incurring a *PARSE violation, as seen in the\npostvocalic disappearance of -i in -in ‘nonfuture accusative’. The alternatives which posit an\nOnsetless syllable .V., or an empty Onset position as in .~V., are declared less harmonic by this\nranking. (Since we are not treating the resolution of VV in any depth here, we abstract away from\nthe issue of deciding which V of VV is to remain unparsed, and we will therefore not offer a\nconstraint discriminating C+V,V from CV+V,.)\n(167) Coda Allowed\nFILLNuc, PARSE >> &COD\nSyllables can have codas. Input CVCCV, for example, is syllabified faithfully (CodaCond willing),\nrather than submitted to aggressive over- or under-parsing that would support the preconsonantal C\nwith an empty nucleus (*FILLNuc) or eject it altogether from syllable structure (*PARSE).\nLet us consider now the position of the pair LX.PR and FTBIN, which jointly entail the\nminimality limitation on words. These two are clearly undominated, because never violated. In\naddition, they must be specifically ranked above certain other constraints. Operationally speaking,\nthe minimal word size condition must trigger epenthesis and block deletion. In Optimality Theoretic\nterms, a constraint that is said to trigger or to block is simply dominant; there are no distinguished\ntriggering and blocking relations. Consequently LX.PR and FTBIN must be dominant over the FILL\nconstraints, which militate against empty structure (triggering its appearance), and over the FREE-V\nconstraint, which favors nonparsing of word-final V (blocking the nonparse).\nTo see the details, let’s first examine the augmentation of subminimal stems. The constraints\nLX.PR and FTBIN are enforced by positing empty syllabic nodes, sometimes unfilled Onset as well\nas unfilled Nucleus. It follows that:\n(168) LX.PR, FTBIN Enforced via Empty Structure\nLX.PR, FTBIN >> FILLNuc, FILLOns\nParses such as .maÏ.~~3 . are therefore optimal, despite violation of both FILLOns and FILLNuc. In any\ncandidate without the additional syllable, fatal violation of the higher-ranked constraints LX.PR or\nFTBIN must occur. The tableau below shows only the LX.PR violation, caused by failure to foot the\ninput. Assigning the input a monomoraic foot would make it possible to satisfy LX.PR, but at the\nunacceptable cost of violating FTBIN.\n\n122\n\nChapter 7\nLX.PR\n\n/maÏ/\n\nL\n\n[(F .maÏ.~~3 . )]PrWd\n.maÏ.\n\nPrince & Smolensky\n\nFILLNuc\n\nFILLOns\n\n*\n\n*\n\n*!\n\nNotice that we are justified in ignoring the other constraints here. Both candidates fail &COD; both\nsatisfy ALIGN; so neither constraint can decide between them.\nIn forms that are precisely minimal, stem-final vowels are parsed in violation of FREE-V,\nbecause of the domination of LX.PR and FTBIN.\n(169) LX.PR, FTBIN Force Parsing of Stem-Final Vowels\nLX.PR, FTBIN >> FREE-V\nIn vowel-final bimoraic stems CVCV, FREE-V conflicts with LX.PR and FTBIN. Parsing the final\nvowel violates FREE-V. Leaving it out produces a monosyllabic monomoraic output, violating either\nLX.PR or FTBIN. The conflict goes to LX.PR and FTBIN, of course. The following tableau shows\nthe LX.PR situation, considering candidates in which no monomoraic feet are assigned:\n(170) Failure of Truncation in Minimal Words\nLX.PR\n\n/wiÛe/ ÿ\n\nL\n\n[( .wi.Ûe. )]PrWd\n.wiÛ.+e,\n\nFREE-V\n\n*\n*!\n\nThe constraint FREE-V also interacts with PARSE, but in the simple way covered by P~Ãini’s\nTheorem. As mentioned in §7.2.1, FREE-V stands to PARSE as specific to general in a P~Ãinian\nrelation: on those inputs where FREE-V applies non-vacuously, V-final stems, satisfying FREE-V\nentails violating PARSE.\nIn fact, FREE-V also stands to ALIGN as specific to general in the P~Ãinian relation: in V-final\nstems, satisfying FREE-V entails that the right MWord boundary (after V) is not a syllable boundary.\nNow let denote whichever of the general constraints PARSE and ALIGN is higher-ranked in Lardil,\nand the other. Consider the possibility that the special constraint = FREE-V is dominated by .\nThen must be active on supraminimal V-final stems, eliminating parses like .CV.CV.CVT.+V,,\nwhere T symbolizes a legal coda as in yi.li.yil.+i,, which violate no other constraints except , which\nis lower-ranked than . So by PTC, since the general constraint\nis active on V-final stems, the\nspecial constraint = FREE-V cannot be active on these inputs: in other words, it may as well not\nbe in the grammar, since it cannot do the work we require of it. Thus this possibility is ruled out:\n\nOptimality Theory\n\n123\n\nChapter 7\n\nmust dominate . Since by definition is the more dominant of PARSE and ALIGN, it follows that\nFREE-V must dominate both PARSE and ALIGN:\n(171) P~Ãini’s Theorem (w.r.t. Final Vowel Parsing), Case 1\nFREE-V >> PARSE\n(172) P~Ãini’s Theorem (w.r.t. Final Vowel Parsing), Case 2\nFREE-V >> ALIGN\nThose who are skeptical of the power of pure reason may wish to examine the following tableau to\nsee the P~Ãinian conclusion affirmed.\n(173) P~Ãini Vindicatus\n/yiliyili/\n\nFREE-V\n\nL .yi.li.yil.+i,\n.yi.li.yi.li.\n\nALIGN\n\nPARSE\n\n*\n\n*\n\n*!\n\nA less obvious interaction between FREE-V and FILLNuc is implicated here as well. It is\nactually possible to omit the final vowel in /wiÛe/ from syllable structure while keeping the overall\noutput bisyllabic: implant an empty final nucleus to replace, as it were, the unparsed vowel. The endof-the-word structure would look like this:\n(174) Simultaneous Under- and Over-parsing /wiÛe/ ÿ *wiÛa\n\nF\nOns\n\nNuc\n\n*\nÛ\n\ne\n\nThis analysis can be transcribed as .wi.Û ~3 .+e, if we keep in mind that no linear order holds between\n3 = Nuc and the segment +e,, as is apparent in the fuller diagram (174). The simultaneous truncation/\n~\naugmentation analysis is plausible because both structures occur independently with other stems;\nwhy should they not be superimposed? That this devious analysis is not correct implies that the\nviolation of FILLNuc by .wi.Û ~3 .+e, is worse than the violation of FREE-V incurred by .wi.Ûe. We must\nhave FILLNuc dominating FREE-V, with results as shown in the following tableau:\n\n124\n\nChapter 7\n\nPrince & Smolensky\n\n(175) No Truncation and Augmentation of the same Stem\n/wiÛe/\n\nFILLNuc\n.wi.Ûe.\n\n.wi.Û ~3 .+e,\n\nFREE-V\n\n*\n*!\n\nThe required ranking is recorded here:\n(176) Unparsed Stem-Final Vowels not Replaced with Empty Nuc\nFILLNuc >> FREE-V\nThis ranking asserts that FREE-V will be sacrificed to avoid epenthesis.62\n\n62\n\nA more interesting line of attack on this problem is potentially available within the present theory.\nSuppose that the constraint responsible for the truncation pattern is not, like FREE-V, in the mold of Bottom\nUp Constructionism (of which extrametricality is a necessary adjunct), but pertains instead to the syllable\nstructure, and, top-down, bans open syllables from final position. Such a constraint is recognizable as a\nspecialization of the NONFINALITY family of §4.3. Instead of demanding that the head of a PrWd or the head\nof a Foot not stand in final position, this constraint demands that the head of a syllable not be final. Call this\nconstraint NONFINSYLHD. Forms like .õa.lu.+k, and .muõ.ku.mu.+õku, satisfy the constraint because no\nsyllable head is truly final, the head of the last syllable being separated from the word-edge by unparsed\nsegmental material. Crucially, augmentation also violates NONFINSYLHD. Thus both .wi.Ûe. and .wi.Û ~3 .+e,\nviolate NONFINSYLHD equally. The analysis .wi.Û ~3 .+e,, which both truncates and augments, has additional\nmarks *ALIGN, *PARSE, and *FILLNuc, which will sink it no matter where those constraints are ranked. It now\nfollows that simple augmentation cannot coexist with truncation, without having to specify a ranking between\nFILLNuc and the constraint that drives truncation — an attractive result. This analysis successfully embodies\nthe idea that augmentation does not go with truncation for the simple reason that augmentation merely\nrecreates the structure that truncation serves to eliminate. Furthermore it releases FILLNuc from having to\ndominate ALIGN, so that it can join FILLOns in a contiguous package of Faithfulness constraints, perhaps\nsimplifying the overall structure of the analysis.\nThe problem with the proposal is that NONFINSYLHD faces yet another method of circumvention:\nclosing the final syllable with an empty Coda. The aimed-for optimum .wi.Ûe. now faces other competitors:\n3 ~.+e,. (Notice that the coda-epenthesized form does not satisfy FREE-V and so is not a\n.wi.Ûe~. and .wi.Û ~\nserious competitor in the analysis proposed in the text.) Depending on details of formulation, one or both of\nthese candidates are likely to satisfy NONFINSYLHD, which .wi.Ûe. fails. (A similar issue arises with respect\nto whole-syllable augmentation: .maÏ.~~3 ~. now begins to look better than .maÏ.~~3 .) Since NONFINSYLHD\nmust dominate ALIGN to allow e.g. muõ.ku.mu.+õku, — ALIGN favors the parsing of stem-final material —,\nthe coda-epenthesized forms cannot be allowed to triumph through victory on NONFINSYLHD.\nThe issue appears to demand a principled resolution, since syllable amplification is not a well-known\nresponse to constraints of the NONFINALITY family. Pending such resolution, we put the matter aside, noting\nthe promise of the approach, both conceptually (it brings truncation into the purview of NONFINALITY) and\nanalytically (it affects the structure of Lardil grammar in ways that may count as simplification).\n\nOptimality Theory\n\nChapter 7\n\n125\n\nALIGN is involved in one last ranking. This constraint forces certain forms to be augmented\nby an entire empty syllable, rather than by a partly empty one. An extra empty node is needed to\ncomplete the empty syllable; FILL violation is driven beyond its absolute minimum. The crucial\nexamples are cases like .maÏ.~~3 . where the stem-final consonant Ï is a possible coda. Compared to\nthe alternative *.ma.Ï ~3 ., the optimal parse has an additional mark *FILLOns. In order that the FILLOns\ndefect be rendered harmless, we must have dominant ALIGN.\n(177) Augment with Complete Syllable\nALIGN >> FILLOns\nThe following tableau lays it out:\n(178) ALIGN compels extra structure\n/maÏ/ ÿ\n\nALIGN\n\nL .maÏ.~~3 .\n.ma.Ï ~3 .\n\nFILLOns\n\n*\n*!\n\nWe have now determined a set of domination relations between pairs or triples of constraints\nby considering candidate comparisons where they conflict. These constraint dominations are\nnecessary in order that the overall constraint ranking be consistent with the Lardil facts. If any one\nof these dominations failed to hold, then the conflicts we have examined would be resolved\ndifferently, and an actual Lardil parse would be less harmonic than at least one competitor, and it\ncould not appear in the output of the grammar.\nAt this point in the analysis we must combine these necessary domination relations to\ndetermine whether they are consistent with some single constraint domination hierarchy. Then we\nmust check that such a hierarchy is logically sufficient to explain the Lardil facts. This final step is\nrequired because in establishing each two- or three-way domination relation, we have only examined\none input and one competitor to the actual Lardil parse. It remains to demonstrate, for the entire\nspectrum of inputs, that the Lardil parse is more harmonic than all competing parses, when all\nconstraints are taken into consideration simultaneously.\n\n126\n\nChapter 7\n\nPrince & Smolensky\n\nThe constraint domination relations we must now unify into a hierarchy are those in\n(165!169, 171!172, 176!177). The unification is performed incrementally in the following table,\nworking down the hierarchy, starting with the superordinate constraints.\n(179) Lardil Constraint Hierarchy Derived:\nConstraint\n\nRanking Justification\n\nRemarks\n\n*COMPLEX,\nCODACOND,\nONS,FTBIN,\nLX.PR\n\nNone crucially\ndominated\n\nAll are unviolated. All force\nviolations.\n\n>>\n\nFILLNuc\n\n>>\n\nLX.PR >> FILLNuc\n\n(168) Empty Nuc to meet word minimality\n\nFREE-V\n\n>>\n\nFILLNuc >> FREE-V\n\n(176) Truncation & augmentation don’t mix\n\nALIGN\n\n>>\n\nFREE-V >> ALIGN\n\n(172) Final V is free\n\nFILLOns\n\n>>\n\nALIGN >> FILLOns\n\n(177) Whole empty F possible to get ALIGN\n\nPARSE\n\n>>\n\nFILLOns >> PARSE\n\n(166) Avoid hiatus by nonparsing of V\n\nPARSE >> &COD\n\n(167) Admit codas\n\n&COD\n\n(165)\n\nNote that this overall ranking is consistent with the following five domination relations,\nwhich were established above in (166!171) as necessary, but which are not among the six used to\ndeduce the hierarchy in (179):\n>>\n\nPARSE\n\n(166)\n\nAvoid Hiatus by nonparsing of V\n\nFILLNuc >>\n\n&COD\n\n(167)\n\nDon’t make potential codas into onsets\n\nLX.PR >>\n\nFILLOns\n\n(168)\n\nCan use whole empty F to get minimal word\n\nLX.PR >>\n\nFREE-V\n\n(169)\n\nDon’t truncate minimals\n\nFREE-V >>\n\nPARSE\n\n(171)\n\nFinal V is free\n\nONS\n\nOf the undominated constraints, we have provided specific evidence for the ranking of FTBIN\nand LX.PR above FILLNuc (168), and for the ranking of ONS above PARSE (166). *COMPLEX and\nCODACOND could in principle be enforced by breach of FILLNuc (with epenthesis to resolve the\nproblematic consonant cluster) or of PARSE (with deletion of one of the cluster members). Because\nFILLNuc>>PARSE is required, it follows that PARSE violation will the least serious infraction in any\nchoice where both are at play. Therefore, *COMPLEX and CODACOND must crucially dominate only\nPARSE. We will not emphasize this refinement, however, and we will persist in representing all\nundominated constraints as grouped together at the top.\n\nOptimality Theory\n\nChapter 7\n\n127\n\n7.3 Verification of Forms\nIn §7.2 we examined interactions among a few constraints at a time, working from pairwise\ncandidate competitions over which the constraints were in conflict. We thereby determined a set of\nrelative domination relations each relating two or three constraint, and we then unified these into the\nconstraint hierarchy (179). If any hierarchy of the constraints in (164) can account for the Lardil\nfacts, it must be this one. (“This one”, that is, up to re-rankings between nonconflicting constraints,\nwhich will involve those in the top-ranked group of table (179); see the discussion following that\ntable.) We arrived at this conclusion by showing, in a variety of cases, that a desired optimum was\nbetter than one of its competitors. To show that the desired optimum is in fact optimal and uniquely\nso, we must establish that it is better than all of its competitors. In addition, we must determine\nwhether this hierarchy correctly generates the complete set of alternations under scrutiny. We will\nconsider the cases summarized in (159) in turn, and check that the actual Lardil parse is indeed\noptimal in each case, as determined by the constraint hierarchy (179).\nIt should be noted that global verification is not a new kind of burden imposed on\ngrammarians by the present approach. Generative theories of phonology with rule-ordering,\nassignment of rules and constraints to various levels, specification of triggering and blocking\nrelations, repair strategies, persistent rules and so on, give rise to complex systems that are often\nargued for on the basis of small-scale interactions. These grammars too can be left unverified overall\nonly at the analyst’s peril. In Optimality Theory, as in all interactionist theories, it is important to\nverify the analysis because interactions often arise which are not obvious to local inspection —\nindeed, this must be so, because getting interesting consequences from simple assumptions is the\nvery rationale for interactionism.\nIn the verification arguments presented here, we will employ a useful methodology for testing\nthe predictions of Optimality Theoretic grammars. To verify that a domination hierarchy yields the\ncorrect output, it is necessary to show that all competing analyses of the input are all less harmonic\nthan the correct analysis. This requires a clear grasp of Gen, and control of a method for establishing\noptimality. The method we will use is this:\n(180) The Method of Mark Eliminability\nTo show that a particular analysis is optimal, consider each of its marks m, and show that any\nway of changing the analysis to eliminate m results in at least one worse mark.63\nWe proceed systematically through the summary of patterns provided in (159), starting with the Cfinal stems.\n\n63\n\nThe logic behind this method is given by the Cancellation/Domination Lemma, stated in (192) and\n(238), of §8, p.142 and p.162, and proved in §A.1 of the Appendix.\n\n128\n\nChapter 7\n\nPrince & Smolensky\n\n7.3.1 Consonant-Final Stems\nStems $ ::. Stem-final consonants, in stems $ ::, non-sub-minimals, are parsed if they satisfy\nthe coda constraint, unparsed otherwise. Examples (159.a!b) are treated in the following tableau:\n(181) Consonant-Final Stems $ ::\n*COMPLEX,FTBIN\nCODACOND,\nFILLNuc FREE-V ALIGN FILLOns PARSE\nONS, LX.PR\nA. i. L\nii.\n\n**\n\n.ken.ta.pal.\n\n.ke.n~3 .ta.pa.+l,\n\nB. i. L\n\n.wa.õal.+k,\n\nii.\n\n.wa.õalk.\n\niii.\n\n.wa.õal.k~3 .\n\nC. i. L\n\n.õa.lu.+k,\n\nii.\n\n.õa.luk.\n\n&COD\n\n*!\n\n*\n\n*\n\n*\n\n*\n\n*! [*COMPLEX]\n*! [CODACOND]\n\n*\n*!\n\n*\n*\n\n*! [CODACOND]\n\n*\n\n*\n*\n*\n\nWhen the stem-final consonant satisfies CODACOND, as in /kentapal/, it appears as a coda in the\noptimal parse (181.A.i). Optimality is readily established. The only marks against (181.A.i) are the\ntwo *&CODs, incurred from parsing n, l as codas. Any more harmonic parse would have to eliminate\none or both these marks.\n•To do so by failing to parse either segment violates the higher- ranked PARSE constraint.\n•To parse either l or n as an onset would require positing an empty nucleus node after it,\nviolating higher-ranked FILLNuc.\nA competitor combining these attempts is shown in (181.A.ii.), along with the marks which show\nit to be less harmonic than the correct output.\nThis provides a concrete example of the general analysis in §6 showing that codas are\npossible when &COD ranks lower than both PARSE and FILLNuc. The basic syllable theory analysis\napplies without modification, because the only constraints coming into play are those of the basic\ntheory, plus ALIGN, which provides a further incentive to parse a stem-final consonant as a Coda.\nHenceforth, we will not comment on the violation marks *&COD that may be incurred in\nparses claimed to be optimal, since, as we have just seen, any attempt to avoid such marks always\nleads to more serious violations. Since &COD violations do not play a decisive role in the\ncompetitions of interest, we will omit &COD from all further tableaux.\n\nOptimality Theory\n\nChapter 7\n\n129\n\nA further constraint comes into play when the final consonant is not a pure coronal, for in that case\nparsing it as a coda violates CODACOND. We see that in the optimal parse of /waõalk/ (181.B.i), the\nfinal k is not parsed, thereby violating both PARSE and ALIGN. This analysis is nonetheless optimal.\n•The only way to avoid both these marks is to parse the final k as a coda (181.B.ii), violating\nthe highest-ranked *COMPLEX and CODACOND.\n•Trying to rescue the k by putting it in the onset of a final syllable with an empty nucleus\n(181.B.iii) still incurs the mark *ALIGN, and trades *PARSE for the worse mark *FILLNuc.\nThe same argument applies in the case of /õaluk/ (181.C.i-ii). The difference is only that the\npenultimate segment is a vowel rather than a possible coda consonant, so the optimal form doesn’t\nviolate &COD and the competitor doesn’t violate *COMPLEX. This doesn’t affect the conclusion,\nsince any attempt to parse the k still violates CODACOND (when parsed as a coda) or FILLNuc (when\nparsed as an onset), both worse than *PARSE and *ALIGN.\n\n130\n\nChapter 7\n\nPrince & Smolensky\n\nStems < ::. With sub-minimal stems the constraints LX.PR and FTBIN come into play, as shown\nbelow in the tableau (182), which displays examples from (159.c!e). Satisfying these constraints\nrequires positing a second syllable with at least one empty position (namely, Nuc).\n(182) Subminimal Consonant-Final Stems\n*COMPLEX,\nCODACOND,\nONS, FTBIN,\nFILLNuc FREE-V ALIGN\nLX.PR\nA. i.\n\nL .maÏ.~~3 .\n\nii.\n\n.maÏ.\n\niii.\n\n.ma.Ï~3 .\n\n*\n\n*!\n\n.Ïel.k~3 .\n\n*\n\n*\n\nB. i.\n\nL\n\n.Ïel.+k,\n\nii.\nC. i.\n\nL\n\n*\n*!\n\n*!\n\n.yak.~~3 .\n\nD. i.\nii.\n\n*\n\n[LX.PR]\n\n*\n\n[LX.PR]\n\n.ya.k~3 .\n\nii.\n\nFILLOns PARSE\n\n*\n*! [CODACOND]\n\n*\n\n*\n\n*\n\n*\n\nL .kaõ.~~3 .\n\n*\n\n*\n\n.ka.õ~3 .\n\n*\n\n*!\n\nIn the first example, /maÏ/, the optimal parse (182.A.i) violates FILLNuc, FILLOns, and &COD [omitted].\n•Any attempt to avoid the worst mark, *FILLNuc will have to give up on the possibility of a\nsecond syllable, as in the faithful parse (182.A.ii). This fatally violates LX.PR or FTBIN, since the\nmonosyllabic parse does not admit binary feet. To avoid violating LX.PR or FTBIN, it is necessary\nto posit an empty Nuc node; we need only consider such parses, then, when seeking optimal parses.64\nAll such parses incur the mark *FILLNuc, so we can therefore ignore this mark in subsequent\n\n64\n\nLardil does not employ vowel lengthening to parse subminimal stems as bimoraic feet. For discussion\nof the constraints relevant to this limitation, see Black 1991, Piggott 1992, Itô & Mester 1992. As argued in\nMcCarthy & Prince 1993 for the parallel case of Axininca Campa, vowel-lengthening is already ruled out\nfor stems CV, because of ALIGN; the pattern .CV.~~3 . preserves MWord/syllable alignment while .CV~.\n. but .tya , of which the latter remains\ndestroys it. For Lardil, this is 50% welcome: we have Ïu.\ny\ninexplicable on the present account (unless it is underlyingly /t /).\nMore generally, Lardil does not use any kind of internal epenthesis to satisfy minimality\nrequirements. Thus, from /maÏ/ we could expect either .ma~Ï. with a long vowel, or bisyllabic .ma.~~3 Ï. or\n.m~3 .~aÏ., both of which are properly aligned. Although the .ma~Ï. type is cross-linguistically attested (see\nMcCarthy & Prince 1986, Lombardi & McCarthy 1991) and therefore suitable for being controlled by a\nrankable constraint, internal syllabic augmentation appears to be unknown and therefore requires a deeper\nand more stable explanation.\n\nOptimality Theory\n\nChapter 7\n\n131\n\ncomparisons. (Note that the null parse, in which no segment is parsed, violates LX.PR and cannot\ntherefore be optimal.)\n•The remaining two marks of the parse (182.A.i), *FILLOns and *&COD, can both be avoided\nby parsing the stem-final consonant Ï not as a Coda but rather than as an Onset (182.A.iii). Parsing\nÏ as an Onset violates ALIGN, fatal because the mark *ALIGN outranks the marks *FILLOns and *&COD\nthat would thereby be avoided. It follows that form (182.A.i) is optimal.65\nThe situation changes, though, when the stem-final consonant (or cluster) is not a legal coda. Now\nthe final consonant is optimally parsed as an onset. With /Ïelk/ (182.B) and /yak/ (182.C), parsing\nthe final k as an onset violates ALIGN, but there is no alternative that is more harmonic. This mark\n*ALIGN could only be avoided by analyzing final k as a Coda, which would violate the superordinate\nconstraint CODACOND (and in (182.B) also *COMPLEX) — yielding a less harmonic parse.\nIt is instructive to compare the fate of the final k in /Ïelk/ (182.B) to that in /waõalk/ (181.B). In the\nlonger word, the final k is not parsed (incurring *PARSE), whereas in the sub-minimal case, the k is\nparsed as an Onset (incurring *FILLNuc).\nWhen LX.PR and FTBIN are not involved, as with /waõalk/, the fact that FILLNuc dominates\nPARSE entails that nonparsing of k is optimal, since *PARSE is the lower-ranked mark. Syllabic wellformedness is achieved through omission of refractory segmental material, rather than through\nsupplying empty structure to support it. But when undominated LX.PR and FTBIN become relevant,\nas with /Ïelk/, they mask the fact that FILLNuc dominates PARSE, and the result reverses. In the\ncompeting analyses of /Ïelk/ in (182.B), it is no longer relevant that PARSE is dominated by FILLNuc,\nsince the low-ranked PARSE violation now comes along with a superordinate failure on LX.PR or\nFTBIN, the minimality enforcers.\nThe final case of /kaõ/ (182.D) works just like the first case (182.A) of /maÏ/, given proper\nformulation of CODACOND, a matter discussed in fn. 60, p.113.\n\nRecall that .maÏ.~~3 . is distinguished from .~~3 .maÏ. on the grounds of proper alignment, as discussed\nin §7.1, p. 114. By ALIGN in the text we mean ALIGN!R, pertaining to final edges. It is LX.PR, construed\nin the Chen-Selkirk manner as requiring initial-edge alignment, that rules out prothesis.\n65\n\n132\n\nChapter 7\n\nPrince & Smolensky\n\n7.3.2 Vowel Final Stems\nStems > ::. The most aggressive truncations in Lardil are observed with supraminimal vowel-final\nstems. The final vowel is unparsed, as are all the preceding consonants which cannot be parsed as\ncodas without violating CODACOND. The examples from (159.f-g) illustrating one, two, and three\nfinal unparsed segments are treated below in the tableau (183).\n(183) Supra-Minimal Vowel-Final Stems\n*COMPLEX,\nCODACOND,\nONS,FTBIN\nLX.PR\nA. i.\n\nL\n\nFILLNuc FREE-V ALIGN FILLOns\n\n.yi.li.yil.+i,\n.yi.li.yi.li.\n\nL\n\n.yu.kaÍ.+pa,\n.yu.kaÍp.+a,\n\nii.\n\n*! [*COMPLEX]\n*! [CODACOND]\n\n.yu.kaÍ.p~3 .+a,\n\n*!\n\niii.\nC. i.\n\n*\n\n*\n\n*\n\n**\n\n*\n\n*\n\n*\n\n*\n\n*!\n\nii.\nB. i.\n\nPARSE\n\n.õa.wu.õa.+wu,\n\n*\n\n**\n\nii.\n\nõa.wu.+õawu,\n\n*\n\n***!*\n\nD. i.\n\nL .muõ.ku.mu.+õku,\n\n*\n\n***\n\nii.\n\n.muõ.ku.muõ.+ku,\n\n*\n\n**\n\nL\n\n*! [CODACOND]\n\nMost striking here is the way that the domination hierarchy permits such flagrant violations\nof PARSE as those observed in .muõ.ku.mu.+õku,, while controlling these violations so that in each\ncase only the correct number of segments are left unsyllabified.\nPARSE is ranked low enough in the hierarchy so as to be out-ranked by several constraints\nwhich conflict with it: relevantly, CODACOND, FILLNuc and FREE-V. With these three in dominant\nposition, it is optimal to leave segments out of syllable structure (*PARSE) if\n• for vowels, parsing them violates FREE-V\n• for consonants, assigning them to coda position violates CODACOND or assigning onset\nstatus violates FILLNuc.\n\nOptimality Theory\n\nChapter 7\n\n133\n\nOn the other hand, while ranked low, PARSE is nonetheless operative in Lardil grammar (as\nin every grammar). Any failure to parse which is not required to meet a higher-ranked constraint\nrenders the overall parse less harmonic, due to the avoidable marks *PARSE thereby incurred.\nTo see how these constraint interactions play out in the actual cases, consider first /yiliyili/ (183.A).\nThe optimal parse incurs the marks *ALIGN, *PARSE, and *&COD (the last being unmentioned in the\ntableau).\n•To avoid the two highest marks, *ALIGN and *PARSE, the final segment would have to be\nparsed. But this would violate FREE-V, a higher-ranked constraint (183.A.ii).\n•As mentioned above in the discussion of (181.A), the lowest mark *&COD, cannot be\navoided without incurring higher marks, because the constraints *FILLNuc, PARSE, and *&COD are\nranked in a pattern characteristic of coda-permitting languages (167),p.121.Thus (183.A.i) is optimal.\nThe relative overall Harmonies of .yi.li.yil.+i, (183.A.i) and .yi.li.yi.li. (183.A.ii) pointedly\nillustrate the strictness of strict domination. Fully parsed .yi.li.yi.li. is less harmonic than truncated\n.yi.li.yil.+i, even though it violates only one constraint, while the truncated form violates three of the\nfour lower-ranked constraints (including !COD). Indeed, a form like .yi.li.yi.li. would seem on first\nglance to be a perfect parse, consisting as it does entirely of optimal CV syllables, and constituting\na perfectly faithful parse in which underlying segments are in one-to-one correspondence with\nsyllable positions. Such is the strength of FREE-V in Lardil, and of the strictness of strict domination,\nthat the sole mark *FREE-V renders the form less harmonic than the optimal output, which violates\nfully three of the four constraints ranked lower than FREE-V.\nThe fate of the stem /yukaÍpa/ (183.B) is almost identical to that of /yiliyili/ (183.A), the only\ndifference being that in the optimal parse, the penultimate consonant (p) remains unsyllabified.\n•The attempt to avoid *ALIGN and *PARSE by syllabifying the final vowel violates higherranked FREE-V, just as with /yiliyili/.\n•Attempts to save the penultimate consonant, and thereby remove the second *PARSE mark,\nmust also decrease Harmony. Parsing p with Í in a single coda (183.B.ii) violates the superordinate\nconstraints *COMPLEX and CODACOND. Parsing it as an onset (183.B.iii) requires a following empty\nNuc node, thus incurring a mark *FILLNuc which is worse than the mark *PARSE thereby avoided.\nThe stem /õawuõawu/ (183.C) is identical in all relevant respects to /yukaÍpa/ (183.B) except that\nthe antepenultimate segment is a vowel; in the optimal output, the last parsed segment is a vowel.\nThe proof of optimality is virtually the same as that just given.\nThe resulting phonetic form [õawuõa] is vowel-final; derivational accounts with a\nfinal-vowel-deletion rule (as in previous interpretations of the phenomenon), must ensure that this\nrule cannot reapply to further delete the now-final a and, presumably, with it the preceding illicit\ncoda consonant õ. This would result in the form [õawu], which is subject to further truncation,\nblocked then by a minimal word constraint. In (183.C.ii) we show the competing output [õawu],\n\n134\n\nChapter 7\n\nPrince & Smolensky\n\nphonologically, .õa.wu.+õawu,, to allay any fears that such iterated truncation, with more than one\nvowel unparsed, can arise to plague the present account. Because the second a is not a word-final\nvowel, it plays no role in assessing violations of FREE-V. Parsing it (183.C.i) is quite irrelevant to\nthe constraint FREE-V. Consequently, the additional mark *PARSE that results from leaving it\nunparsed (183.C.ii) is entirely unjustifiable, as it avoids no other marks. The additional PARSE\nviolation is fatal to the overtruncated [õawu].\nThe conclusion still holds if the preceding consonant were not õ but, say, n, which could\nsafely be parsed as a coda, thereby eliminating the fourth *PARSE mark from (183.C.ii). The fourth\nmark is superfluous; the third *PARSE incurred by not parsing a, a single step beyond necessity, is\nsufficient to decide the competition.\nThe final example .muõ.ku.mu.+õku, (183.D) works just like the others. It is of some interest\nthat the antepenultimate segment õ is unparsed even though it is followed by k. In a derivational\naccount, the sequence of rules which accounts for this is: delete final vowel u, delete illegal coda\nconsonant k, delete illegal coda consonant õ. These steps are serially ordered, since prior to deleting\nu, the k is parsable as an onset; and prior to deleting k, the õ is parsable as a coda. In the present\naccount, there is no derivational sequence and no deletion. The entire final parse is evaluated once\nand for all; everything follows from the primary syllabification of the input string. In the optimal\nanalysis, u is not syllabified; neither is k; nor õ. Parsing any or all of these segments introduces\nviolations of the constraints on syllabification and on the morphology/prosody relation, violations\nmore serious than the three *PARSE marks incurred by not syllabifying the segments in question. The\none case not seen before is the alternative of parsing only õ, shown in (183.D.ii). The undominated\nconstraint CODACOND is violated because the coda õ is linked to no following onset. There is an\nappropriate underlying segment, of course: k; but in the total parse under evaluation, there is no\nfollowing Onset.\n\nStems = ::. Unlike longer stems just reviewed, those vowel-final stems which are exactly minimal\nmust have their final vowel parsed. The example (159.h) is shown in the following tableau:\n(184) Minimal Vowel-Final Stems\n*COMPLEX,\nCODACOND,FTBIN\nONS, LX.PR\nFILLNuc FREE-V ALIGN FILLOns PARSE\ni. L\n\n.wi.Ûe.\n\nii.\n\n.wiÛ.+e,\n\niii.\n\n.wiÛ.~~3 .+e,\n\n*!\n\n*\n\niv.\n\n.wi.Û~3 .+e,\n\n*!\n\n*\n\n*\n*! [Lx.Pr]\n\n*\n\n*\n*\n\n*\n*\n\nIn minimal stems, FREE-V conflicts with LX.PR and FTBIN. The optimal parse violates FREE-V,\nbecause failing to parse the final vowel leads to violation of LX.PR or FTBIN (184.ii), unless empty\nnodes are also posited. Such empty nodes are optimal in sub-minimal consonant final stems (182),\n\nOptimality Theory\n\nChapter 7\n\n135\n\nand we must consider them here. In (184.iii), Û is parsed as a Coda and followed by an empty Onset\nand Nucleus; in (184.iv), Û is parsed as an Onset and followed by an empty Nucleus. In both cases,\nthe high-ranking mark *FILLNuc, absent in the optimal parse, proves fatal.\n\n7.4 Discussion\nSeveral features of the analysis deserve specific comment.\nGrammar building. The typical result in Part I involves the ranking of only a few\nconstraints. The Lardil analysis shows that the formal principles laid out in Part I apply smoothly and\nwithout enrichment to an intricate grammatical system. Other work in the theory offers similar\ndemonstrations; we refer the interested reader to the works cited at the end of §1.\nPitfalls of pre-theoretic intuitions of Harmony. Lardil Final Vowel Deletion is taken by\nGoldsmith (1993) to be a plainly ‘anti-harmonic rule’ — one whose application reduces the\nHarmony of the representation. This construal motivates his proposal that linguistic derivations\ninvolve a set of non- or even anti-harmonic rule applications between levels, in addition to serial\nharmonic rule applications within levels.\nHarmonic rule application is characterized as follows: “... phonological rules apply ... just\nin case their output is better than their input with respect to some criteria specified by a phonotactic\n(of the relevant level)” (Goldsmith 1993:252). He then observes that “word-final vowels are\nperfectly satisfactory” in Lardil. Since there is no phonotactic involved — no descriptively-true\ngeneralization about surface word structure — he is led to conclude that harmonic considerations\nare irrelevant. The claim is, of course, untenable: the truncation pattern respects minimality\nlimitations that are the direct consequence of prosodic well-formedness constraints (Wilkinson 1986,\n1988).\nAlthough we have full sympathy with the general programmatic notion that harmonic\nconsiderations are central to the assignment of linguistic form, we suggest that the problem with the\nGoldsmith proposal for Lardil lies in its reliance on pre-theoretic notions of Harmony, which are\nsimply too ill-defined to provide much of a guide to real-world complexities. Although it seems\nreasonable that rules ought to apply when their output is better “with respect to some criteria\nspecified by a phonotactic,” in realistic situations the output is just as likely to be worse by some\ncriteria specified by other phonotactics, and this worseness can very well be crucial. And, if we are\nright about the universality and generality of constraints, the motivating factors are unlikely to be\nlimited to anything as parochial as a phonotactic presumably is.\nGoldsmith states, plausibly, that “the bulk of phonological rules apply in order to arrive at\nrepresentations that maximally satisfy constraints (or, equivalently, schemata) that involve\nstructuring phonological information [emph. supplied].” But without a well-defined notion of what\nit is to maximally satisfy a set of potentially conflicting constraints, there is in general no way to\nascertain whether a given process is harmonic or the direct opposite; intuition, even steeped in\nscholarship, offers no sure guide.\n\n136\n\nChapter 7\n\nPrince & Smolensky\n\nIn the account developed here, the Harmony of the Lardil analysis is defined in such a way\nthat supra-minimal words with final unparsed vowels are more harmonic than those with final parsed\nvowels. In the appropriate theoretical framework, then, we can formally acknowledge a constraint,\nFREE-V, which asserts that, all other things being equal, leaving word-final vowels unparsed is\noptimal. This constraint not only fits into the overall constraint hierarchy of Lardil, along with other\npre-theoretically more intuitive constraints; it is recognizable (indeed, as is already observed in\nWilkinson 1986) as a slightly peculiar member of a universal family of ‘extrametricality’ constraints,\nwhich deal with the nonfinality of prominence. Understood in this way, its interaction with\nminimality considerations — patently harmonic in character — is entirely expected.\nRelevance of the Basic Syllable Structure Theory. The Basic Syllable Structure Theory\nassumes a certain level of idealization in order to explicate fundamental universal aspects of syllable\nstructure theory. Nonetheless, it forms without modification a crucial sub-structure within the Lardil\nanalysis, indicating that further progress in developing and applying the syllable theory can proceed\nby addition to the basic module rather than by catastrophic renovation of its premises.\nRelation between universal and language-particular phonology. The Basic Syllable\nStructure constraints and the additional constraints brought forth in the Lardil analysis are either\nstrictly universal or mildly parametrized versions of recognizably universal constraints. The general\napproach to typological analysis exemplified by the Basic Syllable Structure Theory, like the\nsubstantive content of its constraints, is carried over intact into the more richly detailed context of\nLardil. As promised in our characterization of the theory, Universal Grammar provides a set of\nconstraints (some parametrized) and the primary mechanism of cross-linguistic variation is the\ndifferent dominance rankings which are chosen by individual languages.\nGeneralization patterns. All decisions required to determine the correct analysis of a given\nstem are handled by the single notion of constraint domination. This includes interactions that would\nbe described in other accounts as involving constraints and rules, ontologically quite different and\nwith problematic interaction. A complete explication is given for how a constraint can appear to\ntrigger or block the application of a rule. Such effects are handled by the same mechanism that\nhandles basic syllabification and all other components of structural analysis: maximizing Harmony,\nas defined through a constraint hierarchy.\nStrictness of strict domination. In several examples the correct analysis violates many\nconstraints, and its optimality rests crucially on the fact that competitors with a cleaner record overall\nhappen to violate some single dominant constraint. Recall the discussion of /yiliyili/ in §7.3.2: a\nstrong contender violating just one constraint is bested by an optimal parse violating three of the four\nless dominant constraints. This effect highlights the content of the central evaluative hypothesis of\nOptimality Theory, and sets the theory apart from others in which richer notions of ‘weighting’ and\n‘trade-off’ are entertained.\nParallelism and representation. The theory operates by evaluating a total candidate parse,\nwhich contains the underlying form, over the entire constraint hierarchy. This non-sequential\napproach offers at least two advantages in the Lardil analyis. First, since the underlying form is\n\nOptimality Theory\n\nChapter 7\n\n137\n\npresent in the structure being evaluated, the status of a vowel as word- or stem-final does not change;\nthus the constraint FREE-V can unproblematically refer to word-final vowels. This constraint is then\nnot violated by the plethora of Lardil forms containing phonetically final vowels that are not\nphonologically final, analyses where the last parsed segment is a vowel which is followed by\nunparsed segments. This eliminates the issue that arises in serial theories of whether a rule of Final\nVowel Deletion can reapply during the derivation (see the discussion of /õawuõawu/ in §7.3.2).\nThe second advantage involves the parallel assessment of constraints on a total analysis.\nConsider the stem /kaõ/, which is analyzed as .kaõ.~~3 ., phonetic [kaõka] (183.D.i). As observed\nin Kirchner 1992a, serialist theories have difficulty explaining how õ surfaces as a coda.\nSuppose there are rules Syllabification and Augmentation that must apply in sequential steps.\nSyllabification must have a chance to apply before Augmentation in order to establish the needed\ndistinction between /maÏ/ ÿ [.maÏ.Ûa.] (183.A.i), in which the stem forms a syllable, and /yak/ÿ\n[.ya.ka.] (183.C.i), in which the stem-final consonant is attached to the next syllable over.\nAugmentation inserts an onset only when the stem-final consonant is already parsed as a coda.\nNow consider /kaõ/. When Syllabification applies, the õ is no more syllabifiable as a coda\nthan the k of /yak/ — õ can only be a coda when linked to a following onset. The situation is\nobviously not improved by trying to allow Augmentation to precede Syllabification, with the aim\nof making it possible for õ to be syllabified as a coda, for then it would be unclear why stem-final\nconsonants should ever be parsed as anything but onsets. In short, Syllabification and Augmentation\nare mutually interdependent: each ‘triggers’ the other. Augmentation triggers the syllabification of\na coda, which itself triggers the insertion of an Onset (which itself triggers coda-syllabification,\nwhich itself ...). This kind of ordering pathology is an artifact of the derivational treatment, which\nresembles but exceeds in severity the problems discussed above for Bottom-Up Constructionism in\nprosodic theory. Interestingly, it is not resolvable by allowing Syllabification to apply freely in a\nserial derivation, an approach which Itô 1986 successfully uses to solve other similar problems. We\nconclude that the coincidence of stem and syllable edges cannot be successfully derived from serial\n(including cyclic) application of syllabification rules.\nWhen all of the relevant constraints are assessed in parallel, as in Optimality Theory, an\nentire completed parse is subject to evaluation. At the point where the status of õ as a licit coda is\njudged, each candidate analysis has already committed once and for all to the presence or absence\nof a following Onset node. The necessity of this kind of information flow is a key prediction of the\npresent theory, and a number of further cases of crucial parallelism are discussed in McCarthy &\nPrince 1993. The crux of the matter is that the grammar must determine which total analysis is wellformed — a task impeded by the use of serial algorithms to build structure step-by-step.\n\n139\n\n8. Universal Syllable Theory II:\nOrdinal Construction of C/V\nand Onset/Coda Licensing Asymmetry\n\nS\n\nyllabification must reconcile two conflicting sources of constraint: from the bottom up, each\nsegment’s inherent featural suitability for syllable peak or margin; and from top down, the\nrequirements that syllables have certain structures and not others. The core conflict can be addressed\nin its most naked form through the idealization provided by CV theory. Input C’s need to be parsed\nas margins; input V’s need to be parsed as peaks. Syllables need to be structured as Onset-PeakCoda; ideally, with an onset present and a coda absent. In the Basic Theory, only one input segment\nis allowed per syllable position. Problematic inputs like /CCVV/ are ones which bring the bottom-up\nand top-down pressures into conflict. These conflicts are resolved differently in different languages,\nthe possible resolutions forming the typology explored in §6.\nThe CV theory gives some articulation to the top-down pressures: syllable shapes deviate\nfrom the Onset-Peak ideal in the face of bottom-up pressure to parse the input. By contrast, the\nbottom-up is construed relatively rigidly: C and V either go into their determined positions, or they\nremain unparsed. In real syllabification, of course, a richer set of possibilities exists. A segment\nideally parsed as a peak may actually be parsed as a margin, or vice versa, in response to top-down\nconstraints on syllable shape. One of the most striking examples of the role of optimality principles\nin syllabification, Tashlhiyt Berber (§2), exploits this possibility with maximal thoroughness. Berber\nsyllabification on the one hand and CV syllabification on the other constitute extremes in the\nflexibility with which input segments may be parsed into different syllable positions in response to\ntop-down pressure. In between the extremes lies the majority of languages, in which some segments\ncan appear only as margins (like C in the CV theory), other segments only as peaks (like V), and the\nremaining segments, while ideally parsed into just one of the structural positions, can under\nsufficient top-down pressure be parsed into others.\nIn this section we will seek to unify the treatments of the two extremes of syllabification,\nBerber and the CV theory. Like the CV theory, the theory developed here will deal with an abstract\ninventory of input segments, but instead of just two abstract segments, each committed to a structural\nposition, the inventory will consist of abstract elements distinguished solely by the property of\nsonority, taken to define a strict order on the set of elements. For mnemonic value we denote these\nelements a, i,..., d, t; but it should be remembered that all dimensions other than sonority are\nidealized away. In the CV theory, the universally superordinate constraints *M/V and *P/C prohibit\nparsing V as a margin or C as a peak. In the more realistic theory we now turn to, the corresponding\nconstraints are not universally superordinate: the constraints against parsing any segment \" as a\nmargin (*M/\") or as a peak (*P/\") may vary cross-linguistically in their rankings. What universal\ngrammar requires is only that more sonorous segments make more harmonic peaks and less\nharmonic margins.\nFrom these simple assumptions there will emerge a universal typology of inventories of\npossible onsets, peaks, and codas. The inventories will turn out to be describable in terms of derived\nparameters BOns, BNuc, and BCod, each with values ranging over the sonority order. The margin\ninventories are the sets of segments less sonorous than the corresponding parameter values BOns or\n\n140\n\nChapter 8\n\nPrince & Smolensky\n\nBCod, and the peak inventory is the set of segments more sonorous than the value of BNuc. Languages\nin which BOns > BNuc are therefore languages with ambidextrous segments, which can be parsed as\neither onset or nucleus. The following diagram pictures the situation; the double line marks the zone\nof overlap.\n(185) Languages with Ambidextrous Segments\nonsets\n2 BOns\nS))))))))))))a4444444444444k)))))))))))) ÷ greater sonority\nBNuc ÷ nuclei\n÷\n÷\n\n2\n\n2\n\nThe theory entails a universal licensing asymmetry between onsets and codas: codas can\ncontain only a subset, possibly strict, of the segments appearing in onsets. This fundamental licensing\nasymmetry will be shown to follow from the asymmetry between Onset and Coda in the Basic\nSyllable Structure Constraints. From the fact that Onsets should be present and Codas absent, it will\nfollow in the theory that Coda is a weaker licenser.66 To our knowledge, no other approach has been\nable to connect the structural propensities of syllables with the licensing properties of syllabic\npositions, much less to derive one from the other. This is surely a significant result, one that indicates\nthat the theory is on the right track in a fundamental way. The exact nature of the obtained licensing\nasymmetry has some empirical imperfections which can be traced to the oversimplified analysis of\ncodas in the internal structure of the syllable, and we suggest possible refinements.\nThe present section constitutes a larger-scale exploration of our general line of attack on the\nproblem of universal typology. Universal Grammar provides a fixed set of constraints, which\nindividual languages rank differently in domination hierarchies; UG also provides certain universal\nconditions on these hierarchies, which all languages must respect. The results obtained here involve\na further development of the basic idea: parametrization by ranking. The parameters BOns, BNuc, and\nBCod are epiphenomenal, in that they do not appear at all in Universal Grammar, or indeed, in\nparticular grammars: they are not, for example, mentioned in any constraint. These parameters are\nnot explicitly set by individual languages. Rather, individual languages simply rank the universal\nconstraints, and it is a consequence of this ranking that the (derived, descriptive) parameters have\nthe values they do in that language. The procedures for reading off these parameter values from a\nlanguage’s constraint domination hierarchy are not, in fact, entirely obvious.\nThe analysis developed here introduces or elaborates several general concepts of the theory:\n(186) Push/Pull Parsing: The parsing problem is analyzed in terms of the direct conflict between\ntwo sets of constraints:\na ASSOCIATE constraints\nPARSE, FILL, ONS, and the like, which penalize parses in which input segments or\nstructural nodes lack structural associations to a parent or child;\n\n66\n\nThe demonstration will require some work, however; perhaps this is not surprising, given the simplicity\nof the assumptions.\n\nOptimality Theory\n\nChapter 8\n\n141\n\nb DON’T-ASSOCIATE constraints\n*M/V, *P/C, and !COD and their like, which penalize parses which contain structural\nassociations of various kinds.\n(187) Universal Constraint Sub-Hierarchies: The DON’T-ASSOCIATE constraints *M/V, *P/C,\nsuperordinate in the CV theory, are replaced by an articulated set of anti-association\nconstraints *M/a, *M/i, ..., *M/d, *M/t; *P/a, *P/i,..., *P/d, *P/t which penalize associations\nbetween Margin or Peak nodes on the one hand and particular input segments on the other.\nUniversal Grammar requires that the domination hierarchy of each language rank these\nconstraints *M/\", *P/\" relative to one another in conformity with the following universal\ndomination conditions:\n*M/a >> *M/i >> þ >> *M/d >> *M/t\n(Margin Hierarchy)\n(Peak Hierarchy)\n*P/t >> *P/d >> þ >> *P/i >> *P/a\nThe Margin Hierarchy states that it’s less harmonic to parse a as a margin than to parse i as\nmargin, less harmonic to parse i as a margin than r, and so on down the sonority ordering.\nThe Peak hierarchy states that it’s less harmonic to parse t as a peak than d, and so on up the\nsonority order.\n(188) Associational Harmony: The universal Margin and Peak Hierarchies ensure the following\nuniversal ordering of the Harmony of possible associations:\nM/t TM M/d TM þ TM M/i TM M/a\nP/a TM P/i TM þ TM P/d TM P/t\nThese represent the basic assumption that the less sonorous an element is, the more harmonic\nit is as a margin; the more sonorous, the more harmonic it is as a Peak.\n(189) Prominence Alignment: These universal rankings of constraints (187) and ordering of\nassociational Harmonies (188) exemplify a general operation, Prominence Alignment, in\nwhich scales of prominence along two phonological dimensions are harmonically aligned.\nIn this case, the first scale concerns prominence of structural positions within the syllable:\nPeak > Margin\nwhile the second concerns inherent prominence of the segments as registered by sonority:\na>i>þ>d>t\n(190) Encapsulation: It is possible to greatly reduce the number of constraints in the theory by\nencapsulating sets of associational constraints *M/\", *P/\" into defined constraints which\nexplicitly refer to ranges of sonority. This corresponds to using a coarse-grained sonority\nscale, obtained by collapsing distinctions. This must be done on a language-specific basis,\nhowever, in a way sensitive to the language’s total constraint hierarchy: which sets of\nassociational constraints can be successfully encapsulated into composite constraints depends\non how the language inserts other constraints such as PARSE, FILL, ONS, and so on, into the\nMargin and Peak Hierarchies, and how these two Hierarchies are interdigitated in the\nlanguage. Encapsulation opens the way to developing a substantive theory of the sonority\nclasses operative in syllable structure phenomena.\nAlong with these conceptual developments, this section introduces a collection of useful\ntechniques for reasoning about constraint domination hierarchies in complex arenas such as that\ndefined by the segmental syllable theory. A few of these techniques are:\n\n142\n\nChapter 8\n\nPrince & Smolensky\n\n(191) Harmonic Bounding for Inventory Analysis: In order to show that a particular kind of\nstructure n is not part of a universal or language-particular inventory, we consider any\npossible parse containing n and show constructively that there is some competing parse (of\nthe same input) which is more harmonic; thus no structure containing n can ever be optimal,\nas it is always bounded above by at least one more-harmonic competitor. (This form of\nargument is used to establish the distribution of epenthesis sites in §6.2.3.)\n(192) Cancellation/Domination Lemma: In order to show that one parse B is more harmonic than\na competitor A which does not incur an identical set of marks, it suffices to show that every\nmark incurred by B is either (i) cancelled by an identical mark incurred by A, or (ii)\ndominated by a higher-ranking mark incurred by A. That is, for every constraint violated by\nthe more harmonic form B, the losing competitor A either (i) matches the violation exactly,\nor (ii) violates a constraint ranked higher.\n(193) The Method of Universal Constraint Tableaux: A generalization of the method of\nlanguage-specific constraint tableaux is developed; it yields a systematic means for using the\nCancellation/Domination Lemma to determine which parse is optimal, not in a specific\nlanguage with a given constraint hierarchy, but in a typological class of languages whose\nhierarchies meet certain domination conditions but are otherwise unspecified.\nExposition proceeds as follows. In §8.1 we define the Basic Segmental Syllable Theory;\nusing our analyses of Berber and the Basic CV Syllable Structure Theory as starting points, we\ndevelop most of the basic notions mentioned above, including Associational Harmony and\nProminence Alignment.\nThe Basic Segmental Syllable Theory defined in §8.1 is then subjected to extended analysis\nin §8.2. The formal techniques mentioned above are introduced and applied, leading ultimately to\na set of necessary and sufficient constraint domination conditions involving *M/\" (or *P/\") which\ngovern whether the segment \" is a possible onset (or nucleus). Some nontrivial analysis is required,\nbecause we are answering the following nontrivial question: considering all possible orderings of\n(a fair number of) constraints, and considering all possible input strings, when is parsing some\nsegment \" as an onset more harmonic than all possible alternative parses? It is possible to skim the\ndetailed analysis; this should suffice for reading the rest of §8, which is considerably less technical.\nThe necessary and sufficient conditions derived in §8.2 are then cashed in (§8.3) for a\nuniversal typology of inventories of onset and nucleus segments. We consider codas, and derive and\ndiscuss the onset/coda licensing asymmetry result. We also derive the procedures for extracting a\nlanguage’s parameters BOns, BNuc, and BCod from its constraint hierarchy.\nIn §8.4 we develop and briefly discuss the Encapsulated Segmental Syllable Theory.\nGiven that this section contains a considerable amount of analysis, it is worth taking a moment at\nthe outset to see a bit more clearly why extended analysis is necessary to establish the results we will\nobtain. The most complex result is the onset/coda licensing asymmetry, which can be stated as\nfollows:\n(194) Cross-linguistically, the inventory of possible codas is a subset of the inventory of possible\nonsets, but not vice versa.\nTo see just what we’ll need to show in order to establish this result, we will give a step-by-step\nreduction of (194) to the elements in terms of which it must actually be demonstrated:\n\nOptimality Theory\n\nChapter 8\n\n143\n\n(194) a.\n\nFor all languages admitted by Universal Grammar, the inventory of possible codas\nis a subset of the inventory of possible onsets, but not vice versa.\n\nb.\n\nformed by ranking the Universal syllable structure\nFor all constraint hierarchies\nconstraints as allowed by Universal Grammar, the inventory of possible codas is a\nsubset of the inventory of possible onsets, but not vice versa.\n\nc.\n\nof the Universal syllable structure constraints allowed by\nFor all rankings\nUniversal Grammar, and\nfor all segments 8,\nif 8 is a possible coda in the language given by\nthen 8 is a possible onset in\n,\nbut not vice versa.\n\nd.\n\nof the Universal syllable structure constraints allowed by\nFor all rankings\nUniversal Grammar, and\nfor all segments 8,\nif there is an input string I8\ncontaining 8\nfor which the optimal parse (w.r.t.\n) is one in which 8 is\nassociated to Cod,\nthen there is an input string I8N\ncontaining 8\nfor which the optimal parse (w.r.t.\n) is one in which 8 is\nassociated to Ons;\nbut not vice versa.\n\ne.\n\nFor all rankings\nof the Universal syllable structure constraints allowed by\nUniversal Grammar, and\nfor all segments 8,\nif there exists an input string I8\ncontaining 8\nfor which there is a parse BCod/8 in which 8 is associated to\nCod\nsuch that\nif C is any other candidate parse of I,\nthen BCod/8 is more harmonic than C w.r.t the ranking\n(BCod/8 TM C),\nthen there exists an input string I8N\ncontaining 8\nfor which there is a parse BOns/8N in which 8 is associated to\nOns\nsuch that\nif CN is any other candidate parse of I8N\nthen BOns/8N is more harmonic than C’ w.r.t. the\nranking\n(BOns/8N TM CN);\nbut not vice versa.\n\n144\n\nChapter 8\n\nPrince & Smolensky\n\nIn the final formulation, as in all the others, the phrase ‘but not vice versa’ means that if ‘Cod’ and\n‘Ons’ are interchanged in the proposition which precedes, then the resulting proposition is false. The\nlogical quantifiers and connectives in this assertion have been set in boldface in order to indicate the\nlogical structure of the proposition without resorting to predicate calculus. The innermost embedded\npropositions (BCod/8 TM C, and likewise for the primed parses) are themselves somewhat complex\npropositions, defined in §5.1, which involve comparisons of the hosts of marks incurred by parses\nof entire strings.\nThe strategy pursued in this chapter is to approach the complexity inherent in such a result\nincrementally, demonstrating the onset/coda licensing asymmetry after accumulating a series of\nincreasingly complex results on segmental inventories. We begin with the most fundamental notion,\nassociational Harmony.\n\n8.1 Associational Harmony\nTo move from the Basic CV Syllable Structure Theory to the Basic Segmental Syllable Structure\nTheory, we need to move from CV strings to segmental string inputs. All we will need to do, in fact,\nis to replace the CV association constraints *M/V (121) and *P/C (122), with constraints that are\nsensitive to the relative Harmonies of pairings between, on the one hand, different segments 8, and,\non the other, structural nodes of type M (margin: Ons and Cod) or P (peak: Nuc). Thus we will need\nto replace *M/V and *P/C by constraints such as *M/8 and *P/8 which refer to particular segments\n8. From these, we will reconstruct categories of segments which behave to first approximation as\nC and V do in the CV theory.\nWe have already seen in Berber the need to make the Harmony of P/8 associations sensitive\nto the sonority of 8; more sonorous segments make more Harmonic syllable peaks. This was\nembodied in the constraint HNUC; it was the central element in our Berber analysis and we claimed\nit to be an element of universal syllable structure theory. Now is the time to spell out this aspect of\nHarmonic syllable structure theory; considerable elaboration of the ideas is necessary, and we can\nmotivate the necessary development by returning to Berber to inspect a minor detail the\nconsequences of which for the general theory turn out to be substantial.\n\n8.1.1 Deconstructing HNUC: Berber, Take 1\nIn our earlier analysis of Berber, we assumed that over- and under-parsing (a.k.a. epenthesis and\ndeletion) are forbidden, that syllable positions are non-complex, and that onsets (except phraseinitially) are required. Together, these had the consequence that in certain cases even highly sonorous\nsegments such as i and u will be parsed as onsets (and realized as y and w, respectively). It turns out,\nhowever, that the most sonorous segment, a, can never be parsed as a margin; it is the only segment\nin Berber that fails to be parsable both as an onset and as a nucleus. Since Berber morphology can\nin fact generate an input containing /aa/, one of our simplifying assumptions must give way; in fact,\nin this one situation, Berber tolerates overparsing, generating an empty onset, so that /aa/ ÿ .á.~á\n(phonetically aya; Guerssel 1985).\n\nOptimality Theory\n\nChapter 8\n\n145\n\nWe can apply the Basic Syllable Structure Theory results of §6 to incorporate this fact about\n/a/ into our Berber analysis as follows. The syllable structure is 3CV(C)ep, so according to the Onset\nTheorem (136), since onsets are required, enforced via overparsing, we must have\n(195) Berber Onsets. {ONS, PARSE} >> FILLOns\nBy the Coda Theorem (138), since codas are not required, we must also have\n(196) {FILLNuc, PARSE} >> !COD.\nThe superordinate constraint *M/V (121) is replaced by\n(197) *M/a: a must not be parsed as a margin.\nThe segment a is the one segment (like V in CV theory) that is so unacceptable as a margin that it\nis more Harmonic to posit an empty onset and thereby violate FILLOns; thus we must have:\n(198) Berber Epenthesis. *M/a >> FILLOns >> HNUC\nThat FILLOns must dominate HNUC follows from the fact that, aside from *M/a, no other constraint\ncan force epenthesis; in particular, HNUC cannot; otherwise, an onset would be epenthesized before\nevery underlying segment, allowing it to be parsed as a nucleus and thereby increasing nuclear\nHarmony.\nNow corresponding to *P/C (122) in the CV theory, in our Berber analysis we have HNUC:\nWhereas *P/C says that C must not be parsed as a peak, HNUC gives an articulated scale for the\nHarmony of associations P/8, governed by the sonority of 8. For now, then, we will replace *P/C\nby HNUC. As we have seen earlier, the onset requirement in Berber takes precedence over the\nforming of more Harmonic nuclei, but nuclear Harmony dominates avoidance of codas, so\n(199) Berber Onset/Nucleus/Coda Interaction. ONS >> HNUC >> !COD\nWe can now assemble these relative domination conditions into a constraint hierarchy for Berber:\n(200) Berber Hierarchy: {ONS, PARSE, FILLNuc, *M/a} >> FILLOns >> HNUC >> !COD\nThus we see in the following tableau, for example, how /aa/ does indeed trigger epenthesis, whereas\n/ia/ or /ai/ or /tk/ does not (as usual, we are assuming that ONS in Berber treats the beginning of a\nphrase as an acceptable onset). Here, as elsewhere in this chapter, we analyze hypothetical inputs\nwhich contain only the material necessary to establish the analytical point at hand, factoring out\nirrelevant complexities and distractions.\n\n146\n\nChapter 8\n\nPrince & Smolensky\n\n(201) Berber Exceptional Epenthesis\nONS\n\nPARSE\n\nFILLNuc\n\n*M/a\n\nFILLOns\n\nHNUC\n\n*\n\náá\n\n!COD\n\n/aa/ ÿ\n\nL\n\n.á.~á.\n.aá.\n.á+a,.\n.á.á.\n\ná\n\n*!\n\ná\n\n*!\n\náá\n\n*!\n\n/ia/ ÿ\n\nL\n\ná\n\n.iá.\n.í.~á.\n\n*!\n\n.ía.\n\n*!\n\náí\ní\n\n*\n\ná\n\n*\n\n/ai/ ÿ\n\nL\n\n.ái.\n.á.~í.\n\n*!\n\n.aí.\n\n*!\n\náí\ní\n\n/tk/ ÿ\n\nL\n\nk'\n\n.tk.\n'\n.t~3 k.\n\n*!\n\n*\n\nWhile this solution is adequate descriptively, it is somewhat unsatisfactory explanatorily. For the\nconstraint *M/a we have introduced expresses the markedness of a as a Margin; and of course the\nstrong affinity of a, the most sonorous segment, for the Peak position is already expressed in HNUC.\nIt seems no coincidence that it is a that has surfaced in a high-ranking constraint disfavoring Margin\nposition, yet there is nothing in our theory so far that would have prevented, say, *M/r from having\nsuddenly appeared in place of *M/a. It is almost as if HNUC were a complex of constraints governing\nthe affinity of segments with varying sonority to the Peak and Margin positions — and while most\nof them are contiguous in the hierarchy, occupying the position we have marked HNUC, the strongest\nof them, pertaining to a, has detached itself from the rest and drifted above certain other constraints:\ncrucially, FILLOns.\n\nOptimality Theory\n\nChapter 8\n\n147\n\nNow while the behavior of a is in a sense marginal in Berber — it is the only segment that\ncannot be parsed into both Peaks and Margins, and this fact only reveals itself in the event that an\ninput contains /aa/ — such behavior is of course the norm in more typical languages; the class of\nsegments that can fill both Peak and Margin positions in most languages consists of at most a few\nsegments, whereas in Berber it consumes all the segments except a. So the need for high-ranking\nconstraints such as *M/a in Berber will extend in most languages to the majority of segments; these\nconstraints are primarily responsible for distinguishing consonants from vowels, as we shall now see,\nand they do a lot of work in typical languages. They function in the segmental theory as did *M/V\n(121) and *P/C (122) in the CV theory.\nSo the program now is to ‘explode’ HNUC into many segment-specific constraints like *M/a,\nso that those that need to may rise high in the domination hierarchy and prevent pure vowels from\nbeing parsed into Margins and pure consonants into Peaks. (In the sense intended here, Berber has\none pure vowel, a, and no pure consonants.)\n\n8.1.2 Restricting to Binary Marks\nAs a glance at the preceding tableau immediately reveals, HNUC stands out from the other constraints\nin its non-binarity; whereas the other constraints invoke a simple ‘*’ when violated, HNUC is a\ngraded constraint favoring more sonorous peaks. The explosion of HNUC now required, which\nliberates the like of *M/a, begins in fact as a recasting of the single, multi-valued HNUC constraint\ninto a set of binary-valued constraints. Recall that\n(202) HNUC: á TM í TM þ TM 't [generally, 83 TM J' if *8* > *J*]\nAt this point it is convenient to rewrite this as follows:\n(203) Peak Harmony: P/a TM P/i TM þ TM P/t\nNow we can achieve this Harmony scale via an exactly corresponding binary constraint hierarchy\nof the form:\n(204) Peak Hierarchy: *P/t >> þ >> *P/i >> *P/a\nformed from the constraints:\n(205) *P/8: 8 must not be parsed as a syllable Peak (i.e., associated to Nuc).\nThe tableau makes this equivalence clear:\n\n148\n\nChapter 8\n\nPrince & Smolensky\n\n(206) HNUC Reduced to Binary Constraints\n*P/t\n\nþ\n\n*P/i\n\nP/a = á\n\n*\n\nP/i = í\n\n*\n\nþ\n\n!\nP/t = 't\n\n*P/a\n\n*\n\nIf we take any two segments 8 and J with *8* > *J*, and compare their Harmonies using this\nconstraint hierarchy, we see that 83 N TM J'.\nIn anticipation of later analysis we point out that the Peak Hierarchy is not completely\nequivalent to HNUC. As far as the harmonic ordering of individual peaks is concerned, the two are\nindeed equivalent, but when entire parses containing multiple peaks are compared, a difference\nemerges. On whole parses, HNUC compares the multiple nuclei from most harmonic to least\nharmonic (as discussed in §5.2.1.2). The Peak Hierarchy, however, evaluates all violations in a parse\nof *P/t first, and so on down the Peak Hierarchy; and the violations of *P/t are incurred by the least\nharmonic nuclei. Thus the Peak Hierarchy evaluates whole parses by comparing the multiple nuclei\nfrom least to most harmonic. We will return to this issue in a later discussion of Berber in §8.3.3.\nIn the meantime, we turn our attention to the consequences of the Peak Hierarchy for syllabification\nuniversally.\nParalleling this hierarchy of Peak association constraints, there is another hierarchy for Margins, with\nopposite polarity:\n(207) Margin Hierarchy: *M/a >> *M/i >> þ >> *M/t\nThe constraints here are in direct correspondence to the Peak counterparts (205):\n(208) *M/8: 8 must not be parsed as a syllable Margin (i.e., associated to Ons or Cod).\nThe most dominant constraint, as promised in the earlier discussion of Berber, is *M/a. This Margin\nHierarchy generates the following Harmony scale:\n(209) Margin Harmony: M/t TM þ TM M/i TM M/a\nThe single non-binary constraint HNUC and the Peak Hierarchy (204) of binary constraints each\ngenerate the same Harmony scale (203) for Nuc/segment associations (202). The power of the Peak\nHierarchy is greater, however, since it will function as does HNUC to correctly rank all the peaks\nregardless of whether all the constraints *P/8 are contiguous in the hierarchy. That is, other\nconstraints may be interspersed within the sequence prescribed by the Peak Hierarchy (204), and\n\nOptimality Theory\n\nChapter 8\n\n149\n\nsimilarly for the Margin Hierarchy (207). This allows Berber, for example, to rank *M/a high in the\nhierarchy (200, 201) — crucially, higher than FILLOns — and all the other Margin constraints *M/i >>\nþ >> *M/t lower than FILLOns in the hierarchy. This will (eventually) lead to another, more\nexplanatory, analysis of Berber which is equivalent to the analysis in (200) and (201); cf. §8.3.3.\nMore importantly, the separated association constraints of the Peak and Margin Hierarchies will\nenable us to handle the typological variation among languages in the degree of flexibility with which\nthey permit segments to move between Margin and Peak positions.\nThe Peak and Margin Hierarchies exemplify a general treatment of the problem of producing\nHarmony scales in the association of two dimensions of structure D1 and D2, one of them binary, by\n“aligning” two pre-defined (non-Harmony) scales on D1 and D2. Here, D1 is the binary structural\ndimension Peak/Margin, with the prominence scale:\n(210) Syllable Position Prominence: P > M\nand D2 is the segment inventory with the prominence scale given by sonority:\n(211) Segmental Sonority Prominence: a > i > þ > t\n(Recall that ‘i’ denotes a sonority level, not a full bundle of distinctive features.) The process of\nalignment of these two prominence scales, (210) and (211), is an operation which by definition\ngenerates two Harmony scales on the associations between the two dimensions: precisely the two\nscales (203) and (209).\n(212) Alignment\nSuppose given a binary dimension D1 with a scale X > Y on its elements {X, Y}, and another\ndimension D2 with a scale a > b > þ > z on its elements. The harmonic alignment of D1 and\nD2 is the pair of Harmony scales:\nHX: X/a TM X/b TM þ TM X/z\nHY: Y/z TM þ TM Y/b TM Y/a\nThe constraint alignment is the pair of constraint hierarchies:\nCX: *X/z >> þ >> *X/b >> *X/a\nCY: *Y/a >> *Y/b >> þ >> *Y/z\nCX and CY are to be understood as sub-hierarchies of a language’s total constraint hierarchy; e.g., CX\nasserts that scattered within the constraint hierarchy of a language are the constraints *X/z, þ , *X/b,\n*X/a, and that they fall in that order (from most to least dominant), with other constraints possibly\nfalling above, below, and among these constraints.\nThe idea of harmonic alignment is easily described in cases like the present one where the\ntwo scales are prominence scales along two dimensions (syllable structure and sonority): the more\nprominent position X prefers the more prominent elements (ideally, a); the less prominent position\nY prefers the less prominent elements (ideally, z). Constraint alignment says that associating less\nprominent elements (like z) to the more prominent position X produces the most dominant marks;\nsimilarly for associating more prominent elements (like a) to the less prominent position Y.\n\n150\n\nChapter 8\n\nPrince & Smolensky\n\nAs illustrated above (206), constraint alignment entails harmonic alignment; conversely, the\nconstraints *X/\" and *Y/\" must be ordered according to constraint alignment if they are to be\nconsistent with harmonic alignment. Thus there are two essentially equivalent ways to enter the\nalignment of two dimensions into Universal Grammar. The first is to assert that the constraint\nhierarchies CX, CY of constraint alignment are universal, that they must be incorporated into the\nparticular constraint hierarchy of any language. The second is to assert that the Harmony scales HX,\nHY of harmonic alignment and the constraints *X/\", *Y/\" are universal; particular languages must\norder these constraints in a way consistent with HX, HY. It then follows as a consequence that\nindividual languages’ constraint hierarchies will always contain the sub-hierarchies CX, CY, i.e.\nsatisfy constraint alignment.\nWe assume the following principle of Universal Grammar:\n(213) Universal Syllable Position/Segmental Sonority Prominence Alignment\nThe syllable position (210) and segmental sonority (211) prominence scales are universally\naligned: the harmonic alignments are the Peak (203) and Margin (209) Harmony scales; the\nconstraint alignments are the Peak (204) and Margin (207) Constraint Hierarchies.\nNote that while (213) fixes universally the relative Harmonies P/8 > P/J and M/J > M/8\n(when *8* > *J*), it leaves the relative Harmonies of P/8 and M/8 open for cross-linguistic\nvariation. We now explore the possibilities that arise when a given language fixes the relative\nrankings of the Peak, Margin, and Basic Syllable Structure Constraints. That is, we develop the\nfollowing theory:\n(214) Basic Segmental Syllable Theory\n• The constraints governing syllable structure are the Peak and Margin association constraints\n(205, 208), and the syllable structure constraints ONS, !COD, PARSE, and FILL (114!117)\nand NUC and *COMPLEX (119!120).\n• The constraints NUC (119) and *COMPLEX (120) are universally undominated, while the\nremaining, lower-ranking constraints can be ranked in any domination hierarchy, limited only\nby universal Syllable Position/Segmental Sonority Prominence Alignment (213).\nIn other words, we study the Factorial Typology induced by these constraints. Our focus will be on\nthe distribution of various segments across syllable positions. For now we take as given the segment\ninventory of a language; in §9.1.2 we will show how the theory can address typological variation in\nthe inventories themselves.\nIn the Basic CV Syllable Structure Theory, the inputs to be parsed were taken to be all\npossible CV strings {C,V}+. Likewise, in the Basic Segmental Syllable Theory, we abstract away\nfrom omissions in the lexicon, and consider the set of inputs to be parsed in a language to be the set\nof all possible strings of our idealized segments a, i,..., d, t. We postpone until §9 our discussion of\nthe issue of structure in the lexicon.\nIn this chapter we show how the theory can elucidate the consequences for universal grammar of\nalignments such as that of sonority and syllable position prominence; while focusing on the role of\n\nOptimality Theory\n\nChapter 8\n\n151\n\nsonority in syllable-internal segment distribution, we are of course not blind to the role of other\ndimensions and constraints. It is for future research to determine the extent to which the methods\ndeveloped here, or their extensions, can also shed new light on the role of factors other than sonority.\nWe shall see that from the ranking of constraints in a given language, a series of parameter\nvalues can be computed, each of which sets a sonority value that delimits a distributional class of\nsegments. All segments more sonorous than a parameter we call BNuc are possible nuclei; all those\nless sonorous than another parameter BOns are possible onsets. If there are any segments in common,\nthese are ambidextrous: they are both possible nuclei and onsets. The possible codas are those\nsegments less sonorous than a parameter BCod, which may have a lower, but not a higher, sonority\nvalue than BOns; the set of possible codas in some languages may be a smaller set than the set of\npossible onsets, but never the reverse.\nIn addition to establishing particular results such as these, the theoretical development to\nfollow in this chapter has two other goals. First, the methods that will be developed are quite general\nand can be applied to a variety of other problems. Secondly, the discussion will show how the theory\nenables a surprisingly rich set of conclusions to be formally extracted from a starting point as simple\nas the Basic Segmental Syllable Theory (214), which involves only simple universal constraints,\nsimple universal operations such as Alignment, and simple means of generating cross-linguistic\nvariation such as the Factorial Typology.\nWe will ultimately be concerned to derive the previously mentioned licensing asymmetry\nbetween onsets and codas. Until we take up this asymmetry, however, we will ignore codas and\nfocus on the distribution of segments within onsets and nuclei.\n\n152\n\nChapter 8\n\nPrince & Smolensky\n\n8.2 Reconstructing the C and V Classes:\nEmergent Parameter Setting via Constraint Ranking\nIn this section we introduce most of the formal techniques summarized at the beginning of the\nchapter, and apply them to the problem of determining the conditions on constraint hierarchies under\nwhich a segment may be optimally parsed into onset and nucleus positions. These conditions are\nassembled in (239) at the beginning of §8.3, in which section they form the basis of our typology of\ninventories of onsets and nuclei. On a first reading, it may be desirable to skim up to §8.3, as the\nformal and logical development of §8.2 is rather involved.\n\n8.2.1 Harmonic Completeness of Possible Onsets and Peaks\nWe begin by observing a direct consequence of the universal Margin and Peak Hierarchies for the\nrole of sonority in the distribution of segments within syllables. The universal Margin Hierarchy says\nthat less sonorous segments make more harmonic onsets; Harmonic Completeness implies that if\nsome segment is a possible onset, then so are all less sonorous segments.\n(215) Harmonic Completeness: Possible Onsets and Nuclei\nIf *8* > *J* and 8 is a possible onset, then so is J. If *\"* > *8* and 8 is a possible nucleus,\nthen so is \".\nThe validity of (215) follows from a basic lemma concerning the Harmonic Ordering of Forms:\n(216) Cancellation Lemma\nSuppose two structures S1 and S2 both incur the same mark *m. Then to determine whether\nS1 TM S2, we can omit *m from the list of marks of both S1 and S2 (‘cancel the common mark’)\nand compare S1 and S2 solely on the basis of the remaining marks. Applied iteratively, this\nmeans we can cancel all common marks and assess S1 and S2 by comparing only their\nunshared marks.\nThis lemma is proved below in the appendix, part of some formal analysis of HOF which we have\npostponed. That (215) follows from (216) requires a slightly involved argument; a first\napproximation to the argument runs as follows. By assumption, 8 is a possible onset, so there must\nbe some input I containing 8 which is assigned an analysis S in which 8 is parsed as an onset, i.e.,\nS contains the association Ons/8 (which incurs the mark *M/8). Replacing this occurrence of 8 by\nJ in I and S produces a new input IN and a new structure SN; we claim that SN is the structure assigned\nto IN, and that therefore J too is a possible onset.\nI:\n\n---8---\n\nS:\n\n---Ons/8---\n\nIN:\n\n---J---\n\nSN:\n\n---Ons/J---\n\nOptimality Theory\n\n153\n\nChapter 8\n\nThe central point is that the marks earned by SN are the same as those earned by S, except that a mark\n*M/8 has been replaced by *M/J; by the Cancellation Lemma, in comparing S and SN we can cancel\nall their common marks and determine which is more harmonic solely on the basis of their unshared\nmarks, *M/8 for S and *M/J for SN. Since *8* > *J*, by (207) *M/8 >> *M/J so we conclude that\nSN TM S. Since S is the output assigned by the grammar to I, it is optimal, that is, more harmonic than\nall its competitors. Since SN TM S, it is tempting to conclude that SN is therefore also optimal, giving\nthe desired conclusion that SN is the output assigned to IN, and that therefore J is a possible onset.\nUnfortunately, the fact that S is more harmonic than all its competitors does not entail that SN is more\nharmonic than all its competitors: the competitors to SN as analyses of IN also have 8 replaced by J,\nand so they too, like SN, can be more harmonic than their 8-counterparts. Here, then, is the actual\nproof:\nProof of (215): Let I,S and IN,SN be as above. Now consider a competitor CN as an output for IN; we\nmust show that SN TM CN. Let C be the corresponding competitor to S (with 8 in place of J).\nI:\n\n---8---\n\nS:\n\n---M/8---\n\nC:\n\n---+8,--- or ---P/8--- or ---M/8---\n\nIN:\n\n---J---\n\nSN:\n\n---M/J---\n\nCN:\n\n---+J,--- or ---P/J--- or ---M/J---\n\nAs pointed out above, we know that SN TM S and that S TM C. We would be done if C š CN, but this\nneed not be case; it depends on the analysis in C (CN) of 8 (J):\nCase 1: 8 is unparsed in C, i.e. +8, in C, and therefore +J, in CN. In this case, the same mark,\n*PARSE, is earned by both 8 and J so C and CN incur exactly the same marks: C . CN.\nThus SN TM S TM C . CN and we are done.\nCase 2: 8 is parsed as a peak P/8 in C, and therefore J is parsed as P/J in CN. Now the\ndifference in marks incurred by C and CN is that C incurs *P/8 while CN incurs *P/J.\nBy the Peak Hierarchy (204), *P/J >> *P/8, so C TM CN and again we are done: SN TM\nS TM C TM CN.\nCase 3: 8 is parsed as a margin M/8 in C, so J is parsed as M/J in CN. Now, since *M/8 >>\n*M/J, we have CN TM C, and we are not done. Since *M/8 is incurred in both S and\nC, however, it cannot be responsible for the fact that S TM C. That is, in comparing the\nmarks incurred by S and by C to determine which is more harmonic, the mark *M/8\ncancels out of the comparison; the fact that S TM C must therefore follow from the\nremaining marks. But these are exactly the same as the marks that remain in the\ncomparison of SN to CN, since *M/8 has been replaced by *M/J in both SN and CN,\nand it cancels in this comparison as well. So just as the marks remaining after\ncancellation of *M/8 determine that S TM C, so these same marks entail after\ncancellation of *M/J that SN TM CN.\n\n154\n\nChapter 8\n\nPrince & Smolensky\n\nAn immediate typological consequence of Harmonic Completeness (215) is:\n(217) Possible Onset and Nuclei Parameters\nThe cross-linguistic variation in the sets of possible onsets and nuclei are governed by two\nparameters, BOns and BNuc, which are sonority cut points in the Margin and Peak hierarchies.\nThe possible onsets are those segments with sonority less than or equal to BOns:\nPossOns = {J : *J* # BOns};\nthe possible peaks are those segments with sonority greater than or equal to BNuc:\nPossPeak = {\" : *\"* $ BNuc}\nExactly characterizing what determines these cut points BOns and BNuc is a main goal of the following\nanalysis: these are not primitive parameters directly set in the grammar of a particular language;\nrather their values are derived consequences of the language’s ranking of the universal constraints.\n(The results are (247) and (248) of §8.3.)\nIn the sequel it will be convenient to adopt the following:\n(218) Definition of t and a\nIn a given language, let t denote a segment of minimal sonority and a a segment of maximal\nsonority.\nIt is clear from (217) that if a language has any possible onsets, then t is one; if any possible peaks,\nthen a. The reason for the qualification is that the theory as developed so far does not rule out a\nlanguage in which all onsets or all nuclei are epenthesized. We assume henceforth that in every\nlanguage, such a possible onset t and possible nucleus a exist.\n\n8.2.2 Peak- and Margin-Affinity\nIn the present theory, the most obvious question concerning the relation between individual segments\nand syllable positions is: for a given segment 8, is the association to Peak, P/8, or to Margin, M/8,\nmore harmonic? This question dichotomizes the segment inventory in a particular language:\n(219) Syllable Position Affinity\nIf in a given language P/8 TM M/8, or equivalently *M/8 >> *P/8, then 8 is a peak-preferring\nsegment; otherwise 8 is margin-preferring.\nThe universal Peak and Margin Hierarchies have a sharp consequence for affinity:\n(220) The Affinity Cut Theorem\nSuppose *8* > *J*. Then if J is peak-preferring, so is 8. If 8 is margin-preferring, so is J.\nThus there is a cut in the sonority scale, above which all segments are peak-preferring and\nbelow, margin-preferring. The only parameter of cross-linguistic affinity variation is the\nsonority level BAff of this cut point.\n\nOptimality Theory\n\n155\n\nChapter 8\n\nTo see this, select for concreteness 8 = a and J = i. Suppose that in a given language i is peakpreferring. Then the following ranking of constraints must hold in the language:\n(221) *M/a >> *M/i >> *P/i >> *P/a\nThe first and last rankings are parts of the universal Margin and Peak Hierarchies, (207) and (204)\nrespectively; the middle ranking *M/i >> *P/i simply asserts our hypothesis that i is peak-preferring.\nReading off the left and right ends of (221), we see that *M/a >> *P/a, i.e., that a too is peakpreferring. The situation can be illustrated as follows, the unshaded cells corresponding directly to\n(221):\n(222) Interleaving of Margin and Peak Hierarchies\nUniversal Peak\nHierarchy (207)\n\n*P/t >>\n\nþ >>\n\n*P/l >>\n\nLanguageParticular\nUniversal Margin\nHierarchy (204)\n\n*P/i >>\n\n*P/a\n\n>>\n*M/a >>\n\n*M/i >>\n\n*M/l >>\n\nþ >>\n\n*M/t\n\nThis diagram represents the large number of hierarchies gotten by unifying the Margin and Peak\nHierarchies into a single hierarchy, in such a way that *M/i >> *P/i. The diagram shows immediately\nthat the same relation, *M/a >> *P/a follows, and in general, that *M/4 >> *P/4 for one segment 4\nwill entail the same domination relation for any more sonorous segment \": if 4 is peak-preferring,\nso must be \". This means that if 4 denotes the least-sonorous peak-preferring segment, the least\nsonorous segment obeying the property *M/4 >> *P/4 displayed by 4 = i in (222), then all segments\nmore sonorous than 4 are peak-preferring also, and all less sonorous segments are margin-preferring\n(else there would be a segment less sonorous than 4 which is peak-preferring, contrary to the\ndefinition of 4). Thus the ‘cut point’ BAff of the Affinity Cut Theorem (220) lies between the sonority\nlevel of 4 and the next sonority level lower: more sonorous segments (starting with 4) are peakpreferring, less sonorous segments are margin-preferring:\n(223) Affinity Parameter: BAff is located as follows between two adjacent sonority levels, that of\nthe most sonorous margin-preferring segment and that of the least sonorous peak-preferring\nsegment:\nmax8{*8* : *P/8 >> *M/8} < BAff < min4{*4* : *M/4 >> *P/4} .\nAs with the sonority values for the parameters BOns and BNuc introduced above, the sonority value BAff\nis not a primitive parameter set directly by a grammar, but rather a value determined by the\nlanguage’s ranking of universal constraints, as illustrated in (222).\n\n156\n\nChapter 8\n\nPrince & Smolensky\n\n8.2.3 Interactions with PARSE\nIn and of itself, the affinity of a segment does not determine its distribution. In general, there will be\nconflicts between respecting the segment’s affinity and other constraints. The easiest such interaction\nto analyze involves PARSE.\nSuppose *M/\" is ranked above PARSE. Then parsing \" as a Margin is so low in Harmony as\nto be even less harmonic than phonetically deleting the entire input string containing \" — that is,\nassigning no structure to it at all (i.e., the Null Parse of §4.3.1). For while assigning no structure\nincurs many *PARSE marks (one for each segment in the input string), the one mark *M/\" that is sure\nto be incurred in any analysis in which \" is parsed as an M is less harmonic than any number of\n*PARSEs, by the hypothesis that *M/\" strictly dominates PARSE. This observation illustrates a useful\ngeneral technique of analysis:\n(224) Harmonic Bounding\nIn order to show that a particular structure n does not appear in the outputs of a grammar,\nit suffices to show that any candidate structure A containing n is less harmonic than one\ncompeting candidate B (of the same input). (B provides a harmonic (upper) bound for A).\nNote that the competing candidate B need not be the most harmonic one, it need only be more\nharmonic than A, i.e. BTMA. In the case at hand, to show the impossibility of the association n = M/\",\nwe have identified a structure B, the Null Parse, which harmonically bounds any structure containing\nn. For the vast majority of inputs, the Null Parse B will not be the optimal analysis; but it\nnonetheless suffices as a harmonic upper bound. (The optimal analysis of an input containing \" may,\nfor example, involve failing to parse only \"; or it may involve parsing \" as a peak.)\nThus a major dichotomy in the segments is induced by the location of PARSE within the\nMargin Hierarchy of constraints:\n(225) Untenable Associations\nA segment \" is defined to be an untenable margin iff *M/\" >> PARSE, i.e., if \" is more\nharmonic deleted +\", than parsed as a margin M/\". J is an untenable peak iff *P/J >> PARSE.\nIf 8 is both an untenable peak and an untenable margin, then 8 is an untenable surface\nsegment. If \" is an untenable margin then it is not a possible margin; likewise for peaks.\nNote that this result gives us a bit of information about the values of the parameters BOns and BNuc.\nThe highest BOns can possibly be is the highest sonority level *J* at which PARSE dominates *M/J;\nfor higher sonority levels *\"* > *J*, *M/\" dominates PARSE and thus \" is an untenable margin hence\nnot a possible onset. This situation is illustrated in (226) with J = i (compare (222)):\n(226) Untenable Margins\n*M/a >>\na: untenable margin\n\nPARSE >>\n\n*M/i >>\n\n*M/l >>\n\nþ >>\n\n÷ ÷ ÷ ÷ BOns (?) ÷ ÷ ÷ ÷\n\n*M/t\n\nOptimality Theory\n\n157\n\nChapter 8\n\nThe maximum sonority of possible onsets, BOns, cannot be higher than the sonority level *i*, because\na is an untenable margin (*M/a >> PARSE). A corresponding illustration for possible peaks (again,\ncompare (222)) is:\n(227) Untenable Peaks\n*P/t >>\n\nþ\n\n*P/n >>\n\nPARSE >>\n\nt!n: untenable peaks\n\n*P/l >>\n\n*P/i >>\n\n*P/a\n\n÷ ÷ ÷ BNuc (?) ÷ ÷ ÷\n\nWhile we have shown that *M/\" >> PARSE entails the impossibility of \" associating to M\nin an output, we have yet to examine the converse, whether PARSE >> *M/J entails that M/J can\nsometimes appear in an output. It will turn out that the answer is affirmative if J is marginpreferring; if J is peak-preferring, then whether it may associate to M turns out to depend on the\nranking of other syllable structure constraints such as ONS and FILLOns.\nThus, while it has been easy to find a necessary condition for J to be a possible margin (viz.,\nPARSE >> *M/J), finding sufficient conditions will be much harder. To find a necessary condition\nfor M/J to surface in a well-formed structure, it sufficed to find one competitor (total phonetic\ndeletion) that must be surpassed. To find a sufficient condition requires showing that for all\nuniversally possible orderings of constraints, there is some input in which an analysis containing M/J\nis more harmonic than all its competing analyses. Establishing such a conclusion is rather involved,\nand we find it prudent to proceed via a series of incrementally developed results, worthwhile in\nthemselves. The result will be necessary and sufficient conditions for a segment to be a possible\nonset or nucleus; from these conditions will follow a typology of segmental inventories, with respect\nto syllable structure distribution, and a universal asymmetry in the licensing of segments in codas\nand onsets.\n\n8.2.4 Restricting Deletion and Epenthesis\nIn order to limit the set of candidate analyses we will need to consider, we pause here to establish\nresults restricting the environments where under- and overparsing (a.k.a deletion and epenthesis) is\npossible. The underparsing result concerns the special case of optimal syllables.\n(228) No Deletion of Tenable Segments in Optimal Syllables\nSuppose J is a tenable margin and \" a tenable peak. Then the structure assigned to /J\"/ can\ninvolve no underparsing.\nFor the obvious analysis .J\"' ., while not necessarily optimal, is more harmonic than any analysis\ninvolving +J, or +\",. Since it represents the universally optimal syllable structure (128), .J\"' . incurs\nonly the marks {*M/J, *P/\"}, with no marks for syllable structure constraint violations. On the other\nhand, any structure containing either +J, or +\", will incur at least one mark *PARSE. Now to assume\nthat J and \" are a tenable margin and peak, respectively, is precisely to assume that PARSE >> *M/J\nand PARSE >> *P/\" (225); thus any alternative containing them which fails to parse either J or \" is\nless harmonic than .J\"' . (In other words, .J\"' . harmonically bounds (224) the set of all candidates\ncontaining either +J, or +\",.)\n\n158\n\nChapter 8\n\nPrince & Smolensky\n\nThe second result is just the Epenthesis Sites theorem (145) of the CV theory (§6.2.3): it\nholds in the segmental theory we are now developing as well, in which the families of constraints\n*M/8 and *P/8 have replaced *M/V (121) and *P/C (122) of the CV theory. The demonstration of\n(145) proceeded via a series of four propositions. Reexamination of these shows that in Propositions\n1 and 2, all the Harmony comparisons involved only unfilled syllable positions, and no segments,\nso no constraints involving segments were relevant to the comparisons; thus exactly the same\narguments go through in the present theory. Proposition 3 showed that epenthesis into the\nenvironment .(~)~3 C. is impossible because of the more harmonic alternative .C~3 . Here, the segment\nC (now call it 8) is parsed as a coda in the first analysis and as an onset in the second; but since both\ninvolve the same constraint *M/8 of the current theory, this common mark cancels, and the original\nconclusion still stands. (This would not be the case if we were to distinguish two families of\nconstraints, *Ons/8 and *Cod/8, but the theory we are now developing lumps these into *M/8.)\nFinally, the new result of Proposition 4 was the impossibility of .C~3 .~V., because it is less harmonic\nthan .CV.; again, since .J~3 .~\"' . and .J\"' . both incur the association marks {*M/J, *P/\"}, these\ncancel, and the argument from the CV theory goes through as before. Thus all the Propositions 1!4\nstill hold in the present segmental theory, therefore so does the FILL Violation Theorem (possible\nepenthesis sites), a direct consequence of these four propositions.\n\n8.2.5 Further Necessary Conditions on Possible Onsets and Nuclei\nWe now proceed to find necessary and sufficient conditions for segments to be possible onsets and\nnuclei. One set of necessary conditions was given in the earlier analysis of untenable associations\n(225); in this section we derive the following further necessary conditions:\n(229) Possible Onset Condition: If J is a possible onset in a language, then:\n[1]\n*P/J or ONS >> *M/J\nand\n[2]\n*P/J or *M/~ >> *M/J\n(230) Possible Peak Condition: If \" is a possible peak in a language, then:\n[3]\n*M/\" or *P/~ >> *P/\"\nHere we have adopted the notations *M/~ / FILLOns and *P/~ / FILLNuc in order to explicitly\nrepresent the conceptual parallelism between the two FILL constraints and the families of *M/8 and\n*P/8 constraints. And of course ‘*P/J or ONS >> *M/J’ means ‘*P/J >> *M/J or ONS >> *M/J’.\nThe virtual isomorphism between the Possible Onset and Possible Peak Conditions is more\nevident in the following pair of alternative, logically equivalent, formulations:\n(231) Possible Onset Condition, Alternate Version: The condition ‘[1] AND [2]’ of (229) is\nequivalent to the condition:\n‘either\n[i]\nJ is margin-preferring (*P/J >> *M/J),\nor\n[ii]\n{ONS, *M/~} >> *M/J >> *P/J ’.\nIf J is a possible onset, then exactly one of [i] or [ii] must hold.\n\nOptimality Theory\n\n159\n\nChapter 8\n\n(232) Possible Peak Condition, Alternate Version: Condition [3] of (230) can be rewritten:\n‘either\n[iii] \" is peak-preferring (*M/\" >> *P/\"),\nor\n[iv]\n*P/~ >> *P/\" >> *M/\" ’.\nIf \" is a possible peak, then exactly one of [iii] or [iv] must hold.\nThe nucleus condition arises from the onset condition by exchanging P and M, and ONS and NUC.\nHowever, NUC is universally superordinate, whereas the domination position of ONS may vary; so\nwhile ONS must be explicitly mentioned in [ii], NUC need not be mentioned in the corresponding\ncondition [iv].\nThe results expressed in conditions (231) and (232), and their justifications, can be rendered\ninformally as follows. We start with (232), which is slightly simpler.\nIn order for \" to be a possible nucleus, either [iii] it must be less harmonic to parse \" as a\nmargin than as a peak (because \" is peak-preferring), or, if \" prefers to be a margin [iv], then an\nunfilled Nuc node that could be created by disassociating \" from Nuc and parsing it instead as a\nmargin must generate a mark *FILLNuc which is worse than the mark *P/\" incurred by parsing \" into\nits disprefered peak position.\nThe situation in (231) is similar. In order for J to be a possible onset, either [i] it must be less\nharmonic to parse J as a peak than as an onset (because J is margin-preferring), or, if J prefers to be\na peak [ii], then the marks incurred in either removing the Ons node so vacated (*ONS), or in leaving\nit in place but unfilled (*FILLOns) must dominate J’s inherent preference.\nWe now make these informal explanations precise. The technique we use runs as follows. Suppose\nwe are given a language in which \" can be parsed as a peak. Then there must be some input I\ncontaining \" whose optimal parse O contains Nuc/\". This means that for any competing parse C of\nI in which \" is not parsed as nucleus, we must have O TM C. By choosing C so that it forms a kind of\nminimal pair with O, we can show that O TM C can only hold if the constraint hierarchy in the\nlanguage meets some domination condition, viz., [3] of (230).\nSo suppose that \" is a possible peak, i.e., that there is some input containing \" whose analysis\nO contains Nuc/\". To generate the competitor C, we simply take O and reassociate \" to Ons:\n(233) Marks for Nuc/\" and a Competitor with Ons/\"\nO:\n\n---\"' ---\n\nC:\n\n---~3 .\"~3 ---\n\n*P/\"\n*P/~, *M/\", *P/~\n\nThe mark *P/\" incurred by O is exchanged in C for {*P/~, *M/\", *P/~}; all the other marks\nincurred by O (not involving \") are shared by C and thus cancel (216). Thus in order that O TM C, it\nmust be that at least one of the marks *P/~ or *M/\" dominates *P/\"; this establishes [3] (230).\nNow consider onsets. Suppose that J is a possible onset, i.e., that there is some input I containing\nJ whose optimal parse O contains Ons/J. We compare O to two competing parses of I, C1 and C2,\nin which J associates to Nuc (i.e., J'):\n\n160\n\nChapter 8\n\nPrince & Smolensky\n\n(234) Marks for Ons/J and Competitors with Nuc/J:\nO:\n\n---.J\"' ---\n\n*M/J\n\nC 1:\n\n---.~J'.~\"' ---\n\n*M/~, *P/J, *M/~\n\nC 2:\n\n---.J'.\"' ---\n\n*ONS, *P/J, *ONS\n\nSince J is an onset in O, it must be followed by a Nuc position; in (234) this has been notated \"' , with\nthe understanding that \" may either be an underlying segment associated to Nuc, or ~, in the case\nthe Nuc following J is unfilled.\nThe marks incurred by O and its competitors are indicated in (234). O incurs *M/J; this is\ntraded for *P/J in C1 and C2, along with a pair of *M/~ marks in C1 and a pair of *ONS marks in C2;\nall other marks incurred by O (not involving J; including those incurred by \") are shared by both C1\nand C2 and thus cancel. In order that O TM C1, either *P/J or *M/~ must dominate *M/J. In order that\nO TM C2, either *P/J or *ONS must dominate *M/J. If O is to be the optimal structure, both these\nconditions must hold. Thus we get (229).\nIn assuming that the languages under study possess a possible onset t and a possible nucleus a, we\nare thus implicitly assuming that (229) holds with J = t and that (230) holds with \" = a.\n\n8.2.6 Sufficient Conditions on Possible Onsets and Nuclei\nNow we move on to the main task, to show that the preceding necessary conditions (225, 229, 230)\nare indeed sufficient for segments to be possible onsets and nuclei:\n(235) Possible Peak Sufficient Condition: If \" is a tenable peak and satisfies [3], then \" is a\npossible peak.\n(236) Possible Onset Sufficient Condition: If J is a tenable margin and satisfies both [1] and [2],\nthen J is a possible onset.\nOur strategy will be to show that segments J meeting the necessary conditions for possible onsets\ndo indeed surface as onsets in /Ja/, and that segments \" meeting the necessary conditions for\npossible nuclei surface as such in /t\"/.\nWe start with peaks, and consider /t\"/; we want to show that no matter how a language ranks\nits constraints, consistent with the strictures of Universal Grammar, the analysis .t\"' . is optimal. The\ncompetitors we must consider have been limited by (228), which rules out all deletions for this input\n[t by assumption is a possible hence tenable onset]; and the possible Epenthesis Sites have been\nlimited by (145). The table (237) below — a universal tableau — shows all the remaining\ncompetitors and the constraints they violate. The ordering of columns does not represent strict\ndomination ranking since we are reasoning about universal and not language-particular constraint\ninteractions, and there is no particular ranking of the constraints that we can assume; this means that\ndrawing the relevant conclusions from this universal tableau will require somewhat more involved\nanalysis than is needed in a language-particular tableau in which the columns are ordered by the\n\nOptimality Theory\n\n161\n\nChapter 8\n\ndomination hierarchy in that language. As we examine the universal tableau, we will see that some\nof the relative positions of the columns have been designed to reflect the domination relations which\nmust hold as a consequence of the hypotheses we have made concerning t and \".\n(237) Universal Tableau for /t\"/:\n/t\"/ÿ\na\n\nL\n\nONS\n\n*P/t\n\n*M/~\n\n*P/~\n\n*M/\"\n\n*M/t\n\n*P/\"\n\n*\n\n*\n\n*MH\n\nMH\n\nPH\n\n*\n\n*3\n\n[ *]\n\n3\n\n*\n\n1\n\n[ *]\n\n1\n\n[ *]\n\n1\n\n3\n\n.t\"' .\n\nb\n\n.t3 \".\n\nc\n\n.t~3 \".\n\nd\n\n.t3 .\"' .\n\n**1\n\n*1\n\ne\n\n.t3 .~\"' .\n\n*1\n\n*1\n\nf\n\n.t3 .\"~3 .\n\n*1\n\n*1\n\ng\n\n.~3t .\"' .\n\n*\n\n*2\n\n*2\n\n2\n\n[ *]\n\nh\n\n.~3t .~\"' .\n\n*2\n\n**2\n\n2\n\n[ *]\n\ni\n\n.~3t .\"~3 .\n\n*2\n\n*2\n\n2\n\n3\n\nj\n\n.t~3 .\"' .\n\n*\n\n[ *]\n\n[ *]\n\nk\n\n.t~3 .~\"' .\n\n*\n\n[ *]\n\n[ *]\n\nl\n\n.t~3 .\"~3 .\n\n[ *]\n\n3\n\n*\n\n*PH\n*3\n*\n*3\n\n*\n*\n\n*3\n\n**3\n\n*3\n\n*3\n\n*3\n\n!COD\n\nIn constructing this large universal tableau, we have exhaustively listed alternatives, rather\nthan following our customary practice with language-particular tableaux of omitting many of the\nleast harmonic candidates. This for the simple reason that here it is not at all clear which are the least\nharmonic candidates, since we are not reasoning about a specific language-particular hierarchy.\nSo our first task is to verify that the candidates [a-l] are indeed the only ones we need\nconsider. Since legal epenthesis sites (145) all involve either a filled onset or a filled nucleus, with\nonly two underlying segments in /t\"/, analyses with more than two syllables must involve illegal\nepenthesis. Given that deletion is impossible for this input (228), the only possible monosyllabic\nparses are those shown in rows [a-c]. Given the constrained epenthesis sites, disyllabic parses are\nlimited to those in which the first syllable contains t and the second contains \". There are three\npossible monosyllables containing t, given the impossibility of epenthesis into coda position: .'t .,\n.~'t ., and .t~3 . These three possibilities are represented in candidates [d-f], [g-i], and [j-l],\nrespectively. There are also the corresponding three possible monosyllables containing \", and the\nnine bisyllabic parses [d-l] comprise all combinations—the Cartesian product—of the three t parses\nwith the three \" parses: [d-l] = {.'t ., .~'t ., .t~3 .} × {.\"' ., .~\"' ., .\"~3 .}. (Actually, one of these bisyllabic\n\n162\n\nChapter 8\n\nPrince & Smolensky\n\ncandidates [k] involves two adjacent epentheses, already ruled out as legal epenthesis sites (145);\nwe have included [k] in order to exhibit the Cartesian product structure of the bisyllabic candidate\nset.)\nOne of these candidates has already been implicitly compared to .t\"' . in the process of\nderiving the Possible Peak Condition [3] which, by hypothesis, holds of \". The condition [3] was\nderived as necessary to ensure that a parse ---\"' --- is more Harmonic than the alternative ---~3 .\"~3--(233). A special case of this comparison is that of [a] to [l]. Thus [3] by construction entails (as we\nshortly verify) that [a] TM [l].\nSimilarly, since t is assumed to be a possible onset, it must meet the conditions [1] and [2]\nnecessary of all possible onsets. So the Harmony comparisons used to derive [1] and [2] have also\nimplicitly been assumed to favor parsing t as an onset. Those comparisons were of ---.t--- to --.~'t .~--- and to ---.'t .---. Thus since t satisfies [1] and [2], it will follow that [a] is more harmonic\nthan [h] and [d].\nUnfortunately this still leaves eight competitors left to check, and we must resort to examination of\nthe table of marks. It will only be necessary to discuss a few of the cases. The procedure illustrates\na general technique, the Method of Universal Tableaux, which is useful in other applications. This\nmethod relies on the following lemma concerning HOF, derived below in the appendix:\n(238) Cancellation/Domination Lemma\nSuppose two parses B and C do not incur identical sets of marks. Then B TM C if and only if\nevery mark incurred by B which is not cancelled by a mark of C is dominated by an\nuncancelled mark of C.\nFor the case at hand, this idea should be intuitively clear. We want to show that B = [a] is more\nharmonic than each of the competitors C in the set [b-l]. [a] incurs two marks, *M/t and *P/\". If a\ncompetitor C’s marks include neither of [a]’s, then in order to show that [a] is more harmonic than\nC, we must show that each of [a]’s marks is dominated by one of C’s marks: this is both necessary\nand sufficient for showing that among the marks of [a] and C, the worst mark is incurred by C, and\nthat therefore [a] is more harmonic. If one of [a]’s marks is shared by C, we can exploit the\nCancellation Lemma and cancel this shared mark from both [a] and C, and then show that the\nremaining mark of [a] is dominated by a remaining mark of C. If both of [a]’s marks are shared by\nC, then both cancel, and if C has any other marks at all, it is less harmonic than [a].\nIn other words, what we need to show is that for any competitor C, the mark *M/t of [a] is\neither cancelled by the same mark in C or dominated by other uncancelled marks of C; and similarly\nfor [a]’s second mark *P/\". Pursuant to this strategy, the Universal Tableau (237) is annotated\naccording to the method for handling each of [a]’s two marks. In the *M/t column for a given\ncompetitor C is an annotation indicating whether this mark of [a] is cancelled or dominated by a\nmark of C. We will have demonstrated that [a] is optimal if we can place an appropriate annotation\nin both the *M/t and *P/\" columns of every competitor.\nThe annotation scheme is as follows. If [a]’s mark *M/t is cancelled, then it must be shared\nby C, so a * must occur in the *M/t column of C; we enclose this in brackets [*] to indicate that this\nmark cancels its counterpart in [a]. If the mark *M/t of [a] is dominated by a mark of C, then the\n*M/t column of C is annotated with the label of a previously established constraint domination\n\nOptimality Theory\n\nChapter 8\n\n163\n\ncondition which demonstrates this domination; in this case, the particular mark(s) of C which\ndominate *M/t are annotated with the same label. The labels are: ‘MH’, Margin Hierarchy (207);\n‘PH’, Peak Hierarchy (204), and ‘1’, ‘2’, ‘3’ for conditions [1], [2], and [3] of (229) and (230). MH\nand PH hold universally; by hypothesis, [1] and [2] hold of J = t and [3] holds of \".\nSo consider the first competitor, [b]. The table indicates that *M/t is dominated by *M/\" in virtue\nof the Margin Hierarchy; this is the case assuming that *\"* > *t*, which will hold in general since\nt is of minimal sonority. (That is, t makes a more harmonic onset than \".) The only exception will\nbe if \" also is of minimal sonority (e.g., if \" = t), in which case the two marks *M/t and *M/\" are\nof equal domination rank and therefore cancel. The table also indicates that *P/\" is dominated by\n*P/t in virtue of the Peak Hierarchy; the same sonority argument applies. (That is, \" makes a more\nharmonic peak than t.) Thus the marks of [a] are dominated by those of [b], unless \" happens to be\nof minimum sonority, in which case both of [a]’s marks are cancelled, which still leaves [b] with the\ntwo uncancelled marks *ONS and *!COD. (That is, even if \" is of the same minimal sonority as t,\nthe syllable structure of [a] is more harmonic than that of [b].) So for any \", [a] TM [b].\nIn the second competitor, [c], t is parsed as an onset, as in [a], so [a]’s first mark *M/t is\ncancelled by [c]. [a]’s second mark *P/\" is not cancelled, since \" is not parsed as a peak in [c];\nhowever, condition [3] of (230) ensures that *P/\" is dominated by either *M/\" or by *P/~, and these\ntwo marks are both incurred by [c]. Therefore the assumption that the constraint hierarchy of the\nlanguage satisfies [3] for segment \" ensures that [a] TM [c]. The situation is annotated in row [c] of\nthe universal tableau by putting ‘3’ under *M/\" and next to the two marks *P/~ and *M/\" of [c]\nwhich together ensure by [3] that *M/\" is dominated.\nWe can now revisit the issue of the ordering of the columns in the universal tableau. Consider\nthe annotations in row [b]. The Peak Hierarchy ensures that *P/t dominates *P/\", which is suggested\nby placing the column *P/t to the left of the column *P/\". (Unless *\"* = *t*, in which case these\ncolumns are really the same.) Similarly for the Margin Hierarchy and the columns for *M/\" and\n*M/t. Note however that there is no reason at all to assume that *P/t dominates *M/\"; the relative\nordering of this pair of columns is not significant. Now consider the annotations in row [c].\nCondition [3] says that either *P/~ or *M/\" dominates *P/\", so that if the columns were ordered\nfor a given language to reflect constraint domination, at least one of the columns for the constraints\n*P/~ or *M/\" would be left of the column for *P/\"; but universally we have no right to assume that\nboth are. Thus the placement in the universal tableau of both *P/~ and *M/\" left of *M/\" must be\ngiven this appropriate disjunctive interpretation. And of course, there is no universal significance at\nall to the relative ordering of the columns *P/~ and *M/\" with respect to each other nor to all the\nother columns left of *M/t. In effect, the annotations indicate that *M/t and *P/\" are dominated in\nevery language by certain of the columns to their left, but beyond that, the order of columns cannot\nbe given a more definite universal interpretation. It is really the constraint domination conditions\nindicated by the annotations rather than the ordering of the columns in the universal tableau which\nis critical to assessing the relative harmonies of [a] and its competitors.\nWe return to the tableau now to consider the remaining, bisyllabic, competitors. Consider [d]\n= .'t .\"' ., for example. Since both [d] and [a] parse \" as a peak, their common marks *P/\" cancel. The\nother mark of [a], *M/t, is, according to [1], dominated either by ONS or by *P/t; since both marks\n*ONS and *P/t are incurred by [d], [1] guarantees that *M/t is dominated. Thus we have annotated\nthe *M/t column of [d] with ‘1’, and used ‘1’ to annotate the relevant pair of [d]’s dominating marks,\n\n164\n\nChapter 8\n\nPrince & Smolensky\n\n*ONS and *P/t. We have ordered ONS and *P/t left of *M/t as a mnemonic for [1], which says that\none—but not necessarily both—of these constraints must dominate *M/t. Note that the second *ONS\nis not appealed to in this argument; in general, a second mark in any column of the table is not\nrequired to demonstrate the greater Harmony of [a]. Neither is any mark *!COD (which appears at\nthe far right since no domination condition ranks it higher than *M/t or *P/\").\nBy tracing the role of [1] in showing that [a] TM [d], we have verified a claim made a few\nparagraphs earlier, that the argument we originally used to derive [1] entails [a] TM [d] as a special\ncase. The reasoning just followed, however, extends also to cases [e] and [f], for which the earlier\nargument does not directly apply. As with [d], in [e] the mark *P/\" is cancelled and the mark *M/t\ndominated by virtue of [1]; in [f], *M/t is also dominated via [1], but now *P/\" no longer cancels.\nInstead, it too is dominated, in virtue of [3], which says that *P/t is dominated by either *P/~ or\n*M/\".\nThe Cartesian product structure of the bisyllabic competitor set [d-l], namely\n{.'t ., .~'t ., .t ~3 .} × {.\"' ., .~\"' ., .\"~3 .}\nis directly manifest in the *M/t and *P/\" columns for these candidates. The mark *M/t incurred by\nt in [a] is dominated via [1] for .'t ., and via [2] for .~'t .; it is cancelled for .t~3 ., which like [a] parses\nt as a margin. [a]’s other mark *P/\" incurred by \" is cancelled for both .\"' . and .~\"' ., both of which\nparse \" as a peak; *P/\" is dominated by [3] in .\"~3 . These dominations via the conditions [1], [2],\nand [3] are hardly surprising; as already discussed, these three conditions were derived precisely to\nensure just these dominations. What the table and all the arguments behind it show, however, is a\nconclusion that is new and non-obvious: that these domination conditions — together with the\nuniversal Margin and Peak Hierarchies, and the assumption that t and \" are respectively a tenable\nmargin and peak, therefore not deletable in /t\"/ (228) — are also sufficient to prove that \" is a\npossible onset. We have thus proved (235).\nThe proof of (236) proceeds analogously. To show that in a language in which J satisfies the\ndomination conditions [1] and [2], J can appear as an onset, we apply the same technique to prove\nthat .Já. is the optimal analysis of the input /Ja/. In fact, the same argument goes through exactly as\nbefore, with J replacing t and a replacing \". This is because the properties [1] and [2] which we now\nhypothesize to hold of J were in the proof of (235) required to hold of t, which is by assumption a\npossible onset; similarly, the possible peak a must satisfy the same property [3] that was\nhypothesized to hold of \" in the proof of (235).\n\nOptimality Theory\n\nChapter 8\n\n165\n\n8.3 The Typology of Onset, Nucleus, and Coda Inventories\nIn this section we first derive from the results of §8.2 a typology of onset and peak inventories\n(§8.3.1), showing explicitly how to extract from the constraint domination hierarchy of a language\nthe values in that language for the parameters BOns and BNuc which determine these inventories. We\nthen obtain the corresponding results for codas, and derive an onset/coda licensing asymmetry\n(§8.3.2). We close the section by returning to Berber to exemplify the results for an actual language\n(§8.3.3).\n\n8.3.1 The Typology of Onset and Nucleus Inventories\nPutting together the results (225, 229!232, 235!236) of the preceding sections, we have the\nfollowing:\n(239) Typology of Possible Onsets and Peaks\nFor J to be a possible onset, it is necessary and sufficient that\neither\n[i]\n{PARSE, *P/J} >> *M/J\n(J a willing onset)\nor\n[ii]\n{PARSE, ONS, *M/~} >> *M/J >> *P/J\n(J a coercible onset).\nFor \" to be a possible peak, it is necessary and sufficient that\neither\n[iii] {PARSE, *M/\"} >> *P/\"\n(\" a willing peak)\nor\n[iv]\n{PARSE, *P/~} >> *P/\" >> *M/\"\n(\" a coercible peak).\nThe onset conditions [i, ii] are the same as those in (231), except that PARSE has been included\nexplicitly to capture the requirement that J be a tenable peak (225). Similarly for [iii, iv] and (232).\nIn (239) we have distinguished the possible onsets satisfying each of the mutually exclusive\nconditions [i] and those [ii], calling the former willing and the latter coercible; willing onsets are\nmargin-preferring tenable margins, while coercible onsets are peak-preferring tenable margins which\ncan be coerced to override their affinity by higher-ranking syllable-structure constraints, ONS and\n*M/~ = FILLOns. And analogously for peaks.\nWe can draw many conclusions from (239). The first concerns affinity (219):\n(240) Affinity and Possibility. Suppose 8 is a tenable surface segment. Then if 8 is marginpreferring, it is a possible onset; if peak-preferring, a possible peak.\nThis conclusion follows immediately from (239): if 8 is margin-preferring, then by definition M/8\nTM P/8, i.e., *P/8 >> *M/8; if 8 is a tenable surface segment, then PARSE must dominate either *P/8\n\n166\n\nChapter 8\n\nPrince & Smolensky\n\nor *M/8, i.e., PARSE must dominate the lowest constraint, *M/8. This establishes [i], so 8 is a\npossible (indeed a willing) onset. And correspondingly if 8 is peak-preferring.\nUsing (239) the segmental inventory in a given language can now be divided into a number\nof overlapping classes. These are illustrated in the following table, for the case of a language with\nambidextrous segments. The horizontal axis is the sonority scale, increasing to the right:\n(241) Segmental Classes (with Ambidextrous Segments)\nIncreasing Sonority ÷\n\nBNuc\n\nt\n\n2\n\nwilling onsets\n\nBAff\n\nBOns\n\na\n\n÷2\n\nwilling peaks\n\n÷\n\n2 coercible peaks ÷2 coercible onsets ÷\npossible onsets\n\n2\n\n÷\n\n2\n\npossible peaks\n\n÷\n\n2 pure onsets ÷2\n\nambidextrous segments\n\n÷2 pure peaks ÷\n\nThis analysis of the segment classes is a direct logical consequence of (239). The reasoning depends\non the following results:\n(242) Segment Classes\na. A coercible onset is a willing peak; a coercible peak is a willing onset.\nb. The set of ambidextrous segments, those which are both possible onsets and possible\npeaks, is the set of coercible segments. Each ambidextrous segment 8 satisfies\nPARSE >> {*M/8, *P/8}.\nc. The set of impossible surface segments, those which are neither possible onsets nor\npossible peaks, is the set of untenable surface segments (225), i.e., those 8 for which\n{*M/8, *P/8} >> PARSE.\nd. The set of possible onsets, { 8 : *8* # BOns}, is the union of the sets of willing and\ncoercible onsets.\ne. The set of possible peaks, { 8 : *8* $ BNuc}, is the union of the sets of willing and\ncoercible peaks.\nf. The set of pure onsets, those segments which are possible onsets but not possible peaks,\nis the set of willing onsets minus the set of coercible peaks.\ng. The set of pure peaks, those segments which are possible peaks but not possible onsets,\nis the set of willing peaks minus the set of coercible onsets.\nThese observations are all immediate consequences of (239) and (217).\n\nOptimality Theory\n\nChapter 8\n\n167\n\nFor example, (242a) follows from (239) since a coercible onset is a segment 8 which satisfies [ii]\nwith J = 8, which includes the requirement that\nPARSE >> *M/8 >> *P/8;\nthen necessarily [iii] holds with \" = 8, so 8 is also a willing peak. The second part of (242a) follows\nby exactly analogous reasoning.\nThen the first part of (242.b) follows immediately, since (242.a) entails that all coercible\nsegments are ambidextrous (and no segment can be ambidextrous unless it is coercible). The second\npart of (242.b) follows since, from [ii] and [iv] we see that, among other things, a coercible segment\n8 must satisfy\nPARSE >> {*M/8, *P/8}.\nThe argument for (242.c) is slightly more involved. Suppose 8 is an impossible surface\nsegment. Like any segment, 8 is either peak-preferring or margin-preferring. Suppose the former:\n(!)\n*M/8 >> *P/8.\nThen if we had\nPARSE >> *P/8,\n8 would be a willing peak; so, since 8 is an impossible surface segment, we must have instead\n*P/8 >> PARSE.\nThus, given (!), we must have\n{*M/8, *P/8} >> PARSE,\nthe desired conclusion. If instead 8 is margin-preferring, the same conclusion follows by exchanging\nM and P in the argument.\nThe remaining points (242.d!g) are obvious, given (242.a), and serve only to introduce\nterminology and reintroduce the parameters BOns and BNuc from (217).\nThe diagram (241) above illustrates a language possessing ambidextrous segments but no impossible\nsurface segments. It turns out that:\n(243) No language can have both ambidextrous and impossible surface segments.\nTo show this, we derive a contradiction from supposing that a single language has an impossible\nsurface segment 8 and an ambidextrous segment \". From (242.b), \" must satisfy\nPARSE >> {*M/\", *P/\"}.\nFrom (242.c), 8 must satisfy the opposite domination,\n{*M/8, *P/8} >> PARSE.\nCombining these, we get:\n{*M/8, *P/8} >> PARSE >> {*M/\", *P/\"}\nBut this contradicts the Peak and Margin Hierarchies (204, 207). For by the Margin Hierarchy,\n*M/8 >> *M/\" entails *8* > *\"*\nwhile by the Peak Hierarchy,\n*P/8 >> *P/\" entails *8* < *\"*.\n\n168\n\nChapter 8\n\nPrince & Smolensky\n\nDiagram (243) asserts that languages divide into those with ambidextrous segments, those with\nimpossible surface segments, and those with neither. The diagram corresponding to (241) for a\nlanguage with impossible surface segments is simpler:\n(244) Segmental Classes (with Impossible Surface Segments)\nIncreasing Sonority ÷\n\nBOns\n\nt\n\nBAff\n\nBNuc\n\na\n\n2 willing onsets ÷\n\n2 willing peaks ÷\n\n2 possible onsets ÷\n\n2 possible peaks ÷\n\npure onsets\n\npure peaks\n\n2\n\n÷2 impossible surface segments ÷2\n\n÷\n\nIn the context of the current Basic Segmental Theory, it is unclear what role could be played in such\na language by the impossible surface segments. There seems to be no way to distinguish the case in\nwhich such a segment is present in a morpheme — and necessarily left unparsed regardless of what\nother segments the morpheme may combine with in an input — and the case in which such a\nsegment is simply not present underlyingly, and indeed not part of the segmental inventory of the\nlanguage. Thus it would appear that there is no need to postulate underlying segments at sonority\nlevels which correspond to impossible surface segments (and indeed the acquisition theory\nintroduced in §9.3 will entail that learners would not posit underlying forms containing such\nsegments). Henceforth, we will restrict attention to languages without such impossible surface\nsegments. In theories richer than the Basic Segmental Theory (214), impossible surface segments\ncould of course function in a language: there would need to be additional constraints which are\nsensitive to such segments even though they are not parsed into syllable structure and not\nphonetically realized.67\nOur assumption that the languages under study are all without impossible surface segments\nhas the following consequence:\n(!)\nPARSE >> *M/J when J is margin-preferring.\nFor if not,\n*M/J >> PARSE\n(\")\n\n67\n\nSuch a situation was, in a sense, illustrated in our analysis of Lardil (§7), where the FREE-V constraint\nasserted that word-final vowels must not be parsed; parsed vowels which are surface-final but followed by\nunparsed underlying segments do not violate this constraint. Thus /wuõkunuõ/ [‘queen-fish’, §7.1 (150.a)]\nsurfaces as [wuõkunu] parsed as .wuõ.ku.nu+õ,.; the final underlying segment õ functions in the language via\nFREE-V to allow the parsing of the last u. The unparsed segment is of course, however, not an impossible\ntype of surface segment; even that particular token of õ in fact surfaces in other inflections of the same stem.\n\nOptimality Theory\n\nChapter 8\n\n169\n\nand since J is margin-preferring,\n*P/J >> *M/J,\nand hence\n{*P/J, *M/J} >> PARSE.\nThen J is an untenable surface segment and by (242.c), J is an impossible surface segment. This\ncontradicts our assumption on the language so (\") must be incorrect and (!) correct. By exchanging\nmargin and peak, the same argument shows that\n(#)\nPARSE >> *P/\" if \" is peak-preferring.\nNow (!) entails that [i] of (239) holds, so a margin-preferring segment J is a possible onset.\nSimilarly, (#) implies [iii] of (239), so a peak-preferring segments \" is a possible onset. Thus:\n(245) In a language without impossible surface segments, all margin-preferring segments are\npossible (hence willing) onsets, and all peak-preferring segments are possible (hence willing)\npeaks.\nThis situation is illustrated in (241): recall that the margin-preferring segments are those left of (less\nsonorous than) BAff, and the peak-preferring segments are those right of (more sonorous than) BAff,\nas seen in (220) and (223).\nUsing (239) we can now derive explicit expressions for the parameters BOns and BNuc which govern\nthe segment classes of (241) and (242). First, define:\n(246) Critical Constraints: COns / min{PARSE, ONS, *M/~}; CNuc / min{PARSE, *P/~}\nThat is, in a particular language, COns names the least dominant of the three constraints PARSE, ONS\nand *M/~ = FILLOns. This is the constraint which, according to (239.ii), determines which peakpreferring segments 8 are coercible onsets: they are the ones for which COns >> *M/8. BOns is by\ndefinition (217) the highest sonority level at which this condition holds. Thus we have:\n(247) Onset Inventory Parameter Value: BOns = max8{ *8* : COns >> *M/8}\nThat is, the value of the parameter BOns in a given language is the sonority value of the most sonorous\nsegment 8 for which *M/8 is dominated by COns. For segments \" more sonorous than this, parsing\nthe segment as an onset incurs a worse mark (*M/\") than the mark (*PARSE, or *ONS, or *M/~)\nwhich would be incurred by some alternative in which \" is not parsed as an onset (as the analysis\nof §8.2 has shown.)\nBy exactly analogous reasoning,\n(248) Nucleus Inventory Parameter Value: BNuc = min8{ *8* : CNuc >> *P/8}\nThat is, BNuc is the sonority value of the least sonorous segment 8 for which *P/8 is dominated by\nCNuc.\n\n170\n\nChapter 8\n\nPrince & Smolensky\n\nWe can illustrate how the ordering of constraints in a particular hypothetical language sets these\nparameters by showing how to go from (222) to (241) via (223), (247), and (248). (In §8.3.3 we\nconsider an actual language, Berber.)\n(249) Deriving Segmental Class Parameters BNuc and BOns: An Example.\nDecreasing Constraint Dominance ÷\na.\n\nf2\n\nb.\n\nBNuc\n\nc.\n\nCNuc=\n\nd. PARSE\n\n*P/~\n\ne. *P/t\n\nPossible Nuclei\n\n=*f*\n\n*P/d\n\n*P/f\n\n*l*<\n\nþ\n\nBAff\n\n*P/l\n\nf.\ng.\n\n÷a\n<*i*\n\n*P/i *P/a\n>>\n\n*M/a\n\n*M/i\n\nh. PARSE *M/~\n\nONS\n\ni.\n\n=COns\n\n*M/l\nþ\n\n*M/d *M/t\n\n*i*=\n\nj.\n\nBOns\n\nk.\n\ni2\n\nPossible Onsets\n\n÷t\n\nIn (249), constraints are indicated in boldface in rows c!i, between the solid lines. They are arranged,\nas usual, with the most dominant constraints to the left. (Note that, unlike (241), the horizontal axis\nshows constraint domination and not sonority.) This is an example of a particular language, so the\nconstraints form a strict domination hierarchy. For clarity, we have vertically separated the\nconstraints into the rows c!i, but they are nonetheless strictly ranked left-to-right. Rows e!g are a\ncopy of (222); we have suppressed the explicit domination symbols ‘>>’ except in row f, which\nshows the cross-over point in the domination hierarchy (as in diagram (222)). To the left of this point\nare the constraints *P/J which dominate their counterparts *M/J; these are the margin-preferring\nsegments. In the example illustrated here, this cross-over point occurs between the sonority levels\n*l* of the most sonorous margin-preferring segments, and *i* of the least sonorous peak-preferring\nsegments. As indicated in line c, this cross-over point on the sonority scale is the affinity parameter\nBAff (223).\nTo determine the sonority values of the other two parameters BNuc (248) and BOns (247), we\nneed first to identify the critical constraints CNuc and COns (246). The constraints relevant to\nidentifying CNuc are shown on line d; the least dominant one in this example is *P/~, which has\ntherefore been identified in line c as CNuc. According to (248), the value of BNuc is the lowest sonority\n\nOptimality Theory\n\nChapter 8\n\n171\n\nvalue *8* of those segments 8 for which CNuc >> *P/8; this value is *f* here, so lines b!c indicate\nthat in this language BNuc = *f*. That is, all segments at least as sonorous as f are possible nuclei\n(217); this is noted in line a.\nAnalogously, the constraints relevant to determining COns are shown in line h (one of them,\nPARSE, was also shown in line d). The lowest ranking is COns = ONS, as noted in line i. Then (247)\ntells us that the value of BOns is the sonority value *8* of the most sonorous segment 8 for which COns\n>> *M/8; in this example, this value is *i*, as noted in lines i!j. That is, as noted in line k, all\nsegments at most as sonorous as i are possible onsets (217).\nNote that for reading off the possible nuclei, we consult the constraints *P/8, which are\narrayed in order of increasing sonority (line e), following the Peak Hierarchy (204), while for\nidentifying the possible onsets, we examine the constraints *M/8, arrayed with decreasing sonority\n(line g), as demanded by the Margin Hierarchy (207). Hence the opposite segment ordering indicated\nin lines a and k.\nIn this example, the ambidextrous segments are those 8 with sonority values at least *f* and\nat most *i*; these are segments for which *P/8 finds itself to the right of CNuc and *M/8 falls to the\nright of COns. The set of ambidextrous segments is not directly evident in the diagram (249), but\nrather inferred as the intersection of the nucleus inventory displayed in line a and the onset inventory\nidentified in line k.\n\n8.3.2 Onset/Coda Licensing Asymmetries\nIn this section, we derive necessary and sufficient conditions for a segment to be a possible coda. The\nanalysis takes the form of a high-speed recapitulation of the methods applied earlier to onsets and\nnuclei. Once the conditions for possible codas are in hand, we can extract the typological\nconsequences, including a licensing asymmetry.\nIn order for a language to permit any codas at all, we must have\n(250) Codas Allowed: {PARSE, *P/~} >> !COD\nas in the Coda Theorem (138), p.102, of CV Theory. We will rederive this condition for the present\nSegmental Theory in the course of establishing the following result:\n(251) Necessary Condition for Possible Codas. If J is a possible coda, then it must meet conditions\n[i] or [ii] for possible onsets (239). In addition, either\n[v]\n{ONS, *M/~} >> !COD\nor\n[vi]\n*P/J >> !COD\nmust hold as well.\nTo see this, consider any input containing J the optimal parse of which is a structure O in which J\nis parsed as a coda. Such a structure can be represented ---\"J\n' .--- since a coda is necessarily preceded\n\n172\n\nChapter 8\n\nPrince & Smolensky\n\nby an nucleus. (Any unparsed segments that may intervene between \" and J can be ignored.) This\nstructure O must be more harmonic than all its competitors, including the four shown below:\n(252) Marks for Cod/J and Competitors:\nS:\n\n---\"J\n' .---\n\n*!COD, *M/J\n\nC 1:\n\n---\"+J,\n' .---\n\n*PARSE\n\nC 2:\n\n---\"' .J~3 .---\n\n*M/J, *P/~\n\nC 3:\n\n---\"' .J'.---\n\n*ONS, *P/J\n\nC 4:\n\n---\"' .~J'.---\n\n*M/~, *P/J\n\nEach competitor Ci is identical to the parse O except in how J is parsed. As in the corresponding\nanalyses for nuclei (233) and onsets (234), we have ignored in (252) all the marks incurred by O and\nC1!C4 except those directly incurred by J, since these other marks all cancel in comparing S to each\ncompetitor (216).\nAccording to the Cancellation/Domination Lemma, (192) and (238), if O is to be optimal,\neach of O’s two marks *!COD and *M/J must be cancelled or dominated by the marks incurred by\neach of these competitors. Thus, considering C1, since *M/J is not cancelled, it must be dominated:\n(!)\nPARSE >> *M/J\ni.e., J must be a tenable margin. Also *!COD must be dominated, so we must have\nPARSE >> !COD,\n(\")\nas claimed above in (250). Considering next C2, since the marks *M/J cancel, we deduce that O’s\nmark *!COD must be dominated by C2's remaining mark:\n(#)\n*P/~ >> !COD.\n(\") and (#) rederive (250).\nNext we consider the competitors C3 and C4, which cancel neither of O’s marks. In order for\nO’s mark *M/J to be cancelled in these two cases, we must have, for C3:\n($)\n*P/J >> *M/J\nor\nONS >> *M/J\nand, for C4:\n(%)\n*P/J >> *M/J\nor\n*M/~ >> *M/J\nIn other words, (including PARSE from (!)) either:\n[i]\n{PARSE, *P/J} >> *M/J\n(in which case the common left half of ($) and (%) holds), or\n[ii]\n{PARSE, ONS, *M/~} >> *M/J\n(in which case the right halves of ($) and (%) hold). These necessary conditions [i, ii] for a possible\ncoda are identical to the conditions for a possible onset (239). So we have established the first part\nof the Necessary Condition for Possible Codas (251).\n\nOptimality Theory\n\nChapter 8\n\n173\n\nBut O incurs another mark, *!COD, which also must be dominated in C3 and C4. The\nconditions are the same as for *M/J, which is now simply replaced by *!COD: ‘either [i] or [ii]’\nbecomes (omitting PARSE now, since it is already covered by (250)) ‘either\n[vi]\n*P/J >> !COD\nor\n[v]\n{ONS, *M/~} >> !COD.’\nCondition [v] does not refer to the segment J; it is a condition on the ranking of the Basic Syllable\nStructure Constraints in the domination hierarchy of a language which may or may not be satisfied.\nIt is completely independent of the condition (250) which admits codas into the language. It says that\nthe language’s aversion to codas (!COD) is less strong than its aversion to onsetless syllables (ONS)\nand unfilled margins (*M/~):\n(253) A language satisfying (251.[v]):\n{ONS, *M/~} >> !COD\nis said to be weakly coda averse.\nIn languages which are not weakly coda averse, the segment-specific condition [vi] must hold of J\nfor it to be a possible coda. In weakly coda averse languages, on the other hand, the Necessary\nCondition for Possible Codas (251) reduces to just the condition for possible onsets.\nThis establishes (251). The idea at the core of this argument is very simple: associating a\nsegment J to a Cod node incurs the same mark *M/J as associating it to an Ons node, and in addition\nthe mark *!COD. The asymmetry in the Basic Syllable Structure Constraints between the Ons (114)\nand Cod (115) nodes entails that the Cod association is inherently more marked than the Ons\nassociation. Therefore additional domination conditions must be met for the association Cod/J to\nbe optimal, above and beyond those conditions necessary for Ons/J to be optimal. These additional\nconditions can, as we will soon see, exclude certain possible onsets from the coda inventory, in\nlanguages where the mark *!COD is sufficiently dominant, i.e., in languages which are not weakly\ncoda averse.\nAn immediate corollary of (251) is:\n(254) Possible Coda Y Possible Onset. If J is a possible coda, then it is a possible onset.\nNext we show:\n(255) Sufficient Conditions for Possible Codas. The conditions of (251) are sufficient for J to be\na possible coda (in a language permitting codas).\nTo see this, consider the input /taJ/; we show that the conditions of (251) entail that the optimal\nanalysis is .táJ., in which J is parsed as a coda. This conclusion follows from the following lemma:\n(256) Lemma: The initial substring /ta/ of /ta---/ is parsed as .táþ.\n\n174\n\nChapter 8\n\nPrince & Smolensky\n\nProof: .tá. is an optimal syllable (128) which violates no Basic Syllable Structure Constraints; its\nonly marks are the associational ones *M/t and *P/a. The presence of the following ‘---’ in\nthe input does not afford opportunities to eliminate any syllable structure constraint\nviolations in .tá., since there aren’t any; alternative parses can only introduce new such\nviolations, while possibly trading the marks *M/t and *P/a for alternative associational\nmarks (if t and a are reassigned to different syllable positions). But we already know that all\nof these alternatives generate marks which dominate those of .tá., for this was established\nby the argument based on the universal tableau (237). This investigation of /t\"/ showed that,\nassuming t to be a possible onset and \" to be a possible nucleus, the marks incurred by .t\"' .\nare dominated by those incurred by all its competitors. Thus if we reiterated all those\ncompetitors, with \" = a, combining them in all possible ways with the possible analyses of\n‘---’, to form the universal tableau for /ta---/, we would simply end up showing that the\nmarks incurred by t and a in any structure of the form .táþ. are dominated by the marks they\nincur in any of the competing analyses that parse the initial substring /ta/ differently.\nFrom this lemma we see that the only competitors to the analyis O = .táJ. that we need consider are\nthose of the form .táþ, with ‘þ’ denoting all possible parses of J. But this is exactly the set of\ncompetitors considered in (252), where the pre-J segment denoted ‘---\"' ‘ in (252) is taken to be ‘.tá’\nand the post-J segment denoted ‘---‘ in (252) is taken to be empty. The necessary conditions of (251)\nwere just those needed to ensure that O was indeed more harmonic than its four competitors in (252).\nThus these necessary conditions are also sufficient.\nThe Necessary (251) and Sufficient (255) Conditions for Possible Codas entail:\n(257) Possible Coda Parameter. The possible codas are those segments with sonority value less\nthan or equal to a cut-off parameter BCod:\nPossCod = { J : *J* # BCod}.\nIn a weakly coda averse language, the value of BCod is given by:\nBCod = BOns;\notherwise,\nBCod = min{BOns, max8{*8* : *P/8 >> !COD} }.\nFor (251) says that if [v] holds, then the conditions on a possible coda are exactly the same as on a\npossible onset, so PossCod = PossOns, and the parameters characterizing the two segmental classes\nhave the same value. So assume the language is not weakly coda averse, i.e., that [v] does not hold.\nThen a possible coda J must be a possible onset, but in addition, [vi] must hold:\n[vi]\n*P/J >> !COD.\nNote that if this condition [vi] is satisfied for any segment J, it is also satisfied by any less sonorous\nsegment 8, for the Peak Hierarchy (204) ensures that\n*P/8 >> *P/J >> !COD.\nThus in order for J to be a possible coda, its sonority value *J* must be less than or equal to that of\nthe most sonorous segment 8 for which\n*P/8 >> !COD,\nas well as being less than the maximum sonority value BOns of possible onsets. This is just what the\nlast line of (257) says.\n\nOptimality Theory\n\n175\n\nChapter 8\n\nNow (257) establishes:\n(258) Onset/Coda Licensing Asymmetry. There are languages in which some possible onsets are\nnot possible codas, but no languages in which some possible codas are not possible onsets.\nThe second half of this asymmetry was already established in (254). The first half follows from\n(257), which asserts that the most sonorous possible onsets 8 will not be possible codas in any\nlanguage which is not weakly coda averse and in which\n!COD >> *P/8.\nSince there are no universal principles violated in such languages, they are indeed possible according\nto the Basic Segmental Syllable Theory (214). The following tableau illustrates a language in which\nd but not i is a possible coda, while both are possible onsets.\n(259) Example Tableau for a Language in which Codas License Fewer Segments than Onsets:\nPARSE\n\n*M/~\n\n*P/d\n\n*P/~\n\n!COD\n\nONS\n\n*M/i\n\n*P/i\n\n*M/d\n\n/tad/ ÿ\n\n*\n\nL .tád.\n.tá.d ~3 .\n\n*!\n\n.tá.d3 .\n\n*\n\n*!\n\n.tá.~d3 .\n.tá.+d,\n\n*\n\n*!\n\n*\n\n*\n\n*!\n\n/tai/ ÿ\n.tái.\n\n*!\n\n.tá.i~3 .\n\n*!\n\n*\n*\n\nL .tá.í.\n.tá.~í.\n.tá.+i,\n\n*\n*\n\n*!\n\n*\n\n*!\n\n/ia/ ÿ\n\nL\n\n*\n\n.iá.\n.í.á.\n\n*!*\n\n.~í.~á.\n.+i,á.\n\n*!*\n*!\n\n*\n*\n\n*\n\n176\n\nChapter 8\n\nPrince & Smolensky\n\nIn this tableau, we have omitted the marks incurred by t and a. By (256), for the two inputs of the\nform /ta8/, we need only consider candidate parses beginning .táþ., and in all these candidates the\nmarks for tá cancel. For /ia/, it follows that the optimal parse is .iá. by the proof (at the very end of\n§8.2.6) of (237), in which /Ja/ was shown to be parsed as .Já. whenever J satisfies the Possible\nOnset Conditions; these are satisfied for J = i because (231. [ii]) holds by inspection of (259):\n{ONS, *M/~} >> *M/i >> *P/i.\nis satisfied for J = i. In (259) we show some competitors simply for illustration. Since all these\ncompetitors also parse a as a peak, we can omit the cancelling marks *M/a.\nThis tableau (259) illustrates that d is a possible coda (/tad/ ÿ .tád.), and while i is a possible\nonset (in /ia/ ÿ .iá.), it is not a possible coda (/tai/ ÿ .tá.í.).\nThis same example of a language in which codas license fewer segments than onsets is analyzed\nmore completely in the following diagram (260), which shows the crucial ranking dependencies.\nHere the example illustrated in (249) has been extended to show the possible codas, delimited by\nBCod. The possible nuclei shown in (249) have been omitted here, but the possible onsets have been\nretained for comparison with the possible codas.\n(260) Deriving the Possible Coda Parameter BCod: An Example\nDecreasing Constraint Dominance ÷\na.\n\nt2\n\nPoss.\nCodas\n\n÷d\n\nb.\n\nBCod\n\nc.\n\n=*d*\n*P/~ !COD\n\nd. PARSE\ne.\n\n*P/t\n\n*P/d\n\n*P/f\n\nþ\n\n*P/l\n\nf.\ng.\n\n*P/i *P/a\n>>\n\n*M/a\n\n*M/i\n\nh. PARSE *M/~\n\nONS\n\ni.\n\n=COns *i*=\n\nj.\n\nBOns\n\nk.\n\ni2\n\n*M/l þ\n\n*M/d *M/t\n\nPossible Onsets\n\nLines e!k of (260) are identical to lines e!k of (249). In line d, we have shown that !COD is lower\nranked than PARSE and *P/~, as required by (250) in order than any codas be possible. The ranking\nof !COD relative to the associational constraints *P/~ and *M/~ now determines BCod (257). We\n\n÷t\n\nOptimality Theory\n\nChapter 8\n\n177\n\nmust first find the most sonorous segment 8 for which *P/8 >> !COD; this is d. We must then set\nBCod equal to the lower of the sonority values *d* and BOns = *i*; so BCod = *d*, as noted in lines b!c.\nThis means that all segments at most as sonorous as *d* are possible codas (257), as noted in line\na. Here we see an example where codas are more restricted than onsets, comparing lines a and k. As\nin (249), however, the figure is potentially a bit confusing because the direction of the sonority scales\nin lines a and k is reversed. This arises for the same reason here as it did in (249); like nuclei, the\npossible codas are determined (in part) by the locations of the constraints *P/8, while the possible\nonsets are determined only by the locations of the constraints *M/8. The figure does not explicitly\nshow that a possible coda is necessarily a possible onset.\nIn this example, the segments with sonority levels higher than BCod = *d* but not higher than BOns =\n*i* are possible onsets but not possible codas. These same segments are also possible nuclei (249).\nIndeed this is always the case:\n(261) PossOns!PossCod d PossNuc. In a language with some possible codas, if 8 is a possible\nonset but not a possible coda, then 8 must also be a possible nucleus.\nProof. The language must not be weakly coda averse, for if it were, all possible onsets would be\npossible codas (257), and no such 8 would exist. Given that the language is not weakly coda\naverse, and that 8 is a possible onset, 8 must fail to be a possible coda in virtue of failing to\nsatisfy condition (251.[vi]); i.e., we must have:\n!COD >> *P/8.\nSince codas are possible in the language, by (250) we must in addition have\n{PARSE, *P/~} >> !COD >> *P/8.\nThis implies that 8 satisfies the Possible Peak Condition (230.[3]):\n*P/~ or *M/8 >> *P/8\nand that 8 is a tenable peak (225):\nPARSE >> *P/8;\nthese two properties mean that 8 satisfies the Possible Peak Sufficient Condition (235).\nThere are two aspects of our onset/coda licensing asymmetry which must be distinguished. On the\none hand, from the fact that !COD asserts that Cod is a marked structural position, we derive the fact\nthat universally, inventories of codas are more restricted than those of onsets. The structural\nmarkedness of Cod entails that it is a weak licenser.\nOn the other hand, there is the particular nature of the relative restrictiveness of codas vis à\nvis sonority: that of the onset inventory the portion admitted into the coda inventory are the least\nsonorous segments. This is empirically unsatisfactory in that the most Harmonic codas are generally\nregarded to be those which are most sonorous (Prince 1983, Zec 1988, in prep., Clements 1990). This\ninadequacy can be traced to the fact that we have treated codas and onsets identically as ‘margins’,\nin contrast with peaks. This is a reasonable first step beyond the CV theory, of course, since codas\nand margins are both ‘C’ positions in contrast to the ‘V’ position of peaks. On the other hand,\nrefinements of this first step are clearly desirable. We have captured the commonality of coda and\nonset, but have ignored the fact that compared to the onset, the coda position is more structurally\nclose to the peak: perhaps in the sense that both comprise the rime, or in that both are moraic.\n\n178\n\nChapter 8\n\nPrince & Smolensky\n\nSo a refinement of the account presented above which immediately suggests itself is the\nfollowing. If a segment 8 is parsed in onset position, it incurs the associational mark *M/8; if in peak\nposition, *P/8; if in coda position, both *M/8 and *P/8: the former because the coda is a margin\nposition, the second because it is moraic (or in the rime). This refinement captures the relationship\nof coda to both onset and to nucleus.\nThe way these relationships are captured, however, makes the coda position symmetrically\nrelated to both onset and nucleus, going too far in the direction of respecting the coda/nucleus\nrelationship. For if the kind of analysis we have presented in this section is repeated with this new\napproach, the conclusion turns out to be that a possible coda must be an ambidextrous segment. This\nresult is not surprising given that the marks a segment incurs when parsed as a coda include as a\nproper subset the marks it would incur as either an onset or a nucleus. And this result succeeds in\nshifting the coda inventory from the least to the most sonorous portion of the onset inventory — but\noverenthusiastically, including only those onsets which are so sonorous as to be themselves possible\nnuclei.\nAnd assigning two marks {*M/8, *P/8} to Cod/8 while only one mark to either Ons/8 and\nNuc/8 makes the coda position inherently more marked that the other positions, above and beyond\nthe structural mark *!COD which is the sole source of the greater markedness of Cod in the approach\ndeveloped above. There are several related alternatives which assign two marks to all syllable\npositions; the simplest of which assigns {*M/8, *P/8} to Cod/8, {*P/8, *P/8} to Nuc/8, and {*M/8,\n*M/8} to Ons/8. A somewhat more complex approach introduces a separate Rime Hierarchy of\nconstraints *R/8 which is aligned with sonority like the Peak Hierarchy (more sonorous segments\nmaking more harmonic rimes); in such an account, Cod/8 incurs {*M/8, *R/8}; Nuc/8 incurs {*P/8,\n*R/8}, and Ons/8 {*M/8, *M/8}. This last approach breaks the symmetry of the relations between\nCod and Nuc on the one hand and Cod and Ons on the other, a symmetry afflicting the previous\nalternatives. And this has the consequence that possible codas are necessarily possible onsets but not\nnecessarily possible nuclei.\nThe merits of these more complex approaches relative to each other and to the simplest\naccount developed in this section are largely yet to be explored. One conclusion, however, should\nbe clear. The basic result at the core of the onset/coda licensing asymmetry which comes out of\nOptimality Theory is that the structural markedness of Cod entails that it is a weak licenser. The\nparticular nature of the restrictions applying to codas, however, depends on details of the treatment\nof codas which are yet to be seriously explored; in this section, we have examined only the very\nsimplest of possibilities.\n\n8.3.3 An Example: Berber, Take 2\nWe now illustrate the Basic Segmental Theory (214) by applying our results to the analysis of\nBerber. We repeat for convenience our previously determined constraint hierarchy (200):\n(262) Berber Hierarchy: {ONS, PARSE, *P/~, *M/a} >> *M/~ >> HNUC >> !COD\nFirst, from (262) we see that Berber is weakly coda averse (253):\n{ONS, *M/~} >> !COD.\n\nOptimality Theory\n\n179\n\nChapter 8\n\nThus the possible codas are the same as the possible onsets; we can refer to them simply as the\npossible margins. The hypothetical example illustrated in (249) can be modified to accommodate\nthe domination hierarchy (200) of Berber. We also modify it to reflect the fact that in Berber, all\nsegments are possible peaks and all segments except a are possible margins:\n(263) Determining Parameters for Berber\nDecreasing Constraint Dominance ÷\na.\n\nt2\n\nb.\n\nBNuc\n\nc. CNuc=\n\n=*t*\n\nPossible Nuclei\n\n÷a\n\nd. {PARSE, *P/~}\ne.\n\nþ\n\n*P/t\n\nf.\n\n*P/a\n\n??\n\ng.\n\n*M/a\n\nþ\n\n*M/t\n\nPossible Margins\n\n÷t\n\n*M/i\n\nh. {PARSE, ONS}\n\n*M/~\n\ni.\n\n=COns\n\n*i*=\n\nj.\n\nBOns\n\nk.\n\ni2\n\nThe relative ranking of the associational constraints {*P/t, þ, *P/a} and {*M/i, þ, *M/t} need to be\ndetermined by considering the Dell-Elmedlaoui algorithm, which resolves in a certain way the\ninherent conflict between trying to maximize nuclear vs. marginal Harmony, or, to minimize nuclear\nvs. marginal markedness. Consider the following hypothetical inputs:\n(264) Berber Peak and Margin Hierarchies.\n*M/f\n\n*M/d\n\n*M/t\n\n*P/t\n\n.t3 .kt3 .\n\n[*]\n\n{*} *\n\n.tk3 t.\n\n[ *] * !\n\n{*}\n\n*P/d\n\n*P/f\n\n/tkt/ ÿ\n\nL\n/fdt/ ÿ\n\nL .f3 .d 3t .\n.fd3 t.\n\n*\n*\n\n*\n*\n\n*\n*\n\n180\n\nChapter 8\n\nPrince & Smolensky\n\nThe Dell-Elmedlaoui algorithm gives .'t .k't . as the correct parse of /tkt/. It is instructive to compare\nthis correct parse to the competitor .tk' t., shown in the tableau (264). This tableau shows the relevant\nportions of the Peak (204) and Margin (207) Hierarchies; at this point we do not know how these\nrank relative to one another. Comparing these two alternative parses, we have cancelled a matching\npair of *M/t marks, enclosed in square brackets, and a pair of *P/t marks enclosed in curly brackets.\nThe two remaining marks are *P/t for the correct parse and *M/t for the incorrect parse\n(remembering that since *k* = *t*, k is treated like t by the constraints of both hierarchies). That is,\nsince all sonority values are equal, the correct parse has one more peak (incurring *P/t) and the\nincorrect parse one more margin (earning *M/t). In order that the correct parse (the one with more\npeaks) be the more harmonic, we must have *M/t >> *P/t. Since *M/t is the bottom of the Margin\nHierarchy and *P/t the top of the Peak Hierarchy, this entails that the entire Margin Hierarchy must\nbe ranked higher than the entire Peak Hierarchy.\nThe second example illustrated in (264) is perhaps clearer. The least harmonic peak in the\ncorrect parse of /fdt/, 3t , is less harmonic than the least harmonic peak in the incorrect parse, d3 . Thus\nif the Peak Hierarchy were dominant, the incorrect parse would be chosen, in order to avoid the least\nharmonic peak. The correct result does however arise by placing the Margin Hierarchy above the\nPeak Hierarchy: for the least harmonic margin in the incorrect parse, f, is less harmonic than the least\nharmonic margin in the correct parse, d.\nAs pointed out in fn. 10 of §2, p. 17, and briefly mentioned in §8.1.2, there are two equivalent\nharmonic ways of viewing the Dell-Elmedlaoui algorithm. The simplest is as a procedure which\nscans unsyllabified material in a string for the most harmonic nucleus, and makes it the nucleus of\na new syllable. The other is as a procedure which scans for the least harmonic potential margin, and\nit makes the nucleus of a new syllable.\nThe operations performed under either description are identical. While the first formulation\nhas the virtue of simplicity, it has a decided disadvantage as far as the current enterprise is\nconcerned: it evaluates (nuclei) from most to least harmonic. As long as this is confined within a\nsingle constraint HNUC, this falls within the purvue of Optimality Theory (as formally explained in\n§5.2.1.2). But in §8 the work done within the single constraint HNUC is now distributed over\nmultiple constraints in the Peak and Margin Hierarchies. These marks assessed by these constraints\nare scattered across the columns of constraint tableaux, and these marks operate in harmonic\nevaluation from worst to best, i.e., from those incurred by the least harmonic structures first. The\n‘worst first’ aspect of harmonic evaluation concords with the second formulation of the DellElmedlaoui algorithm, which scans for the least harmonic potential margin and parses it as a nucleus.\nThis is a consequence of the fact derived through (264), that the Margin Hierarchy dominates the\nPeak Hierarchy in Berber. In the example of /fdt/ (264), the most sonorous segment f controls the\nparsing by means of the highest-ranked (relevant) margin constraint *M/f, which must be satisfied\nif at all possible, and not by the lowest-ranked (relevant) peak constraint *P/f.\nAnother way of seeing why the Dell-Elmedlaoui algorithm in effect places the Margin\nHierarchy higher than the Peak Hierarchy can be understood through the notion of affinity introduced\nearlier. Since the entire Margin Hierarchy outranks the entire Peak Hierarchy, we have for every\nsegment 8 that:\n*M/8 >> *P/8,\ni.e., that\n*P/8 TM *M/8.\n\nOptimality Theory\n\nChapter 8\n\n181\n\nThat is, every segment is peak preferring: most harmonic when parsed as a nucleus. For the DellElmedlaoui descends the entire sonority hierarchy, preferring to construct (the most harmonic\npossible) peaks, being undetered even by voiceless stops. As long as this does not prevent (via other\nconstraints such as ONS) a more sonorous segment from being parsed as a nucleus, even ts will be\nparsed as peaks rather than margins.68\nSo what aspects of the Dell-Elmedlaoui algorithm are explained by the Optimality Theoretic\ntreatment of Berber? We have seen how the algorithm is a result of the operation of the Peak and\nMargin Hierarchies, when the Margin Hierarchy is dominant. Our analysis would also permit a\nlanguage (BerberN) in which the Peak Hierarchy dominated the Margin Hierarchy. In BerberN, the\nwinners and losers in (264) are exchanged: the parsing is driven to avoid the least harmonic peaks,\nthereby getting the most harmonic margins, rather than the other way around, as in Berber. The\nvariant of the Dell-Elmedlaoui algorithm which implements syllabification in BerberN scans the\nsonority hierarchy from least to most sonorous, at each stage constructing a new syllable in which\nthe least-sonorous possible segment is parsed as a margin.\nAt the level of individual syllables Berber and BerberN involve the same notion of syllabic\nwell-formedness: minimum-sonority margins, maximum-sonority peaks. They differ only in\nmultisyllabic comparisons, minimal cases of which are illustrated in (264). In multisyllabic parses,\nconflicts can arise between optimizing the nuclear Harmony of one syllable and optimizing the\nmarginal Harmony of an adjacent syllable; Berber and BerberN differ in whether the former or the\nlatter has priority. And since harmonic ordering works by filtering out constraint violators starting\nwith the worst, Berber’s priority on optimizing nuclear Harmony is achieved by filtering out first\nthose parses in which the most harmonic potential nuclei have been parsed as margins, that is, those\nwith the least harmonic margins. In Berber, the Margin Hierarchy dominates, giving rise to\nmultisyllabic parses in which optimizing nuclear Harmony has higher priority than optimizing\nmarginal Harmony. The reverse is true in BerberN. But both Berber and BerberN share the universal\nHarmony scales determining what constitutes a more harmonic nucleus or a more harmonic margin.\nWhat is important to note is that our theory completely rules out syllabication systems which\nconstruct syllables with minimum-sonority nuclei or maximum-sonority margins. Such systems\nwould arise from a variant of the Dell-Elmedlaoui algorithm in which the sonority scale was\ndescended from top to bottom, and at each stage the most sonorous available segment was parsed\nas a margin. Or a variant in which the sonority scale was mounted from bottom to top, the least\nsonorous available segment being parsed as a nucleus. Such syllabification systems ruled out by our\ntheory correspond to harmonic syllable systems in which the Peak Hierarchy is inverted (*P/a >> þ\n>> *P/t) and likewise for the Margin Hierarchy. In other words, our theory universally restricts the\nranking of constraints within the Peak sub-Hierarchy which determine the relative Harmony of\ndifferent nuclei, and similarly for margins. What it leaves open for cross-linguistic variation is the\n68\n\nIn fact, as pointed out in §2.1, we are abstracting away from certain complications which are not\nhandled by the Dell-Elmedloui algorithm, including effects which Dell and Elmedlaoui treat with subsequent\ndesyllabification rules operating at word boundaries. It may well be possible to incorporate such additional\ncomplexities into the present account via constraints which are sensitive to boundaries, and perhaps by\nreconsidering whether the Margin Hierarchy completely dominates the Peak Hierarchy (that is, whether even\nthe obstruents are all peak preferring).\n\n182\n\nChapter 8\n\nPrince & Smolensky\n\nway the Peak and Margin Hierarchies rank relative to each other. If the entire Margin Hierarchy\ndominates the entire Peak Hierarchy, all segments are peak-preferring and we get Berber; the other\nway around, and we get BerberN. As the analysis in §8 has shown, if the two hierarchies intersect,\nwe get more typical syllabic systems in which some number of the most sonorous segments can be\npeaks, and some number of the least sonorous can be margins.\nWe can now return to the overall analysis of Berber which helped motivate the Segmental Theory\nin the first place. The Berber constraint hierarchy (262) can now be given as:\n(265) Berber\n{ONS, PARSE, *P/~, *M/a} >> *M/~ >> [*M/i >> þ >> *M/t] >> {!COD, [*P/t >>þ >> *P/a]}\nThe constraint ‘HNUC’ of (200) has been replaced by the lower portion of the Margin Hierarchy\n[*M/i >> þ >> *M/t], and the Peak Hierarchy [*P/t >> þ >> *P/a] has been ranked beneath the\nMargin Hierarchy. The relative ranking of !COD and the Peak Hierarchy appears to have no\nempirical consequences, so we leave this ranking unspecified.\nAs a simple illustration of (265), the following tableau shows one hypothetical example:\n(266) Berber\n\n/iun/ ÿ\n\nONS,\nPARSE,\n*P/~ *M/a }\n\n*M/~\n\n*M/i\n\nL .í.u1⁄2.\n\n*\n\n.iún.\n\n*\n\n.í.~ún.\n.iú.n ~3 .\n\n*!\n*!\n\n*\n\n*M/n\n\n*M/t\n\n!COD\n\n*P/t\n\n*P/n\n\n*P/i\n\n*\n\n*\n\n*!\n\n*\n\n*\n\n*\n\n*\n\n**\n\n*\n\n*P/a\n\n*\n\nIn this tableau, we have abbreviated the sonority hierarchy to a > i > n > t and considered a\nhypothetical input which involves only these three segments. We have arbitrarily positioned !COD\nleft of the Peak Hierarchy, suggesting this arbitrariness by using a dotted line to separate them. The\ndashed lines are only used to help bind together the adjacent portions of the Margin and Peak\nHierarchies, in anticipation of the next development.\n\nOptimality Theory\n\nChapter 8\n\n183\n\n8.4 Simplifying the Theory by Encapsulating Constraint Packages\n8.4.1 Encapsulating the Association Hierarchies\nThe typology of segment classes we have developed, illustrated in the diagrams (249) and (260),\nsuggests that we may reduce the number of constraints, and enhance the interpretability of the\nanalysis, by encapsulating portions of the Peak and Margin Hierarchies into the following derived\n(parameterized) constraints:\n(267) POSS-NUC(BNuc):\n\nInterpretation: Segments with sonority less than BNuc may not be\nparsed as peaks.\nAbbreviates: [*P/t >> þ >> *P/J], where J is the most sonorous\nsegment with *J* < BNuc.\nRanking: Above CNuc. Hence, unviolated.\n\n(268) POSS-MAR(BOns):\n\nInterpretation: Segments with sonority greater than BOns may not be\nparsed as margins.\nAbbreviates: [*M/a >> þ >> *M/\"] where \" is the least sonorous\nsegment with *\"* > BOns.\nRanking: Above COns. Hence, unviolated.\n\n(269) POSS-COD(BCod):\n\nInterpretation: Segments with sonority greater than BCod may not be\nparsed as codas.69\nRanking: Sufficiently high to be unviolated.\n\n(270) *P:\n\nInterpretation: The lower *8*, the more marked the association P/8.\nAbbreviates: [*P/. >> þ >> *P/a], where *.* = BNuc.\nRanking: Below CNuc.\n\n(271) *M:\n\nInterpretation: The higher *8*, the more marked the association M/8.\nAbbreviates: [*M/D >> þ >> *M/t], where *D* = BOns.\nRanking: Below COns.\n\nTogether with the Basic Syllable Structure Constraints (114!120), these constraints define the\nEncapsulated Segmental Syllable Theory. We discuss them in turn.\nThe constraints POSS-NUC and POSS-MAR are unviolated by construction. POSS-NUC and POSS-MAR\neach encapsulate by definition exactly those associational constraints *P/8 or *M/8 which we have\n69\n\nThe discussion at the end of §8.3.2 introduces several possible refinements of the account of codas\ndeveloped here. All these refinements have as a consequence that the coda inventory is governed by two\nparameters ranging over the sonority scale: a lower limit as well as an upper limit.\n\n184\n\nChapter 8\n\nPrince & Smolensky\n\nthrough rather extensive analysis shown to be unviolated in all outputs. They also each encapsulate\njust those associational constraints which dominate what we have shown to be a critical constraint\n(246): either CNuc (the lowest-ranked of PARSE, ONS, and *M/~) or COns (the lowest-ranked of PARSE\nand *P/~). Thus the positions of POSS-NUC and POSS-MAR in the constraint hierarchy must reflect\nthis, and the restrictions on the allowed rankings of these constraints are noted in (267) and (268).\nThat the derived constraint POSS-X (X = NUC or MAR) dominate the corresponding Basic Syllable\nStructure Constraint CX is sufficient (as our analysis has shown) to ensure that they are unviolated,\nand so it does not matter where each is ranked above CX.\nIt is clear that POSS-NUC and POSS-MAR constitute a reconstruction within the Basic\nSegmental Syllable Theory (214) of the analogs of the two universally high-ranked constraints of the\nBasic CV Syllable Theory (123):\n*P/C: C may not be parsed as a peak (122), and\n*M/V: V may not be parsed as a margin (121).\nThe constraint POSS-COD is less directly constructed. In languages without onset/coda licensing\nasymmetries, where BCod = BOns, such a constraint is not needed; POSS-MAR suffices to block illegal\nassociations to both Ons and Cod. So consider a language in which there is a segment 8 which is a\npossible onset but not a possible coda (BCod < BOns). Associations Cod/8 must be blocked, but not\nby blocking M/8, since Ons/8 is legal. The arrangement of Basic Segmental Syllable Theory\nconstraints that conspires to block Cod/8 is more spread out than that which blocks Ons/\" for an\nillegal onset \" (simply, *M/8 >> COns). Included is the requirement (257) that !COD >> *P/8, but\nneither !COD nor *P/8 can be absorbed into a derived constraint POSS-COD. We therefore simply\ndefine POSS-COD by its interpretation in (269), without reducing its definition to an abbreviation of\nassociational constraints. We also simply assert that it must be sufficiently highly ranked to be\nunviolated, without stating precisely what constitutes a high enough ranking to ensure this.\nThe constraints *P and *M encapsulate the lower portions of the Peak and Margin Hierarchies,\nrespectively: the portions remaining after the highest parts have been incorporated into the POSS-NUC\nand POSS-MAR constraints. As discussed in §8.3.3 in the context of Berber, the constraints *P\nconstitutes a reconstruction of HNUC, but with a subtle change: *P evaluates marks from worst to\nbest, whereas HNUC evaluates marks from best to worst. (This difference among constraints was\ndiscussed formally at the end of §5.2.1.2 in terms of the order in which constraints list the marks\nincurred by entire parses.) Like HNUC, the constraints *P and *M are non-binary, and their use in\nranking competing structures is a bit more complex than with the binary constraints they encapsulate.\nRemembering that they are mere abbreviations for portions of the Peak and Margin Hierarchies,\nrespectively, it is clear that to use them in a constraint tableau, under *P one lists all the marks *P/8\nincurred by a candidate, starting from the worst. Then to compare two candidates’ violations of *P,\nwe tick off their respective marks *P/8 starting from the worst. When the two candidates share a\nparticular mark *P/8, that mark cancels. As soon as one candidate reaches a mark that is not\ncancelled by the other, the candidate with the worst mark loses. We illustrate with our canonical\nexample.\n\nOptimality Theory\n\n185\n\nChapter 8\n\n8.4.2 An Example: Berber, Take 3\nUsing the encapusalated constraints, we can rewrite the Berber constraint domination heirarchy (265)\nas follows:\n(272) Berber: {ONS, PARSE, *P/~, POSS-MAR} >> *M/~ >> *M >> {!COD, *P}\nPOSS-COD is unnecessary, merely repeating POSS-MAR, since there is no onset/coda licensing\nasymmetry. POSS-MAR is simply *M/a, since in Berber only a is not a possible margin. Note that\nPOSS-MAR is indeed ranked higher than COns / min{PARSE, ONS, *M/~} = *M/~ in Berber, as\nrequired by (268). *M encapsulates all the Margin Hierarchy except *M/a = POSS-MAR, and, as\nrequired by (271), *M ranks lower than COns. Since all segments are possible nuclei in Berber, POSSNUC vanishes, and *P is the entire Peak Hierarchy. As required by (270), *P ranks lower than CNuc\n/ min{PARSE, *P/~} in Berber.\nWe illustrate this encapsulated account of the Berber analysis (272) by showing the resulting tableau\nwhich encapsulates (266):\n(273) Berber:\n{ONS,\nPARSE,\n*P/~\n/iun/ ÿ\n\nPOSSMAR}\n\n*M/~\n\n*M/a\n\n*M/i\n\nL.í.u1⁄2.\n\n*i\n\n.iún.\n\n*i\n\n.í.~ún.\n.iú.n ~3 .\n\n*!\n*!\n\n!COD\n\n*M\n\n*i\n\n*M/n\n\n*M/t\n\n*P\n*P/t\n\n*P/n\n\n*P/i\n\n*n\n\n*i\n\n*n !\n\n*\n\n*i\n\n*n\n\n*\n\n*i *i\n\n*n\n\n*P/a\n\n*i\n\n8.4.3 Sufficiency and Richness of the Encapsulated Theory\nIn the preceding analysis of Berber, the Encapsulated Segmental Syllable Theory was sufficient to\nre-express the earlier Basic Segmental Syllable Theory analysis. This is because it was not necessary\nto insert additional constraints into the midst of the portions of the Peak and Margin Hierarchies that\nare encapsulated by *P and *M. How generally this will turn out to be the case is an open question.\nThere seems to be no obvious principle that would prevent such intrusions of additional constraints.\nIt is also somewhat unclear whether the Encapsulated Theory has sufficient expressive power\nto cover all analyses possible within the Basic Segmental Syllable Theory. For example, if *P and\n*M are ranked as wholes one above the other, as required by the Encapsulated Theory, this does not\n\n186\n\nChapter 8\n\nPrince & Smolensky\n\npermit expression of the general patterns of interdigitating the Peak and Margin Hierarchies which\nare possible with the Basic Theory. We are no longer free, for example, to independently manipulate\nthe parameter BAff which determines the sonority value separating peak- from margin-preferring\nsegments.\nIt is however not clear whether this limitation reduces the languages which can be analyzed.\nWe do know that some languages analyzable within the Basic Theory require !COD to be inserted\nwithin the constraints encapsulated by *P. Consider a language which allows:\n{t, þ, i} as onsets,\nonly {t, d} as codas, and\n{d, þ, a} as peaks.\nThis possibility would be illustrated by (249) and (260), if in (249) *P/d were down-ranked slightly,\nbelow CNuc = *P/~. Encapsulating this analysis,\nPOSS-NUC / *P/t,\nsince t is the only impossible nucleus. Thus\n*P / [*P/d >> *P/f >> þ >> *P/a].\nBut in order that d but not f be a possible coda, while both are possible onsets, we must have, by the\nPossible Coda Parameter expression (257):\n*P/d >> !COD >> *P/f.\nSo !COD must insert itself into the constraints encapsulated by *P in order to separate the legal from\nillegal codas.\nHowever, this language does seem to be analyzable in the Encapsulated Theory, even though\n!COD cannot be inserted into *P now treated as a single constraint. This is achieved simply by\nsetting BCod = *d* in POSS-COD.\nYet even if the Encapsulated Theory does turn out to offer less generality of analysis than the Basic\nTheory with its full hierarchies of associational constraints, it appears to be worthwhile determining\nwhether analysis within the Encapsulated Theory is possible before resorting to the more complex\nBasic Theory. The general conception of constraint encapsulation can be applied in other ways than\nin (267)!(271), and other modes of encapsulation may be appropriate under certain ranking\nconditions.\nWere it not for the influence of our primary example, Berber, where HNUC has been the driving force\nfor our analysis, one might have been tempted to try a more Boolean encapsulation strategy. The\nsegmental inventory having been divided into the classes (242), we might try to simply define\nconstraints that rule out all impossible associations, and leave it at that. Aside from the role of\nsonority in separating the classes of possible nuclei, possible onsets, and possible codas from one\nanother, sonority would then play no role within the classes themselves. This would amount to\nadopting the parametrized high-ranking (unviolated) constraints POSS-NUC, POSS-MAR, and POSSCOD, but omitting the constraints *P and *M which serve to distinguish the relative Harmonies of\npossible associations. In such a theory, all the segments within a given class would be\ndistributionally equivalent.\nIt is worth emphasizing that this alternative Boolean encapsulation would fail rather seriously\nto do justice to the Basic Segmental Syllable Theory. We have of course seen many examples of the\nrole of sonority in governing syllabification within the large class of ambidextrous segments in\n\nOptimality Theory\n\n187\n\nChapter 8\n\nBerber. Indeed, the following example shows that, at least in languages that permit codas, Berberlike syllabification is universal within the class of ambidextrous segments:\n(274) Sonority is Operative within the Class of Ambidextrous Segments\n/tat8182/ ÿ\n.tá.t 83182.\n\n*P/81, *M/82\n\n.tát.81832.\n\n*M/81, *P/82\n\nHere 81 and 82 are two ambidextrous segments: possible nuclei, margins, and codas. By (256) we\nknow that the initial /ta/ is parsed .tá. The question is whether the segments 8182 will be parsed as\nthe rime of a closed syllable starting with t, or as an open syllable, leaving the second t to close the\nfirst syllable. The marks incurred by 81 and 82 are shown in (274). Clearly, if *81* > *82*, then both\nthe marks *P/81 and *M/82 of the first parse are dominated by the marks of the second, thanks to the\nPeak (204) and Margin (207) Hierarchy. For in this case 81 is a more harmonic peak and 82 is a more\nharmonic margin. If, on the other hand, *81* < *82*, then the reverse holds and the second parse is\nthe optimal one. Thus within the ambidextrous segments, sonority operates within syllabification to\nfind the optimal nuclei, as in Berber.\nTo see how sonority differences affect syllabification even within the classes of pure onsets\nand pure peaks, consider a deletion language, one where {ONS, *M/~ = FILLOns, *P/~ = FILLNuc } >>\nPARSE. First suppose J1 and J2 are pure onsets: they are possible onsets but not possible peaks.\nConsider the following example:\n(275) Sonority is Operative within the Class of Pure Onsets\n/J1J2a/ ÿ\n.+J1,J2á.\n\n*M/J2\n\n.J1+J2,á.\n\n*M/J1\n\nSince we are in a deletion language, the prefered repair here will be deletion. The question is, which\nconsonant will be deleted? If J1 is deleted, the onset incurs the mark *M/J2; and likewise with 1 and\n2 interchanged. The least marked onset will contain the least sonorous segment, so the more\nsonorous segment is the one to delete. Thus sonority differences within the class of pure consonants\nare operative in syllabification.\nThe parallel example for pure peaks \"1 and \"2 is:\n(276) Sonority is Operative within the Class of Pure Peaks:\n/t\"1\"2/ ÿ\n.t+\"1,\"' 2.\n\n*P/\"2\n\n.t\"' 1+\"2,.\n\n*P/\"1\n\nHere, it is the least sonorous segment that deletes, to create the most harmonic nucleus.\n\n188\n\nChapter 8\n\nPrince & Smolensky\n\nPART III\n\nIssues and Answers in Optimality Theory\n\nOptimality Theory\n\nChapter 9\n\n191\n\n9. Inventory Theory and the Lexicon\n\nA\n\nll grammatical constraints are violable, in principle. A constraint such as ONS, ‘syllables have\nonsets’, in and of itself and prior to its interaction with other constraints, does not assert that\nsyllables lacking onsets are impossible, but rather that they are simply less harmonic than\ncompetitors possessing onsets. Its function is to sort a candidate set by measuring adherence to\n(equivalently: divergence from) a formal criterion. Constraints therefore define relative rather than\nabsolute conditions of ill-formedness, and it may not be immediately obvious how the theory can\naccount for the absolute impossibility of certain structures, either within a given language or\nuniversally. Yet in the course of the preceding analyses we have seen many examples of how\nOptimality Theory explains language-particular and universal limits to the possible. In this section,\nwe identify the general explanatory stategy that these examples instantiate, and briefly illustrate how\nthis strategy can be applied to explaining segmental inventories. We then consider implications for\nthe lexicon, proposing a general induction principle which entails that the structure of the constraints\nin a language’s grammar is strongly reflected in the content of its lexicon. This principle, Lexicon\nOptimization, asserts that when a learner must choose among candidate underlying forms which are\nequivalent in that they all produce the same phonetic output and in that they all subserve the\nmorphophonemic relations of the language equally well, the underlying form chosen is the one\nwhose output parse is most harmonic.\n\n9.1 Language-Particular Inventories\nWe begin by examining a simple argument which illustrates the central challenge of accounting for\nabsolute ill-formedness in a theory of relative well-formedness:\n“For Optimality Theory, syllables without onsets are not absolutely ill-formed, but only\nrelatively. The syllable .VC. (for example) is more ill-formed than the syllable .CV., but .VC. is not\nabsolutely ill-formed. How can Optimality Theory bar .VC. from any language’s syllable inventory?\n“What Optimality Theory would need in order to outlaw such syllables is some additional\nmechanism, like a threshold on ill-formedness, so that when the graded ill-formedness of syllables\npasses this threshold, the degree of ill-formedness becomes absolutely unacceptable.”\nThe fallacy buried in this argument has two facets: a failure to distinguish the inputs from\nthe outputs of the grammar, coupled with an inappropriate model of grammar in which the ill-formed\nare those inputs which are rejected by the grammar. In Optimality Theory, the job of the grammar\nis not to accept or reject inputs, but rather to assign the best possible structure to every input. The\nplace to look for a definition of ill-formedness is in the set of outputs of the grammar. These outputs\nare, by definition, well-formed; so what is ill-formed — absolutely ill-formed — is any structure\nwhich is never found among the outputs of the grammar. To say that .VC. syllables are not part of\nthe inventory of a given language is not to say that the grammar rejects /VC/ and the like as input,\nbut rather that no output of the grammar ever contains .VC. syllables.\n\n192\n\nChapter 9\n\nPrince & Smolensky\n\nWe record this observation in the following remark:\n(277) Absolute ill-formedness. A structure n is (absolutely) ill-formed with respect to a given\ngrammar iff there is no input which when given to the grammar leads to an output that\ncontains n.\nNote further that in a demonstration that .VC. syllables are ill-formed according to a given\ngrammar, the input /VC/ has no a priori distinguished status. We need to consider every possible\ninput in order to see whether its output parse contains a syllable .VC. Of course, /VC/ is a promising\nplace to start the search for an input which would lead to such a parse, but, before concluding that\n.VC. syllables are barred by the grammar, we must consider all other inputs as well. Perhaps the\noptimal parse of /C/ will turn out to be .~3 C., providing the elusive .VC. syllable. It may well be\npossible to show that if any input leads to .VC. syllables, then /VC/ will — but in the end such an\nargument needs to be made.\nIf indeed .VC. syllables are ill-formed according to a given grammar, then the input /VC/\nmust receive a parse other than the perfectly faithful one: .VC. At least one of the faithfulness\nconstraints PARSE and FILL must be violated in the optimal parse. We can therefore generally\ndistinguish two paths that the grammar can follow in order to parse such problematic inputs:\nviolation of PARSE, or violation of FILL. The former we have called ‘underparsing’ the input, and in\nsome other accounts would correspond to a ‘deletion repair strategy’; the latter, overparsing,\ncorresponds to an ‘epenthesis repair strategy’. (In §10.3 we explicitly compare Optimality Theory\nto some repair theories.) These two means by which a grammar may deal with problematic inputs\nwere explicitly explored in the Basic CV Syllable Structure Theory of §6. There we found that .VC.\nsyllables were barred by either\n[i] requiring onsets: ranking either PARSE or FILLOns lower than ONS; or\n[ii] forbidding codas: ranking either PARSE or FILLNuc lower than !COD.\nOne particularly aggressive instantiation of the underparsing strategy occurs when the\noptimal structure assigned by a grammar to an input is the null structure: no structure at all. This\ninput is then grammatically completely unrealizable, as discussed in §4.3.1. There is some subtlety\nto be reckoned with here, which turns on what kinds of structure are asserted to be absent in the null\noutput. In one sense, the null means ‘lacking in realized phonological content’, with maximal\nviolation of PARSE, a possibility that can hardly be avoided in the candidate set if underparsing is\nadmitted at all. In another sense, the null form will fail to provide the morphological structure\nrequired for syntactic and semantic interpretation, violating M-PARSE. To achieve full explicitness,\nthe second move requires further development of the morphological apparatus; the first requires\nanalogous care in formulating the phonetic interpretation function, which will be undefined in the\nface of completely unparsed phonological material. In this discussion, we will gloss over such\nmatters, focusing on the broader architectural issues.\nIt would be a conceptual misstep to characterize null parsing as rejection of the input and to\nappeal to such rejection as the basis of a theory of absolute ill-formedness. For example, it would\nbe wrong to assert that a given grammar prohibits .VC. syllables because the input /VC/ is assigned\nthe null structure; this is a good hint that the grammar may bar .VC. syllables, but what needs to be\n\nOptimality Theory\n\nChapter 9\n\n193\n\ndemonstrated is that no input leads to such syllables. In addition, a grammar which assigns some\nnon-null structure to /VC/, for example .~V.+C,, might nonetheless prohibit .VC. syllables.\nSubject to these caveats, it is clear that assigning null structure to an input is one means a\ngrammar may use to prevent certain structures from appearing in the output. The Null Parse is a\npossible candidate which must always be considered and which may well be optimal for certain\nparticularly problematic inputs. We have already seen two types of examples where null structures\ncan be optimal. The first example emerged in the analysis of Latin minimal word phenomenon in\n§4.3.1, where, given a certain interpretation of the data, under the pressure of FTBIN and LX.PR, the\noptimal parse of the monomoraic input is null (but see Mester 1992:19-23). The second was in the\nCV Syllable Structure Theory of §6, where it was shown that the structure assigned to /V/ is null in\nany language requiring onsets and enforcing ONS by underparsing: that is, where PARSE is the least\nsignificant violation, with {ONS, FILLOns} >> PARSE; as in ex. (134), p.101.\n\n9.1.1 Harmonic Bounding and Nucleus, Syllable, and Word Inventories\nAbsolute ill-formedness, explicated in (277), is an emergent property of the interactions in a\ngrammar. Showing that a structure n is ill-formed in a given language requires examination of the\nsystem. One useful strategy of proof is to proceed as follows. First we let A denote an arbitrary\ncandidate parse which contains the (undesirable) structure n. Then we show how to modify any such\nanalysis A to produce a particular (better) competing candidate parse B of the same input, where B\ndoes not contain n and where B is provably more harmonic than A. This is sufficient to establish that\nno structure containing n can ever be optimal. The structure n can never occur in any output of the\ngrammar, and is thus absolutely ill-formed. We have called this method of proof “Harmonic\nBounding” — it establishes that every parse containing the structure n is bettered by, bounded\nabove by, one that lacks n.\nThe strategy of Harmonic Bounding was implicitly involved, for example, in the analysis of\nthe minimal word phenomenon (§4.3.1). In this case, the impossible structure is n = [:]PrWd. We\nexamined the most important type of input, a monomoraic one like /re/, and showed that the analysis\ncontaining n, A = [[ré]F]PrWd, is less harmonic than a competitor B = +re,, the Null Parse, which lacks\nn. The method of constructing B from A is simply to replace structure with no structure.\nTo complete the demonstration that the Latin constraint hierarchy allows no monomoraic\nwords in the output, we must consider every input that could give rise to a monomoraic word. We\nneed to examine inputs with less than one mora, showing that they do not get overparsed as a single\nempty mora: [[~3 :]F]PrWd. We also must consider inputs of more than one mora, showing that these\ndo not get underparsed, with only one mora being parsed into the PrWd: [[:]F]PrWd+:þ,. Both of these\nare also harmonically bounded by the Null Parse of the relevant inputs. On top of whatever violation\nmarks are earned by complete structuring of monomoraic input — marks that are already sufficient\nto establish the superiority of the Null Parse — these moraic over- and under-parses incur *FILL and\n*PARSE marks as well, and it is even clearer that a monomoraic parse cannot be optimal.\nSimilarly, in the analysis of Lardil in §7, we provided the core of the explanation for why no\nwords in its inventory can be monomoraic. The result is the same as in Latin, but enforcement of\nLX.PR and FTBIN for monomoraic inputs is now by overparsing rather than by underparsing, due\nto differences in the constraint ranking. The structure we wish to exclude is again n = [:]PrWd, and,\n\n194\n\nChapter 9\n\nPrince & Smolensky\n\nas in Latin, we examined monomoraic inputs such as /maÏ/ (182), p.130, to see if their parses\ncontained n. In each case, the optimal parse is a bisyllabic competitor B with an unfilled second\nmora. We also examined vowel-final bimoraic inputs (184), p.134, because, for longer inputs, a final\nvowel is optimally unparsed, a pattern which would lead to monomoraicity if universally applied.\nHowever, both moras in bimoraic inputs must be parsed, so again we fail to produce a monomoraic\noutput. Inputs with three or more moras leave a final vowel unparsed, but parse all the others (183),\np.132. Thus, there are no inputs, long or short, which produce monomoraic outputs.\nIt is worth emphasizing that, even though the lack of monomoraic words in the Latin and\nLardil inventories is a result of the high ranking of LX.PR and FTBIN in the domination hierarchy,\nit would be distinctly incorrect to summarize the Optimality Theory explanation as follows: “LX.PR\nand FTBIN are superordinate therefore unviolated, so any monomoraic input is thereby rendered\nabsolutely ill-formed.” An accurate summary is: “LX.PR and FTBIN dominate a FAITHFULNESS\nconstraint (PARSE in Latin; FILL in Lardil), so for any input at all — including segmentally\nmonomoraic strings as a special case — monomoraic parses are always less harmonic than available\nalternative analyses (Null Parse for Latin, bisyllable for Lardil); therefore outputs are never\nmonomoraic.”\nSuccessful use of the Harmonic Bounding argument does not require having the optimal\ncandidate in hand; to establish *n in the absolute sense, it is sufficient to show that there is always\na B-without-n that is better than any A-with-n. Whether any such B is optimal is another question\nentirely. This can be seen clearly in the kind of argument pursued repeatedly above in the\ndevelopment of the Basic Segmental Syllable Theory in §8. For example, as part of the process of\nderiving the typology of segmental inventories licensed by various syllable positions, we showed that\nthe inventory of possible nuclei could not include a segment \" in any language in which\n*P/\" >> {FILLNuc, *M/\"}).70 These are languages in which it is\n[i] more important to keep \" out of the Nucleus (P = ‘peak’) than to fill the Nucleus, and\n[ii] more important to keep \" out of the Nucleus than to keep it out of the syllable margins.\nThe n we want to see eliminated is the substructure Nuc/\", in which the segment \" is dominated by\nthe node Nucleus. Let A denote an arbitrary parse containing Nuc/\" = \"' , so that a segment \"\nappearing in the input string is parsed as a nucleus: A = ~\"' ~. The bounding competitor B is identical\nto A except that the structure in question, Nuc/\", has been replaced by the string in which \" is an\nonset sandwiched between two empty nuclei; B = ~~3 .\"~3 ~. In terms of the slash-for-domination\nnotation, the crucial replacement pattern relating A to B can be shown as\nB = ... Nuc/~. Ons/\" Nuc/~. ... .\nA = ... Nuc/\" ...\nWe have then the following argument:\n(278) Harmonic Bounding Argument showing \" is an impossible nucleus\na. Assumed constraint ranking\n*P/\" >> {FILLNuc, *M/\"}\nHere, *M/\" and *P/\" are the constraints against parsing \" as a Margin (Onset, Coda) and as a Peak\n(Nucleus), respectively; this is the contrapositive of the Possible Peak Condition (230).\n70\n\nOptimality Theory\n\nb. Structures\ni.\nn = \"'\nii. A = ~ \"' ~\niii. B = ~ ~3.\"~3 ~\n\nChapter 9\n\n195\n\n(segment \" qua nucleus)\n(any parse taking \" to be a nucleus)\n(analysis A modified in a specific way to make \" nonnuclear)\n\nc. Argument: show that B bests A.\nIt should be clear that B is always more harmonic than A in the given languages. The mark *P/\"\nincurred by nucleizing \" in A is worse than both the marks *M/\" (for marginalizing \") and *FILLNuc\n(for positing empty nuclei) that are incurred by B. Hence, in such a grammar the optimal parse can\nnever include n = Nuc/\", no matter what the input. The conclusion is that \" is not in the inventory\nof possible nuclei for these languages. However, we cannot conclude that every occurence of \" is\nin onset position, as in the bounding analysis B, or indeed, without further argument, that any\noccurrence of \" is in onset position. There may be other analyses that are even more harmonic than\nB in specific cases; but we are assured that \" will never be a nucleus in any of these. (In fact, under\ncertain rankings consistent with (278a) \" will be banned from the surface altogether, barred from the\nonset as well as the nucleus, as an ‘untenable association’, (225), p. 156.)\nThe Harmonic Bounding strategy is explicitly carried out for syllable inventories in the CV\ntheory in the appendix, and is implicitly involved in a number of other results derived above.\nSamek-Lodovici (1992ab) makes independent use of the same method of proof (taking B to be a kind\nof Null Parse) to establish the validity of his Optimality theoretic analysis of morphological\ngemination processes.\n\n9.1.2 Segmental Inventories\nHaving illustrated the way prosodic inventories are delimited, from the structural level of the syllable\nposition (e.g. Nuc) up through the syllable itself to the word, we can readily show how the technique\nextends downward to the level of the segment. Now we take as inputs not strings of already formed\nsegments, but rather strings of feature sets. These must be optimally parsed into segments by the\ngrammar, just as (and at the same time as) these segments must be parsed into higher levels of\nphonological structure. The segmental inventory of a language is the set of segments found among\nthe optimal output parses for all possible inputs.\nWe now illustrate this idea by analyzing one particular facet of the segmental inventory of\ny\nYidin (Kirchner 1992b). Our scope will be limited: the interested reader should examine the more\ncomprehensive analysis of the Yidiny inventory developed in Kirchner’s work, which adopts the\ngeneral Optimality Theory approach to inventories, but pursues different analytic strategies from the\nones explored here.\n\n196\n\nChapter 9\n\nPrince & Smolensky\n\nThe consonant inventory of Yidiny looks like this:\nLabial\n\nCoronal\n\nb\nm\n\nd\nn\nl\nr\n\nRetroflex\nCoronal\n\nPalatalized\nCoronal\n\nVelar\n\ndy\nny\n\ng\nõ\n\nÏ\n\nHere [r] is a “trilled apical rhotic” and [Ï] an “apical postalveolar (retroflex) rhotic continuant,”\naccording to Dixon (1977:32).\nComplex articulations are found only at coronal place of articulation; this is the\ngeneralization we wish to derive. The complexities include palatalization in [dy, ny] and the\nretroflexion in [Ï]. (A similar but more articulated system is found in Lardil; see (148), §7.1, p. 109.)\nWe propose to analyze the normal and palatalized coronals as follows, along lines developed in\nClements 1976, 1991 and Hume 1992:\n(279) Representation of Coronals\na. Normal\nb. Palatalized\nPLACE\n*\nC-Pl\n*\nCor\n\nPLACE\nC-Pl\n*\nCor\n\nV-Pl\n*\nCor\n\nIn line with the findings of Gnanadesikan 1992 and Goodman in prep, we hold that retroflexion is\ndorsalization rather than coronalization (as it is in Kirchner 1992b). To focus the discussion, we will\ndeal only with the coronalized coronals. As a compact representation of these structures, we will use\nbracketing to denote the structure of the Place node, according to the following scheme:\n(280) Bracketting Notation for Place Geometry\n‘feature \" occupies C-Place, there is no V-Place’ node.\na. [\"]\nb. [\" $]\n‘feature \" occupies C-Place and feature $ occupies V-Place’\nWith this notation, structure (279.a) is denoted by [Cor] and structure (279.b), by [Cor Cor].\nIn this representational system, the palatalized coronals are literally complex, with two places\nof articulation, while the other, unmarked coronals are literally simple. The generalization is now\nclear: of all the possible structurally complex places, only one is admitted into the Yidiny lexicon:\nthe one in which the primary and secondary places are both Cor — generally held to be the unmarked\nplace of articulation (Avery & Rice 1989, and see especially the papers in Paradis & Prunet 1991,\nreviewed in McCarthy & Taub 1993).\n\nOptimality Theory\n\nChapter 9\n\n197\n\nInformally speaking, two generalizations are involved:\n(281) Coronal unmarkedness (observation). “Don’t have a place of articulation other than\nCoronal.”\n(282) Noncomplexity (observation). “Don’t have structurally complex places of articulation.”\nOur goal is to analyze the interaction between coronal unmarkedness and complexity markedness.\nThis is of particular interest because it exemplifies a common pattern of interaction: each constraint\nis individually violated, but no form is admitted which violates both of them at once. There are\nconsonants with single Lab or Dors specifications, violating coronal unmarkedness, and there are\nconsonants with two place specifications, violating noncomplexity. But no consonant with any\nnoncoronal place feature has a complex specification. We dub this generalization pattern banning\nthe worst of the worst.\nThe worst-of-the-worst interaction is absent in the Basic CV Syllable Structure Theory. The\ntwo dimensions of well-formedness there — Onset well-formedness (more harmonic when present)\nand Coda well-formedness (more harmonic when absent) — operate independently. Requiring Onset,\nprohibiting Coda will generate the entire Jakobson Typology; the *worst-of-the-worst languages do\nnot appear. Such a language would allows onsets to be absent, and codas to be present, but not in the\nsame syllable; its inventory would include CV, V, CVC but exclude VC. This inventory is not\npossible according to the Basic CV Syllable Structure Theory, and we know of no reason to believe\nthat this is anything but a desirable result.\nThe techniques already developed enable a direct account of the interaction between coronality and\nstructural complexity. We assume that the input to the grammar is a string of root nodes each with\na set of (unassociated) features. The output is an optimal parse in which these features are associated\nto root nodes (with the root nodes associated to syllable-position nodes, and so on up the prosodic\nhierarchy). To minimize distractions, let’s assume a universally superordinate constraint requiring\nroot notes to have a child PL (Place) node. (This parallels the assumption made in §6 that the syllable\nnode always has a child Nuc, due to universal superordinance (123) of the relevant constraint NUC\n(119), p. 96.) For the present analysis of consonant inventories, we similarly assume a universally\nsuperordinate constraint, or restriction on Gen, to the effect that in consonants the presence of VPlace entails the presence of C-Place. (This head/dependent type of relationship is conveniently\nencoded in the bracketing notation of (280), because the configuration [\" is always interpreted as\n‘\" is C-Pl’.)\nOur focus will be on which of the place features in an input feature set gets associated to the\nPL node. As always, unparsed input material is phonetically unrealized; underparsing is therefore\na principal means of barring certain feature combinations from the inventory. If certain infelicitous\ncombinations of features should appear in an input feature set, the grammar may simply leave some\nof them unparsed; the feature combinations which surface phonetically define a segmental inventory\nfrom which certain ill-formed feature combinations have been absolutely banned.\nIn Yidiny, the feature set {Cor, Cor} gets completely parsed. Both Cor features are associated\nto the PL node in the optimal parse, and the segment surfaces as dy or ny, depending on which other\n\n198\n\nChapter 9\n\nPrince & Smolensky\n\nfeatures are in the set. On the other hand, the set {Lab, Lab} does not get completely parsed: the\ninventory does not include complex labials. In contrast, the unit set {Lab} does get completely\nparsed; the language has simple labials.\nTo minimize notation we will deal only with Cor and Lab; any other non-coronal place\nfeatures receive the same analysis for present purposes as Lab.\nCoronal unmarkedness can be formally stated as the following universal Harmony scale:\n(283) Coronal Unmarkedness, Harmony Scale: PL/Cor TM PL/Lab\nThe notation ‘PL/Cor’ refers to a structural configuration in which PL dominates Cor, understood\nto be through some intermediate node — either C-Pl or V-Pl. The simplest theory, which we develop\nhere, treats the two intermediate nodes alike for purposes of Harmony evaluation.\nFollowing the same analytic strategy as for Universal Syllable Position/Segmental Sonority\nProminence Alignment (213), §8, p.150, we convert this Harmony scale to a domination ranking of\nconstraints on associations:\n(284) Coronal Unmarkedness, Domination Hierarchy: *PL/Lab >> *PL/Cor\nFollowing the general ‘Push/Pull’ approach to grammatical parsing summarized in §8.1 (186), the\nidea here is that all associations are banned, some more than others. The constraint hierarchy (284)\nliterally says that it is a more serious violation to parse labial than to parse coronal. Coronal\nunmarkedness in general means that to specify PL as coronal is the least offensive violation. The\nconstraint *PL/Lab is violated whenever Lab is associated to a PL node; this constraint universally\ndominates the corresponding constraint *PL/Cor because Lab is a less well-formed place than Cor.\nIn addition to these two associational constraints we have the usual FAITHFULNESS constraints PARSE\nand FILL. They are parametrized by the structural elements they pertain to; in the present context,\nthey take the form:\n(285) PARSEFeat: An input feature must be parsed into a root node.\n(286) FILLPL: A PL node must not be empty (unassociated to any features).\nJust as with the segmental syllable theory, we have a set of deeply conflicting universal constraints:\nassociation constraints (*PL/Lab, *PL/Cor), which favor no associations, and FAITHFULNESS\nconstraints which favor associations (PARSEFeat from the bottom up, FILLPL from the top down). This\nconflict is resolved differently in different languages by virtue of different domination hierarchies.\nThe four constraints can be ranked in 4! = 24 ways overall; Universal Grammar, in the guise of\nCoronal Unmarkedness (283), rules out the half of these in which *PL/Lab is ranked below *PL/Cor,\nleaving 12 possible orderings, of which 8 are distinct. These induce a typology of segment\ninventories which includes, as we will shortly see, the Yidiny case.\nIn languages with a wider variety of complex segments than Yidiny, we need to distinguish\nan input which will be parsed as [Cor Vel] – a velarized coronal like [tp]– from an input which will\n\nOptimality Theory\n\nChapter 9\n\n199\n\nbe parsed as [Vel Cor] – a palatalized velar like [ky]. (Both these segments occur, for example, in\nIrish and Russian). For this purpose we assume that the feature set in the first input is {Cor, VelN}\nand in the second, {CorN, Vel}; the notation fN means that the feature f is designated in the feature\nset as secondary, one which is most harmonically parsed in the secondary place position. That is, we\nhave the constraint:\n(287) * [ fN. fN is not parsed as the primary place of articulation (not associated to C-Pl).\nSince f and fN designate the same place of articulation, parsing either of them incurs the same mark\n*PL/f; there are no separate marks *PL/fN because *PL/f refers only to the place of articulation f.\nNow we are ready to analyze the interaction between coronal unmarkedness and complexity in\nYidiny. The analysis is laid out for inspection in table (288):\n\n200\n\nChapter 9\n\nPrince & Smolensky\n\n(288) Segmental Inventory\nInput POA’s\nCoronalized\nCoronal\n\nCandidates\n\nFILLPL\n\n*PL/Lab\n\nPARSEFeat\n\n*PL/Cor\n\n[Cor CorN]\n\n**\n\n{PL, Cor, CorN} b.\n\n[CorN Cor]\n\n**\n\nc.\n\n[Cor] +CorN,\n\n*!\n\n*\n\nd.\n\n[CorN] +Cor,\n\n*!\n\n*\n\ne.\n\n[ ] +Cor, CorN,\n\nf.\n\n[Lab LabN]\n\n**!\n\n{PL, Lab, LabN} g. L\npw μ p\nh.\n\n[Lab] +LabN,\n\n*\n\nCoronalized\nLabial\n\ni.\n\n[Lab CorN]\n\n*!\n\nj.\n\n[Lab] +CorN,\n\n*!\n\nk. L\n\n[CorN] +Lab,\n\nl.\n\n[ ] +Lab, CorN,\n\nm.\n\n[Cor LabN]\n\nn. L\n\n[Cor] +LabN,\n\no.\n\n[LabN] +Cor,\n\np.\n\n[ ] +Cor, LabN,\n\nq. L\n\n[Cor]\n\nr.\n\n[ ] +Cor,\n\nSimple Labial\n\ns. L\n\n[Lab]\n\n{PL, Lab}\npμp\n\nt.\n\n[ ] +Lab,\n\nty μ ty\n\nLabialized\nLabial\n\n{PL, Lab, CorN}\np μt\ny\n\nLabialized\nCoronal\n\n{PL, Cor, LabN}\nt μt\nw\n\nSimple Coronal\n\n{PL, Cor}\ntμt\n\na. L\n\n[ ] +Lab, LabN,\n\n*!\n\n*!\n*\n\n**\n\n*!\n\n*\n**\n*\n*\n*\n\n*!\n\n*\n\n*\n\n**\n*!\n\n*\n*\n\n*!\n*!\n\n*\n\n*\n\n*\n\n**\n*\n\n*!\n\n*\n*\n\n*!\n\n* [ fN\n\n*\n\nOptimality Theory\n\nChapter 9\n\n201\n\nThe size of the table gives a misleading impression of intricacy. The idea behind this analysis is quite\nsimple. Association must be forced, since the anti-association constraints *PL/\" militate against it.\nThe location of PARSE amid the anti-association constraints marks a kind of cut-off point: those\n*PL/\" below PARSE are overruled and association of their \" is compelled; those above PARSE, by\nconstrast, are under no bottom-up pressure to associate. Only the top-down pressure of FILL will\ncompel association – but since violations must be minimal, only minimal association can be forced.\nGlancing across the top of the tableau, one can see that all Cor’s will be forced into association by\nPARSE, but Lab-association, driven only by FILL, will be minimal.\nHere we give the details of the argument just outlined. Since *PL/Lab >> PARSEFeat, it is more\nharmonic to leave Lab features unparsed (incurring *PARSEFeat) than to associate them to PL\n(incurring *PL/Lab). Thus, ceteris paribus, Lab features remain unparsed.\nThe only reason that Lab nodes are ever parsed at all is to satisfy FILLPL, which dominates\n*PL/Lab. FILL is exactly the ceteris that is not paribus. If the only features available in the set are\nLab features, then failing to parse all of them would leave PL unfilled, earning a worse mark *FILLPL\nthan is incurred by parsing one of the Lab nodes.\nOn the other hand, only one Lab feature need be parsed to satisfy FILLPL. When two are\navailable, as in (f!h), parsing both would only increase the degree of violation of *PL/Lab. Since\nviolations are minimal, the least necessary concession is made to FILLPL. If two Labs are available\nin the set, one of them satisfies its intrinsic tendency to remain unparsed, while the other sacrifices\nthis for the higher goal of ensuring that PL is not completely empty.\nThe situation is reversed for Cor, however; it is more harmonic to parse these features than\nto leave them unparsed, because PARSEFeat >> *PL/Cor.\nAs we see from the tableau, the Yidiny inventory includes simple labials, as in rows (g,s),\nsimple coronals, as in rows (k,n,q), and complex coronals as in row (a) but no other complex\nPlaces.71 The grammar foils the attempt to create a complex labial from the input {PL,Lab,LabN} in\nrows (f!h) by underparsing this set: a simple labial is output, as in (g), with one of the Lab features\nunparsed. The input {PL,Lab,CorN}in rows (i!l) also fails to generate a complex segment, because\nthe grammar parses only the Cor feature, outputting a simple coronal, row (k). The same output\nresults from the input {PL,Cor,LabN} of rows (m!p). This then is an instance of what we called\n‘Stampean Occultation’ in §4.3.1; potential complex places involving Lab cannot surface, because\nthe grammar always interprets them as something else, behind which they are effectively hidden. In\nthe simplest case, the learner would never bother to posit them (see §9.3 for discussion).\n\nIn the tableau, a label like ‘Labialized Labial’ for the input {PL,Lab,LabN}is keyed to what would result\nfrom a faithful parse. The actual grammar underparses this input, and the output is a simple labial. Such\nlabels are intended to aid the reader in identifying the input collocation and do not describe the output.\n71\n\n202\n\nChapter 9\n\nPrince & Smolensky\n\n9.2 Universal Inventories\nIn addition to language-particular inventories, any theory must make possible an account of universal\ninventories. We have already seen a number of examples of universal inventory construction, and\nthe preceding analysis of segmental inventories provides yet another, which we will now explore.\nThe general issue of universal inventories has two aspects which we will exemplify; the following\nstatements are intended to fix the terms of the discourse.\n(289) Absolute Universal Inventory Characterizations.\na. Absence. A structure n is absent from the universal inventory if, for every possible\ngrammar and every possible input, the optimal output parse of that input for that grammar\nlacks n.\nb. Presence. A structure n is universally present in language inventories if, for any possible\ngrammar, there is some input whose optimal parse in that grammar contains n.\n(290) Relative Universal Inventory Characterizations:\nAn implicational universal of the form ‘R in an inventory implies n in the inventory’ holds\nif, for every possible grammar in which there is some input whose optimal parse includes R,\nthere is an input whose optimal parse in that same grammar includes n.\nThe phrase ‘possible grammar’ refers to the well-formedness constraints provided by Universal\nGrammar, interacting via a particular domination hierarchy consistent with the domination\nconditions imposed by Universal Grammar.\n\n9.2.1 Segmental Inventories\nThe segmental inventory of Yidiny, barring only the worst-of-the-worst (complex, with at least one\nnoncoronal Place), is but one of the inventories in the universal typology generated by the 12\npossible domination hierarchies which can be constructed from the four constraints *PL/Cor,\n*PL/Lab, FILLPL, PARSEFeat, consistent with the universal domination condition (283) that yields\nCoronal Unmarkedness. This typology includes, for example, inventories which exclude all segments\nwith complex places, and inventories which exclude all labials. The basic sense of the typology\nemerges from a couple of fundamental results, demonstrated below; these results correspond directly\nto the informal observations of Noncomplexity (282) and Coronal Unmarkedness (281), taken as\nimplicational universals:\n(291) Complex Y Simple. [B RN] Y [B], [R]\nIf the segment inventory of a language includes a complex segment with primary place B and\nsecondary place R, it has a simple segment with place B and a simple segment with place R.\n\nOptimality Theory\n\nChapter 9\n\n203\n\n(292) Lab Y Cor\n[þLabþ] Y [þCorþ]\nIf the segment inventory of a language admits labials, it admits coronals.\na. Harmonic Completeness w.r.t. Simple Segments: [Lab] Y [Cor]\nIf a language has simple labials, then it has simple coronals.\nb. Harmonic Completeness w.r.t. Primary Place: [Lab RN] Y [Cor RN]\nIf a language has a complex segment with primary place Lab and secondary place R, then it\nhas a complex segment with primary place Cor and secondary place R.\nc. Harmonic Completeness w.r.t. Secondary Place: [B LabN] Y [B CorN]\nIf a language has a complex segment with secondary place Lab and primary place B, then it\nhas a complex segment with secondary place Cor and primary place B.\nRecall that we are using ‘Lab’ to denote any non-coronal place of articulation. All\nnoncoronals satisfy these implicational universals, because like Lab they all satisfy the Coronal\nUnmarkedness constraint domination condition (284). Both ‘Lab’ and ‘Cor’ should be taken here\nas no more than concrete place-holders for ‘more marked entity’ and ‘less marked entity’.\nHarmonic completeness means that when a language admits forms that are marked along\nsome dimension, it will also admit all the forms that are less marked along that dimension. More\nspecifically, if some structure is admitted into a language’s inventory, and if a subpart of that\nstructure is swapped for something more harmonic, then the result is also admitted into that\nlanguage’s inventory. Like the syllable structure results — for example, (215) of §8.2.1, p.152 —\nthe implications Complex Y Simple and Lab Y Cor ensure harmonic completeness in exactly this\nsense.\nThese results entail that only harmonically complete languages are admitted by the constraint\nsystem, no matter what rankings are imposed. In other words, harmonic completeness in POA is a\nnecessary condition for the admissibility of a language under the constraint system at hand. This\nresult is not as strong as we would like: it leaves open the possibility that there are nevertheless some\nharmonically complete languages that the system does not admit. For example, if the factorial\ntypology turned out to generate only those languages where the distinctions among the coronals were\nexactly the same as those among the labials, the theorems Complex Y Simple and Lab Y Cor\nwould still hold true, for such languages are harmonically complete. (In fact, we know by\nconstruction that this is not the case: the Yidiny hierarchy allows secondary articulations among the\ncoronals but nowhere else.) What we want, then, is that harmonic completeness be also a sufficient\ncondition for admissibility, so that all harmonically complete languages are admitted. Let us single\nout and name this important property:\n(293) Strong Harmonic Completeness (SHARC) Property.\nIf a typology admits all and only the harmonically complete languages, then we say that it\nhas Strong Harmonic Completeness (SHARC) .\n\n204\n\nChapter 9\n\nPrince & Smolensky\n\nIf a typology has the SHARC, then it manifests what has been referred to in the literature as\n‘licensing asymmetry’. For place of articulation, in the circumscribed realm we have been\nexamining, this comes out as follows:\n(294) POA Licensing Asymmetry. In any language, if the primary place Lab licenses a given\nsecondary place, then so does Cor; but there are languages in which the secondary places\nlicensed by Cor are a strict superset of those licensed by Lab.\nIn the common metaphor, Cor is a ‘stronger’ licenser of secondary places than Lab. With the\nSHARC, there is the broader guarantee that every asymmetric system is possible. We know that the\nsystem of constraints examined here has the POA licensing asymmetry property, because harmonic\ncompleteness is a necessary property of admitted languages, and because we have produced at least\none (Yidiny) where the secondary articulations among the coronals are a strict superset of those\npermitted with labials. The factorial typology of the constraint system presented here does not in fact\nhave the SHARC, as the reader may determine, but is a step in that direction.\nIt is worth noting that the SHARC is undoubtedly not true of POA systems in languages, and\ntherefore not true of the entire UG set of constraints pertaining to POA. Indeed, it is unlikely that\nharmonic completeness is even a necessary condition on POA systems, as John McCarthy has\nreminded us. With respect to labialization, for instance, many systems have kw or gw with no sign of\ntw or dw. With respect to Simple Y Complex, one recalls that Irish has velarized labials and\npalatalized labials, but no plain labials. McCarthy points to the parallel case of Abaza, which has\npharyngealized voiceless uvulars but not plain ones. We do not see this as cause for dismay,\nhowever. Virtually any theory which aims to derive implicational universals must include\nsubcomponents which, in isolation, predict the necessity of harmonic completeness and even its\nsufficiency as well. The constraints discussed here are a very proper subset of those relevant to POA.\nIn particular, the key domination hierarchy is concerned only with context-free comparison of single\nfeatures, and contains no information about effects of combination (labial+velar, round+back,\nATR+high, etc.), which greatly alter the ultimate predictions of the system (Chomsky & Halle 1968:\nch. 9, Cairns 1969, Kean 1974, Stevens & Keyser 1989, Archangeli & Pulleyblank 1992). Optimality\nTheory, by its very nature, does not demand that individual constraints or constraint groups must be\ntrue in any simple a-systematic sense. What this means is that an established subsystem or module\ncan be enriched by the introduction of new constraints, without necessarily revising the original\nimpoverished module at all. (We have already seen this in the transition from the basic syllable\nstructure theory to the analysis of Lardil.) This fact should increase one’s Galilean confidence that\nfinding a subtheory with the right properties is a significant advance.\nThe POA subtheory examined here derives the relative diversity of coronals in inventory\nfrom the single fact of their unmarkedness. These two characteristics are so commonly cited together\nthat it can easily be forgotten that underspecification theory cannot relate them. This important point\ncomes from McCarthy & Taub 1993:\nEqually important as evidence for the unmarked nature of coronals is the fact that they\nare extremely common in phonemic inventories, where they occur with great richness\n\nOptimality Theory\n\nChapter 9\n\n205\n\nof contrast... .[The] phonetic diversity of coronals is represented phonologically by\nsetting up a variety of distinctive features that are dependent on the feature coronal....\nAs explanations for different aspects of coronal unmarkedness,\nunderspecification and dependent features are distinct or even mutually incompatible.\nBy the logic of dependency, a segment that is specified for a dependent feature ... must\nalso be specified for the corresponding head feature ... For example, even if the English\nplain alveolars t, d, l, r and n are underspecified for [coronal] the dentals 2/ð and palatoalveolars .../j4/š/ž must be fully specified to support the dependent features [distributed]\nand [anterior]. As a consequence, the dentals and palato-alveolars should not participate\nin the syndrome of properties attributed to coronal underspecification, and conversely,\nthe plain alveolars should not function as a natural class with the other coronals until\napplication of the [coronal] default rule.\nIt seems clear that the only way out is to abandon underspecification in favor of markedness theory\n(cf. Mohanan 1991). This is an ill-advised maneuver if it means embracing nothing more substantial\nthan an elusive hope. The present theory shows that solid formal sense can be made of the notion of\nmarkedness, and, more significantly, that results about subtleties of inventory structure — permitted\nfeatural combinations — can be deduced from hypotheses about the relative markedness of\nindividual atomic features. The coronal diversity result parallels the result in §8.3.2 that onsets are\nstronger licensers of segments than codas. In the syllable structure case, it is the structural\nmarkedness of the Cod node relative to the Ons node which impairs its ability to license segments.\nHere, licensing is diminished by the markedness of Lab as a place relative to Cor. Formally, the\nrelationship of licenser to licensed is quite different in the two cases, but in both cases the\nmarkedness of the licenser governs its ability to license. We have, then, a very general mode of\nsubtheory construction within Optimality Theory which allows us to argue from the markedness of\natomic components to limitations on the structure of systems.\n\n206\n\nChapter 9\n\nPrince & Smolensky\n\nWe now turn to the demonstrations of (291) and (292), with the goal of identifying a general\ntechnique for establishing such implicational universals.72\nThe argument establishing (291) runs as follows:\n(295) Proof of Complex Y Simple: For the case of the secondary place, i.e, proof that if a language\nhas [B RN] it has [R]:\na. By definition of admission into the inventory, the output [B RN] must appear in an optimal\nparse of some input; the only possible such input is {PL,B,RN}.\n\n72\n\nAnother related technique, used in §8 and to an extended degree in Legendre, Raymond & Smolensky\n1993, can be effectively used here as well; the results are more general but the technique is a bit more\nabstract. This other technique, which might be called the Technique of Necessary and Sufficient Conditions,\ngoes as follows. Step 1: Determine necessary and sufficient conditions on the ranking of constraints in a\nhierarchy in order that each of the relevant structures be admitted into the inventory by that constraint\nranking. Step 2: Examine the logical entailments that hold among these conditions: arguments of the form:\nin order to admit structure N it is necessary that the constraints be ranked in such-and-such a way, and this\nentails that the constraint ranking meets the sufficient conditions to admit structure R. To carry out Step 1,\nto determine the necessary and sufficient conditions for a structure N to be admitted, one takes a general\nparse containing N and compares it to all alternative parses of the same input, and asks, how do the\nconstraints have to be ranked to ensure that N is more harmonic than all the competitors? And this in turn\nis done by applying the Cancellation/Domination Lemma, (192) of §8.2.6, p.142: for each mark *m incurred\nby N, and for each competitor C, if *m is not cancelled by an identical mark incurred by C then it must be\ndominated by at least one mark of C.\nIn the present context, this technique gives the following results (Step 1):\n(!) In order that [P] be admitted into an inventory it is necessary and sufficient that:\neither PARSEFeat or FILLPL >> *PL/P\n(\") In order that [B R] be admitted into an inventory it is necessary and sufficient that:\na. PARSEFeat >> *PL/R, and\nb. either PARSEFeat or *[fN >> *PL/B, and\nc. either PARSEFeat or *FILLPL >> *PL/B\nFrom here, Step 2 is fairly straightforward. The result Complex Y Simple (291) for the secondary\nplace R follows immediately, since (\".a) Y (!) for P = R. The result Complex Y Simple for the primary\nplace B follows similarly since (\".c) Y (!) for P = B.\nFor the Harmonic Completeness results (292), we use the Coronal Unmarkedness domination\ncondition (284)\n*PL/Lab >> *PL/Cor\nThis means that whenever any of the domination conditions in (!) or (\") hold of the feature Lab, it must also\nhold of the feature Cor; for in that case, each asserts that some constraint must dominate *PL/Lab, which\nmeans the same constraint must also dominate *PL/Cor since *PL/Lab >> *PL/Cor. Spelling this observation\nout in all the cases a!c of (292) proves the result Lab Y Cor.\n\nOptimality Theory\n\nChapter 9\n\n207\n\nb. This means that [B RN] (incurring two marks *PL/B, *PL/R) must be more harmonic than\nall competing parses of the input {PL,B,RN}, including [B]+RN, (incurring the marks\n*PL/B, *PARSEFeat).\nc. This entails that PARSEFeat must dominate *PL/R.\nd. This in turn implies that with the input {PL,R}, the parse [R] (incurring *PL/R) is more\nharmonic than its only competitor, [ ]+R, (incurring *PARSEFeat [as well as *FILLPL]),\nhence [R] is the optimal parse.\ne. Which means that the simple segment [R] is admitted into the segmental inventory.\nBroadly put, the argument runs like this. Association must be compelled, over the resistance of the\nanti-association constraints. Either PARSE or FILL can be responsible. The existence of [B RN] in an\noptimal output guarantees that association of R is in fact compelled by the grammar and indeed\ncompelled by PARSE, since FILL would be satisified by merely parsing B. Therefore, the association\n[R] must also occur, driven by PARSE. A similar but slightly more complex argument also establishes\nthat [B] must be admitted.\nThe parallel argument establishing (292) is just a little more complicated:\n(296) Proof of Lab Y Cor: For the case of simple segments, (292.a):\na. If a grammar admits simple labials, then the feature Lab in some input feature set must get\nassociated to PL: [Lab] must appear in the optimal parse of this input.\nb. In order for this to happen, the association [Lab incurring *PL/Lab, must be more\nharmonic than leaving Lab unparsed (incurring *PARSEFeat, and also possibly *FILLPL\nif there are no other features in the set to fill PL).\nc. This means the language’s domination hierarchy must meet certain conditions: either\n[i]\nPARSEFeat >> *PL/Lab\nor\n[ii]\nFILLPL >> *PL/Lab.\nd. These conditions [i!ii] on the ranking of *PL/Lab entail that the same conditions must\nhold when *PL/Lab is replaced by the universally lower-ranked constraint *PL/Cor:\nsince *PL/Lab >> *PL/Cor, by Coronal Unmarkedness (283), if [i], then:\n[iN]\nPARSEFeat >> *PL/Lab >> *PL/Cor;\nif [ii], then:\n[iiN] FILLPL >> *PL/Lab >> *PL/Cor.\n\n208\n\nChapter 9\n\nPrince & Smolensky\n\ne. This in turn entails that parsing Cor must be better than leaving it unparsed: the input\n{PL,Cor} must be parsed as [Cor] (incurring *PL/Cor), since the alternative [ ] +Cor,\nwould incur both *FILLPL and *PARSEFeat, at least one of which must be a worse mark\nthan *PL/Cor by d.\nf. This means that coronals are admitted into the inventory.\nAgain, the argument can be put in rough-and-ready form. Association must be compelled, either\nbottom-up (by PARSE) or top-down (by FILL). The appearance of [Lab — primary labial place — in\nan optimal output of the grammar guarantees that labial association has in fact been compelled one\nway or the other. Either a dominant PARSE or a dominant FILL forces violation of *PL/Lab ‘don’t\nhave a labial place’. The universal condition that labial association is worse than coronal association\nimmediately entails that the less drastic, lower-ranked offense of coronal association is also\ncompelled, by transitivity of domination.\nThe two proofs, (295) and (296), illustrate a general strategy:\n(297) General Strategy for Establishing Implicational Universals R Y n\na. If a configuration R is in the inventory of a grammar G, then there must be some input IR\nsuch that R appears in the corresponding output, which, being the optimal parse,\nmust be more harmonic than all competitors.\nb. Consideration of some competitors shows that this can only happen if the constraint\nhierarchy defining the grammar G meets certain domination conditions.\nc. These conditions entail — typically by dint of universal domination conditions — that an\noutput parse containing n (for some input In) is also optimal.\n\n9.2.2 Syllabic Inventories\nThe general strategy (297) was deployed in §8 for deriving a number of implicational universals as\npart of developing the Basic Segmental Syllable Theory. One example is the Harmonic\nCompleteness of the inventories of Possible Onsets and Nuclei (215), which states that if J is in the\nonset inventory, then so is any segment less sonorous than J, and if \" is in the nucleus inventory,\nthen so is any segment more sonorous than \". A second example is (254), which asserts that if J is\nin the inventory of possible codas, then J is also in the inventory of possible onsets. That the\nconverse is not an implicational universal is the content of Onset/Coda Licensing Asymmetry (258).\nSo far, our illustrations of universal inventory characterizations have been of the\nimplicational or relative type (290). Examples of the absolute type (289) may be found in the Basic\nCV Syllable Structure Theory of §6. A positive example is the result (128), p. 98, that every syllable\ninventory contains CV, the universally optimal syllable. A negative example is the result (144), p.\n\nOptimality Theory\n\nChapter 9\n\n209\n\n105, which states that, in syllabic theory (which does not include constraints like LX.PR), two\nadjacent empty syllable positions (phonetically realized as two adjacent epenthetic segments) are\nuniversally impossible: the universal word inventory, under the Basic Theory, includes no words\nwith two adjacent epenthetic segments.\n\n9.3 Optimality in the Lexicon\nThe preceding discussions have been independent of the issue of what inputs are made available for\nparsing in the actual lexicon of a language. Under the thesis that might be dubbed Richness of the Base,\nwhich holds that all inputs are possible in all languages, distributional and inventory regularities follow\nfrom the way the universal input set is mapped onto an output set by the grammar, a language-particular\nranking of the constraints. This stance makes maximal use of theoretical resources already required,\navoiding the loss of generalization entailed by adding further language-particular apparatus devoted\nto input selection. (In this we pursue ideas implicit in Stampe 1969, 1973/79, and deal with\nKisseberth’s grammar/lexicon ‘duplication problem’ by having no duplication.) We now venture\nbeyond the Richness of the Base to take up, briefly, the issue of the lexicon, showing how the specific\nprinciples of Optimality Theory naturally project the structure of a language’s grammar into its lexicon.\nConsider first the task of the abstract learner of grammars. Under exposure to phonetically\ninterpreted grammatical outputs, the underlying inputs must be inferred. Among the difficulties is one\nof particular interest to us: the many-to-one nature of the grammatical input-to-output mapping, arising\nfrom the violability of FAITHFULNESS. To take the example of the Yidiny segmental inventory\nillustrated above in the tableau (288), two different inputs surface as a simple labial: the input {PL,Lab}\nwhich earns the faithful parse [Lab], and the input {PL,Lab,LabN} which is parsed [Lab]+LabN,. These\noutputs are phonetically identical: which underlying form is the learner to infer is part of the underlying\nsegmental inventory? Assuming that there is no morphophonemic evidence bearing on the choice, the\nobvious answer — posit the first of these, the faithfully parsable contender— is a consequence of the\nobvious principle:\n(298) Lexicon Optimization73. Suppose that several different inputs I1, I2,..., In when parsed by a\ngrammar G lead to corresponding outputs O1, O2, ..., On, all of which are realized as the same\nphonetic form M — these inputs are all phonetically equivalent with respect to G. Now one of\nthese outputs must be the most harmonic, by virtue of incurring the least significant violation\nmarks: suppose this optimal one is labelled Ok. Then the learner should choose, as the\nunderlying form for M, the input Ik.\n\n73\n\nThe term ‘lexicon’ here is really overly restrictive, since this is actually a principle for inducing\nunderlying forms in general, not just those of lexical entries. For example, it can apply in syntax as well. The\nrules of the syntactic base might well generate structures such as [[[[[he]DP]DP]DP]DP]DP as well as simple\n[he]DP. But, as we shall see, the principle (298) will imply that the simpler alternative will be selected as the\nunderlying form.\n\n210\n\nChapter 9\n\nPrince & Smolensky\n\nThis is the first time that parses of different inputs have been compared as to their relative Harmony.\nIn all previous discussions, we have been concerned with determining the output that a given input\ngives rise to; to this task, only the relative Harmony of competing parses of the same input is relevant.\nNow it is crucial that the theory is equally capable of determining which of a set of parses is most\nharmonic, even when the inputs parsed are all different.\nMorphophonemic relations can support the positing of input-output disparities, overriding the\nLexicon Optimization principle and thereby introducing further complexities into lexical analysis. But\nfor now let us bring out some of its attractive consequences. First, it clearly works as desired for the\nYidiny consonant inventory. Lexicon Optimization entails that the analysis of the Yidiny constraint\nhierarchy (288) simultaneously accomplishes two goals: it produces the right outputs to provide the\nYidiny inventory, and it leads the learner to choose (what we hypothesize to be) the right inputs for the\nunderlying forms. The items in the Yidiny lexicon will not be filled with detritus like feature sets\n{PL,Cor,LabN} or {PL,Lab,LabN}. Since the former surfaces just like {PL,Cor} and the latter just like\n{PL,Lab}, and since the parses associated with these simpler inputs avoid the marks *PARSEFeat\nincurred by their more complex counterparts, the needlessly complex inputs will never be chosen for\nunderlying forms by the Yidiny learner.74\nLexicon Optimization also has the same kind of result – presumed correct under usual views\nof lexical contents – for many of the other examples we have discussed. In the Basic CV Syllable\nStructure Theory, for example, Lexicon Optimization entails that the constraints on surface syllable\nstructure will be echoed in the lexicon as well. In the typological language family 3CVdel,del, for\nexample, the syllable inventory consists solely of CV. For any input string of Cs and Vs, the output will\nconsist entirely of CV syllables; mandatory onsets and forbidden codas are enforced by underparsing\n(phonetic nonrealization). Some inputs that surface as [CV] are given here:\n(299) Sources of CV in 3CVdel,del\na /CVV/\nÿ\n.CV.+V,\nb /CCVV/\nÿ\n+C,.CV.+V,\nc /CCVVV/ ÿ\n+C,+C,.CV.+V,+V,\nThe list can be extended indefinitely. Clearly, of this infinite set of phonetically equivalent inputs, /CV/\nis the one whose parse is most harmonic (having no marks at all); so ceteris paribus the 3CVdel,del\nlearner will not fill the lexicon with supererogatory garbage like /CCVVV/ but will rather choose /CV/.\nIgnoring morphological combination (which functions forcefully as ceteris imparibus) for the moment,\nwe see that CV-language learners will never insert into the lexicon any underlying forms that violate\nthe (surface) syllable structure constraints of their language; that is, they will always choose lexical\nforms that can receive faithful parses given their language’s syllable inventory.\nMorphological analysis obviously enlivens what would otherwise be a most boringly optimal\nlanguage, with no deep/surface disparities at all. So let’s add to our CV language some stem+affix\nmorphology. Away from the stem/affix boundary, the lack of deep/surface disparities will clearly\n\n74\n\nThe Yidiny system follows the pattern called ‘Stampean Occultation’ in §4.3.1 above. The principle\nof Lexical Optimization thus makes explicit the content of the Occultation idea.\n\nOptimality Theory\n\nChapter 9\n\n211\n\nremain, but at this boundary we can see a bit of interesting behavior beginning. As an example, we\nconsider the CV idealization (with slight simplification) of the justly celebrated case of deep/surface\ndisparity in Maori passives discussed in Hale 1973. The language is in the typological class we’ve\ncalled 3(C)V: onsets optional, codas forbidden; the paradigm of interest is illustrated in (300):\n(300) CV inflectional paradigm (phonetic surface forms cited)\nuninflected\ninflected\na.\nCVCV\nCVCVV\nb.\nCVCV\nCVCVCV\nThe inflected form is composed exactly of the uninflected form followed by additional material, which\nin case (300a) consists only of V, and in case (300b) consists of CV. At issue is how to analyze the\nsuffix. One analysis is shown in (301):\n(301) Phonological Analysis:\nstem\n\n+affix\n\nuninflected\n\ninflected\n\na.\n\nCVCV\n\n+V\n\n.CV.CV.\n\n.CV.CV.V.\n\nb.\n\nCVCVC\n\n+V\n\n.CV.CV.+C,\n\n.CV.CV.CV.\n\nThis analysis runs as follows: the inflection is a suffix +V; there are two classes of stems: V-final (a),\nand C-final (b); the means used to enforce the prohibition on codas is underparsing, so that in the\nuninflected form, the final C is not parsed. (In terms of the CV Syllable Structure Theory of §6, the\nlanguage is 3(C)Vdel.)\nIn his discussion of Maori, Hale calls this analysis the phonological analysis; in derivational\nterms, it calls on a phonological rule of final C deletion. This is to be contrasted with what Hale calls\nthe conjugation analysis, shown in (302):\n(302) Conjugation Analysis:\nstem\n\n+affix\n\nuninflected\n\ninflected\n\nI.\n\nCVCV\n\n+V\n\n.CV.CV.\n\n.CV.CV.V.\n\nII.\n\nCVCV\n\n+CV\n\n.CV.CV.\n\n.CV.CV.CV.\n\nHere class-I and class-II stems are distinguished in the lexicon with a diacritic whose force is to select\ndifferent forms for the inflectional affix: +V in the first case and +CV in the second.\nThe question now is this: how do these two analyses fare with respect to the Lexicon\nOptimization principle (298)? In the conjugation analysis, the parses are completely faithful, incurring\nno marks at all. By contrast, the phonological analysis requires underparsing for uninflected C-final\n\n212\n\nChapter 9\n\nPrince & Smolensky\n\n(class-II) stems: this incurs a *PARSE mark. Thus, as stated in (298), the Lexicon Optimization principle\nwould appear to favor the conjugation analysis. Indeed, in general it favors analyses that minimize\ndeep/surface disparities, and that maximize faithful parsing, thereby avoiding *PARSE and *FILL marks.\nYet it is clear that in many circumstances, phonological analyses like (301) are to be preferred to\nconjugational analyses like (302). The deficiency in the formulation (298) of Lexicon Optimization is\nthat it attempts a form-by-form optimization, without taking into consideration, for example, the\noptimization (minimization) of the number of allomorphs associated with an affix.\nIn general, morphological analysis entails that morphemes will appear in multiple combinations\nwith other morphemes; the underlying form for a morpheme which is optimal (in the sense of Lexicon\nOptimization) when it appears in some combinations will not be optimal when it appears with others.\nThe conjugational analysis avoids this by limiting the possible combinations (the class-I form of the\naffix, +V, can only co-occur with class-I stems), at the obvious cost of not minimizing the number of\nallomorphs for the affix. It seems clear that Lexicon Optimization must be reformulated so that, instead\nof form-by-form optimization, a more global optimization of the lexicon is achieved, in which more\ndeep/surface disparities are accepted in order to minimize the constraints on allowed morphological\ncombination which are part and parcel of conjugational analyses.\nOne simple way of formulating such a global lexicon optimization would be in terms of\nminimizing the totality of underlying material contained in the lexicon (precisely the kind of solution\nproposed in Chomsky & Halle 1968: ch. 8). Applied to the problem of deciding between the\nphonological and conjugational analyses illustrated by our CV example, such a Minimal Lexical\nInformation approach would go something like this. The conjugation and phonological analyses share\na common core consisting of a set of uninflected stems and the affix +V. In addition to this core, the\nconjugational analysis requires an additional allomorph for the affix, +CV, and a diacritic for each stem\nindicating which allomorph it takes. (In an actual language, an additional allomorph instantiating +CV\nwould be needed for each possible consonant that can instantiate C.) The phonological analysis\nrequires, in addition to the shared core, additional final Cs on the class-II stems. (In an SPE-style\nsegmental derivational theory, the phonological analysis also requires an extra final C deletion rule, but\nin any modern syllabic theory this comes for free, courtesy of the same grammatical structure — for\nus, constraint hierarchy — that determines the syllable inventory in the first place.) Specification of all\nthe stem-final Cs in the phonological analysis, and specification of all the diacritics distinguishing the\nconjugational classes in the conjugational analysis, require basically the same amount of lexical\ninformation — depending on details of accounting and of distribution of possible final Cs which we\nset aside here. What is left to differentiate the quantity of lexical information required by the two\nanalyses is simply the additional allomorphic material +CV in the conjugational analysis. Thus, if the\nomitted details are properly handled, the principle of Minimal Lexical Information would appear to\nfavor the phonological analysis — if only by the barest of margins.\nIt is quite possible that this accounting grossly underassesses the costs of multiple allomorphs.\nThe true cost of unnecessary allomorphs may not be that of having them — as assessed by the\nadditional underlying material they contain — but rather in the increased difficulty of learning them;\nmore precisely, of learning to identify a morpheme which has multiple exponents, each with its own\nidiosyncratic limitation on the other allomorphs or stems with which it can combine. The problem of\ndetecting the combinatorial structure underlying stem+affix may well be much easier when the affix\nhas a unique exponent, even when compared to the case of just two allomorphs. Evidence bearing\n\nOptimality Theory\n\nChapter 9\n\n213\n\nindirectly on this claim comes from a series of learning experiments carried out by Brousse &\nSmolensky (1989) and Brousse (1991) using connectionist (‘neural’) network learning techniques.\nNetworks were trained to identify inputs which possessed the structure stem+affix, where stem was any\nmember of a set S and affix any member of another set A; the network had to learn the classes S and\nA as well as the means of morphologically decomposing the inputs into stem+affix. This task was very\nrobustly learnable; from a tiny proportion of exclusively positive examples, the networks acquired a\ncompetence (under a somewhat subtle definition) extending far beyond the training examples. Next,\nlimitations on legal combination were imposed: networks had to learn to identify inputs with either of\nthe legal forms stemI+affixI or stemII+affixII, distinguishing them from other inputs, such as those with\nthe illegal forms stemI+affixII or stemII + affixI. (Here stemI is any member of a set SI of ‘class-I stems’,\nstemII any member of a set SII of ‘class-II stems’, affixI any member of a set AI of ‘class-I affixes’, and\naffixII any member of a set AII of ‘class-II affixes’.) This task was completely unlearnable by the same\nnetworks that had no trouble at all in learning the first task, in which stem/affix combination is not\nconstrained in the way it must be in conjugational analyses. Thus there may be very strong learnability\npressure to minimize combinatorial constraints, i.e., to minimize conjugational classes and the number\nof exponents of each morpheme.\nWhile properly reformulating Lexicon Optimization from a form-by-form optimization to a\nglobal lexicon optimization is a difficult problem, one that has remained open throughout the history\nof generative phonology, a significant step towards bringing the Minimal Lexical Information principle\nunder the scope of Lexicon Optimization as formulated in (298) is suggested by a slight reformulation,\nthe Minimal Redundancy principle: to the maximal extent possible, information should be excluded\nfrom the lexicon which is predictable from grammatical constraints. Such considerations figure\nprominently, e.g., in discussions of underspecification (e.g. Kiparsky’s Free Ride). An example of the\nconsequences of this principle, if taken to the limit, is this: in a language in which t is the epenthetic\nconsonant, a t interior to a stem which happens to fall in an environment where it would be inserted by\nepenthesis if absent in underlying form should for this very reason be absent in the underlying form\nof that stem. A rather striking example of this can be provided by the CV Theory. Consider a 3(C)Vep\nlanguage (onsets not required; codas forbidden, enforced by overparsing — ‘epenthesis’). The Minimal\nLexical Redundancy principle would entail that a stem that surfaces as .CV.CV.CV. must be\nrepresented underlyingly as /CCC/, since this is overparsed as .C~3 .C~3 .C~3. , which is phonetically\nidentical to .CV.CV.CV.: it is redundant to put the V’s in the lexicon of such a language. Given the\nconstraints considered thus far, Lexicon Optimization as stated in (298) selects /CVCVCV/ and not\n/CCC/ in this case; again, avoiding deep/surface disparities whenever possible. But this is at odds with\nthe principle that the lexicon should not contain information which can be predicted from the grammar.\nThe approach to parsing we have developed suggests an interesting direction for pursuing this\nissue. As stated in (186), the Push/Pull Parsing approach views parsing as a struggle between\nconstraints which prohibit structure and constraints which require structure. As noted in §3.1, the most\ngeneral form of the structure-prohibiting constraint is *STRUC which penalizes any and all structure.\nThere is a specialization of it which would be invisible during parsing but which can play an important\nrole in learning:\n(303) *SPEC: Underlying material must be absent.\n\n214\n\nChapter 9\n\nPrince & Smolensky\n\nEach underlying feature in an input constitutes a violation of this constraint75. But these violations\ncannot influence parsing since the underlying form is fixed by the input, and no choice of alternative\noutput parses can affect these violations of *SPEC. But Lexicon Optimization is an inverse of parsing:\nit involves a fixed phonetic output, and varying underlying inputs; thus, among phonetically equivalent\ninputs, *SPEC favors those with fewest featural and segmental specifications.\nNow an interesting change occurs if *SPEC outranks FAITHFULNESS: Lexicon Optimization\n(298) selects /CCC/ over /CVCVCV/ in the CV theory example — since minimizing FAITHFULNESS\nviolations (and thereby deep/surface disparities) is now less important than minimizing underlying\nmaterial. If on the other hand, FAITHFULNESS dominates *SPEC, we are back to /CVCVCV/ as the\noptimal underlying form.\nClearly a great deal of work needs to be done in seriously pursuing this idea. Still, it is\nremarkable how the addition of *SPEC to the constraint hierarchy can allow Lexicon Optimization —\nin its original straightforward formulation (298) — to capture an important aspect of the Minimal\nLexical Information and Minimal Redundancy principles. It remains to be seen whether a constraint\nlike *SPEC can supplant other possible constraints aimed specifically at limiting allomorphy,\ndemanding (for example) a 1:1 relation between a grammatical category and its morphemic exponent.\nIt is important to note that the addition of *SPEC makes no change whatever to any of the analyses we\nhave considered previously. This raises the intriguing question of whether there are other constraints\nwhich are invisible to parsing — the operation of the grammar — but which play indispensable roles\nin grammar acquisition.\n\n75\n\nThe constraint is thus identical to the featural measure of lexical complexity in Chomsky & Halle\n1968:381.\n\n215\n\n10. Foundational Issues and Theory-Comparisons\n“If this is the best of all possible worlds, what are the others like?”\n— Candide, ou l’optimisme, Ch. VI.\n\n10.1 Thinking about Optimality\n10.1.1 Fear of Optimization\nWe distinguish three species of qualm that have dissuaded people from thinking about\noptimality-based theories of linguistic form.\nQ1. Computation. “Optimization is computationally intractable. Even simple optimization\nproblems typically turn out to be inordinately expensive in terms of computational time and space.\nMany problems based on satisfaction of well-formedness conditions (much less relative wellformedness conditions) are even undecidable.”\nQ2. Loss of Restrictiveness. “In order to handle optimality, you must use numbers and use\ncounting. The numerical functions required belong to a vast class which cannot be constrained in a\nreasonable way. Arbitrary quantization will be required, both in the weighting of degrees of\nconcordance with (and violation of) individual constraints and in the weighting of the importance\nof disparate constraints with respect to each other. The result will be a system of complicated tradeoffs (e.g. ‘one serious violation of can be overcome when three moderate agreements with cooccur with two excellent instances of ’), giving tremendous descriptive flexibility and no hope of\nprincipled explanation. Therefore, the main goal of generative grammatical investigation is\nirredeemably undermined.”\nQ3. Loss of Content. “Appeal to scalar constraints — degrees of well-formedness — leads\ninevitably to a functionalizing narrative mush of the ‘better for this/better for that’ sort. By means\nof such push-pull, any imaginable state-of-affairs can be comfortably (if hazily) placed in a best of\nall possible worlds. Vagueness of formulation is reinstated as the favored mode of discourse, and\nPullum’s worst fears are realized.”\n\n10.1.2 The Reassurance\nQ1. Computation. This qualm arises from a misapprehension about the kind of thing that\ngrammars are. It is not incumbent upon a grammar to compute, as Chomsky has emphasized\nrepeatedly over the years. A grammar is a function that assigns structural descriptions to sentences;\nwhat matters formally is that the function is well-defined. The requirements of explanatory adequacy\n(on theories of grammar) and descriptive adequacy (on grammars) constrain and evaluate the space\nof hypotheses. Grammatical theorists are free to contemplate any kind of formal device in pursuit\n\n216\n\nChapter 10\n\nPrince & Smolensky\n\nof these goals; indeed, they must allow themselves to range freely if there is to be any hope of\ndiscovering decent theories. Concomitantly, one is not free to impose arbitrary additional metaconstraints (e.g. ‘computational plausibility’) which could conflict with the well-defined basic goals\nof the enterprise.\nIn practice, computationalists have always proved resourceful. All available complexity\nresults for known theories are stunningly distant from human processing capacities (which appear\nto be easily linear or sublinear), yet all manner of grammatical theories have nonetheless been\nsuccessfully implemented in parsers, to some degree or another, with comparable efficiency (see e.g.\nBarton, Berwick, & Ristad 1987; Berwick, Abney, and Tenny 1991.) Furthermore, it is pointless to\nspeak of relative degrees of failure: as a failed image of psychology, it hardly matters whether a\ndevice takes twice as long to parse 5 words as it takes to parse 4 words, or a thousand times as long.\nFinally, real-world efficiency is strongly tied to architecture and to specific algorithms, so that\nestimates of what can be efficiently handled have changed radically as new discoveries have been\nmade, and will continue to do so. Consequently, there are neither grounds of principle nor grounds\nof practicality for assuming that computational complexity considerations, applied directly to\ngrammatical formalisms, will be informative.\nQ2. Loss of Restrictiveness through Arithmetic. Concern is well-founded here. As we have\nshown, however, recourse to the full-blown power of numerical optimization is not required. Order,\nnot quantity (or counting), is the key in Harmony-based theories. In Optimality Theory, constraints\nare ranked, not weighted; harmonic evaluation involves the abstract algebra of order relations rather\nthan numerical adjudication between quantities.\nQ3. Loss of Content through Recourse to the Scalar and Gradient. Here again there is a real\nissue. Recourse to functional explanations, couched in gradient terms, is often accompanied by\nsevere loss of precision, so that one cannot tell how the purported explanation is supposed to play\nout over specific cases. A kind of informal terminological distinction is sometimes observed in the\nliterature: a ‘law’ is some sort of functional principle, hard to evaluate specifically, which grammars\nshould generally accord with, in some way or other, to some degree or other; a ‘rule’ is a precise\nformulation whose extension we understand completely. Thus, a ‘law’ might hold that ‘syllables\nshould have onsets,’ where a ‘rule’ would be: ‘adjoin C to V.’ ‘Laws’ typically distinguish better\nfrom worse, marked from unmarked; while ‘rules’ construct or deform.\nLinguistic theory cannot be built on ‘laws’ of this sort, because they are too slippery, because\nthey contend obscurely with partly contradictory counter-‘laws’, because the consequences of\nviolating them cannot be assessed with any degree of precision. With this in mind, one might feel\ncompelled to view a grammar as a more-or-less arbitrary assortment of formal rules, where the\nprinciples that the rules subserve (the ‘laws’) are placed entirely outside grammar, beyond the\npurview of formal or theoretical analysis, inert but admired. It is not unheard of to conduct\nphonology in this fashion.\nWe urge a re-assessment of this essentially formalist position. If phonology is separated from\nthe principles of well-formedness (the ‘laws’) that drive it, the resulting loss of constraint and\ntheoretical depth will mark a major defeat for the enterprise. The danger, therefore, lies in the other\ndirection: clinging to a conception of Universal Grammar as little more than a loose organizing\n\nOptimality Theory\n\nChapter 10\n\n217\n\nframework for grammars. A much stronger stance, in close accord with the thrust of recent work,\nis available. When the scalar and the gradient are recognized and brought within the purview of\ntheory, Universal Grammar can supply the very substance from which grammars are built: a set of\nhighly general constraints which, through ranking, interact to produce the elaborate particularity of\nindividual languages.\n\n10.2 The Connectionism Connection, and other Computation-based\nComparisons\n10.2.1 Why Optimality Theory has nothing to do with connectionism\nThe term ‘Harmony’ in Optimality Theory derives from the concept of the same name proposed in\n‘Harmony Theory’, part of the theory of connectionist (or abstract neural) networks (Smolensky\n1983, 1984ab, 1986). It is sometimes therefore supposed that Optimality Theory should be classified\nwith the other connectionist approaches to language found in the literature (McClelland &\nKawamoto 1986; Rumelhart & McClelland 1986; Lakoff 1988, 1989; McMillan & Smolensky 1988;\nStolcke 1989; Touretzky 1989, 1991; Elman 1990, 1991, 1992; Goldsmith & Larson 1990; Larson\n1990, 1992; Legendre, Miyata, & Smolensky 1990abc, 1991ab; Hare 1990; Rager & Berg 1990; St.\nJohn & McClelland 1990; Berg 1991; Jain 1991; Miikkulainen & Dyer 1991; Touretzky & Wheeler\n1991; Goldsmith 1992; Wheeler & Touretzky 1993 is a small sample of this now vast literature;\ncritiques include Lachter & Bever 1988, Pinker & Prince 1988). Despite their great variety, almost\nall of these connectionist approaches to language fall fairly near one or the other of two poles, which\ncan be characterized as follows:\n(304) Eliminativist connectionist models. Representing the mainstream connectionist approach to\nlanguage, the primary goals of these models are to show:\na.\nthat basic analytic concepts of generative theory ‘can be eliminated’ in some sense;\nb.\nthat numerical computation can eliminate computing with symbolically structured\nrepresentations;\nc.\nthat knowledge of language can be empirically acquired through statistical induction\nfrom training data.\n(305) Implementationalist connectionist models. At the other pole, these models aim to contribute\nto the theory of language by studying whether (and how) more-or-less standard versions of\nconcepts from generative grammar or symbolic natural language processing can be\ncomputationally implemented with connectionist networks. As with symbolic computational\napproaches, the claim is that limitations on what can be (efficiently) computed bear\nimportantly on issues of language theory.\nThe conspicuous absence of connectionist models in this work shows how far Optimality Theory is\nfrom either of these poles; both eliminativist and implementationalist connectionism depend\n\n218\n\nChapter 10\n\nPrince & Smolensky\n\ncrucially on the study of specific connectionist networks. All three of the prototypical objectives in\neliminativist research (304a!c) are completely antithetical to Optimality Theory. And as for the\nimplementationalist approach, rather than arguing for the contribution of Optimality Theory based\non issues of connectionist implementation, we have not even entertained the question.76\n\n10.2.2 Why Optimality Theory is deeply connected to connectionism\nThat Optimality Theory has nothing to do with eliminativist or implementationalist connectionism\nis related to the fact that, fundamentally, Harmony Theory itself has little to do with eliminativist or\nimplementationalist connectionism. Harmony Theory develops mathematical techniques for the\ntheory of connectionist computation which make it possible to abstract away from the details of\nconnectionist networks. These techniques show how a class of connectionist networks can be\nanalyzed as algorithms for maximizing Harmony, and, having done so, how Harmony maximization\nitself, rather than the low-level network algorithms used to implement it, can be isolated as one of\nthe central characteristics of connectionist computation. Optimality Theory constitutes a test of the\nhypothesis that this characterization of connectionist computation is one which can enrich — rather\nthan eliminate or implement — generative grammar: by bringing into the spotlight optimization as\na grammatical mechanism.\nOptimality Theory has abstract conceptual affinities with Harmonic Grammar (Legendre,\nMiyata, & Smolensky, 1990a), a grammar formalism which is mathematically derivable from\nHarmony Theory and general principles concerning the realization of symbolic structure within\ndistributed connectionist networks (Dolan 1989, Dolan & Dyer, 1987, Legendre, Miyata &\nSmolensky 1991, 1992, Smolensky 1987, 1990; relatedly, Pollack 1988, 1990). Harmonic Grammar\nis more intimately connected than Optimality Theory to a connectionist substrate: the relative\nstrengths of constraints are encoded numerically, rather than through non-numerical domination\nhierarchies. Harmonic Grammar has been applied to the formulation of a detailed account of the\ncomplex interaction of syntactic and semantic constraints in unaccusativity phenomena in French\n(Legendre, Miyata, & Smolensky 1990bc, 1991; Smolensky, Legendre & Miyata, 1992).\nIt is instructive to ask what happens to Optimality Theory analyses when they are recast\nnumerically in the manner of Harmonic Grammar. Suppose we assess numerical penalties for\nviolating constraints; the optimal form is the one with the smallest total penalty, summing over the\nwhole constraint set. A relation of the form ÷1 >> ÷2 means considerably more than that the penalty\nfor violating ÷1 is greater than that for violating ÷2. The force of strict domination is that no number\nof ÷2 violations is worth a single ÷1 violation; that is, you can’t compensate for violating ÷1 by\npointing to success on ÷2, no matter how many ÷2 violations are thereby avoided. In many real-world\nsituations, there will be a limit to the number of times ÷2 can be violated by any given input; say, 10.\nThen if pk is the penalty for violating ÷k, it must be that p1 is greater than 10×p2.\n\n76\n\nIt is clear that Optimality Theory can be readily implemented using non-connectionist computation, and\nstudy of implementational issues in both connectionist and non-connectionist systems is a large open area\nfor research.\n\nOptimality Theory\n\nChapter 10\n\n219\n\nThe same reasoning applies on down the constraint hierarchy ÷1 >> ÷2 >> þ >> ÷n >> þ. If\n÷3 admits a maximum of 10 violations, then p2 > 10×p3, and p1 > 10×10×p3. For pn, we’ll have p1 >\n10n&1×pn, if we cling artificially to 10 as the standard number of possible violations per constraint.\nThe result is that, in order to represent the domination relation, the penalties must grow\nexponentially. Optimality Theory, on this practical construal, represents a very specialized kind of\nHarmonic Grammar, with exponential weighting of the constraints.\nWhen we remove the artifice of limiting the number of violations per constraint, it becomes\nclear that the real essence of the domination idea is that the penalty for violating ÷1 is infinitely\ngreater than the penalty for violating ÷2. The notion of Harmony in Optimality Theory, then, cannot\nbe faithfully mapped into any system using standard arithmetic. Nevertheless, Optimality Theory is\nrecognizable as a regimentation and pushing to extremes of the basic notion of Harmonic Grammar.\nThe interested reader is referred to Smolensky, Legendre, & Miyata 1992, in which the relations\nbetween Harmonic Grammar, Optimality Theory, and principles of connectionist computation are\nsubjected to detailed scrutiny.\n\n10.2.3 Harmony Maximization and Symbolic Cognition\nThe relation of Optimality Theory to connectionism can be elaborated as follows (for extended\ndiscussion, see Smolensky, 1988, in press). In seeking an alternative to eliminativist and\nimplementationalist connectionism, a natural first question to ask is whether, and how, connectionist\nprinciples might be capable of informing generative grammar. Suppose connectionism is viewed as\na computational hypothesis concerning the structure of cognition at a level lower than that assumed\nin standard symbolic cognitive theory — a level closer to, but not as low as, the neural level. The\nquestion then becomes, how can connectionist computational principles governing this lower level\nof description constructively interact with principles operating at the higher level of description\nwhere grammar has traditionally been carried out? As a first step toward a reconciliation of the kinds\nof processes and representations assumed by connectionism to operate at the lower level with those\nassumed to operate in grammar, it seems necessary to find ways of introducing symbolic principles\ninto connectionist theory and means of importing connectionist principles into symbolic theory. The\nformer can take the form of new principles of structuring connectionist networks so that their\nrepresentational states can be formally characterized at a higher level of analysis as symbolically\nstructured representations.\nIn the reverse direction, principles of connectionist computation need to be introduced into\nsymbolic grammatical theory. What principles might these be? Perhaps the most obvious are the\nprinciples of mutual numerical activation and inhibition which operate between connectionist units\n(or ‘abstract neurons’). Work along these lines includes Goldsmith and Larson’s Dynamic Linear\nModel (DLM), in which the levels of activity of mutually exciting and inhibiting units are taken to\nrepresent, typically, levels of prominence of adjacent phonological elements, e.g., derived sonority,\nstress (Goldsmith 1992, Goldsmith & Larson 1990, Larson 1990, 1992). As Goldsmith and Larson\nhave shown, linguistically interesting behaviors are observed in these models; a variety of results to\nthis effect have been proven in Prince 1993, which provides detailed formal analysis of the models,\nincluding explicit mathematical expressions characterizing their behavior. (It must also be noted that\nthis analysis reveals a number of non-linguistic behaviors as well.)\n\n220\n\nChapter 10\n\nPrince & Smolensky\n\nPrinciples of mutual activation and inhibition are the lowest-level principles operating in\nconnectionist networks. Rather than attempting to import such low-level principles to as high-level\na theoretical enterprise as the theory of grammar, an alternative strategy is to identify the highest\nlevel principles to emerge from connectionist theory, and attempt to import these instead. Such high\nlevel principles are presently in very short supply. One of the few available is Harmony\nmaximization.\nStripping away the mathematical technicalities, the principle of Harmony maximization can\nbe couched in the following quite general terms:77\n(306) Connectionist Harmony Maximization. In a certain class of connectionist network, the\nnetwork’s knowledge consists in a set of conflicting, violable constraints which operate in\nparallel to define the numerical Harmonies of alternative representations. When the network\nreceives an input, it constructs an output which includes the input representation, the one\nwhich best simultaneously satisfies the constraint set — i.e., which has maximal Harmony.\nThat Harmony maximization could be imported into phonological theory as a leading idea was\nsuggested by Goldsmith (1990), working within the context of concerns about the role of wellformedness constraints in influencing derivations; it plays a central role in the model called\nHarmonic Phonology (Goldsmith 1990, 1993; Bosch 1991, Wiltshire 1992). (Immediately below,\nwe examine some features of the class of models to which this belongs.) In line with our assessment\nof fundamentally different modes of interaction between connectionist and symbolic theories, it is\nimportant to recognize that the Dynamic Linear Model is conceptually and technically quite distinct\nfrom the family of linguistic models employing notions of Harmony, and in understanding its special\ncharacter it is necessary to be aware of the differences. The DLM is a discrete approximation to a\nforced, heavily-to-critically damped harmonic oscillator. The networks of the DLM do not conform\nin general to the formal conditions on activation spread which guarantee Harmony maximization\n(either equally-weighted connections going in both directions between all units, or no feedback—\nsee Prince & Smolensky 1991 for discussion). To the best of our knowledge, no Harmony function\nexists for these networks. Further, while Harmonic Phonology is based on symbol structures, the\nrepresentations in the DLM are crucially numerical and non-structural. Thus, even if a Harmony\nfunction existed for the networks, it is unlikely that the activation passing in them can be construed\nas Harmonic Rule Application.\nOptimality Theory, by contrast, seeks to strengthen the higher-level theory of grammatical\nform. It can be viewed as abstracting the core idea of the principle of Harmony Maximization and\nmaking it work formally and empirically in a purely symbolic theory of grammar. We see this as\nopening the way to a deeper understanding of the relation between the cognitive realm of symbol\nsystems and the subcognitive realm of activation and inhibition modeled in connectionist networks.\nThe property of strict domination is a new element, one quite unexpected and currently\nunexplainable from the connectionist perspective,78 and one which is crucial to the success of the\nenterprise.\n77\n\nThis principle, and an appreciation of its generality and importance, is the result of the work of a\nnumber of people, including Hopfield 1982, 1984; Cohen & Grossberg 1983; Hinton & Sejnowki 1983,\n1986; Smolensky 1983, 1986; Golden 1986, 1988; and Rumelhart, Smolensky, Hinton, & McClelland 1986.\nThere are almost as many names for the Harmony function as investigators: it (or its negative) also goes by\nthe names Lyapunov-, energy-, potential-, or goodness-function.\n78\n\nFor a possible line of explanation, see Smolensky, Legendre & Miyata 1992 (§3.3).\n\nOptimality Theory\n\nChapter 10\n\n221\n\n10.3 Analysis of ‘Phonotactics+Repair’ Theories\nAs discussed in §1, Optimality Theory is part of a line of research in generative syntax and\nphonology developing the explanatory power of output constraints. Most other research in this line\nhas been derivational and in phonology has tended to use constraints only for surface- (or level-)79\nunviolated conditions: phonotactics. The fact that these phonotactics are surface-true arises in these\nderivational theories from a variety of factors, including the blocking of phonological processes\nwhich would lead to violation of a phonotactic, and the triggering of repair rules which take\nrepresentations violating a phonotactic and modify them in one way or another so that the\nphonotactic holds of the result.\nIn these Phonotactics+Repair theories, interactions between phonotactics and repair rules\ncan be handled in a variety of ways, across and within particular theories. An individual repair may\nbe associated with individual phonotactics or not; they may be ordered with respect to other\nphonological rules or not; a phonotactic may block a rule or not. As we have observed throughout\nthis work, all these patterns of interaction between phonotactics and repair rules have effects which\nare obtained in Optimality Theory from the single device of constraint domination. Domination\nyields not only the effects of phonotactic/repair interactions, but also accomplishes all the other work\nof the grammar, including the prosodic parse and the effects of what in derivational theories are\ngeneral phonological processes. This constitutes a pervasive unification of what is expressed in other\ntheories through a fragmented diversity of incommensurable mechanisms.\nIn this section we explicitly compare Optimality Theory to two representatives of the family\nof Phonotactics+Repair theories: the persistent rule theory (Myers 1991), and the Theory of\nConstraints and Repair Strategies (Paradis 1988ab).We will focus on one issue of central importance:\ncomparing the notions of conflict which operate in Optimality Theory on the one hand and in\nPhonotactics+Repair theories on the other. We will see how a special case of Optimality Theoretic\nresolution of constraint conflict by ranking directly yields results which Phonotactics+Repair theories\nachieve by regulating phonotactic/rule interaction. The configuration at issue is one in which certain\nphonological rules are not blocked by a phonotactic, leading to intermediate derivational states in\nwhich the phonotactic is violated, at which point one of a set of possible repair rules is selected to\nrestore compliance with the phonotactic. The cases we examine are treated within Optimality Theory\nvia a straightforward interaction pattern which is quite familiar from descriptive work in the theory.\nWhile we will not consider Harmonic Phonology explicitly here, the general comparative analysis\nwe will provide is relevant to it as well, as a member of the Phonotactics+Repair (henceforth, ‘P+R’)\nfamily of theories. The interaction of phonotactics, repair rules, and the general rules implementing\nphonological processes is structured in Harmonic Phonology in the following way (Goldsmith 1990,\n1993, Bosch 1991, Wiltshire 1992). The overall derivation involves several levels of representation.\nAt each level certain specified phonotactics apply. At each level there is a set of rules, essentially\nrepair rules, which apply freely within that level, governed by the principle of Harmonic Rule\nApplication: “phonological rules apply ... just in case their output is better than their input with\n79\n\nThroughout this section, properties predicated of the ‘surface’ will refer to properties which hold either\nlevel-finally or derivation-finally.\n\n222\n\nChapter 10\n\nPrince & Smolensky\n\nrespect to some criteria specified by a phonotactic (of the relevant level)” (Goldsmith 1993: 252).\nRules apply one at a time within a level, but the derivational step to another level involves a parallel\napplication of a specified set of rules which are not subject to Harmonic Rule Application. As with\nthe P+R theories we treat specifically below, rules are used to achieve results which in Optimality\nTheory arise through the interaction of violable constraints. Optimality Theory differs crucially in\nexplicitly assessing Harmony using constraints many of which are surface- (or level-) violated. A\nspecific comparison on this point was provided in the Lardil analysis, §7.4; all effects in the\nOptimality Theoretic account are the result of harmonic evaluation, while the Harmonic Phonology\nperspective requires that crucial parts of the analysis be attributed to cross-level rules to which\nharmonic principles do not apply. The main reason for this difference is that crucial well-formedness\nconditions in the Optimality Theoretic analysis are not surface-unviolated phonotactics. The\nconstraints, unlike phonotactics, come from Universal Grammar — they cannot be gleaned from\ninspection of surface forms. Indeed, there is no hope of constructing UG in this way if its constraints\nmust be inviolable, and conversely, no hope of constructing individual grammars from inviolable\nconstraints if they must be universal. In this situation, we argue, it is necessary to go for a strong UG\nrather than cling to the notion that constraints are a priori inviolable.\nThe central idea, then, which distinguishes Optimality Theory from other related proposals in the\ngenerative literature, notably Phonotactics+Repair theories, is this: constraints which are violated\non the surface do crucial work in the grammar.80 In alternative approaches, the work done in\nOptimality Theory by surface-violable constraints is generally performed by derivational rules. The\nissue of conflict is central here, since in Optimality Theory, surface violations of constraints arise\nonly when they are forced by conflicts with more dominant constraints. Such conflicts between\nconstraints in Optimality Theory are related in non-obvious ways to conflicts which arise in other\ntheories between surface-unviolated constraints and derivational rules. Clarifying the relation\nbetween constraint/constraint conflict in Optimality Theory and rule/phonotactic conflict in P+R\ntheories is a main goal of this section.\nExamining the relation between these two kinds of conflict will allow us to compare\nOptimality Theory to a few specific P+R proposals in the literature. Our goal is to explicitly relate\nan important class of accounts based on a combination of surface-true constraints and derivational\nrules to Optimality Theoretic accounts based exclusively on constraints, both surface-true and\nsurface-violated, and in the process to relate rule/phonotactic conflict in other theories to constraint/\nconstraint conflict in Optimality Theory. For this purpose we will sketch particular Optimality\nTheoretic accounts of phonological interactions which are kept as close as possible to selected P+R\naccounts; and we will flesh out these Optimality Theoretic accounts just sufficiently to allow us to\nconcretely illustrate the following general observations, for an interesting class of cases:\n\n80\n\nWe are grateful to Robert Kirchner and John McCarthy for clarificatory discussion. See Kirchner\n(1992bc).\n\nOptimality Theory\n\nChapter 10\n\n223\n\n(307) The Rule/Constraint Divide\na. The work done in P+R theories by specific repair rules is included under Optimality\nTheory in the consequences of general, violable constraints which function generally\nwithin the grammar to ensure correct parsing. In many cases, they are kinds of\nFAITHFULNESS constraints, versions of PARSE and FILL.\nb. P+R theories distinguish sharply between phonotactics and repair rules, which must be\ntreated entirely differently. Optimality Theory makes no such distinction, exploiting\nthe single theoretical construct of the violable constraint: higher-ranked constraints\nend up surface-unviolated; lower-ranked ones, surface-violated. Avoiding the\nontological phonotactic/repair-rule distinction considerably strengthens Universal\nGrammar, because the same constraint which is surface-violated in one language\n(correlating with a repair rule) is surface-unviolated in another (corresponding to a\nphonotactic). Universal Grammar provides violable constraints which individual\ngrammars rank; whether a constraint appears as surface-violated (‘repair-like’) or\nsurface-unviolated (‘phonotactic-like’) in a given language is a consequence of the\nconstraint’s ranking in the grammar.\nc. Under Optimality Theory, the universally fixed function Gen supplies all structures; there\nare no special structure-building or structure-mutating processes that recapitulate the\ncapacities of Gen in special circumstances. Because of Gen, the correct form is\nsomewhere out there in the universe of candidate analyses; the constraint hierarchy\nexists to identify it. In a nut-shell: all constraint theories, in syntax as well as\nphonology, seek to eliminate the Structural Description term of rules; Optimality\nTheory also eliminates the Structural Change.\n(308) Conflict and Violation\na. Conflict between a phonotactic ÷ and a phonological rule R does not correspond in\nOptimality Theory to conflict between ÷ and the constraint ÷R which does the main\nwork of the rule R; both ÷R and ÷ are surface-unviolated, hence the two constraints\ncannot be in conflict.\nb. Instead, the conflict in Optimality Theory is between the pair {÷, ÷R} on the one hand,\nand a third constraint ÷rstr on the other: this third constraint is one which is violated\nby the repair rule which is used in the P+R theory to enforce the phonotactic ÷.\nc. One consequence of the P+R approach is the conclusion that constraints which are\nunviolated on the surface must nonetheless be violated at intermediate stages of\nderivations. In Optimality Theory, surface-violable constraints which do some of the\nwork of repair rules eliminate the need for temporary violation of surface-unviolated\nconstraints.\nIt is clear that the very idea of repair strategies demands that surface-inviolable constraints\nbe violated in the course of derivations: a repair strategy is a derivational process which takes a\nrepresentation in which a constraint is violated and mutates it into a representation in which the\nconstraint is satisfied. Such a process cannot take place unless representations violating the\nconstraint are present in the derivation.\n\n224\n\nChapter 10\n\nPrince & Smolensky\n\nA derivational process is by definition a sequential procedure for converting an input into an\noutput; a sharp ontological distinction between input and output is not possible since there is a host\nof intermediate representations bridging them. Constraints need to be evaluated over all such\nrepresentations, and part of the reason theoretical complexities arise is that constraints which are\nunviolated on the surface may be violated in underlying forms (especially after morphological\ncombination) and then at least for some time during the derivation; or constraints may be initially\nvacuously satisfied because they refer to structure that is not yet constructed, but as soon as the\nrelevant structure is built, violation occurs. In the non-serial version of Optimality Theory, however,\nthere is a sharp ontological difference between inputs and outputs: Markedness constraints are\nevaluated only with respect to the output; and Faithfulness constraints, which value realization of\nthe input, must also look to the output to make their assessments. Any surface-unviolated constraint\nis therefore literally entirely unviolated in the language, as it would be a basic category error to say\nthat the constraint is violated by underlying forms.\nWhile it is obvious that a repair strategy approach requires that surface-unviolated constraints\nbe violated at least temporarily during derivations, it is much less obvious, of course, that the work\nof repair strategies can in fact be done by violable constraints, the violations of which are governed\nby domination hierarchies. Evidence for this conclusion is implicit in most of the preceding sections,\nsince many of the Optimality Theoretic analyses we have presented use the freedom of Gen and\nconstraint violation to do work which is performed in other accounts by repair rules. In this section,\nwe focus on explicit comparison between Optimality Theoretic and a few P+R accounts from the\nliterature. It turns out that several of these comparisons have a structure which is already implicit in\none of our basic analyses, the CV syllable structure typology of §6. So before turning to our\ncomparisons, we set up their general structure by examining this simplest case.\n\n10.3.1 CV Syllable Structure and Repair\nConsider syllabification in the typological class 3CV(C)ep: onsets are mandatory, enforced by\noverparsing. In §6.2.2.1, we examined the input /V/, and saw that it was parsed as .~V., surfacing\nas a CV syllable with an epenthetic onset. A simple analysis of this situation using a surfaceunviolated phonotactic and a repair rule runs as follows. The language has a syllable structure\nconstraint SYLLSTRUC given by the template CV(C). (In the terminology of §6, SYLLSTRUC\nencapsulates the constraint package {ONS, NUC, *COMPLEX}.) A syllabification rule Rsyll erects a F\nnode and associates V to it (via a Nuc or : node). This onsetless F violates SYLLSTRUC and this\nviolation triggers a repair rule Rep: a C-epenthesis rule.\nEven in this utterly simple situation, the most basic of the problematic issues which loom\nlarge in richer contexts are already present. Why doesn’t the constraint SYLLSTRUC block the\nsyllabification rule in the first place? (Indeed, this is just what might be assumed in a comparable\nanalysis of the underparsing case, 3CV(C)del.) What general principle licenses temporary violation of\nSYLLSTRUC?\nThese questions disappear when derivational rules are replaced by Optimality Theory’s\nviolable constraints. The work of the syllabification rule Rsyll is done by the constraint PARSE, which\nhappens to be surface-unviolated in this language. The work of the repair rule Rep is performed by\nthe constraint FILL (more precisely, FILLOns) which happens to be surface-violated in this language.\n\nOptimality Theory\n\n225\n\nChapter 10\n\nFor theory comparison, the cross-theoretic relation between the derivational rule Rsyll and the\nOptimality Theory constraint PARSE is an important one, for which it is convenient to have a name;\nwe will say that PARSE is a postcondition of Rsyll: the constraint PARSE gives a condition (‘underlying\nmaterial must be parsed into syllable structure’) which is satisfied after the operation of the rule Rsyll,\nwhich parses underlying material into syllable structure. There is not a unique postcondition\nassociated with a rule; and not just any one will result in an Optimality Theoretic account that works.\nThe theory comparison enterprise on which we now embark is certainly not a mechanical one. The\npostcondition relation is a strictly cross-theoretic notion; since it is not a notion internal to\nOptimality Theory, the fact that it is not uniquely defined in no way undermines the well-definition\nof Optimality Theory.\nThe relation between the repair rule Rep and the constraint FILL is also cross-theoretically\nimportant, and different from that relating Rsyll and PARSE. The repair rule Rep does not apply unless\nit is necessary to save the SYLLSTRUC constraint; it is precisely the avoidance of FILL violations\nwhich prevents overparsing (epenthesis), except when necessary to meet SYLLSTRUC. A\npostcondition of the rule Rep is thus SYLLSTRUC. FILL, on the other hand, is a restraint on the repair\nrule: it is violated when the rule fires. (Like postcondition, restraint is a cross-theoretic relation\nwhich is not uniquely defined.)\nThe Optimality Theory treatment employs the basic domination relation:\n(309) SYLLSTRUC >> FILL\nThis is central to achieving the same result as that obtained in the P+R account by stating that the\nrepair rule applies when necessary to meet SYLLSTRUC (but otherwise not, ‘in order to avoid\nviolating FILL’). The domination (309) illustrates the general case: when a repair rule Rrep has as\npostcondition a (surface-unviolated) constraint (corresponding to a phonotactic) ÷tac, and when this\nrule is restrained by a (surface-violated) constraint ÷rstr, we must have:\n(310) ÷tac >> ÷rstr\nThe restraining constraint must be subordinate to the constraint corresponding to the phonotactic.\nThis situation is summarized in the following table:\n(311) 3CV(C)ep:\nRule\n\nConstraint\n\nRepair/Phonotactic\n\nRrep\n\n= C-Epenthesis\n\n÷tac\n\n= SYLLSTRUC\n\nProcess/Postcondition\n\nRproc\n\n= Syllabification\n\n÷proc\n\n= PARSE\n\nviolated by Rrep:\n\n÷rstr\n\n= FILL\n\nRestraining Constraint\nRanking:\ni.e.\n\n{÷tac, ÷proc}\n>> ÷rstr\n{SYLLSTRUC, PARSE} >> FILL\n\n226\n\nChapter 10\n\nPrince & Smolensky\n\nThis table, it turns out, captures the general structure of several more complex theory-comparisons\nwhich will be spelled out in analogous tables below (314, 316, 318). It is important to note, however,\nthat the labeled columns do not partition the theories, and a point-for-point occamite match-up is not\non offer here. Along with the cited rules, the P+R theory includes an exact image of the Markedness\nconstraint(s) SYLLSTRUC; and in addition includes a condition (functioning like PARSE) that causes\nthe Syllabification rule to fire in the presence of unsyllabified material, and another condition,\nanalogous to Faithfulness in general and here functioning like FILL, which restrains C-epenthesis,\nrestricting repair to minimal modification. On the OT side, there is Gen, which supplies candidates\ncorresponding to those produced by C-Epenthesis and Syllabification (as well as many more).\nIn the P+R account, the parsing of /V/ involves a conflict between the constraint SYLLSTRUC\nand the rule Rsyll: this is a case of rule/phonotactic conflict. The locus of conflict in the Optimality\nTheoretic account is elsewhere, however. The clearest Optimality Theoretic counterpart of the rule\nRsyll is its postcondition PARSE, and there is no conflict between SYLLSTRUC and PARSE; the conflict\nis between the pair of constraints {SYLLSTRUC, PARSE} on the one hand and FILL on the other: and\nit is FILL which gets violated. The rule/phonotactic conflict between SYLLSTRUC and Rsyll arises in\nthe P+R account from the fact that Rsyll chooses to procedurally implement PARSE with a construction\nthat implicitly also tries to implement FILL: for Rsyll constructs a syllable with no unfilled nodes. To\nsee the consequences of this, let’s trace the status of the three constraints SYLLSTRUC, PARSE, and\nFILL during the simple derivation of /V/ ÿ .~V.\n(312) Constraint Violation History of a Simple Derivation\n\nStep\n\nForm\n\nRule\n\n0\n\n/V/\n\n1\n\n.V.\n\nRsyll\n\n2\n\n.~V.\n\nRep\n\nSYLLSTRUC\n\nPARSE\n\nFILL\n\n*\n*\n*\n\nThe rule Rsyll eliminates the PARSE violation by parsing V into a new F, but chooses to construct this\nF in such a way as to avoid violations of FILL; that is, it constructs a F with no onset. The problem\nis that this then creates a violation of SYLLSTRUC which next needs repair. The P+R analysis requires\na stage of derivation, step 1 (shaded), in which a phonological rule has been allowed to produce a\nviolation of a surface-unviolated rule. And, of course, such a violation is necessary to trigger Rep. The\nOptimality Theory account, however, involves no violation of the surface-unviolated constraint\nSYLLSTRUC: it involves a violation of the surface-violated constraint FILL.\n\n10.3.2 General Structure of the Comparisons: Repair Analysis\nThe simple example of syllabification of /V/ in 3CV(C)ep illustrates a very general situation. In the P+R\naccount, the story goes as follows. At one stage of a derivation, the conditions of a phonological\nprocess (e.g. Syllabification) are met; the process applies, creating a structure which violates a\n\nOptimality Theory\n\nChapter 10\n\n227\n\nphonotactic; the conditions of a repair rule now being met, the repair applies; and then the\nphonotactic is satisfied.\nThe Optimality Theory view of this P+R account goes like this. The surface-unviolated\nphonotactic is a high-ranking constraint ÷tac. The phonological process achieves some postcondition,\nanother constraint ÷proc. ÷proc is not ‘blocked’ in any sense by ÷tac because in fact the two do not\nconflict: there is a way of satisfying them both, at the expense of a third constraint ÷rstr which is\nlower-ranked than both ÷tac and ÷proc.\nThere is no constraint/constraint conflict between ÷proc and ÷tac even though there is\nrule/phonotactic conflict between Rproc and ÷tac. This is because the rule Rproc enforcing ÷proc\nintroduces a stage of derivation in which ÷tac is violated in order to meet ÷proc. But the subsequent\nrepair produces an ultimate structure which meets both ÷tac and ÷proc, which is possible only because\nthere is no constraint/constraint conflict between these two constraints. The constraint/constraint\nconflict is actually between the pair {÷tac, ÷proc} on the one hand, and ÷rstr on the other. In this\nconflict, ÷rstr loses: it is the constraint violated by the repair rule.\nThe Optimality Theory account of the same situation is simply this (from (311)):\n(313) {÷tac, ÷proc} >> ÷rstr\nIn an unproblematic input (e.g., /CV/ above), ÷tac, ÷proc and ÷rstr are all satisfied. In a problematic\ninput (e.g., /V/ above), ÷tac and ÷proc together force the violation of ÷rstr.\nThis general comparative analysis can be applied to relate a variety of P+R accounts to Optimality\nTheoretic accounts of the same phonemena, as we now see. It is useful to have a name for this\nstrategy: we call it Repair Analysis.\nWe reiterate the importance of distinguishing theory-comparative and Optimality Theoryinternal notions in this discussion. Within Optimality Theory, all constraints have exactly the same\nstatus. The theory does not recognize, for example, a difference between ‘violable’ and ‘inviolable’\nconstraints. All constraints are potentially violable, and which ones happen to emerge as violated on\nthe surface is a logical consequence of the domination hierarchy, the set of inputs, and the content\nof the constraints (which determines which of them conflict on the inputs). Similarly, although\nRepair Analysis distinguishes constraints as ÷tac, or ÷proc, or ÷rstr, this distinction is entirely theorycomparative: from the Optimality Theory-internal perspective, they are all simply violable\nconstraints, interacting in the only way sanctioned by the theory: strict domination. The distinction\nbetween ÷tac, ÷proc, and ÷rstr only arises in comparing an Optimality Theoretic account to a P+R\naccount; they are constraints which relate to elements (e.g., phonotactics and repair rules) which have\nmarkedly different theoretical status in the P+R account — the constraints have identical theoretical\nstatus in Optimality Theory.\nTwo major features of subsequent Repair Analyses are also simply illustrated in the example\nof syllabification in 3CV(C)ep. The first feature is generality: the constraints involved in the Optimality\nTheoretic account are extremely general ones, which function pervasively in the grammar to define\nwell-formedness. The effects of a specific repair rule (epenthesis in a specific kind of environment)\nare derived consequences of the interaction of general well-formedness constraints.\n\n228\n\nChapter 10\n\nPrince & Smolensky\n\nThe constraints in the Optimality Theoretic account are general in another sense, beyond their\ngeneral applicability within the given language: the constraints in question are the same ones which\noperate in other languages exemplifying typologically different syllabification classes — this was\nexactly the point of the CV Syllable Structure Theory developed in §6. Thus the second important\nfeature illustrated in this example is universality. From the perspective of comparison to P+R\ntheories, the point is this: a constraint ÷ may happen to be surface-unviolated in language L1 and\nformalized as a phonotactic in a P+R theory, and the same constraint may well be operative but\nsurface-violated in another language L2 — and therefore not treatable as a phonotactic. ÷ may play\nthe role ÷tac in L1, but may be demoted to the role of a subordinate constraint ÷rstr in L2. In the\nOptimality Theoretic treatment, ÷ may have exactly the same form in both languages; but in\nPhonotactics+Repair theory, this is completely impossible.\nThis situation has been exemplified in a number of cases discussed in previous sections, and\nis quite clear in the syllable structure example. In the language L1 = 3CV(C)ep discussed in §10.3.1, the\nsurface-unviolated constraint is ÷tac = SYLLSTRUC = {NUC, *COMPLEX, ONS} while the surfaceviolated constraint is ÷rstr = FILL. However for a language L2 in the family 3(C)V(C), for example, the\nroles of ONS and FILL are interchanged: now ONS is surface-violated while FILL is surfaceunviolated. The constraint ONS is part of the phonotactic ÷tac in L1; and similarly !COD is also part\nof the corresponding phonotactic for a language L1N in the family 3CV. Yet at least one of ONS and\n!COD must be active in L2 = 3(C)V(C), even though both are surface-violated (since /CVCV/ must be\nsyllabified .CV.CV. rather than .CVC.V., a pair of legal syllables in L2). To see how ONS and !COD\nare demoted from the status of ÷tac in L1 and L1N to the status of ÷rstr in L2, consider the following P+R\naccount of L2. A Core Syllabification Rule builds core syllables, and if any unsyllabified segments\nremain after core syllabification, these defects are repaired by rules of Coda Attachment (for free Cs)\nand Onsetless Open Syllable Construction (for free Vs). The first repair rule is restrained by the\nconstraint !COD and the second by ONS. So in a Repair Analysis of this P+R account of L2, ONS and\n!COD fill the role of ÷rstr.\nThe fact that Optimality Theory has no equivalent of the phonotactic/rule dichotomy, but\nrather a single category of potentially violable constraint, makes it possible for Universal Grammar\nto simply specify a set of general constraints: the distinction between surface-violated and surfaceunviolated, then, is a derived language-particular consequence of constraint ranking. These universal\nconstraints capture generalizations which, in P+R terms, link what appear as phonotactics and\npostconditions in some languages to what are effectively restraining constraints on repair rules in\nothers.\n\n10.3.3 Persistent Rule Theory\nIn the preceding discussion we have been contrasting Phonotactics+Repair approaches, which use\nconstraints for surface-unviolated phonotactics only, and Optimality Theory, which uses constraints\nmuch more widely. One recent analysis of the role of constraints in generative phonology is Myers\n1991, which argues that constraints must be used less widely: only for a subset of phonotactics.\nPhonotactics are argued to divide into two classes which need to be theoretically treated in two\ndifferent ways: one, as constraints which block phonological rules, the other, via persistent rules\nwhich do not block other phonological rules (but may in some cases undo their effects). The\n\nOptimality Theory\n\n229\n\nChapter 10\n\nconclusion that the second class of phonotactics should not be treated as constraints but rather as the\nresult of derivational rules is one which we now attempt to reconcile with Optimality Theory, in\nwhich such rules are eschewed in favor of constraints (surface-violated as well as surfaceunviolated).\nThe repair rules of persistent rule theory (henceforth PRT) are ‘persistent’ in the sense that\nthey are not ordered with respect to other rules, but rather apply whenever their conditions are met.\nThe persistence of these rules does not, however, bear on the applicability of Repair Analysis: what\nmatters is only that these rules are repair rules.\nThe arguments for PRT consist centrally in showing that a subset of phonotactics do not\nblock phonological rules; that these rules apply, generating intermediate representations which\nviolate the phonotactic, representations which are then repaired by a persistent rule. We will consider\ntwo such cases, and apply Repair Analysis to show how the necessary interactions fall out of very\nsimple constraint interactions within Optimality Theory. We reiterate that our objective here is not\nat all to give full alternative treatments of these phenomena, but rather to illustrate the application\nof Repair Analysis to some relevant examples from the literature.\n\n10.3.3.1 English Closed Syllable Shortening\nA simple application of Repair Analysis is to Myers’ analysis (his §2.4) of English vowel length\nalternations like keep/kept, deep/depth, resume/resumption. The PRT analysis assumes a phonotactic\nwhich bars CVVC syllables; we can take this to be a constraint *::: barring trimoraic syllables. In\nthe P+R account, this phonotactic does not block the process of Syllabification of, e.g., the final two\nconsonants in kept, although the result of such syllabification is an illicit CVVC syllable, which then\ntriggers a repair rule of Closed F Shortening. The resulting derivation involves first associating the\nunderlying long vowel of the stem keep to two syllabified moras, then associating p to a mora in the\nsame syllable, then delinking the second mora for the vowel.\nAn Optimality Theoretic account of these interactions gives a straightforward application of\nRepair Analysis. The following table shows the relevant rules and constraints, in exact\ncorrespondence with the table for CV syllabification (311):\n(314) English Closed Syllable Shortening\nRule\n\nConstraint\n\nRepair/Phonotactic\n\nRrep\n\n= Closed F Shortening\n\n÷tac\n\nProcess/Postcondition\n\nRproc\n\n= Syllabification\n\n÷proc = PARSESeg\n\nRestraining Constraint\n\nRanking:\ni.e.:\n\nviolated by Rrep:\n\n{÷tac, ÷proc}\n>> ÷rstr\nSeg\n{*:::, PARSE } >> PARSE:\n\n(313)\n\n÷rstr\n\n= *:::\n= PARSE:\n\n230\n\nChapter 10\n\nPrince & Smolensky\n\nThe phonotactic is ÷tac = *:::. The phonological process not blocked by the phonotactic is Rproc =\nSyllabification; the postcondition associated with this process is PARSESeg. The repair rule is Rrep =\nClosed F Shortening. This is restrained by the constraint ÷rstr = PARSE: which says that moras must\nbe parsed (see §4.5): this is the constraint which must be violated in order to perform shortening.\nHere we assume the following analysis of keep/kept, designed to be minimally different from the\nPRT analysis:\n(315)\nF\n\nF\n::\n/kip + d/\n\n:: :\nÿ\n\nk\n\ni\n\np\n\nd\n\nLike the PRT account, ours does not treat the segmental alternations i/g, d/t. For comparative\npurposes, we retain Myers’ assumption of a (superordinate) constraint entailing that the final\nconsonant is extrasyllabic (at least at this level of representation); we assume that segments attached\nto prosodic structure at any hierarchical level (e.g., the foot F) are phonetically realized, and that the\nfailure to parse the second : of i means the vowel is phonetically realized as short. We use failure\nto parse the second : of i into F here, rather than the PRT delinking of i to the second :, in\nconformity with the general Optimality Theoretic principle that a parse of an input must always\ninclude the entire input representation (here, including two :s and their associations to i). The\nconstraint ranking in (314) ensures that the parse in (315), which incurs the mark *PARSE:, is the\noptimal one.81\nWe observe that the Optimality Theoretic treatment involves no violation of *:::\nwhatsoever: there is no need for an intermediate stage of derivation in which the long vowel is fully\nparsed into syllable structure in order to provide the conditions for a Shortening rule; the second :\nis simply never parsed. By using the (surface-violated, subordinate) constraint PARSE: instead of the\nderivational repair rule, the (surface-unviolated, superordinate) constraint *::: is spared even\ntemporary violation.\nIn this case, the PRT account involves a conflict between the phonotactic *::: and the\nphonological process of Syllabification. But in the Optimality Theory account, without the\nSyllabification rule but with instead its postcondition PARSESeg, no conflict arises between this\nconstraint and the constraint *:::; rather, the conflict is between the combination {*:::, PARSESeg}\non the one hand, and the subordinate constraint PARSE: on the other. The Syllabification rule creates\na conflict with *::: by doing syllabification in such a way as to satisfy PARSE: (in addition to\nPARSESeg): all :s are parsed into syllable structure, and this then needs to be undone by the repair\nrule.\n\n81\n\nAn absolutely direct assault is available if we recognize the ‘canceled link’ as a representational entity\nwhose distribution is governed by a generalized version of PARSE.\n\nOptimality Theory\n\nChapter 10\n\n231\n\nIn the Optimality Theoretic account, the correct interactions fall out directly from the simple\nconstraint domination in (314), exactly the same domination pattern as in (311): the pattern\ncharacteristic of Repair Analysis. Furthermore, whereas repair rules (like Closed F Shortening) are\nspecialized rules which perform marked operations in order to overcome specific phonotactic\nviolations created by phonological processes, the constraints which do the work in the Optimality\nTheoretic account are extremely general ones which are responsible for doing the central work in the\ngrammar. Here, the repair rule of Closed F Shortening performs the marked, anti-grammatical\noperation of Shortening or Delinking, in the very specifically circumscribed context of a Closed F.\nBy contrast, PARSE: and PARSEseg are extremely general constraints which do the main grammatical\nwork of ensuring the underlying material gets parsed ... except when doing so would violate more\nhighly-ranked constraints. The final ‘except’ clause is automatically furnished by the fundamental\noperation of the theory, and there is therefore no need to build the specific cases where this exception\nis realized into a specialized repair rule which undoes parsing exactly when it should never have\noccurred in the first place.\n\n10.3.3.2 Shona Tone Spreading\nOur second example of an argument from Myers 1991 against formalizing phonotactics as\nconstraints is more complex: Shona Tone Spreading. Here the phonotactic is a prohibition on\ncontour tones. The phonological process which is not blocked by this phonotactic are Association\nof syllables to tones, and Rightward Spread of High Tone. The repair rule is Simplification, which\ndelinks the right tonal association of any syllable which has two tonal associations.\nH tones are present in underlying forms, and L tones arise from a rule of Default. The basic\nspreading facts are that underlying H tones always dock and then spread right, unboundedly through\na stem but only to the first F after crossing a morphological boundary (which we’ll denote ‘*’). The\ninput /ku*mú*verengera/ — which has a single underlying H tone (denoted ') on /mú/ — surfaces\nas kumúvérengera, with the underlying H tone spreading right one F to yield vé, the remaining Fs\nreceiving default L tone.\nThe derivation of this output displays the now-familiar pattern in which the phonotactic is\nviolated temporarily. On the first cycle, L tone is associated by default to the stem; next, with the\ninnermost prefix /mú/ added, the underlying H tone spreads right to the first syllable of the stem, ve,\nwhich syllable is now doubly-linked to both H and L, in violation of the phonotactic; this doubleassociation then triggers Simplification, which delinks the right (L) association of this syllable,\nsatisfying the phonotactic.\nThe situation is more complex, but, with appropriate flexing, Repair Analysis applies here\nas well. The table corresponding to tables (311) and (314) is:\n\n232\n\nChapter 10\n\nPrince & Smolensky\n\n(316) Shona Tone Spread\nRule\nRepair/Phonotactic\nProcess/Postcondition\n\nRrep\n\n= Simplification (delink right T)\n\n÷tac\n\n= *F4\n\nRproc1\n\n= Association\n\n÷proc1\n\n= PARSET\n\nRproc2\n\n= Spread H÷\n\n÷proc2\n\n= *FF\n1\n\n÷rstr 1\n\n= *T{*F\n\npotentially violated by Rproc2:\nSubordinate\nConstraints\n\nRanking:\ni.e.\n\nConstraint\n\nRsub2\n\n= Spread H÷\n\n÷proc2N\n\n= *FF\n'\n\nRsub3\n\n= Default T is L\n\n÷rstr 2\n\n= *F'\n\n{÷tac, ÷proc}\n>> ÷rstr\n(313)\n1\n2\n1\n2N\n{÷tac, ÷proc , ÷proc } >> ÷rstr >> ÷proc >> ÷rstr 2\n\nThe Optimality-theoretic constraint corresponding to the phonotactic is written *F4 , where F4 denotes\na doubly-associated F. The first phonological process not blocked by this phonotactic, Association,\nhas a postcondition PARSET. The second such process, Spread H÷, requires a bit more discussion.\nFor present purposes, the following treatment of spreading will suffice. In Optimality Theory\nthe phonological and morphological content of the input is assumed to be an identifiable part of\nevery candidate output. In an output, let F' denote a syllable associated to H, and F1 a syllable\nassociated to a tautomorphemic H. Then we can capture Shona’s rightward spreading as a pair of\nconstraints, the first of which is *FF\n' : this is violated when an L-bearing F follows an H-bearing F.\nThe second, higher-ranked constraint is *FF\n1 , violated when an L-bearing F follows a F bearing a\n82\ntautomorphemic H tone.\nWe assume without further comment that a familiar set of constraints are imposed on the\ncandidate sets generated by Gen: e.g., all Fs must be associated to tones, association lines do not\ncross, the OCP.\nThe Default rule of L-association is motivated by a (lowest-ranked) constraint barring Hbearing syllables: *F' . The only remaining constraint is one which assesses a mark for each tonal\nassociation line which crosses a morphological boundary; we iconically name this constraint *T{*F.\nThe Optimality Theory analysis follows the general form of the previous cases: compare the\nconstraint ranking in (316) to those in (311) and (314). Now, however, the lower-ranking constraints\ncorresponding to ÷rstr are crucially ranked with respect to one another. Because *T{*F is ranked lower\n1 and higher than *FF\n' , it follows that H tones will spread rightward, exactly one syllable\nthan *FF\nacross a morphological boundary: the rightmost H-bearing F is then F' rather than F1 ; so failing to\ncontinue to spread violates *FF\n' , but continuing to spread violates higher-ranked *T{*F.\nHeteromorphemic H-tone association (violating *T{*F) can only be forced by *FF\n1 , which is satisfied\n\nA more complete analysis would attempt to capture the connection between *T{\n*F, which penalizes\nhetero-morphemic association, and the subhierarchy *FF\n1 >> *FF\n' , which asserts that hetero-morphemic\nassociations are weaker licensers of “spreading”.\n82\n\nOptimality Theory\n\nChapter 10\n\n233\n\nby spreading a single syllable across the morpheme boundary. Because *F' is lowest-ranked, it will\nbe violated in optimal forms in which H tones spread: but it ensures that any syllable not receiving\nH tone by spread from an underlying H tone will bear a L tone.\nAs in the preceding examples, in the Optimality Theory account, the constraint ÷tac is not\n(even temporarily) violated. In /ku*mú*verengera/ ÿ .ku*mú*vérengera., the syllable ve does not\nhave the tonal association history i ÿ L ÿ HL ÿ H which it undergoes in the Phonotactics+Rules\naccount; it never receives L-tone in the first place, and there is thus no need to revoke it. And like\nthe previous example, the work of a specialized repair rule is done by extremely general constraints\nwhich are also responsible for doing the primary grammatical work of correctly assigning parses to\ninputs.\n\n10.3.3.3 Summary\nThe analysis in this section is obviously preliminary, and the conclusion therefore a tentative one.\nAccording to Persistent Rule Theory, the role of constraints in grammar is restricted to that subset\nof surface-unviolated phonotactics which block phonological rules; other phonotactics arise as the\nconsequence of persistent rules. We have seen that the failure of a phonotactic to block a\nphonological process is an inevitable outcome within a constraint-based theory in which there is no\nconflict between the constraint ÷tac corresponding to the phonotactic and the constraint ÷proc which\nis a postcondition of the phonological process; these two constraints can be simultaneously met, at\nthe expense of a third subordinate constraint ÷rstr which is surface-violated; this additional constraint\nis what is violated by the operation of the persistent repair rules in PRT. Optimality Theory handles\nsuch cases straightforwardly via the simple domination condition (313):\n{÷tac, ÷proc} >> ÷rstr\nThe constraints involved in the Optimality Theoretic account are highly general ones which do the\nprimary work of the grammar: but because the complete set of constraints ÷tac, ÷proc, ÷rstr cannot all\nbe simultaneously satisfied in certain special problematic cases, something has to give, and the\ndomination hierarchy determines that it is ÷rstr. The special situations in which this subordinate\nconstraint is violated are a logical consequence of the account, rather than a stipulated environment\nhand-wired into a specialized repair rule. Recall that the labels on the constraints are intended merely\nas guides to cross-theory comparison. The root prediction is that all domination orders are possible,\nyielding a typology of different systems, in which of course, from the operationalist point of view,\nthere would be different constraints and different repairs.\n\n10.3.4 The Theory of Constraints and Repair Strategies\nWhereas Myers 1991 argues for restricting the role of constraints in grammar, Paradis has forcefully\nargued the opposite position. Optimality Theory builds on her work and further promotes the role\nof constraints, adding a theory of constraint interaction in which lower-ranked constraints are\nviolated in order to satisfy higher-ranked ones. In this section we explicitly consider key aspects of\n\n234\n\nChapter 10\n\nPrince & Smolensky\n\nthe relation between the approaches, concretely grounding the discussion in a specific illustrative\nanalysis from Paradis 1988 (to which paper page number citations in this section refer).\nLike the theories considered previously, Paradis’ Theory of Constraints and Repair Strategies\n(TCRS) is a derivational Phonotactics+Repair framework, in which all constraints explicitly treated\nas such are surface-unviolated phonotactics. Thus the constraints in TCRS cannot conflict in the\nsense of Optimality Theory. We need to properly understand, then, statements such as the following:\n“All these facts lead me to conclude that phonological processes do not freely violate\nphonological constraints. Actually, violations occur when there is a constraint conflict,\nwhich must be solved in some way. I argue that this is accomplished by the PLH.”\np. 90, emphasis added.\n‘PLH’ refers to the “phonological level hierarchy ... : metrical > syllabic > skeletal > segmental” (p.\n89). An example of Paradis’ sense of ‘constraint conflict’ is provided by her analysis of Fula, about\nwhich she says\n“the constraint violation ... follows from a conflict of two constraints: the obligatory\nSegmental Licensing Convention for skeletal slots ... (no floating slot); and the\nconstraint against continuant geminates ...”\np. 89, emphasis added.\nThe derivation she refers to has a now-familiar form:\n\nOptimality Theory\n\n235\n\nChapter 10\n\n(317) Fula Gemination: An example derivation\nStep\n\n0\n\n1\n\n2\n\nForm\nXXXX XX\n* *' * *\nl a w+ i\n\nF\nF\n*(\n*\nXXXX XX\n* *' *' *\nl a w+ i\nF\nF\n'*(\n(\n'*\n'*\nXXXX XX\n* *' *' *\nl a b+ i\nblocked\n\n3\n\nF\nF\n'*(\n'*\n'*(\nXXX XX\n* *' 2' *\nla b i\n\nRule\n\n*V+C+\n\n*GEMCONT\n\nInput\n\nSpreading,\nNucleus\nSyllabification\n\nFeature\nChanging,\nOnset\nSyllabification\n\n*\n\nFILLX\n\nPARSEX\n\n*\n\n******\n\nPARSEfeat\n\n***\n\n*\n\n*\n\nCoda\nSyllabification\nSegmental\nDelinking,\nSkeletal\nDeletion\n\n*\n\nFula has a phonotactic barring geminate continuant consonants. This phonotactic is temporarily\nviolated during the derivation (317), at step 1 (shaded).\nThe strategy of Repair Analysis applies to this analysis as well. The following table is the\ncounterpart of (311), (314), and (316):\n\n236\n\nChapter 10\n\nPrince & Smolensky\n\n(318) Fula Gemination\nRule\nRrep1 =\n\nSegmental\nDelinking and\nSkeletal Deletion\n\n÷tac1\n\n= *V:C:\n\nRrep2 =\n\n[+cont] ÿ [!cont]\n\n÷tac2\n\n= *GEMCONT\n\nRproc =\n\nSpreading\n\n÷proc\n\n= FILLX\n\nviolated by Rrep1:\n\n÷rstr1\n\n= PARSEX\n\nviolated by Rrep2:\n\n÷rstr2\n\n= PARSEfeat\n\nRepair/\nPhonotactic\nProcess/\nPostcondition\nRestraining\nConstraint\nRanking:\ni.e.\n\nConstraint\n\n{÷tac, ÷proc}\n>> ÷rstr (313)\n1\n2\n{÷tac , ÷tac , ÷proc} >> {÷rstr1, ÷rstr2}\n\nThere are two phonotactics involved; the first is the prohibition on geminate continuant consonants.\nIn the Optimality Theoretic analysis, this is captured in a constraint *GEMCONT which is violated\nwhenever a consonantal root node is associated to the feature [+cont] and to two skeletal positions\n(regardless of whether those skeletal positions are parsed into syllable structure). The other\nphonotactic (related to that of the English Closed F Shortening example discussed in §10.3.3.1) is\na prohibition on the sequence V:C:. In the Optimality Theoretic analysis this takes the form of a\nconstraint, *V:C:, which is violated if a V is associated to two Xs, a following C is associated to two\nXs, and all four Xs are parsed into prosodic structure. (To focus on differences between the\nOptimality Theory and TCRS frameworks, rather than substantive phonological assumptions, we\nstick as close as possible to the substantive assumptions of Paradis 1988.)\nThe phonological process which is not blocked by the phonotactics is Spreading; in step 1\nof (317), this geminates a continuant consonant in violation of *GEMCONT. This violation is repaired\nby the rule [+cont] ÿ [!cont] which changes w to b in step 2. A postcondition of the Spreading rule\nis that the Xs previously unassociated to underlying segments are now so associated: we dub this\npostcondition FILLX.\nAt step 2 of the derivation (317) the first X associated to b is unparsed (its syllabification\nbeing blocked by *V:C:); this violates a ‘no floating slot’ constraint. The repair for this are rules of\nSegmental Delinking and Skeletal Deletion. In the TCRS treatment, the ‘ ’ in step 3 has been\ndeleted from the representation; in the Optimality Theoretic treatment, this skeletal position is part\nof the output (as it must be since it is part of the underlying form) but this ‘ ’ is not parsed into\nprosodic structure and therefore the consonant b associated to it does not surface long. Thus in the\nOptimality Theoretic account, the constraint violated by the repair rule of Skeletal Deletion is\nPARSEX.\nThe effects of the other repair rule, [+cont] ÿ [!cont], arise naturally within an Optimality\nTheoretic account following the treatment of segment inventories in §9.1.2. We will assume that the\n\nOptimality Theory\n\nChapter 10\n\n237\n\nunderlying segment denoted w in the example (317) is actually a set of features which need to be\nparsed (associated to a root node) in order to surface. The feature [+cont] would normally be so\nparsed (to satisfy PARSEfeat), except that in the particular problematic case of (317), parsing this\nfeature would violate *GEMCONT, so underparsing is forced; we assume the segment is phonetically\nrealized as [!cont] as a result of the failure to parse [+cont]. This failure to parse [+cont] constitutes\na violation of PARSEfeat, which is crucially lower-ranked than FILLX (318): this is why in the optimal\nanalysis (the final representation in (317), with ‘ ’ present but unparsed into syllable structure), the\nfloating position ‘X’ of the suffix is filled (associated to ‘b’, with ‘b’ having an unparsed [+cont]\nfeature) rather than unfilled (unassociated to a segmental root node).\nIn the TCRS derivation (317), the segment w/b is first associated (step 1) and later delinked\n(step 3) to a second X. From the perspective of the Optimality Theoretic account, there is another\nassociation/dissociation: the feature [+cont] of this same segment is first parsed into the root node\n(step 0) then unparsed (step 2). The intermediate stage (step 1) at which the phonotactic *GEMCONT\nis violated is necessary in the derivational account to trigger the repair rule [+cont] ÿ [!cont] which\napplies only to geminate consonants. This derivation exhibits opacity in the sense of Kiparsky 1973a.\nHow does the Optimality Theory account explain the opaque outcome, where the consonant\nsurfaces as b even though it does not surface long? That is, how does it explain the optimality of the\nfinal representation in (317)? As follows. High-ranked FILLX forces the floating ‘X’ to be filled,\nwhich is achieved by associating it to the root node of underlying w; *GEMCONT forces [+cont] not\nto be parsed into this root node, violating lower-ranked *PARSEfeat; this explains why b surfaces. At\nthe same time (and in fact, logically independently), *V:C: forces ‘ ’ not to be parsed, violating\nlower-ranked *PARSEX; this is why b surfaces short. Note that the exact formulation of the\nconstraints *GEMCONT and *V:C: are crucial to this explanation. *GEMCONT, as formulated above,\nwould be violated if [+cont] were parsed into the root node — even though one of the two skeletal\npositions to which this root node is associated, , is not itself parsed into syllable structure.\n\n238\n\nChapter 10\n\nPrince & Smolensky\n\nFurthermore, *V:C:, as formulated above, is not violated in the optimal parse precisely because\nis unparsed.83\nWe now return to the issue of constraint conflict within Paradis’ account. As quoted earlier, she\nstates that the constraint ‘no floating slot’ conflicts with the constraint *GEMCONT; however, in the\nend, both constraints are satisfied, appropriate repairs having been made. The relevant sense of\n‘constraint conflict’ here centers around the crucial step 1 of the derivation (317): gemination of\nunderlying w, in conflict with *GEMCONT, but necessary to trigger [+cont] ÿ [!cont]. The question\nParadis raises in her discussion is: why does gemination occur at step 1 rather than Skeletal Deletion\n\n83\n\nThe Fula analysis in Paradis (1988) has further complexities, and in (318) we have focussed on the\naspects most relevant to the issues under consideration in this section: a general Optimality Theoretic\nanalysis of Phonotactics+Repair theories, with specific attention to what Paradis terms ‘constraint conflict’\nin TCRS. Going beyond the elements displayed in (318), several additional factors involved in the Fula\nanalysis are addressed in the text and footnotes of Paradis 1988. Questions about the derivation (317) which\nmust be addressed include these two:\n(a) Why is the free X in the suffix filled by spreading from the preceding consonant rather than from\nthe following vowel?\n(b) Why does the long vowel in the stem not shorten in order to satisfy the *V:C: constraint?\nLike the core of the TCRS analysis displayed in (318), the core of the Optimality Theoretic analysis\npresented there must be supplemented in order to address these questions. Given that our objective here is\nnot at all to provide a full treatment of Fula, we content ourselves with a few remarks about how the\nobservations Paradis makes in answer to these questions straightforwardly suggest Optimality Theoretic\nconstraints which satisfactorily complete the treatment of our example (317); properly testing these possible\nconstraints across Fula goes beyond our goals here.\nTo question (a), Paradis offers two possible explanations: “[i] a nuclear segment does not spread to\na non-nuclear position if a non-nuclear segment is available. Moreover, [ii] nouns cannot end with long\nvowels in Fula.” (p. 90; numbers added.) The second possible explanation [ii] refers to a surface-unviolated\nconstraint which could obviously be added to the top of the constraint hierarchy in the Optimality Theoretic\naccount. The first proposed explanation [i] is more interesting, and since it has the ‘except when’ structure,\nit is a natural product of an Optimality Theoretic treatment involving constraint conflict. One possible such\nanalysis would involve a constraint against vowels associated to two skeletal positions (which may or may\nnot be parsed into syllable structure): ‘*V:’. Obviously, this is surface-violated; violations are forced by a\ndominating constraint FILLX. The constraint *V:, dominated by FILLX, yields explanation [i] as a\nconsequence: it entails that a free X will be associated to a vowel only if a consonant is not available. In\n(317), a consonant is available (even though it happens to be [+cont]).\nParadis does not explicitly address question (b) in the context of the derivation (317), but in a\nfootnote discussing CV:C syllables generally, she observes that in a variety of environments, shortening does\nnot occur to avoid such syllables (note 4). This discussion would suggest a surface-unviolated constraint with\nthe effect that underlying long vowels surface long. One way to achieve this in the Optimality Theoretic\nanalysis would be to assume, as we have done before, that underlying long vowels are distinguished by\nalready being associated to two Xs or two :s in the input; and then to place superordinate in the Fula\nhierarchy a constraint which requires nuclear skeletal positions to be parsed. In this case, ‘PARSEX’ in (318)\nwould be specialized to apply to C skeletal positions (‘PARSEC’) and another constraint PARSEV for V\npositions would be inserted at the top of the hierarchy.\n\nOptimality Theory\n\nChapter 10\n\n239\n\n(which, after all, does occur at step 3)? This is where the Phonological Level Hierarchy is invoked.\nBecause skeletal > segmental in this hierarchy, Paradis observes that\na slot, which has priority over a segment, cannot be deleted because of a segmental\nrestriction (viz. a segmental feature). Therefore the spreading of the continuant consonant\nseems to be the last resort. It causes a minimal violation, that is a violation of a segmental\ntype, which can be minimally repaired in changing the value of the feature.\np. 90, emphasis added.\nThus the issue comes down to a choice between two repairs: deleting a skeletal position or changing\na feature. In the TCRS account, only one repair can apply first, and the choice is crucial — even\nthough, in the end, both repairs will be made. The repair lower in the phonological level hierarchy\n(feature change) is made first.\nAs in the previous applications of Repair Analysis, the Optimality Theoretic view of the\nconflicts inherent in this situation is rather different. In the TCRS account, the ‘no floating slot’\nconstraint is met in the surface representation because ‘ ’ has been deleted. Thus in this account the\nconstraint is surface-unviolated. In the Optimality Theoretic analysis, however, the constraint PARSEX\nis in fact violated in the output; only when this constraint is treated as violable can it truly conflict\nwith the other constraints, and be violated as a result. The other victim of conflict, from the\nperspective of the Optimality Theoretic account, is the constraint PARSEfeat, which is therefore also\nsurface-violated.\nTo summarize: from the TCRS perspective, it is the constraints ‘no floating slot’ and\n*GEMCONS which conflict, even though in the TCRS account both are surface unviolated. In our\nview, such conflict arises only when the former constraint is treated as violable, PARSEX, and is in\nfact violated in output forms. Furthermore, the mechanism which TCRS invokes in cases regarded\nas constraint conflict is a mechanism of choosing which repair rule to apply first; it is therefore\nformally very different from the Optimality Theoretic mechanism of constraint domination for\nresolving conflicts between constraints which cannot be simultaneously satisfied in a possible output.\nThe Optimality Theoretic conflicts crucially involve other surface-violated constraints such as FILLX\nand PARSEfeat which are not part of the constraint component of TCRS, but rather correspond to\nrules, in much the same way as we have seen in the previous analyses of Phonotactics+Repair\naccounts.\nThe work of Paradis addresses a number of important and difficult issues which must be resolved\nin order to render well-defined those derivational theories in which various kinds of rules interact\nwith constraints. We have argued that foregrounding constraints, their interactions, and their\nconflicts — giving due prominence to the crucial notion that linguistic constraints are violable —\nmakes it possible to formulate phonological analyses which offer fresh substantive insights. The\nresult is a strengthened theory of Universal Grammar, conceived as a set of violable constraints the\ninteractions among which are determined on a language-particular basis. Among the principles of\nUniversal Grammar are cognates of those formerly thought to be no more than loose typological and\nmarkedness generalizations. Formally sharpened, these principles now provide the very material\nfrom which grammars are built.\n\nOptimality Theory\n\n241\n\nAppendix\n\nAppendix\n+incomplete,\n\nA.1 The Cancellation and Cancellation/Domination Lemmas\n(216) Cancellation Lemma. Suppose two structures S1 and S2 both incur the same mark *m. Then\nto determine whether S1 TM S2, we can omit *m from the list of marks of both S1 and S2\n(`cancel the common mark') and compare S1 and S2 solely on the basis of the remaining\nmarks. Applied iteratively, this means we can cancel all common marks and assess S1 and\nS2 by comparing only their unshared marks.\n(192, 238) Cancellation/Domination Lemma. Suppose two parses B and C do not incur identical\nsets of marks. Then B TM C if and only if every mark incurred by B which is not cancelled by\na mark of C is dominated by an uncancelled mark of C.\n\nA.2 CV Syllable Structure\n(136) Onset Theorem (Part). If ONS dominates either PARSE and FILLOns, onsets are required.\n(138) Coda Theorem (Part). If !COD dominates either PARSE and FILLNuc, codas are forbidden.\n\nA.3 P~Ãini's Theorem on Constraint-ranking\nLemma. Suppose a form f is accepted by a constraint hierarchy\nf satisfies C, or C is not active on the input i\n\nwhich includes C. Then either:\n\nProof. Consider the filtering of the candidate set at C; f must pass this filter since it passes all of\n. Suppose f violates C. Then f will be filtered out by C unless C is violated by all the\ncandidates which pass the filtering in\nprior to C, in which case C is not active on i. So\nif f violates C then C is not active on i. This is equivalent to the statement in the Lemma.\n(112) P~Ãini's Theorem on Constraint-ranking (PTC). Let and stand as specific to general\nin a P~Ãinian constraint relation. Suppose these constraints are part of a constraint hierarchy\n, and that is active in\non some input i. Then if >> , is not active on i.\nProof. Assume so placed in the hierarchy; then any form which is subject to evaluation by must\nhave survived the filtering of the top portion of the hierarchy down to and including ; call\nthis subhierarchy T. Let i be an input for which is active, which exists by hypothesis.\nConsider the candidate set Gen(i). By the lemma, any parse f in Gen(i) which survives T\nmust satisfy . So every parse f which survives to be evaluated by satisfies . But by the\ncontrapositive of the P~Ãinian relationship, satisfying entails failing . Since all the\ncandidates which gets to evaluate fail , cannot filter any of them out, and is therefore\nnot active on the input i.\n\n242\n\nOptimality Theory\n\nReferences\n\n243\n\nReferences\n[Not corrected or updated from Tech Report version, except for one 1995 entry ]\n\nAllen, W. S. 1973. Accent and rhythm. Cambridge: Cambridge University Press.\nAnderson, Stephen R. 1972. On Nasalization in Sundanese. Linguistic Inquiry 3, 253-268.\nAnderson, Stephen R. 1969. West Scandinavian Vowel Systems and the Ordering of Phonological\nRules. Doctoral dissertation. MIT.\nAnderson, Stephen R. 1982. The analysis of French schwa, or how to get something for nothing.\nLanguage 58, 534-573.\nAoun, Joseph. 1979. Is the syllable or supersyllable a constituent? In MITWPL 1: Papers on syllable\nstructure, metrical structure, and Harmony processes, ed. Ken Safir. MIT, Cambridge.\nAoun, Joseph. 1986. Generalized binding: the syntax and logical form of wh-interrogatives. Studies\nin Generative Grammar 26. Dordrecht: Foris.\nArchangeli, Diana. 1984. Underspecification in Yawelmani phonology and morphology. Doctoral\nDissertation. MIT, Cambridge, MA. [Garland Press, 1988.]\nArchangeli, Diana and Douglas Pulleyblank. 1992. Grounded phonology. Ms. University of Arizona\nand University of British Columbia.\nArchangeli, Diana and Douglas Pulleyblank. 1991. African tongue root Harmony: optimal systems.\nPaper presented at NSF/LSA Conference on Phonological Feature Organization. UCSC,\nSanta Cruz.\nArchangeli, Diana and Douglas Pulleyblank. 1992. Grounded Phonology. Ms. University of Arizona\nand University of British Columbia.\nAvery, P. and Keren Rice. 1989. Segment structure and coronal underspecification. Phonology 6,\n179-200.\nBach, Emmon and Deirdre Wheeler. 1981. Montague Phonology: A First Approximation. University\nof Massachusetts Occasional Papers in Linguistics 7. 27-45.\nBarton, G. Edward, Robert C. Berwick, Eric Sven Ristad. 1987. Computational complexity and\nnatural language. Cambridge, MA: MIT Press.\nBell, Alan. 1971. Some patterns of occurrence and formation of syllable structures. In Working\npapers on language universals, Number 6, 23-137. Language Universals Project, Stanford\nUniversity.\nBell, Alan and Joan Bybee Hooper. 1978. Syllables and Segments. New York: Elsevier!North\nHolland.\nBerg, G. 1991. Learning recursive phrase structure: combining the strengths of PDP and X-Bar\nSyntax. Technical Report 91!5, Dept. of Computer Science, State University of New York,\nAlbany.\nBerwick, Robert, Steven Abney, and Carol Tenny, eds. 1991. Principle-based parsing: computation\nand psycholinguistics. Dordrecht: Kluwer Academic Publishers.\nBird, Steven. 1990. Constraint-based phonology, Doctoral dissertation, University of Edinburgh.\nBittner, Maria. 1993. Cross-linguistic semantics. Ms. Rutgers University.\nBlack, H. Andrew. 1991. The optimal iambic foot and reduplication in Axininca Campa. Phonology\nat Santa Cruz 2, 1-18.\n\n244\n\nReferences\n\nPrince & Smolensky\n\nBlack, Andrew. 1993. Constraint-ranked derivation: truncation and stem binarity in Southeastern\nTepehuan. Ms. UC Santa Cruz.\nBorowsky, Toni. 1986a. Topics in the lexical phonology of english, Doctoral dissertation, University\nof Massachusetts, Amherst.\nBorowsky, Toni. 1986b. Structure preservation and the syllable coda in English. Natural Language\n& Linguistic Theory 7, 145-166.\nBosch, A. 1991. Phonotactics at the level of the phonological word. Doctoral Dissertation.\nUniversity of Chicago.\nBroselow, Ellen. 1982. On the interaction of stress and epenthesis, Glossa 16, 115-132.\nBroselow, Ellen. 1992. Parametric variation in Arabic dialect phonology. In Perspectives on Arabic\nLinguistics IV, ed. E. Broselow, M. Eid and J. McCarthy. Amsterdam: Benjamins.\nBroselow, Ellen and John McCarthy. 1983. A theory of internal reduplication. Linguistic Review 3,\n25-88.\nBrousse, O. 1991. Generativity and Systematicity in Neural Network Combinatorial Learning.\nDoctoral dissertion. Department of Computer Science, University of Colorado, Boulder.\nBrousse, O. and Smolensky, P. 1989. Virtual memories and massive generalization in connectionist\ncombinatorial learning. In Proceedings of the Eleventh Annual Conference of the Cognitive\nScience Society, 380!387. Ann Arbor, MI. Lawrence Erlbaum.\nBrowning, M. A. 1991. Bounding conditions on representation. Linguistic Inquiry 22, 541-562.\nBurzio, Luigi. 1987. English Stress. in P.-M. Bertinetto & M. Loporcaro, eds., Certamen\nPhonologicum: Proceedings of the 1987 Cortona Phonology Meeting.\nBurzio, Luigi. 1992a. Metrical consistency. Abstract of paper presented at DIMACS Workshop,\nPrinceton University.\nBurzio, Luigi. 1992b. Principles of English stress, ms., Johns Hopkins University.\nBybee, Joan. 1985. Morphology: a study of the relation between meaning and form. Amsterdam:\nJohn Benjamins.\nCairns, Charles. 1969. Markedness, neutralization and universal redundancy rules. Language 45,\n863-885.\nCairns, Charles. 1988. Phonotactics, markedness, and lexical representation. Phonology 5, 209-236.\nCairns, Charles and Mark Feinstein. 1982. Markedness and the theory of syllable structure.\nLinguistic Inquiry 13, 193-226.\nCalabrese, Andrea. 1988. Towards a theory of phonological alphabets. Ph.D. diss., MIT,\nCambridge, MA.\nCarlson, Lauri. 1978. Word stress in Finnish. Ms. MIT, Cambridge, MA.\nChen, Matthew Y. 1987. The Syntax of Xiamen Tone Sandhi. Phonology Yearbook 4. 109-150.\nChomsky, Noam. 1951. Morphophonemics of Modern Hebrew. Master’s Thesis. University of\nPennsylvania, Philadelphia, PA.\nChomsky, Noam. 1992. A minimalist program for linguistic theory. MIT Occasional Papers in\nLinguistics. Cambridge, MA: MIT Department of Linguistics and Philosophy.\nChomsky, Noam. 1965. Aspects of the theory of syntax. Cambridge, MA: MIT Press.\nChomsky, Noam. 1989. Some notes on economy of derivation and representation. In MIT Working\nPapers in Linguistics 10, 43-47, ed. Itziar Laka and Anoop Mahajan. Cambridge, MA: MIT\nDepartment of Linguistics and Philosophy.\n\nOptimality Theory\n\nReferences\n\n245\n\nChomsky, Noam. 1986. Barriers, MIT Press, Cambridge, MA.\nChomsky, Noam. 1981. Lectures on government and binding. Dordrecht: Foris.\nChomsky, Noam and Morris Halle. 1968. The sound pattern of English. New York: Harper and\nRow.\nChurchward, Clerk Maxwell. 1953. Tongan grammar. London: Oxford University Press.\nChurchyard, Henry. 1991. Biblical Hebrew prosodic structure as the result of preference-ranked\nconstraints. Ms. University of Texas, Austin.\nClements, G. N and S.J. Keyser. CV Phonology. Cambridge, MA: MIT Press.\nClements, G. N. 1976. Palatalization: linking or assimilation? Proceedings of the Twelfth Regional\nMeeting of the Chicago Linguistic Society, 96-109.\nClements, G. N. 1990. The role of the sonority cycle in core syllabification. In Papers in Laboratory\nPhonology I, ed. John Kingston and Mary Beckman, 283-333. Cambridge University Press.\nClements, G. N. 1991. Place of articulation in vowels and consonants: a unified theory. In\nL’Architecture et la géométrie des représentations phonologiques, ed. B. Laks and A.\nRialland, Paris: CNRS-Editions.\nCohen, M. A. and Grossberg, S. 1983. Absolute stability of global pattern formation and parallel\nmemory storage by competitive neural networks. IEEE Transactions on Systems, Man, and\nCybernetics, 13:815!825.\nCole, J. S. 1992. Eliminating cyclicity as a source of complexity in phonology. UIUC-BI-CS\nTechnical Report, Beckman Institute, University of Illinois. To be published in the\nproceedings of the Illinois conference on Linguistics and Computation.\nColeman, John. 1991. Phonological representations — their Names, Forms, and Powers. Doctoral\nDissertation. University of York.\nDavis, Stuart. 1988a. Syllable weight hierarchies and stress assignment. Ms. Indiana Univerity,\nBloomington.\nDavis, Stuart. 1988b. Syllable onsets as a factor in stress rules. Phonology 5, 1-19.\nDell, François. 1973. Les règles et les sons. Paris: Hermann.\nDell, François and Mohamed Elmedlaoui. 1985. Syllabic consonants and syllabification in Imdlawn\nTashlhiyt Berber. Journal of African Languages and Linguistics 7, 105-130.\nDell, François and Mohamed Elmedlaoui. 1988. Syllabic consonants in Berber: some new evidence.\nJournal of African Languages and Linguistics 10, 1-17.\nDell, François and Mohamed El-Medlaoui. 1989. Quantitative transfer in the nonconcatenative\nmorphology of Imdlawn Tashlhiyt Berber. Journal of Afroasiatic Languages.\nDevine, A. M. and Laurence Stephens. 1980. Latin prosody and meter: brevis brevians. Classical\nPhilology 75, 142-157.\nDixon, R. M. W. 1977. A grammar of Yidiny. Cambridge: Cambridge University Press.\nDixon, R. M. W. 1988. A grammar of Boumaa Fijian. Chicago: University of Chicago Press.\nDolan, C. P. 1989. Tensor Manipulation Networks: Connectionist and Symbolic Approaches to\nComprehension, Learning, and Planning. PhD thesis, Department of Computer Science,\nUniversity of California, Los Angeles, CA.\nDolan, C. P. and Dyer, M. G. 1987. Symbolic schemata, role binding, and the evolution of structure\nin connectionist memories. In Proceedings of the IEEE First International Conference on\nNeural Networks, pages II:287!298, San Diego, CA.\n\n246\n\nReferences\n\nPrince & Smolensky\n\nDressler, Wolfgang. 1985. On the predictiveness of natural morphology. Journal Linguistics 21,\n321-337.\nElman, J. L. 1990. Finding structure in time. Cognitive Science, 14:179.\nElman, J. L. 1991. Distributed representations, simple recurrent networks, and grammatical\nstructure. Machine Learning, 7:195!226.\nElman, J. L. 1992. Grammatical structure and distributed representations. In Davis, S., editor,\nConnectionism: Theory and Practice. Oxford University Press, Oxford.\nEmonds, Joseph. 1970. Root and structure-preserving transformations. Doctoral Diss. MIT,\nCambridge, MA.\nEverett, Daniel. 1988. On metrical constituent structure in Pirahã. Natural Language & Linguistic\nTheory 6, 207-246.\nFrench, Koleen Matsuda. 1988. Insights into Tagalog reduplication. Infixation and stress from nonlinear phonology. MA Thesis. University of Texas, Arlington. SIL and University of Texas,\nArlington, Publications in Linguistics No. 84.\nFurby, C. 1974. Garawa phonology. Pacific Linguistics Series A, #37. Australian National\nUniversity, Canberra.\nGiegerich, Heinz. 1985. Metrical phonology and phonological structure. Cambridge: Cambridge\nUniversity Press.\nGnanadesikan, Amalia. 1992. The feature geometry of coronal subplaces. Ms. UMass, Amherst.\nGolden, R. M. 1986. The “Brain-State-in-a-Box” neural model is a gradient descent algorithm.\nMathematical Psychology, 30!31:73!80.\nGolden, R. M. 1988. A unified framework for connectionist systems. Biological Cybernetics,\n59:109!120.\nGoldsmith, John. 1990. Autosegmental and metrical phonology. Oxford: Basil Blackwell.\nGoldsmith, John. 1992. Local modeling in phonology. In Davis, S., editor, Connectionism: Theory\nand Practice. Oxford University Press, Oxford.\nGoldsmith, John. 1993. Phonology as an intelligent system. In Bridges between Psychology and\nLinguistics: A Swarthmore Festschrift for Lila Gleitman, ed. Donna Jo Napoli and Judy\nKegl, 247!267. ,. Hillsdale, NY: Lawrence Erlbaum Associates.\nGoldsmith, John and Gary Larson. 1990. Local modeling and syllabification. In Proceedings of the\n26th Meeting of the Chicago Linguistic Society: Parasession on the Syllable in Phonetics\nand Phonology, ed. K. Deaton, M. Noske, and M. Ziolkowski. Chicago, IL.\nGoodman, Beverley. 1993. The integration of hierarchical features into a phonological system.\nDoctoral dissertation, Cornell University.\nGoodman, Beverley. 1993. The Integration of Hierarchical Features into a Phonological System.\nDoctoral dissertation, Cornell University.\nGreen, Tom. 1992. Core syllabification and the grid: explaining quantity sensitivity. In Proceedings\nof NELS 22. [in press].\nGrimshaw, Jane. 1993. Minimal projection, heads, and inversion. Ms. Rutgers University, New\nBrunswick, NJ.\nGuerssel, M. 1985. Glides in Berber and syllabicity. Linguistic Inquiry 17, 1-12.\nHaiman, John. 1972. Phonological targets and unmarked structures, Language 48, 365-377.\n\nOptimality Theory\n\nReferences\n\n247\n\nHale, Kenneth. 1973. Deep-surface canonical disparities in relation to analysis and change: an\nAustralian example, Current Trends in Linguistics 11, 401-458.\nHale, Kenneth and A. Lacayo Blanco. 1988. Vocabulario preliminar del ULWA (Sumu meridional).\nCentro de investigaciones y documentación de la Costa Atlantica, Karawala, Zelaya Sur,\nNicaragua and Center of Cognitive Science, MIT, Cambridge, MA.\nHalle, Morris. 1973. Stress rules in English, a new version. Linguistic Inquiry 4, 451-464.\nHalle, Morris and Jean-Roger Vergnaud. 1987. An essay on stress. Cambridge, MA: MIT Press.\nHammond, Michael. 1984. Constraining metrical theory: a modular theory of stress and destressing.\nDoctoral Dissertation. UCLA.\nHammond, Michael. 1992. Deriving ternarity. Ms. University of Arizona, Tucson.\nHare, M. 1990. The role of similarity in Hungarian vowel harmony: A connectionist account.\nConnection Science, 2:123!150.\nHayes, Bruce. 1980. A metrical theory of stress rules. Doctoral Dissertation. MIT, Cambridge, MA.\nHayes, Bruce. 1982. Extrametricality and English stress. Linguistic Inquiry 13, 227-276.\nHayes, Bruce. 1985. Iambic and trochaic rhythm in stress rules. In Proceedings of the thirteenth\nmeeting of the Berkeley Linguistics Association, 429-446. University of California, Berkeley.\nHayes, Bruce. 1987. A revised parametric metrical theory. In Proceedings of the Northeastern\nLinguistics Society 17, GLSA, University of Massachusetts, Amherst.\nHayes, Bruce. 1991. Metrical stress theory: principles and case studies. Samizdat. Los Angeles.\nPublished as Hayes 1995.\nHayes, Bruce. 1995. Metrical stress theory: principles and case studies. The University of Chicago\nPress. Chicago.\nHewitt, Mark. 1992. Vertical maximization and metrical theory. Doctoral dissertation. Brandeis\nUniversity, Waltham.\nHewitt, Mark and Alan Prince. 1989. OCP, locality, and linking: the N. Karanga Verb. in\nProceedings of the Eighth WCCFL, ed. E. Jane Fee and K. Hunt. Stanford University,\nStanford, CA.\nHooper, Joan Bybee. 1972. The syllable in linguistic theory. Language 48, 525-540.\nHopfield, J. J. 1982. Neural networks and physical systems with emergent collective computational\nabilities. Proceedings of the National Academy of Sciences, USA, 79:2554!2558.\nHopfield, J. J. 1984. Neurons with graded response have collective computational properties like\nthose of two-state neurons. Proceedings of the National Academy of Sciences, USA,\n81:3088!3092.\nHoward, Irwin. 1973. A directional theory of rule application. Doctoral Dissertation, MIT.\nBloomington: IULC.\nHudson, Grover. 1974. The role of SPC’s in Natural Generative Phonology. In Papers from the\nparasession on Natural Phonology, ed. Anthony Bruck, Robert A. Fox, and Michael W.\nLaGaly, 171-183. Chicago: Chicago Linguistic Society.\nHulst, Harry van der. 1984. Syllable structure and stress in Dutch. Dordrecht: Foris.\nHulst, Harry van der. 1992. The independence of stress and rhythm. Ms. Rijksuniversiteit te Leiden.\nHume, Elizabeth V. 1992. Front Vowels, Coronal Consonants, and Their Interaction in Nonlinear\nPhonology. Doctoral dissertation. Cornell University, Ithaca.\n\n248\n\nReferences\n\nPrince & Smolensky\n\nHung, Henrietta. 1992. Relativized suffixation in Choctaw: a constraint-based analysis of the verb\ngrade system. Ms. Brandeis University, Waltham.\nHung, Henrietta. in preparation. The Rhythmic and Prosodic Organization of Edge Constituents.\nDoctoral dissertation. Brandeis University, Waltham.\nHyman, Larry. 1985. A theory of phonological weight. Dordrecht: Foris.\nInkelas, Sharon. 1989. Prosodic Constituency in the Lexicon. Ph.D. Dissertation. Stanford\nUniversity.\nItô, Junko. 1986. Syllable Theory in Prosodic Phonology, Ph. D. Dissertation, UMass, Amherst.\nItô, Junko. 1989. A Prosodic Theory of Epenthesis, Natural Language & Linguistic Theory 7, 217260.\nItô, Junko. Yoshihisa Kitagawa. and R. Armin Mester. 1992. Prosodic type preservation in Japanese:\nevidence from zuuja-go. SRC-92-05. Syntax Research Center. University of California. Santa\nCruz.\nItô, Junko & R. Armin Mester. 1992. Weak layering and word binarity. Report LRC-92-09,\nLinguistics Research Center. Santa Cruz: University of California.\nItô, Junko and R. Armin Mester. to appear. Licensed segments and safe paths. In Constraints,\nviolations, and repairs in phonology, ed. Carole Paradis, Darlene LaCharité. and Emmanuel\nNikiema. Special issue of the Canadian Journal of Linguistics.\nJackendoff, Ray. 1983. Semantics and cognition. Cambridge, MA: MIT Press.\nJackendoff, Ray. 1987. Consciousness and the computational Mind. Cambridge, MA: MIT Press.\nJackendoff, Ray 1991. Musical parsing and musical affect. Music Perception 9, 199-230.\nJakobson, Roman. 1962. Selected writings 1: phonological studies. The Hague: Mouton.\nJohnson, C. Douglas. 1972. Formal aspects of phonological description. The Hague: Mouton.\nJain, A. N. 1991. Parsing complex sentences with structured connectionist networks. Neural\nComputation, 3:110!120.\nKager, René. 1989. A Metrical Theory of Stress and Destressing in English and Dutch. = Een\nmetrische theorie over klemtoon en klemtoonverlies in het Engels en het Nederlands.\nDordrecht: ICG.\nKager, René. 1992a. Are there any truly quantity-insensitive Systems?. To appear in Proceedings\nof the Berkeley Linguistics Society, 18.\nKager, René. 1992b. Shapes of the Generalized Trochee. To appear in Proceedings of the Eleventh\nWest Coast Conference on Formal Linguistics.\nKager, René. 1992c. Alternatives to the Iambic-Trochaic Law. To appear in Natural Language &\nLinguistic Theory.\nKager, René & Ellis Visch. 1984a. Een metrische analyse van ritmische klemtoonverschuiving. MA\nthesis. Instituut de Vooys voo12r Nederlanse taal- en letterkunde. R. U. Utrecht.\nKager, René & Ellis Visch. 1984b. Syllable weight and Dutch word stress. in Linguistics in the\nNetherlands 1984, ed. Hans Bennis and WUS van Lessen Kloeke, 197-205. Dordrecht: Foris.\nKahn, Daniel. 1976. Syllable-based generalizations in English phonology. Doctoral Dissertation.\nMIT, Cambridge, MA.\nKaye, Jonathan and Jean Lowenstamm. 1981. Syllable structure and markedness theory. In The\ntheory of markedness in generative grammar, ed. A. Belletti, L. Brandi, and L. Rizzi, 287315. Scuola Normale Superiore di Pisa.\n\nOptimality Theory\n\nReferences\n\n249\n\nKaye, Jonathan, Jean Lowenstamm, and Jean-Roger Vergnaud. 1985. The Internal Structure of\nPhonological Elements: A Theory of Charm and Government, Phonology Yearbook 2, 305328.\nKaye, Jonathan and Jean Lowenstamm. 1984. De la syllabicité, in F. Dell, D. Hirst, and J.-R.\nVergnaud, ed., Forme sonore du langage, Hermann, Paris.\nKaye, Jonathan. 1990. ‘Coda’ licensing. Phonology 7, 301-330.\nKean, Mary-Louise. 1974. The theory of markedness in Generative Grammar. Doctoral Dissertation.\nMIT.\nKelkar, Ashok R. 1968. Studies in Hindi-Urdu I: introduction and word phonology. Deccan College,\nPoona.\nKiparsky, Paul. 1973a. Abstractness, opacity, and global rules. Bloomington: Indiana University\nLinguistics Club.\nKiparsky, Paul. 1973b. Elsewhere in phonology. In A Festschrift for Morris Halle, ed. S. Anderson\nand P. Kiparsky, 93-106. New York: Holt, Rhinehart, and Winston.\nKiparsky, Paul. 1980. Vowel harmony, ms. MIT, Cambridge.\nKiparsky, Paul. 1982. Lexical Phonology and Morphology, in I.S. Yang ed., Linguistics in the\nMorning Calm. LSK, Hanshin, Seoul.\nKiparsky, Paul. 1991. Quantity sensitivity and the nature of templatic parsing. Undated handout.\nBerkeley Linguistics Society. Berkeley, CA.\nKiparsky, Paul. 1992. Catalexis. Ms. Stanford University, Stanford, CA.\nKirchner, Robert. 1992a. Lardil truncation and augmentation: a morphological account. Ms.\nUniversity of Maryland, College Park.\nKirchner, Robert. 1992b. Harmonic Phonology within One Language: An Analysis of Yidiny. MA\nthesis. University of Maryland. College Park.\nKirchner, Robert. 1992c. Yidiny prosody in Harmony Theoretic Phonology. Ms. UCLA.\nKisseberth, Charles. 1970a. On the functional unity of phonological rules. Linguistic Inquiry 1, 291306.\nKissberth, Charles. 1970b. Vowel elision in Tonkawa and derivational constraints. In Studies\npresented to Robert B. Lees by his students, ed. J. Sadock and A. Vanek. Champain:\nLinguistic Research Inc.\nKisseberth, Charles. 1972. On derivative properties of phonological rules. In Contributions to\nGenerative Phonology, ed. Michael K. Brame., 201-228. Austin, TX: University of Texas\nPress.\nKlokeid, Terry Jack. 1976. Topics in Lardil grammar. Doctoral dissertation. MIT, Cambridge, MA.\nKury»owicz, Jerzy. 1968. Indogermanische Grammatik. Band II: Akzent. Ablaut. Heidelberg: Carl\nWinter.\nLachter, J. and Bever, T. G. 1988. The relation between linguistic structure and associative theories\nof language learning—a constructive critique of some connectionist learning models.\nCognition, 28:195!247.\nLakoff, George. 1965. On the nature of syntactic irregularity. Doctoral Dissertation. Harvard\nUniversity. Harvard Computational Lab Report NSF-16. Cambridge, MA.\nLakoff, George. in press. Cognitive Phonology, in John Goldsmith, ed., The Last Phonological Rule,\nUniversity of Chicago Press, Chicago.\n\n250\n\nReferences\n\nPrince & Smolensky\n\nLaPointe, Steven and Mark Feinstein. 1982. The Role of Vowel Deletion and Epenthesis in the\nAssignment of Syllable Structure, in The Structure of Phonological Representations.Part\nII, ed. H.v.d.Hulst and N. Smith, 69-120. Foris, Dordrecht, .\nLarson, G. 1990. Local computational networks and the distribution of segments in the Spanish\nsyllable. In Proceedings of the 26th Meeting of the Chicago Linguistic Society: Parasession\non the Syllable in Phonetics and Phonology, ed. K. Deaton, M. Noske, and M. Ziolkowski.\nChicago, IL.\nLarson, G. 1992. Dynamic computational networks and the representation of phonological\ninformation. Doctoral Dissertation. Linguistics Department, University of Chicago.\nLegendre, G., Miyata, Y., and Smolensky, P. 1990a. Harmonic Grammar—A formal multi-level\nconnectionist theory of linguistic well-formedness: Theoretical foundations. In Proceedings\nof the Twelfth Annual Conference of the Cognitive Science Society, 388!395. Cambridge,\nMA: Lawrence Erlbaum.\nLegendre, G., Miyata, Y., and Smolensky, P. 1990b. Harmonic Grammar—A formal multi-level\nconnectionist theory of linguistic well-formedness: An application. In Proceedings of the\nTwelfth Annual Conference of the Cognitive Science Society, 884!891. Cambridge, MA:\nLawrence Erlbaum.\nLegendre, G., Miyata, Y., and Smolensky, P. 1990c. Can connectionism contribute to syntax?\nHarmonic Grammar, with an application. In Proceedings of the 26th Meeting of the Chicago\nLinguistic Society: Parasession on the Syllable in Phonetics and Phonology, ed. K. Deaton,\nM. Noske, and M. Ziolkowski. Chicago, IL.\nLegendre, G., Miyata, Y., and Smolensky, P. 1991a. Unifying syntactic and semantic approaches to\nunaccusativity: A connectionist approach. In Proceedings of the Seventeenth Annual Meeting\nof the Berkeley Linguistics Society, ed. L. Sutton, and C. Johnson (with Ruth Shields).\nBerkeley, CA.\nLegendre, G., Miyata, Y., and Smolensky, P. 1991b. Distributed recursive structure processing. In\nAdvances in Neural Information Processing Systems 3, ed. D. S. Touretzky and R. Lippman,\n591!597. San Mateo, CA: Morgan Kaufmann.\nLegendre, Géraldine, William Raymond, and Paul Smolensky. 1993. Analytic typology of case\nmarking and grammatical voice. To appear in Proceedings of the Berkeley Linguistics\nSociety, 19.\nLerdahl, Fred and Ray Jackendoff 1983. A generative theory of tonal music. Cambridge, MA: MIT\nPress.\nLevelt, Clara. 1991. Samoan reduplication: how to behave as a plural and other good manners.\nProceedings of the Leiden Conference for Junior Linguists 2, ed. J. van Lit, R. Mulder and\nR. Sybesma. Leiden University: The Netherlands.\nLevin [Blevins], Juliette. 1985. A Metrical Theory of Syllabicity. Doctoral Dissertation. MIT,\nCambridge.\nLiberman, Mark. 1975. The intonational system of English. Doctoral Dissertation. MIT, Cambridge.\nLiberman, Mark and Alan Prince. 1977. On stress and linguistic rhythm. Linguistic Inquiry 8, 249336.\nLevin [Blevins], Juliette. 1985. A Metrical Theory of Syllabicity. Ph.D. Dissertation. MIT.\nCambridge.\n\nOptimality Theory\n\nReferences\n\n251\n\nLombardi, Linda and John McCarthy. 1991. Prosodic circumscription in Choctaw morphology.\nPhonology 8, 37-71.\nLowenstamm, Jean and Jonathan Kaye. 1986. Compensatory lengthening in Tiberian Hebrew, in\nStudies in Compensatory Lengthening, ed. L. Wetzels and E. Sezer. Foris: Dordrecht.\nMcCarthy, John. 1979. Formal Problems in Semitic Phonology and Morphology, Doctoral\ndissertation, MIT, Cambridge, MA.\nMcCarthy, John. 1986. OCP effects: gemination and antigemination. Linguistic Inquiry 17, 207-263.\nMcCarthy, John. To appear. A case of surface constraint violation. Canadian Journal of Linguistics.\nspecial issued edited by Carole Paradis. Darlene LaCharité. and Emmanuel Nikiema.\nMcCarthy, John and Alan Prince. 1986. Prosodic Morphology. Samizdat, Amherst and Waltham,\nMA.\nMcCarthy, John and Alan Prince. 1988. Quantitative Transfer in Reduplicative and Templatic\nMorphology. in Linguistic Society of Korea. ed. Linguistics in the Morning Calm 2. Hanshin\nPublishing Co. Seoul. Pp. 3-35.\nMcCarthy, John and Alan Prince. 1990a. Foot and Word in Prosodic Morphology: The Arabic\nBroken Plurals. Natural Language and Linguistic Theory 8. 209-282.\nMcCarthy, John and Alan Prince. 1990b. Prosodic Morphology and Templatic Morphology. In\nPerspectives on Arabic Linguistics: Papers from the Second Symposium, ed. M. Eid and J.\nMcCarthy, 1-54. Amsterdam: Benjamins.\nMcCarthy, John and Alan Prince. 1991a. Prosodic Minimality. lecture presented at University of\nIllinois Conference The Organization of Phonology.\nMcCarthy, John and Alan Prince. 1991b. Linguistics 240: Prosodic Morphology. lectures and\nhandouts from 1991 LSA Linguistic Institute Course. University of California. Santa Cruz.\nMcCarthy, John and Alan Prince. 1993. Prosodic Morphology I: constraint interaction and\nsatisfaction. Ms. University of Massachusetts, Amherst, and Rutgers University, New\nBrunswick, NJ.\nMcCarthy, John and Alison Taub. 1992. Review of Carole Paradis and Jean-François Prunet, The\nSpecial Status of Coronals. Phonology [in press].\nMcClelland, J. L. and Kawamoto, A. H. 1986. Mechanisms of sentence processing: Assigning roles\nto constituents. In Parallel Distributed Processing: Explorations in the Microstructure of\nCognition. Volume 2: Psychological and Biological Models, ed. D. E. Rumelhart, J. L.\nMcClelland, and the PDP Research Group, ch. 19, 272!325. Cambridge, MA: MIT\nPress/Bradford Books.\nMarcus, Gary, Steven Pinker, Michael Ullman, Michelle Hollander, T. John Rosen, & Fei Xu. 1992.\nOverregularization in language acquisition. Monographs of the Society for Research in\nChild Development, 57 (4, Serial No. 228). Also MIT CCS Occasional Paper #41.\nMester, R. Armin. 1991. Some remarks on Tongan stress. Ms. UCSC, Santa Cruz, CA.\nMester, Ralf-Armin. 1992. The quantitative trochee in Latin. SRC-92-06, Syntax Research Center,\nUC Santa Cruz. To appear in Natural Language and Linguistic Theory, 1993.\nMichelson, Karin. 1988. A comparative study of Lake Iroquoian accent. Dordrecht: Kluwer.\nMiikkulainen, R. and Dyer, M. G. 1991. Natural language processing with modular PDP networks\nand distributed lexicon. Cognitive Science, 343!399.\n\n252\n\nReferences\n\nPrince & Smolensky\n\nMohanan, K. P. 1991. On the bases of radical underspecification. Natural Language & Linguistic\nTheory 9.2, 285-325.\nMohanan, K. P. in press. Fields of Attraction in Phonology, in John Goldsmith, ed., The Last\nPhonological Rule [sic], University of Chicago Press, Chicago.\nMyers, Scott. 1987a. Tone and the structure of words in Shona. Doctoral dissertation. University\nof Massachusetts, Amherst.\nMyers, Scott. 1987b. Vowel shortening in English. Natural Language & Linguistic Theory 5, 485518.\nMyers, Scott. 1991. Persistent rules. Linguistic Inquiry 22, 315-344.\nNespor, Marina & Irene Vogel. 1986. Prosodic phonology. Dordrecht: Foris.\nNoske, Roland. 1982. Syllabification and Syllable-changing Rules in French, in Harry van der Hulst\nand Norval Smith, ed., The Structure of Phonological Representations. Part II., Foris,\nDordrecht.\nOehrle, Richard. 1971. Some remarks on the role of morphology in the assignment of stress. Ms.\nMIT.\nParadis, Carole. 1988a. On Constraints and Repair Strategies, The Linguistic Review 6, 71-97.\nParadis, Carole. 1988b. Towards a Theory of Constraint Violations, McGill Working Papers in\nLinguistics 5, 1-44.\nParadis, Carole and François Prunet, eds. 1991. The special status of coronals: internal and external\nevidence. As Phonetics and phonology, Volume 2. New York: Academic Press.\nPayne, David. 1981. The Phonology and Morphology of Axininca Campa. Summer Institute of\nLinguistics. Arlington, TX.\nPayne, David. Judith Payne. and Jorge Santos. 1982. Morfologia. Fonologia. y Fonetica del\nAsheninca del Apurucayali. Campa—Arawak Preandino. Ministry of Education. Summer\nInstitute of Linguistics. Yarinacocha. Peru.\nPerlmutter, David. 1971. Deep and surface structure constraints in syntax. NY: Holt, Rhinehart, &\nWinston.\nPiggott, Glyne and Raj Singh. 1985. The phonology of epenthetic segments. Canadian Journal of\nLinguistics 30, 415-453.\nPiggott, Glyne. 1992. Satisfying the minimal word. Ms. McGill University, Montréal.\nPinker, Steven. 1984. Language learnability and language development. Cambridge: Harvard Univ.\nPress.\nPinker, Steven and Alan Prince. 1988. On language and connectionism: analysis of a parallel\ndistributed processing model of language acquisition. Cognition, 28:73!193.\nPollack, J. B. 1988. Recursive auto-associative memory: Devising compositional distributed\nrepresentations. In Proceedings of the Tenth Annual Meeting of the Cognitive Science\nSociety. Montreal, Canada: Erlbaum Associates.\nPollack, J. B. 1990. Recursive distributed representation. Artificial Intelligence, 46:77!105.\nPoser, William J. 1985. Cliticization to NP and Lexical Phonology. WCCFL 4, 262-272.\nPoser, William J. 1986. Invisibility. GLOW Newsletter 16, 63-64.\nPrince, Alan. 1976. ‘Applying’ stress. Ms. University of Massachusetts, Amherst.\nPrince, Alan. 1980. A Metrical Theory for Estonian Quantity. Linguistic Inquiry 11, 511-562.\nPrince, Alan. 1983. Relating to the Grid. Linguistic Inquiry 14. 19-100.\n\nOptimality Theory\n\nReferences\n\n253\n\nPrince, Alan. 1986. Improving tree theory. In Proceedings of the Eleventh annual meeting of the\nBerkeley Linguistics Society, ed. Mary Niopokuj, Mary VanClay, Vassiliki Nikiforidou,\nDeborah Feder, 471-490. University of California, Berkeley.\nPrince, Alan. 1990. Quantitative Consequences of Rhythmic Organization. In CLS 26-II: Papers\nfrom the Parasession on the Syllable in Phonetics and Phonology, ed Karen Deaton,\nManuela Noske, and Michael Ziolkowski. Chicago Linguistic Society, Chicago.\nPrince, Alan. 1993. In defense of the number i: anatomy of a linear dynamical model of linguistic\ngeneralizations. Technical Report RuCCS TR-1, Rutgers Center for Cognitive Science.\nPrince, Alan and Paul Smolensky. 1991a. Optimality. Talk given at Arizona Phonology Conference.\nUniversity of Arizona, Tucson\nPrince, Alan and Paul Smolensky. 1991b. Notes on connectionism and Harmony Theory in\nlinguistics. Technical Report CU-CS-533-91. Department of Computer Science, Univ. of\nColorado, Boulder.\nPrince, Alan and Paul Smolensky. 1992. Optimality: constraint interaction in generative grammar.\nRevised and augmented handout from talk delivered at WCCFL.\nPulleyblank, Douglas. 1983. Tone in Lexical Phonology. Dordrecht: D. Reidel.\nPyle, Charles. 1972. On Eliminating BM’s, CLS 8.\nRizzi, Luigi. 1990. Relativized Minimality. Linguistic Inquiry Monograph 16. Cambridge: MIT\npress.\nRager, J. and G. Berg 1990. A connectionist model of motion and government in Chomsky’s\ngovernment-binding theory. Connection Science, 2:35!52.\nRosenthall, Sam. in preparation. The phonology of vowels and glides. Doctoral dissertation.\nUniversity of Massachusetts, Amherst.\nRosenthall, Sam. in prep. The Phonology of Vowels and Glides. Doctoral dissertation. University\nof Massachusetts, Amherst.\nRubach, Jerzy and Gert Booij. 1985. A grid theory of stress in Polish. Lingua 66, 281-319.\nRumelhart, D. E. and J. L. McClelland 1986. On learning the past tenses of English verbs. ch. 18,\n216!271. Cambridge, MA: MIT Press/Bradford Books.\nRumelhart, D. E., P. Smolensky, J. L. McClelland, and G. E. Hinton, 1986. Schemata and sequential\nthought in PDP models. In Parallel Distributed Processing: Explorations in the\nMicrostructure of Cognition. Volume 2: Psychological and Biological Models, ed. J. L.\nMcClelland, D. E. Rumelhart, and the PDP Research Group, ch. 14, pages 7!57.\nCambridge, MA: MIT Press/Bradford Books.\nSamek-Lodovici, Vieri. 1992a. Universal constraints and morphological gemination: a\ncrosslinguistic study. Ms. Brandeis University.\nSamek-Lodovici, Vieri. 1992b. A unified analysis of crosslinguistic morphological gemination. In\nProceedings of CONSOLE-1.\nSapir, Edward. 1930. The Southern Paiute language. Proceedings of the American Academy of Arts\nand Sciences 65, 1-296.\nSchachter, Paul. 1987. Tagalog. In The world’s major languages, ed. Bernard Comrie, ch. 47, p.\n936-958. Croom Helm: London and Sidney.\nSchachter, Paul and Fe Otanes. 1972. Tagalog reference grammar. Berkeley, CA: Univ. of\nCalifornia Press.\n\n254\n\nReferences\n\nPrince & Smolensky\n\nScobbie, James. 1991. Attribute Value Phonology. Doctoral dissertation, University of Edinburgh.\nScobbie, James. 1992. Towards Declarative Phonology, Edinburgh Working Papers in Cognitive\nScience 7, 1-26.\nSelkirk, Elisabeth. 1980a. Prosodic domains in phonology: Sanskrit revisited. In Juncture, ed. Mark\nAronoff and Mary-Louise Kean, 107-129. Anma Libri, Saratoga, CA.\nSelkirk, Elisabeth. 1980b. The role of prosodic categories in English word stress, LI 11, 563-605.\nSelkirk, Elisabeth. 1981. Epenthesis and degenerate syllables in Cairene Arabic. In Theoretical\nIssues in the Grammar of the Semitic Languages, ed. H. Borer and J. Aoun. MIT,\nCambridge.\nSelkirk, Elisabeth. 1984. Phonology and Syntax: the Relation between Sound and Structure.\nCambridge: MIT Press.\nSelkirk, Elisabeth. 1986. On Derived Domains in Sentence Phonology. Phonology Yearbook 3. 371405.\nSelkirk. Elisabeth. 1993. The prosodic structure of functional elements: affixes, clitics, and words.\nHandout of talk presented at the Signal to Syntax Conference. Brown University, Providence.\nSherer, Tim. in prep. Prosodic Phonotactics. Doctoral dissertation. Univ. of Massachusetts,\nAmherst.\nSingh, Raj. 1987. Well-formedness Conditions and Phonological Theory, in Wolfgang Dressler et\nal., ed., Phonologica 1984, Cambridge University Press, Cambridge.\nSommerstein, A. H. 1974. On Phonotactically Motivated Rules, Journal of Linguistics 10, 71-94.\nSmolensky, P. 1983. Schema selection and stochastic inference in modular environments. In\nProceedings of the National Conference on Artificial Intelligence, 378!382, Washington,\nDC.\nSmolensky, P. 1984a. Harmony Theory: thermal parallel models in a computational context.\nTechnical report 8404, Institute for Cognitive Science, Univ. of California at San Diego. In\nP. Smolensky & M. Riley, Harmony theory: Problem solving, parallel cognitive models,\nand thermal physics.\nSmolensky, P. 1984b. The mathematical role of self-consistency in parallel computation. In\nProceedings of the Sixth Annual Conference of the Cognitive Science Society, 319!325.\nBoulder: Erlbaum.\nSmolensky, P. 1986. Information processing in dynamical systems: Foundations of Harmony\nTheory. In Parallel Distributed Processing: Explorations in the Microstructure of Cognition.\nVolume 1: Foundations, ed. D. E.Rumelhart, J. L. McClelland, and the PDP Research\nGroup, ch. 6, pages 194!281. Cambridge, MA: MIT Press/Bradford Books,\nSmolensky, P. 1987. On variable binding and the representation of symbolic structures in\nconnectionist systems. Technical Report CU-CS-355-87. Department of Computer Science,\nUniversity of Colorado at Boulder.\nSmolensky, P. 1988. On the proper treatment of connectionism. The Behavioral and Brain Sciences,\n11:1!74.\nSmolensky, P. 1990. Tensor product variable binding and the representation of symbolic structures\nin connectionist networks. Artificial Intelligence, 46:159!216.\n\nOptimality Theory\n\nReferences\n\n255\n\nSmolensky, P. In press. Constituent structure and explanation in an integrated\nconnectionist/symbolic cognitive architecture. In The Philosophy of Psychology: Debates on\nPsychological Explanation, ed. C. Macdonald and G. Macdonald. Oxford: Basil Blackwell.\nSmolensky, P., G. Legendre, and Y. Miyata. 1992. Principles for an integrated\nconnectionist/symbolic theory of higher cognition. Technical Report CU-CS-600-92.\nDepartment of Computer Science, University of Colorado at Boulder.\nSpring, Cari. 1990. Implications of Axininca Campa for Prosodic Morphology and Reduplication.\nDoctoral dissertation. University of Arizona. Tucson.\nSt. John, M. and J. L. McClelland. 1990. Learning and applying contextual constraints in sentence\ncomprehension. Artificial Intelligence, 46:217!258.\nStampe, David. 1969. The acquisition of phonetic representation. In Papers from the Fifth Regional\nMeeting of the Chicago Linguistic Society.\nStampe, David. 1973. On chapter nine. In Issues in phonological theory, ed. Michael Kenstowicz\nand Charles Kisseberth, 44-52. The Hague: Mouton.\nStampe, David. 1973/9. A Dissertation in Natural Phonology, Doctoral Dissertation. NY: Garland\nPubl. Co.\nSteriade, Donca. 1982. Greek prosodies and the nature of syllabification. Doctoral Dissertation.\nMIT, Cambridge, MA.\nSteriade, Donca. 1988. Greek accent: a case for preserving structure. Linguistic Inquiry 19, 271-314.\nStevens, Kenneth and S. J. Keyser. 1989. Primary features and their enhancement in consonants.\nLanguage 65, 81-106.\nStevens, Kenneth, S. J. Keyser, and H. Kawasaki. 1986. Toward a phonetic and phonological theory\nof redundant features. In Invariance and variability in speech processes, ed. J. Perkell and\nD. Klatt. Hillsdale, NJ: Erlbaum.\nStolcke, A. 1989. Unification as constraint satisfaction in structured connectionist networks. Neural\nComputation, 1:559!567.\nStump, Gregory. 1989. A note on Breton pluralization and the Elsewhere Condition. Natural\nLanguage & Linguistic Theory 7, 261-273.\nTouretzky, D. S. 1989. Towards a connectionist phonology: The “many maps” approach to sequence\nmanipulation. In Proceedings of the Eleventh Annual Conference of the Cognitive Science\nSociety, 188!195, Ann Arbor, MI: Lawrence Erlbaum.\nTouretzky, D. S., editor. 1991. Special issue: Connectionist approaches to language learning.\nMachine Learning, 7:105!252.\nTouretzky, D. S. and Wheeler, D. W. 1991. Sequence manipulation using parallel mapping\nnetworks. Neural Computation, 3:98!109.\nVennemann, Theo. 1972. On the theory of syllabic phonology. Linguistische Berichte 18, 1-18.\nVisch, Ellis. 1989. A metrical theory of rhythmic stress phenomena. (Een metrische theorie van\nritmische klemtoonverschijnselen). Dordrecht: ICG.\nVoltaire. 1759. Candide, ou l’optimisme. Revised 1761 [for the worse, in our view]. tr. Lowell Bair\nas Candide by Voltaire, 1959. New York: Bantam Books.\nWertheimer, Max. 1923. Laws of organization in perceptual forms. In A source book of Gestalt\npsychology, ed. W. D. Ellis. London: Routledge & Kegan Paul.\n\n256\n\nReferences\n\nPrince & Smolensky\n\nWheeler, Deirdre. 1981. Aspects of a Categorial Theory of Phonology, Doctoral dissertation,\nUniversity of Massachusetts, Amherst.\nWheeler, Deirdre. 1988. Consequences of some categorially motivated phonological assumptions.\nIn Categorial grammars and natural language structures, ed. R. Oehrle, E. Bach, and D.\nWheeler. Dordrecht: Reidel.\nWheeler, D. W. and Touretzky, D. S. 1993. A connectionist implementation of cognitive phonology.\nIn The Last Phonological Rule [sic], ed. John Goldsmith. Chicago, IL: Univ. of Chicago\nPress.\nWilkinson, Karina. 1986. Syllable structure and Lardil phonology. Ms. Univ. of Massachusetts,\nAmherst.\nWilkinson, Karina. 1988. Prosodic structure and Lardil phonology. Linguistic Inquiry 19, 325-334.\nWiltshire, Caroline. 1992. Syllabification and Rule Application in Harmonic Phonology. Doctoral\nDissertation. University of Chicago.\nWoodbury, Anthony. 1981. Study of the Chevak dialect of Central Yupik Eskimo. University of\nCalifornia, Berkeley.\nWurzel, Wolfgang. 1985. On morphological naturalness. Nordic Journal of Linguistics 7, 145-163.\nYip, Moira. 1988. The obligatory contour principle and phonological rules: a loss of identity.\nLinguistic Inquiry 19, 65-100.\nYip, Moira. 1992. Cantonese loan word phonology and optimality. To appear in Journal of East\nAsian Linguistics.\nYip, Moira. 1993. Phonological constraints, optimality, and phonetic realization in Cantonese.\nUPenn Colloquium.\nZec, Draga. 1988. Sonority constraints on syllable structure. Doctoral Dissertation. Stanford\nUniversity: Stanford, CA.\nZec, Draga. in prep. Coda constraints and conditions on syllable weight.\nZoll, Cheryl. 1992a. When syllables collide: a theory of alternating quantity. Ms. Brandeis\nUniversity.\nZoll, Cheryl 1992b. pc. Remarks on the OCP. Internet.\nZoll, Cheryl. 1993. Ghost consonants and optimality. WCCFL, Santa Cruz.\nZonneveld, Wim. 1976. Destressing in Halle’s English stress rules. Linguistic Inquiry 7, 520-525.\n\n","pages":{"startPosition":[0,5001,9997,15000,19997,25000,29994,34987,40001,44999,49996,54999,59997,64990,70001,75000,79998,84993,90000,95000,99998,104997,110000,114992,119990,124987,129989,134998,140001,144996,149999,154999,159995,165000,170001,174999,179992,184999,189999,194998,199997,204997,210001,214994,220001,225000,229999,234993,239998,244996,250001,254997,260001,265000,270000,275001,279999,285000,289996,295000,299995,305001,310001,314996,320001,324996,329998,334996,339999,345000,349999,354997,359991,364996,369987,375000,380000,384999,389995,395000,400000,404997,409999,414998,419997,425000,429999,435000,439989,444996,450000,454998,460000,464997,469999,474998,479998,484996,489996,494988,499999,504995,509987,515001,519994,524998,529993,534995,539992,545001,550000,554997,560001,564998,569997,574998,580000,584997,589991,594992,599994,604992,609988,614997,619999,625000,629994,634999,639997,644994,650001,654996,660000,664998,670000,674998,679992,684998,689995,694996]}},"html":{"comparison":{"identical":{"groupId":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,14,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,16,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,33,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,34,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,36,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,38,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,42,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,44,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,46,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,48,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,50,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,52,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53],"source":{"chars":{"starts":[3677845,3677862,3677870,3677887,3677895,3677912,3677920,3677937,3677945,3677962,3677970,3677987,3677995,3678012,3678020,3678037,3678045,3678062,3678070,3678087,3678095,3678112,3678120,3678137,3678145,3678162,3678170,3678187,3678195,3678212,3678220,3678237,3678245,3678262,3678270,3678287,3678295,3678312,3678320,3678337,3678345,3678362,3678370,3678387,3678395,3678696,3678713,3678721,3678738,3678746,3678763,3678771,3678788,3678796,3678813,3678821,3678838,3678846,3678863,3678871,3678888,3678896,3678913,3678921,3678938,3678946,3678963,3678971,3678988,3678996,3679013,3679021,3679038,3679046,3679063,3679071,3679088,3679096,3679113,3679121,3679138,3679146,3679163,3679171,3683779,3683796,3683804,3683821,3683829,3683846,3683854,3683871,3683879,3683896,3683904,3683921,3683929,3683946,3683954,3683971,3683979,3683996,3684004,3684021,3684029,3684046,3684054,3684071,3684079,3684096,3684104,3684121,3684129,3684146,3684154,3684171,3684179,3684196,3684204,3684221,3684229,3684840,3684857,3684865,3684882,3684890,3684907,3684915,3684932,3684940,3684957,3684965,3684982,3684990,3685007,3685015,3685032,3685040,3685057,3685065,3685082,3685090,3685107,3685115,3685132,3685140,3685157,3685165,3685182,3685190,3685207,3685215,3685232,3685240,3685257,3685265,3685282,3685290,3685307,3685315,3685332,3685340,3685357,3685365,3685382,3685390,3685407,3685415,3685432,3685440,3685457,3685465,3685482,3685490,3685507,3685515,3685532,3685540,3685557,3685565,3686694,3686711,3686719,3686736,3686744,3686761,3686769,3686786,3686794,3686811,3686819,3686836,3686844,3686861,3686869,3686886,3686894,3686911,3686919,3686936,3686944,3686961,3686969,3686986,3686994,3687011,3687019,3687036,3687044,3687061,3687069,3687086,3687094,3687111,3687119,3687136,3687144,3687161,3687169,3687186,3687194,3687211,3687219,3687236,3687244,3687261,3687269,3687286,3687294,3687311,3687319,3687336,3687344,3687944,3687961,3687969,3687986,3687994,3688011,3688019,3688036,3688044,3688061,3688069,3688086,3688094,3688111,3688119,3688136,3688144,3688161,3688169,3688186,3688194,3688211,3688219,3688236,3688244,3688261,3688269,3688286,3688294,3688311,3688319,3688336,3688344,3688361,3688369,3688386,3688394,3688411,3688419,3688436,3688444,3688461,3688469,3688486,3688494,3688511,3688519,3688536,3688544,3688561,3688569,3688586,3688594,3688611,3688619,3688636,3688644,3689874,3689891,3689899,3689916,3689924,3689941,3689949,3689966,3689974,3689991,3689999,3690016,3690024,3690041,3690049,3690066,3690074,3690091,3690099,3690116,3690124,3690141,3690149,3690166,3690174,3690191,3690199,3690216,3690224,3690241,3690249,3690266,3690274,3690291,3690299,3690316,3690324,3690341,3690349,3693697,3693714,3693722,3693739,3693747,3693764,3693772,3693789,3693797,3693814,3693822,3693839,3693847,3693864,3693872,3693889,3693897,3693914,3693922,3693939,3693947,3693964,3693972,3693989,3693997,3694014,3694022,3694039,3694047,3694064,3694072,3694089,3694097,3694114,3694122,3694139,3694147,3694164,3694172,3694189,3694197,3694214,3694222,3694239,3694247,3694264,3694272,3694289,3694297,3694314,3694322,3694339,3694347,3694364,3694372,3694389,3694397,3694414,3694422,3694439,3694447,3695509,3695526,3695534,3695551,3695559,3695576,3695584,3695601,3695609,3695626,3695634,3695651,3695659,3695676,3695684,3695701,3695709,3695726,3695734,3695751,3695759,3695776,3695784,3695801,3695809,3695826,3695834,3695851,3695859,3695876,3695884,3695901,3695909,3695926,3695934,3695951,3695959,3697388,3697405,3697413,3697430,3697438,3697455,3697463,3697480,3697488,3697505,3697513,3697530,3697538,3697555,3697563,3697580,3697588,3697605,3697613,3697630,3697638,3697655,3697663,3697680,3697688,3697705,3697713,3697730,3697738,3697755,3697763,3697780,3697788,3697805,3697813,3697830,3697838,3697855,3697863,3697880,3697888,3697905,3697913,3697930,3697938,3697955,3697963,3697980,3697988,3698005,3698013,3698030,3698038,3698928,3698945,3698953,3698970,3698978,3698995,3699003,3699020,3699028,3699045,3699053,3699070,3699078,3699095,3699103,3699120,3699128,3699145,3699153,3699170,3699178,3699195,3699203,3699220,3699228,3699245,3699253,3699270,3699278,3699295,3699303,3699320,3699328,3699345,3699353,3699370,3699378,3699395,3699403,3712449,3712466,3712474,3712491,3712499,3712516,3712524,3712541,3712549,3712566,3712574,3712591,3712599,3712616,3712624,3712641,3712649,3712666,3712674,3712691,3712699,3712716,3712724,3712741,3712749,3712766,3712774,3712791,3712799,3712816,3712824,3712841,3712849,3712866,3712874,3712891,3712899,3712916,3712924,3712941,3712949,3712966,3712974,3712991,3712999,3713016,3713024,3714469,3714486,3714494,3714511,3714519,3714536,3714544,3714561,3714569,3714586,3714594,3714611,3714619,3714636,3714644,3714661,3714669,3714686,3714694,3714711,3714719,3714736,3714744,3714761,3714769,3714786,3714794,3714811,3714819,3714836,3714844,3714861,3714869,3714886,3714894,3714911,3714919,3714936,3714944,3714961,3714969,3714986,3714994,3715011,3715019,3715036,3715044,3715061,3715069,3715086,3715094,3715111,3715119,3715136,3715144,3715161,3715169,3715186,3715194,3716229,3716246,3716254,3716271,3716279,3716296,3716304,3716321,3716329,3716346,3716354,3716371,3716379,3716396,3716404,3716421,3716429,3716446,3716454,3716471,3716479,3716496,3716504,3716521,3716529,3716546,3716554,3716571,3716579,3716596,3716604,3716621,3716629,3716646,3716654,3716671,3716679,3716696,3716704,3716721,3716729,3716746,3716754,3717086,3717103,3717111,3717128,3717136,3717153,3717161,3717178,3717186,3717203,3717211,3717228,3717236,3717253,3717261,3717278,3717286,3717303,3717311,3717328,3717336,3717353,3717361,3717378,3717386,3717403,3717411,3717428,3717436,3717453,3717461,3717478,3717486,3717503,3717511,3717835,3717852,3717860,3717877,3717885,3717902,3717910,3717927,3717935,3717952,3717960,3717977,3717985,3718002,3718010,3718027,3718035,3718052,3718060,3718077,3718085,3718102,3718110,3718127,3718135,3718152,3718160,3718177,3718185,3718202,3718210,3718227,3718235,3718252,3718260,3718277,3718285,3718302,3718310,3718327,3718335,3718352,3718360,3719062,3719079,3719087,3719104,3719112,3719129,3719137,3719154,3719162,3719179,3719187,3719204,3719212,3719229,3719237,3719254,3719262,3719279,3719287,3719304,3719312,3719329,3719337,3719354,3719362,3719379,3719387,3719404,3719412,3719429,3719437,3719454,3719462,3719479,3719487,3719504,3719512,3719529,3719537,3719554,3719562,3719579,3719587,3719604,3719612,3719629,3719637,3719654,3719662,3719679,3719687,3719704,3719712,3720534,3720551,3720559,3720576,3720584,3720601,3720609,3720626,3720634,3720651,3720659,3720676,3720684,3720701,3720709,3720726,3720734,3720751,3720759,3720776,3720784,3720801,3720809,3720826,3720834,3720851,3720859,3720876,3720884,3720901,3720909,3720926,3720934,3720951,3720959,3720976,3720984,3721001,3721009,3721026,3721034,3721051,3721059,3723212,3723229,3723237,3723254,3723262,3723279,3723287,3723304,3723312,3723329,3723337,3723354,3723362,3723379,3723387,3723404,3723412,3723429,3723437,3723454,3723462,3723479,3723487,3723504,3723512,3723529,3723537,3723554,3723562,3723579,3723587,3723604,3723612,3723629,3723637,3723654,3723662,3723679,3723687,3723704,3723712,3723729,3723737,3723754,3723762,3723779,3723787,3723804,3723812,3723829,3723837,3724098,3724115,3724123,3724140,3724148,3724165,3724173,3724190,3724198,3724215,3724223,3724240,3724248,3724265,3724273,3724290,3724298,3724315,3724323,3724340,3724348,3724365,3724373,3724390,3724398,3724415,3724423,3724440,3724448,3724465,3724473,3724490,3724498,3724515,3724523,3724540,3724548,3724565,3724573,3724590,3724598,3724615,3724623,3724640,3724648,3724665,3724673,3724690,3724698,3724715,3724723,3725667,3725684,3725692,3725709,3725717,3725734,3725742,3725759,3725767,3725784,3725792,3725809,3725817,3725834,3725842,3725859,3725867,3725884,3725892,3725909,3725917,3725934,3725942,3725959,3725967,3725984,3725992,3726009,3726017,3726034,3726042,3726059,3726067,3726084,3726092,3726109,3726117,3726134,3726142,3726159,3726167,3726184,3726192,3726458,3726475,3726483,3726500,3726508,3726525,3726533,3726550,3726558,3726575,3726583,3726600,3726608,3726625,3726633,3726650,3726658,3726675,3726683,3726700,3726708,3726725,3726733,3726750,3726758,3726775,3726783,3726800,3726808,3726825,3726833,3726850,3726858,3726875,3726883,3726900,3726908,3726925,3726933,3726950,3726958,3726975,3726983,3727000,3727008,3727025,3727033,3727050,3727058,3727075,3727083,3727475,3727492,3727500,3727517,3727525,3727542,3727550,3727567,3727575,3727592,3727600,3727617,3727625,3727642,3727650,3727667,3727675,3727692,3727700,3727717,3727725,3727742,3727750,3727767,3727775,3727792,3727800,3727817,3727825,3727842,3727850,3727867,3727875,3727892,3727900,3728165,3728182,3728190,3728207,3728215,3728232,3728240,3728257,3728265,3728282,3728290,3728307,3728315,3728332,3728340,3728357,3728365,3728382,3728390,3728407,3728415,3728432,3728440,3728457,3728465,3728482,3728490,3728507,3728515,3728532,3728540,3728557,3728565,3728582,3728590,3728607,3728615,3728632,3728640,3728657,3728665,3728682,3728690,3728707,3728715,3728732,3728740,3728757,3728765,3729039,3729056,3729064,3729081,3729089,3729106,3729114,3729131,3729139,3729156,3729164,3729181,3729189,3729206,3729214,3729231,3729239,3729256,3729264,3729281,3729289,3729306,3729314,3729331,3729339,3729356,3729364,3729381,3729389,3729406,3729414,3729431,3729439,3729456,3729464,3729481,3729489,3729506,3729514,3729531,3729539,3731122,3731139,3731147,3731164,3731172,3731189,3731197,3731214,3731222,3731239,3731247,3731264,3731272,3731289,3731297,3731314,3731322,3731339,3731347,3731364,3731372,3731389,3731397,3731414,3731422,3731439,3731447,3731464,3731472,3731489,3731497,3731514,3731522,3731539,3731547,3737445,3737462,3737470,3737487,3737495,3737512,3737520,3737537,3737545,3737562,3737570,3737587,3737595,3737612,3737620,3737637,3737645,3737662,3737670,3737687,3737695,3737712,3737720,3737737,3737745,3737762,3737770,3737787,3737795,3737812,3737820,3737837,3737845,3737862,3737870,3752761,3752778,3752786,3752803,3752811,3752828,3752836,3752853,3752861,3752878,3752886,3752903,3752911,3752928,3752936,3752953,3752961,3752978,3752986,3753003,3753011,3753028,3753036,3753053,3753061,3753078,3753086,3753103,3753111,3753128,3753136,3753153,3753161,3753178,3753186,3753203,3753211,3753228,3753236,3753253,3753261,3753278,3753286,3753303,3753311,3753328,3753336,3754407,3754424,3754432,3754449,3754457,3754474,3754482,3754499,3754507,3754524,3754532,3754549,3754557,3754574,3754582,3754599,3754607,3754624,3754632,3754649,3754657,3754674,3754682,3754699,3754707,3754724,3754732,3754749,3754757,3754774,3754782,3754799,3754807,3754824,3754832,3754849,3754857,3754874,3754882,3754899,3754907,3754924,3754932,3754949,3754957,3754974,3754982,3754999,3755007,3755024,3755032,3755049,3755057,3755074,3755082,3755099,3755107,3755124,3755132,3756330,3756347,3756355,3756372,3756380,3756397,3756405,3756422,3756430,3756447,3756455,3756472,3756480,3756497,3756505,3756522,3756530,3756547,3756555,3756572,3756580,3756597,3756605,3756622,3756630,3756647,3756655,3756672,3756680,3756697,3756705,3756722,3756730,3756747,3756755,3756772,3756780,3756797,3756805,3756822,3756830,3756847,3756855,3756872,3756880,3756897,3756905,3756922,3756930,3757227,3757244,3757252,3757269,3757277,3757294,3757302,3757319,3757327,3757344,3757352,3757369,3757377,3757394,3757402,3757419,3757427,3757444,3757452,3757469,3757477,3757494,3757502,3757519,3757527,3757544,3757552,3757569,3757577,3757594,3757602,3757619,3757627,3757644,3757652,3757669,3757677,3757694,3757702,3757719,3757727,3757744,3757752,3758089,3758106,3758114,3758131,3758139,3758156,3758164,3758181,3758189,3758206,3758214,3758231,3758239,3758256,3758264,3758281,3758289,3758306,3758314,3758331,3758339,3758356,3758364,3758381,3758389,3758406,3758414,3758431,3758439,3758456,3758464,3758481,3758489,3758506,3758514,3758778,3758795,3758803,3758820,3758828,3758845,3758853,3758870,3758878,3758895,3758903,3758920,3758928,3758945,3758953,3758970,3758978,3758995,3759003,3759020,3759028,3759045,3759053,3759070,3759078,3759095,3759103,3759120,3759128,3759145,3759153,3759170,3759178,3759195,3759203,3759220,3759228,3759245,3759253,3759270,3759278,3759295,3759303,3759320,3759328,3759345,3759353,3759370,3759378,3760702,3760719,3760727,3760744,3760752,3760769,3760777,3760794,3760802,3760819,3760827,3760844,3760852,3760869,3760877,3760894,3760902,3760919,3760927,3760944,3760952,3760969,3760977,3760994,3761002,3761019,3761027,3761044,3761052,3761069,3761077,3761094,3761102,3761119,3761127,3761144,3761152,3761169,3761177,3761194,3761202,3761219,3761227,3764118,3764135,3764143,3764160,3764168,3764185,3764193,3764210,3764218,3764235,3764243,3764260,3764268,3764285,3764293,3764310,3764318,3764335,3764343,3764360,3764368,3764385,3764393,3764410,3764418,3764435,3764443,3764460,3764468,3764485,3764493,3764510,3764518,3764535,3764543,3764560,3764568,3764585,3764593,3764610,3764618,3764635,3764643,3764660,3764668,3764685,3764693,3764710,3764718,3764735,3764743,3764760,3764768,3764785,3764793,3765836,3765853,3765861,3765878,3765886,3765903,3765911,3765928,3765936,3765953,3765961,3765978,3765986,3766003,3766011,3766028,3766036,3766053,3766061,3766078,3766086,3766103,3766111,3766128,3766136,3766153,3766161,3766178,3766186,3766203,3766211,3766228,3766236,3766253,3766261,3766278,3766286,3766303,3766311,3766328,3766336,3766353,3766361,3766378,3766386,3766403,3766411,3766428,3766436,3766453,3766461,3766478,3766486,3766503,3766511,3766719,3766736,3766744,3766761,3766769,3766786,3766794,3766811,3766819,3766836,3766844,3766861,3766869,3766886,3766894,3766911,3766919,3766936,3766944,3766961,3766969,3766986,3766994,3767011,3767019,3767036,3767044,3767061,3767069,3767086,3767094,3767111,3767119,3767136,3767144,3767161,3767169,3767186,3767194,3767211,3767219,3767236,3767244,3767261,3767269,3767286,3767294,3767311,3767319,3767336,3767344,3767361,3767369,3767386,3767394,3771472,3771489,3771497,3771514,3771522,3771539,3771547,3771564,3771572,3771589,3771597,3771614,3771622,3771639,3771647,3771664,3771672,3771689,3771697,3771714,3771722,3771739,3771747,3771764,3771772,3771789,3771797,3771814,3771822,3771839,3771847,3771864,3771872,3771889,3771897,3771914,3771922,3771939,3771947,3771964,3771972,3772280,3772297,3772305,3772322,3772330,3772347,3772355,3772372,3772380,3772397,3772405,3772422,3772430,3772447,3772455,3772472,3772480,3772497,3772505,3772522,3772530,3772547,3772555,3772572,3772580,3772597,3772605,3772622,3772630,3772647,3772655,3772672,3772680,3772697,3772705,3772722,3772730,3772961,3772978,3772986,3773003,3773011,3773028,3773036,3773053,3773061,3773078,3773086,3773103,3773111,3773128,3773136,3773153,3773161,3773178,3773186,3773203,3773211,3773228,3773236,3773253,3773261,3773278,3773286,3773303,3773311,3773328,3773336,3773353,3773361,3773378,3773386,3773864,3773881,3773889,3773906,3773914,3773931,3773939,3773956,3773964,3773981,3773989,3774006,3774014,3774031,3774039,3774056,3774064,3774081,3774089,3774106,3774114,3774131,3774139,3774156,3774164,3774181,3774189,3774206,3774214,3774231,3774239,3774256,3774264,3774281,3774289,3774306,3774314,3774331,3774339,3774356,3774364,3774381,3774389,3774406,3774414,3774431,3774439,3774456,3774464,3774481,3774489,3774506,3774514,3774531,3774539,3774556,3774564,3774581,3774589,3774852,3774869,3774877,3774894,3774902,3774919,3774927,3774944,3774952,3774969,3774977,3774994,3775002,3775019,3775027,3775044,3775052,3775069,3775077,3775094,3775102,3775119,3775127,3775144,3775152,3775169,3775177,3775194,3775202,3775219,3775227,3775244,3775252,3775269,3775277,3775294,3775302,3775319,3775327,3775344,3775352,3775369,3775377,3775394,3775402,3775419,3775427,3775444,3775452,3779134,3779151,3779159,3779176,3779184,3779201,3779209,3779226,3779234,3779251,3779259,3779276,3779284,3779301,3779309,3779326,3779334,3779351,3779359,3779376,3779384,3779401,3779409,3779426,3779434,3779451,3779459,3779476,3779484,3779501,3779509,3779526,3779534,3779551,3779559,3779576,3779584,3779601,3779609,3779626,3779634,3779651,3779659,3779676,3779684,3779701,3779709,3779726,3779734,3780412,3780429,3780437,3780454,3780462,3780479,3780487,3780504,3780512,3780529,3780537,3780554,3780562,3780579,3780587,3780604,3780612,3780629,3780637,3780654,3780662,3780679,3780687,3780704,3780712,3780729,3780737,3780754,3780762,3780779,3780787,3780804,3780812,3780829,3780837,3780854,3780862,3780879,3780887,3780907,3780915,3780932,3780940,3793795,3793812,3793820,3793837,3793845,3793862,3793870,3793887,3793895,3793912,3793920,3793937,3793945,3793962,3793970,3793987,3793995,3794012,3794020,3794037,3794045,3794062,3794070,3794087,3794095,3794112,3794120,3794137,3794145,3794162,3794170,3794187,3794195,3794212,3794220,3794237,3794245,3794262,3794270,3794287,3794295,3794312,3794320,3794337,3794345,3794362,3794370,3795374,3795391,3795399,3795416,3795424,3795441,3795449,3795466,3795474,3795491,3795499,3795516,3795524,3795541,3795549,3795566,3795574,3795591,3795599,3795616,3795624,3795641,3795649,3795666,3795674,3795691,3795699,3795716,3795724,3795741,3795749,3795766,3795774,3795791,3795799,3795816,3795824,3795841,3795849,3795866,3795874,3795891,3795899,3795916,3795924,3795941,3795949,3796246,3796263,3796271,3796288,3796296,3796313,3796321,3796338,3796346,3796363,3796371,3796388,3796396,3796413,3796421,3796438,3796446,3796463,3796471,3796488,3796496,3796513,3796521,3796538,3796546,3796563,3796571,3796588,3796596,3796613,3796621,3796638,3796646,3796663,3796671,3796688,3796696,3796713,3796721,3796738,3796746,3796763,3796771,3796788,3796796,3796813,3796821,3796838,3796846,3796863,3796871,3796888,3796896,3798974,3798991,3798999,3799016,3799024,3799041,3799049,3799066,3799074,3799091,3799099,3799116,3799124,3799141,3799149,3799166,3799174,3799191,3799199,3799216,3799224,3799241,3799249,3799266,3799274,3799291,3799299,3799316,3799324,3799341,3799349,3799366,3799374,3799391,3799399,3799416,3799424,3799441,3799449,3799466,3799474,3799491,3799499,3799516,3799524,3799541,3799549,3799566,3799574,3799591,3799599,3799616,3799624,3800527,3800544,3800552,3800569,3800577,3800594,3800602,3800619,3800627,3800644,3800652,3800669,3800677,3800694,3800702,3800719,3800727,3800744,3800752,3800769,3800777,3800794,3800802,3800819,3800827,3800844,3800852,3800869,3800877,3800894,3800902,3800919,3800927,3800944,3800952,3800969,3800977,3800994,3801002,3801019,3801027,3801044,3801052,3801069,3801077,3801094,3801102,3801119,3801127,3801144,3801152,3801411,3801428,3801436,3801453,3801461,3801478,3801486,3801503,3801511,3801528,3801536,3801553,3801561,3801578,3801586,3801603,3801611,3801628,3801636,3801653,3801661,3801678,3801686,3801703,3801711,3801728,3801736,3801753,3801761,3801778,3801786,3801803,3801811,3801828,3801836,3801853,3801861,3801878,3801886,3801903,3801911,3801928,3801936,3801953,3801961,3802163,3802180,3802188,3802205,3802213,3802230,3802238,3802255,3802263,3802280,3802288,3802305,3802313,3802330,3802338,3802355,3802363,3802380,3802388,3802405,3802413,3802430,3802438,3802455,3802463,3802480,3802488,3802505,3802513,3802530,3802538,3802555,3802563,3802580,3802588,3802605,3802613,3802630,3802638,3802655,3802663,3802680,3802688,3802705,3802713,3802730,3802738,3802755,3802763,3802780,3802788,3802805,3802813,3803227,3803244,3803252,3803269,3803277,3803294,3803302,3803319,3803327,3803344,3803352,3803369,3803377,3803394,3803402,3803419,3803427,3803444,3803452,3803469,3803477,3803494,3803502,3803519,3803527,3803544,3803552,3803569,3803577,3803594,3803602,3803619,3803627,3803644,3803652,3803669,3803677,3803694,3803702,3803719,3803727,3803744,3803752,3803769,3803777,3912114,3912141,3912149,3912166,3912174,3912191,3912199,3912216,3912224,3912241,3912249,3912266,3912274,3912291,3912299,3912316,3912324,3912341,3912349,3912366,3912374,3912391,3912399,3912416,3912424,3912441,3912449,3912466,3912474,3912491,3912499,3912516,3912524,3912541,3912549,3912566,3912574,3912591,3912599,3912616,3912624,3912641,3912649,3912666,3912674,3912691,3912699,3912716,3912724,3912741,3912749,3912766,3912774,3985283,3985312,3985320,3985337,3985345,3985362,3985370,3985387,3985395,3985412,3985420,3985437,3985445,3985462,3985470,3985487,3985495,3985512,3985520,3985537,3985545,3985562,3985570,3985587,3985595,3985612,3985620,3985637,3985645,3985662,3985670,3985687,3985695,3985712,3985720,3985737,3985745,3985762,3985770,3985787,3985795,3985812,3985820,3985837,3985845,3985862,3985870,3985887,3985895,3985912,3985920,3985937,3985945,3985962,3985970,3985987,3985995,3986012,3986020,3986037,3986045,3986062,3986070,3986087,3986095],"lengths":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,7,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,9,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]},"words":{"starts":[5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5805,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5835,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,5999,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6032,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6096,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6135,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6198,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6311,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6374,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6436,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6489,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6558,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6623,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6684,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6714,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6740,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6779,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6829,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6914,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,6946,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7000,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7028,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7064,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7088,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7119,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7188,7399,7399,7399,7399,7399,7399,7399,7399,7399,7399,7399,7399,7399,7399,7399,7399,7399,7399,7399,7399,7399,7399,7399,7399,7399,7399,7399,7399,7399,7399,7399,7399,7399,7399,7399,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7524,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7582,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7652,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7684,7714,7714,7714,7714,7714,7714,7714,7714,7714,7714,7714,7714,7714,7714,7714,7714,7714,7714,7714,7714,7714,7714,7714,7714,7714,7714,7714,7714,7714,7714,7714,7714,7714,7714,7714,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7738,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7799,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7908,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,7970,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8002,8155,8155,8155,8155,8155,8155,8155,8155,8155,8155,8155,8155,8155,8155,8155,8155,8155,8155,8155,8155,8155,8155,8155,8155,8155,8155,8155,8155,8155,8155,8155,8155,8155,8155,8155,8155,8155,8155,8155,8155,8155,8183,8183,8183,8183,8183,8183,8183,8183,8183,8183,8183,8183,8183,8183,8183,8183,8183,8183,8183,8183,8183,8183,8183,8183,8183,8183,8183,8183,8183,8183,8183,8183,8183,8183,8183,8183,8183,8207,8207,8207,8207,8207,8207,8207,8207,8207,8207,8207,8207,8207,8207,8207,8207,8207,8207,8207,8207,8207,8207,8207,8207,8207,8207,8207,8207,8207,8207,8207,8207,8207,8207,8207,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8240,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8276,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8416,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8453,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8480,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8532,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8563,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8654,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8709,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8741,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8768,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,8803,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,11106,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658,12658],"lengths":[22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32]}},"suspected":{"chars":{"starts":[4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4041,4095,4095,4095,4095,4095,4095,4095,4095,4095,4095,4095,4095,4095,4095,4095,4095,4095,4095,4095,4095,4095,4095,4095,4095,4095,4095,4095,4095,4095,4095,4095,4095,4095,4095,4095,4095,4095,4095,4095,4223,4223,4223,4223,4223,4223,4223,4223,4223,4223,4223,4223,4223,4223,4223,4223,4223,4223,4223,4223,4223,4223,4223,4223,4223,4223,4223,4223,4223,4223,4223,4223,4223,4223,4223,4223,4223,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4328,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4516,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4693,4939,4939,4939,4939,4939,4939,4939,4939,4939,4939,4939,4939,4939,4939,4939,4939,4939,4939,4939,4939,4939,4939,4939,4939,4939,4939,4939,4939,4939,4939,4939,4939,4939,4939,4939,4939,4939,4939,4939,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5108,5239,5239,5239,5239,5239,5239,5239,5239,5239,5239,5239,5239,5239,5239,5239,5239,5239,5239,5239,5239,5239,5239,5239,5239,5239,5239,5239,5239,5239,5239,5239,5239,5239,5239,5239,5239,5239,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5685,5932,5932,5932,5932,5932,5932,5932,5932,5932,5932,5932,5932,5932,5932,5932,5932,5932,5932,5932,5932,5932,5932,5932,5932,5932,5932,5932,5932,5932,5932,5932,5932,5932,5932,5932,5932,5932,5932,5932,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,5986,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6093,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,6396,7269,7269,7269,7269,7269,7269,7269,7269,7269,7269,7269,7269,7269,7269,7269,7269,7269,7269,7269,7269,7269,7269,7269,7269,7269,7269,7269,7269,7269,7269,7269,7269,7269,7269,7269,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7789,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,7992,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8303,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8479,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8781,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8922,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,8990,9044,9044,9044,9044,9044,9044,9044,9044,9044,9044,9044,9044,9044,9044,9044,9044,9044,9044,9044,9044,9044,9044,9044,9044,9044,9044,9044,9044,9044,9044,9044,9044,9044,9044,9044,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9228,9345,9345,9345,9345,9345,9345,9345,9345,9345,9345,9345,9345,9345,9345,9345,9345,9345,9345,9345,9345,9345,9345,9345,9345,9345,9345,9345,9345,9345,9345,9345,9345,9345,9345,9345,9345,9345,9345,9345,9345,9345,9608,9608,9608,9608,9608,9608,9608,9608,9608,9608,9608,9608,9608,9608,9608,9608,9608,9608,9608,9608,9608,9608,9608,9608,9608,9608,9608,9608,9608,9608,9608,9608,9608,9608,9608,9732,9732,9732,9732,9732,9732,9732,9732,9732,9732,9732,9732,9732,9732,9732,9732,9732,9732,9732,9732,9732,9732,9732,9732,9732,9732,9732,9732,9732,9732,9732,9732,9732,9732,9732,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9786,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,9854,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10293,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10543,10610,10610,10610,10610,10610,10610,10610,10610,10610,10610,10610,10610,10610,10610,10610,10610,10610,10610,10610,10610,10610,10610,10610,10610,10610,10610,10610,10610,10610,10610,10610,10610,10610,10610,10610,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10664,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10828,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,10916,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11501,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,11749,12276,12276,12276,12276,12276,12276,12276,12276,12276,12276,12276,12276,12276,12276,12276,12276,12276,12276,12276,12276,12276,12276,12276,12276,12276,12276,12276,12276,12276,12276,12276,12276,12276,12276,12276,12276,12276,12276,12276,12276,12276,12988,12988,12988,12988,12988,12988,12988,12988,12988,12988,12988,12988,12988,12988,12988,12988,12988,12988,12988,12988,12988,12988,12988,12988,12988,12988,12988,12988,12988,12988,12988,12988,12988,12988,12988,12988,12988,13392,13392,13392,13392,13392,13392,13392,13392,13392,13392,13392,13392,13392,13392,13392,13392,13392,13392,13392,13392,13392,13392,13392,13392,13392,13392,13392,13392,13392,13392,13392,13392,13392,13392,13392,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13468,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13843,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,13994,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14109,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,14354,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15417,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15731,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,15785,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16043,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16142,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16261,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,16315,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,15500,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493,5493],"lengths":[45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,57,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,61,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,39,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,55,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,41,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,37,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,35,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,49,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,43,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,47,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,51,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,53,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,45,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,59,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73,73]},"words":{"starts":[572,572,572,572,572,572,572,572,572,572,572,572,572,572,572,572,572,572,572,572,572,572,572,572,572,572,572,572,572,572,572,572,572,572,572,572,572,572,572,572,572,572,572,572,572,599,599,599,599,599,599,599,599,599,599,599,599,599,599,599,599,599,599,599,599,599,599,599,599,599,599,599,599,599,599,599,599,599,599,599,599,599,599,599,653,653,653,653,653,653,653,653,653,653,653,653,653,653,653,653,653,653,653,653,653,653,653,653,653,653,653,653,653,653,653,653,653,653,653,653,653,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,700,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,781,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,847,931,931,931,931,931,931,931,931,931,931,931,931,931,931,931,931,931,931,931,931,931,931,931,931,931,931,931,931,931,931,931,931,931,931,931,931,931,931,931,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1007,1061,1061,1061,1061,1061,1061,1061,1061,1061,1061,1061,1061,1061,1061,1061,1061,1061,1061,1061,1061,1061,1061,1061,1061,1061,1061,1061,1061,1061,1061,1061,1061,1061,1061,1061,1061,1061,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1210,1278,1278,1278,1278,1278,1278,1278,1278,1278,1278,1278,1278,1278,1278,1278,1278,1278,1278,1278,1278,1278,1278,1278,1278,1278,1278,1278,1278,1278,1278,1278,1278,1278,1278,1278,1278,1278,1278,1278,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1305,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1337,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1426,1714,1714,1714,1714,1714,1714,1714,1714,1714,1714,1714,1714,1714,1714,1714,1714,1714,1714,1714,1714,1714,1714,1714,1714,1714,1714,1714,1714,1714,1714,1714,1714,1714,1714,1714,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1891,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,1965,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2068,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2139,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2264,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2321,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2348,2375,2375,2375,2375,2375,2375,2375,2375,2375,2375,2375,2375,2375,2375,2375,2375,2375,2375,2375,2375,2375,2375,2375,2375,2375,2375,2375,2375,2375,2375,2375,2375,2375,2375,2375,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2450,2503,2503,2503,2503,2503,2503,2503,2503,2503,2503,2503,2503,2503,2503,2503,2503,2503,2503,2503,2503,2503,2503,2503,2503,2503,2503,2503,2503,2503,2503,2503,2503,2503,2503,2503,2503,2503,2503,2503,2503,2503,2603,2603,2603,2603,2603,2603,2603,2603,2603,2603,2603,2603,2603,2603,2603,2603,2603,2603,2603,2603,2603,2603,2603,2603,2603,2603,2603,2603,2603,2603,2603,2603,2603,2603,2603,2657,2657,2657,2657,2657,2657,2657,2657,2657,2657,2657,2657,2657,2657,2657,2657,2657,2657,2657,2657,2657,2657,2657,2657,2657,2657,2657,2657,2657,2657,2657,2657,2657,2657,2657,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2684,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2712,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,2900,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3004,3031,3031,3031,3031,3031,3031,3031,3031,3031,3031,3031,3031,3031,3031,3031,3031,3031,3031,3031,3031,3031,3031,3031,3031,3031,3031,3031,3031,3031,3031,3031,3031,3031,3031,3031,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3058,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3104,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3137,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3333,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3428,3589,3589,3589,3589,3589,3589,3589,3589,3589,3589,3589,3589,3589,3589,3589,3589,3589,3589,3589,3589,3589,3589,3589,3589,3589,3589,3589,3589,3589,3589,3589,3589,3589,3589,3589,3589,3589,3589,3589,3589,3589,3823,3823,3823,3823,3823,3823,3823,3823,3823,3823,3823,3823,3823,3823,3823,3823,3823,3823,3823,3823,3823,3823,3823,3823,3823,3823,3823,3823,3823,3823,3823,3823,3823,3823,3823,3823,3823,3971,3971,3971,3971,3971,3971,3971,3971,3971,3971,3971,3971,3971,3971,3971,3971,3971,3971,3971,3971,3971,3971,3971,3971,3971,3971,3971,3971,3971,3971,3971,3971,3971,3971,3971,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,3998,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4151,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4207,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4252,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4354,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4685,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4804,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4831,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4927,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,4959,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5013,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,5040,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,4722,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143,1143],"lengths":[22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,28,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,30,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,20,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,18,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,17,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,29,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,24,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,22,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,26,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32,32]}}},"minorChanges":{"groupId":[],"source":{"chars":{"starts":[],"lengths":[]},"words":{"starts":[],"lengths":[]}},"suspected":{"chars":{"starts":[],"lengths":[]},"words":{"starts":[],"lengths":[]}}},"relatedMeaning":{"groupId":[],"source":{"chars":{"starts":[],"lengths":[]},"words":{"starts":[],"lengths":[]}},"suspected":{"chars":{"starts":[],"lengths":[]},"words":{"starts":[],"lengths":[]}}}}},"version":3}