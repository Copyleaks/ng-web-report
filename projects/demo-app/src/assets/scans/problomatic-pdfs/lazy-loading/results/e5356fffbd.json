{"statistics":{"identical":127,"minorChanges":0,"relatedMeaning":0},"text":{"comparison":{"identical":{"source":{"chars":{"starts":[50479,51396,56292,62855,74166,74370,77595,78977,79493,80105],"lengths":[19,27,25,23,21,23,23,31,21,31]},"words":{"starts":[8314,8511,9545,11035,13660,13735,14573,14914,15073,15144],"lengths":[9,13,12,11,10,11,11,15,10,15]}},"suspected":{"chars":{"starts":[380,261,530,857,1057,1081,1166,1228,1304,1366],"lengths":[19,27,25,23,21,23,23,31,21,31]},"words":{"starts":[86,40,123,232,301,313,345,363,388,412],"lengths":[9,13,12,11,10,11,11,15,10,15]}}},"minorChanges":{"source":{"chars":{"starts":[],"lengths":[]},"words":{"starts":[],"lengths":[]}},"suspected":{"chars":{"starts":[],"lengths":[]},"words":{"starts":[],"lengths":[]}}},"relatedMeaning":{"source":{"chars":{"starts":[],"lengths":[]},"words":{"starts":[],"lengths":[]}},"suspected":{"chars":{"starts":[],"lengths":[]},"words":{"starts":[],"lengths":[]}}}},"value":"CHAPTER 22\n\nOverview of Multiscale\nSimulations of Materials\nGang Lu, Efthimios Kaxiras\nDepartment of Physics and Division of Engineering and Applied Science,\nHarvard University, Cambridge, Massachusetts, USA\nCONTENTS\n1.\n2.\n\n3.\n\n4.\n\n5.\n\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1\nSequential Multiscale Approaches . . . . . . . . . . . . . . . . . . . . . 4\n2.1. Peierls–Nabarro Model of Dislocations . . . . . . . . . . . . . 5\n2.2. Phase-Field Model of Coherent Phase\nTransformations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\n2.3. Other Sequential Approaches . . . . . . . . . . . . . . . . . . . 10\nConcurrent Multiscale Approaches . . . . . . . . . . . . . . . . . . . . 12\n3.1. Macroscopic Atomistic Ab Initio Dynamics . . . . . . . . . 12\n3.2. Quasicontinuum Model . . . . . . . . . . . . . . . . . . . . . . . 15\n3.3. Coarse-grained Molecular Dynamics . . . . . . . . . . . . . . 18\n3.4. Other Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\nExtending Timescales . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n4.1. Accelerated Dynamics . . . . . . . . . . . . . . . . . . . . . . . . 21\n4.2. Finding Transition Pathways . . . . . . . . . . . . . . . . . . . . 23\n4.3. Escaping Free-Energy Minima . . . . . . . . . . . . . . . . . . 26\n4.4. Other Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\nConclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\nReferences . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\n\n1. INTRODUCTION\nSome of the most fascinating problems in all fields of science involve multiple spatial or\ntemporal scales: Processes that occur at a certain scale govern the behavior of the system\nacross several (usually larger) scales. The notion and practice of multiscale modeling can be\ntraced back to the beginning of modern science (see, e.g., the discussion in [1]). In many\nproblems of materials science, this notion arises quite naturally: The ultimate microscopic\nconstituents of materials are atoms, and the interactions among them at the microscopic\nlevel (on the order of nanometers and femtoseconds) determine the behavior of the material\nISBN: 1-58883-042-X/$35.00\nCopyright © 2005 by American Scientific Publishers\nAll rights of reproduction in any form reserved.\n\nHandbook of Theoretical and Computational Nanotechnology\nEdited by Michael Rieth and Wolfram Schommers\nVolume X: Pages (1–33)\n\n1\n\n2\n\nOverview of Multiscale Simulations of Materials\n\nat the macroscopic scale (on the order on centimeters and milliseconds and beyond), with\nthe latter being the scale of interest for technological applications. The idea of performing\nsimulations of materials across several characteristic length and timescales has, therefore,\nobvious appeal as a tool of potentially great effect on technological innovation [2–4]. The\nadvent of ever-more-powerful computers that can handle such simulations provides further\nargument that such an approach can address realistic situations and can be a worthy partner\nto the traditional approaches of theory and experiment.\nIn the context of materials simulations, one can distinguish four characteristic length levels:\n1. The atomic scale (∼10−9 /m or a few nanometers), in which the electrons are the players,\nand their quantum-mechanical state dictates the interactions among the atoms.\n2. The microscopic scale (∼10−6 /m or a few micrometers), where atoms are the players\nand their interactions can be described by classical interatomic potentials (CIP) that\nencapsulate the effects of bonding between them, which is mediated by electrons.\n3. The mesoscopic scale (∼10−4 /m or hundreds of micrometers), where lattice defects such\nas dislocations, grain boundaries, and other microstructural elements are the players.\nTheir interactions are usually derived from phenomenological theories that encompass\nthe effects of interactions between the atoms.\n4. The macroscopic scale (∼10−2 /m or centimeters and beyond), where a constitutive law\ngoverns the behavior of the physical system, which is viewed as a continuous medium.\nIn the macroscale, continuum fields such as density, velocity, temperature, displacement\nand stress fields, and so forth are the players. The constitutive laws are usually formulated so that they can capture the effects on materials properties from lattice defects\nand microstructural elements. Phenomena at each length scale typically have a corresponding timescale that, in correspondence to the four length scales mentioned above,\nranges roughly from femtoseconds to picoseconds, to nanoseconds, to milliseconds and\nbeyond.\nAt each length and timescale, well-established and efficient computational approaches\nhave been developed over the years to handle the relevant phenomena. To treat electrons\nexplicitly and accurately at the atomic scale, methods known as quantum Monte Carlo\n(QMC) [5] and quantum chemistry (QC) [6] can be employed, which are computationally too\ndemanding to handle more than a few tens of electrons. Methods based on density-functional\ntheory (DFT) and local density approximation (LDA) [7, 8] in its various implementations,\nalthough less accurate than QMC or QC methods, can be readily applied to systems containing several hundred atoms for static properties. Dynamical simulations with DFT methods\nare usually limited to timescales of a few picoseconds. For materials properties that can be\nmodeled reasonably well with a small number of atoms (such as bulk crystal properties or\npoint defects), the DFT approach can provide sufficiently accurate results. Recent progress\nin linear scaling electronic structure methods [9] has enabled DFT-based calculations to deal\nwith a few thousand atoms (corresponding to sizes of a couple of nanometers on a side) with\nadequate accuracy. Finally, the semiclassical tight-binding approximation (TBA), although\ntypically not as accurate as DFT methods, can extend the reach of simulations to a few\nnanometers in linear size and a few nanoseconds in timescale for the dynamics [10].\nFor material properties at the microscopic scale, molecular dynamics (MD) and Monte\nCarlo (MC) simulations are usually performed employing CIP, which can often be derived\nfrom DFT calculations [11, 12]. Although not as accurate as the DFT and TBA methods, the\nclassical simulations are able to provide insight into atomic processes involving considerably\nlarger systems, reaching up to ∼109 atoms [13]. The timescale that MD simulations based\non CIP can reach is up to a microsecond.\nAt the mesoscopic scale, the atomic degrees of freedom are not explicitly treated, and only\nlarger-scale entities are modeled. For example, in what concerns the mechanical behavior of\nsolids, dislocations are the objects of interest. In treating dislocations, recent progress has\nbeen concentrated on the so-called dislocation dynamics (DD) approach [14–17], which has\ncome to be regarded as one of the most important developments in computational materials\nscience and engineering in the last two decades [18]. Such DD models deal with the kinetics\n\n3\n\nOverview of Multiscale Simulations of Materials\n\nof dislocations and can study systems a few tens of microns in size and with a maximum\nstrain ∼0\u00015% for a strain rate of 10 sec−1 in bcc metals [19].\nFinally, for the macroscopic scale, finite-element (FE) methods [20] are routinely used to\nexamine the large-scale properties of materials considered an elastic continuum [21]. For\nexample, FE methods have been brought to bear on problems of strain-gradient plasticity,\nsuch as geometrically necessary dislocations [22]. Continuum Navier–Stoke equations are\nalso often used to study fluids.\nThe challenge in modern simulations of materials science and engineering is that real\nmaterials usually exhibit phenomena on one scale that require a very accurate and computationally expensive description, and phenomena on another scale for which a coarser\ndescription is satisfactory and, in fact, necessary to avoid prohibitively large computations.\nBecause none of the methods above alone would suffice to describe the entire system, the\ngoal becomes to develop models that combine different methods specialized at different\nscales, effectively distributing the computational power where it is needed most. It is the\nhope that a multiscale approach is the answer to such a quest, and it is by definition an\napproach that takes advantage of the multiple scales present in a material and builds a\nunified description by linking the models at the different scales. Figure 1 illustrates the\nconcept of a unified multiscale approach that can reach the length and timescale that individual methods, developed to treat a particular scale accurately, fail to achieve. At the same\ntime, the unified approach can retain the accuracy that the individual approaches provide in\ntheir respective scales, allowing, for instance, for very high accuracy in particular regions of\nthe systems as required. As effective theories, multiscale models are also useful for gaining\nphysical insight that might not be apparent from brute force computations. Specifically, a\nmultiscale model can be an effective way to facilitate the reduction and analysis of data,\nwhich sometimes can be overwhelming. Overall, the goal of multiscale approaches is to predict the performance and behavior of materials across all relevant length and timescales,\nstriving to achieve a balance among accuracy, efficiency, and realistic description.\nConceptually, two categories of multiscale simulations can be envisioned, both sequential\nand concurrent. The sequential methodology attempts to piece together a hierarchy of computational approaches in which large-scale models use the coarse-grained representations\nwith information obtained from more detailed, smaller-scale models. This sequential modeling approach has proven effective in systems in which the different scales are weakly coupled.\nThe characteristic of the systems that are suited for a sequential approach is that the largescale variations decouple from the small-scale physics, or the large-scale variations appear\nAccuracy\n\nQMC\n\nDFT\nMultiscale\nTBA\n–15\n–8\n–7\n–6\n–5\n\n–12\n\n–9\nCIP\n\n–6\n\n–3\nT/sec\n\n–3\nL /cm\nFigure 1. A schematic illustration of spacial and temporal scales achievable by various simulation approaches. The\nscales are in centimeters for the length dimension and seconds for the time dimension, both logarithmic. QMC,\nquantum Monte Carlo; DFT, density-functional theory; TBA, tight-binding approximation; CIP, classic interatomic\npotentials.\n\n4\n\nOverview of Multiscale Simulations of Materials\n\nhomogeneous and quasi-static from the small-scale point of view. Sequential approaches\nhave also been referred to as serial, implicit, or message-passing methods. The vast majority\nof multiscale simulations that are actually in use is sequential. Examples of such approaches\nabound in literature, including almost all MD simulations whose underlying potentials are\nderived from electronic structure theory [23, 24], usually ab initio calculations [11, 12]. One\nfrequently mentioned [25, 26] example of sequential multiscale simulations is the work of\nClementi et al. [27], who used QC calculations to evaluate the interaction of several water\nmolecules; from this database, an empirical potential was parameterized for use in MD simulations; the MD simulations were then used to evaluate the viscosity of water from atomic\nautocorrelation functions; and finally, the computed viscosity was employed in computational\nfluid dynamics calculations to predict the tidal circulation in Buzzard’s Bay of Massachusetts.\nThe second category of multiscale simulations consists of the so-called concurrent, parallel, or explicit approaches. These approaches attempt to link methods appropriate at each\nscale together in a combined model, where the different scales of the system are considered\nconcurrently and communicate with some type of hand-shaking procedure. This approach\nis necessary for systems that are inherently multiscale; that is, systems whose behavior at\neach scale depends strongly on what happens at the other scales. In contrast to sequential approaches, the concurrent simulations are still relatively new, and only a few models\nhave been developed to date. In a concurrent simulation, the system is often partitioned\ninto domains characterized by different scales and physics. The challenge of the concurrent\napproach lies at the coupling between the different regions treated by different methods; a\nsuccessful multiscale model seeks a smooth coupling between these regions.\nIn principle, multiscale simulations could be based on a hybrid scheme, using elements\nfrom both the sequential and the concurrent approaches. We will not examine this type of\napproach in any detail, as it involves no new concepts other than the successful combination\nof elements underlying the other two types of approaches.\nThere already exist a few review papers and special editions of articles on multiscale simulation of materials in the literature [2, 3, 28–32]. A mathematic perspective of multiscale\nmodeling and computation is also available [33]. The present overview does not aim to\nprovide another collection of various multiscale techniques but, rather, to identify the characteristic features and classify multiscale simulation approaches into rational categories in\nrelation to the problems where they apply. We select a few illustrative examples for each category and try to establish connections between these approaches whenever possible. Because\nalmost all interesting material behavior and processes are time dependent, we will address\nboth the issue of length scales and the issue of timescales integration in materials modeling.\nThe examples presented in this overview to some extent reflect our own research interests,\nand they are by no means exhaustive. Nevertheless, we hope that they give a satisfactory\ncross section of the current state of the field and that they can serve as inspiration for further\ndevelopments in this exciting endeavor.\n\n2. SEQUENTIAL MULTISCALE APPROACHES\nTwo ingredients are required to construct a successful sequential multiscale model: first, it\nis necessary to have a priori and complete knowledge of the fundamental processes at the\nlowest scale involved. This knowledge or information can then be used for modeling the\nsystem at successively coarser scales. Second it is necessary to have a reliable strategy for\nencompassing the lower-scale information into the coarser scales. This is often accomplished\nby phenomenological theories, which contain a few key parameters (these can be functions),\nthe value of which is determined from the information at the lower scale. This messagepassing approach can be performed in sequence for multiple-length scales, as in the example\ncited in the introduction [27]. The key attribute of the sequential approach is that the simulation at a higher level critically depends on the completeness and the correctness of the\ninformation gathered at the lower level, as well as the efficiency and reliability of the model\nat the coarser level.\nTo illustrate this type of approach, we will present two examples of sequential multiscale\napproaches in some detail. The first example concerns the modeling of dislocation properties\n\n5\n\nOverview of Multiscale Simulations of Materials\n\nin the context of the Peierls–Nabarro (P-N) phenomenological model, where the lower scale\ninformation is in the form of the so-called generalized stacking fault energy surface (also\nreferred to as the \u0002-surface) and the coarse-grained model is a phenomenological continuum\ndescription. The second example concerns the modeling of coherent phase transformations\nin the context of the phase-field approach, where the lower scale knowledge is in the form\nof ab initio free energies and the coarse-grained model is again a continuum model.\n\n2.1. Peierls–Nabarro Model of Dislocations\nDislocations are central to our understanding of mechanical properties of crystalline solids.\nIn particular, the creation and motion of dislocations mediate the plastic response of a\ncrystal to external stress. Although continuum elasticity theory describes well the long-range\nelastic strain of a dislocation for length scales beyond a few lattice spacings, it breaks down\nin the immediate vicinity of the dislocation core. There has been a great deal of interest\nin accurately describing the dislocation core structure on an atomic scale because the core\nstructure to a large extent dictates the dislocation properties [34, 35]. So far, direct atomistic\nsimulation of dislocation properties based on CIP has not been satisfactory because the CIP\nis not always reliable, or may even not be available for the material of interest, especially\nwhen the physical system involves several types of atoms. However, ab initio calculations are\nstill computationally expensive for the study of dislocation core properties, particularly for\nthat of dislocation mobility. Recently, a promising approach based on the framework of the\nP-N model has attracted considerable interest in the study of dislocation core structure and\nmobility [36–47]. This approach, when combined with ab initio calculations for the energetics,\nrepresents a plausible alternative to the direct ab initio simulations of dislocation properties.\nThe P-N model is an inherently multiscale framework, first proposed by Peierls [48] and\nNabarro [49] to incorporate the details of a discrete dislocation core into a framework that is\nessentially a continuum. Consider a solid with an edge dislocation in the middle (Fig. 2): the\nsolid containing this dislocation is represented by two elastic half-spaces joined by atomiclevel forces across their common interface, known as the glide plane (dashed line). The goal\nof the P-N model is to determine the slip distribution on the glide plane, which minimizes the\ntotal energy. The dislocation is characterized by the slip (relative displacement) distribution\nf \u0003x\u0005 = u\u0003x\u0006 0+ \u0005 − u\u0003x\u0006 0− \u0005\n\n(1)\n\nwhich is a measure of the misfit across the glide plane; u\u0003x\u0006 0+ \u0005 and u\u0003x\u0006 0− \u0005 are the displacement of the half-spaces at position x immediately above and below the glide plane.\nY\n\nLinear elastic\nhalfspaces\n\nNonlinear\ninterplanar\npotential\n\nX\n\nFigure 2. A schematic illustration showing an edge dislocation in a lattice. The partition of the dislocated lattice\ninto a linear elastic region and a nonlinear atomistic region allows a multiscale treatment of the problem.\n\n6\n\nOverview of Multiscale Simulations of Materials\n\nThe total energy of the dislocated solid includes two contributions: the nonlinear potential\nenergy resulting from the atomistic interaction across the glide plane, and the elastic energy\nstored in the two half-spaces associated with the presence of the dislocation. Both energies\nare functionals of the slip distribution f \u0003x\u0005. Specifically, the nonlinear misfit energy can be\nwritten as\n\u0001\u0005\nUmisfit =\n\u0002\bf \u0003x\u0005 dx\n(2)\n−\u0005\n\nwhere \u0002\u0003f \u0005 is the generalized stacking fault energy surface (the \u0002-surface) introduced by\nVitek [50]. The nonlinear interplanar \u0002-surface can, in general, be determined from atomistic\ncalculations. For systems in which CIP are not available or not reliable (e.g., it is exceedingly\ndifficult to derive reliable potentials for multicomponent alloys), ab initio calculations can\nbe performed to obtain the \u0002-surface. However, the elastic energy of the dislocation can\nbe calculated reasonably from elasticity theory: The dislocation may be thought of as a\ncontinuous distribution of infinitesimal dislocations whose Burgers vectors integrate to that\nof the original dislocation [51]. Therefore, the elastic energy of the original dislocation is\njust the sum of the elastic energy caused by all the infinitesimal dislocations (from the\nsuperposition principle of linear elasticity theory), which can be written as\nUelastic =\n\n\u0001\n2 \u00031 − \u0005\n\ndx\n\n\u0001\n\ndx\u0006 ln\n\nL df \u0003x\u0005 df \u0003x\u0006 \u0005\n\u0007x − x\u0006 \u0007 dx\ndx\u0006\n\n(3)\n\nwhere\nand are the shear modulus and Poisson’s ratio, respectively. The variable L is\nan inconsequential constant introduced as a large-distance cutoff for the computation of\nthe logarithmic interaction energy [52]. Note that the Burgers vector of each infinitesimal\ndislocation is the local gradient in the slip distribution df \u0003x\u0005/dx. The gradient of f \u0003x\u0005 is\ncalled dislocation (misfit) density, denoted by \u0010\u0003x\u0005. Because the P-N model requires that\natomistic information (embodied in the \u0002-surface) be incorporated into a coarse-grained\ncontinuum framework, it is a sequential multiscale strategy. Thus, the successful application\nof the method depends on the reliability of both \u0002-surface and the underlying elasticity\ntheory, which is the basis for the formulation of the phenomenological theory.\nIn the current formulation, the total energy is a function of misfit distribution f \u0003x\u0005 or,\nequivalently, \u0010\u0003x\u0005, and it is invariant with respect to arbitrary translation of \u0010\u0003x\u0005 and f \u0003x\u0005.\nTo regain the lattice discreteness, the integration of the \u0002-energy in Eq. (2) was discretized\nand replaced by a lattice sum in the original P-N formulation\nUmisfit =\n\n\u0005\n\u0002\ni=−\u0005\n\n\u0002\u0003fi \u0005\u0012x\n\n(4)\n\nwith xi the reference position and \u0012x the average spacing of the atomic rows in the lattice.\nThis procedure, however, is inconsistent with evaluation of elastic energy [Eq. (3)] as a continuous integral. Therefore, the total energy is not variational. Furthermore, in the original\nP-N model, the shape of the solution f \u0003x\u0005 is assumed to be invariant during dislocation\ntranslation, a problem that is also associated with the nonvariational formulation of the total\nenergy.\nTo resolve these problems, a so-called semidiscrete variational P-N (SVPN) model was\nrecently developed [43] that allows for the first time the study of narrow dislocations, a\nsituation that the standard P-N model can not handle. Within this approach, the equilibrium\nstructure of a dislocation is obtained by minimizing the dislocation energy functional\nUdisl = Uelastic + Umisfit + Ustress + Kb 2 lnL\nwhere\nUelastic =\n\n\u00021\ni\u0006 j\n\n2\n\n\u0003 \u0004 \u00031\u0005 \u00031\u0005\n\u00032\u0005 \u00032\u0005 \u0005\n\u00033\u0005 \u00033\u0005 \u0006\n\u0018ij Ke \u0010i \u0010j + \u0010i \u0010j + Ks \u0010i \u0010j\n\n(5)\n\n(6)\n\n7\n\nOverview of Multiscale Simulations of Materials\n\nUmisfit =\nUstress = −\n\n\u0002\n\n\u0012x\u00023 \u0003fi \u0005\n\n(7)\n\n2 \u0004\n\u0002 xi2 − xi−1\n\u0003l\u0005 \u0003l\u0005 \u0005\n\u0010i \u001bi\n2\ni\u0006 l\n\n(8)\n\ni\n\n\u00031\u0005\n\n\u00032\u0005\n\n\u00033\u0005\n\nwith respect to the dislocation misfit density. Here, \u0010i , \u0010i , and \u0010i are the edge, vertical, and screw components of the general interplanar misfit density at the ith nodal point,\nrespectively, and \u00023 \u0003fi \u0005 is the corresponding three-dimensional \u0002-surface. The components\n\u00031\u0005\n\u00032\u0005\n\u00033\u0005\nof the applied stress interacting with the \u0010i , \u0010i , and \u0010i are \u001b \u00031\u0005 = \u001c21 , \u001b \u00032\u0005 = \u001c22 , and\n\u001b \u00033\u0005 = \u001c23 , respectively. The variables K, Ke , and Ks are the prelogarithmic elastic energy\nfactors [52]. The dislocation density at the ith nodal point is \u0010i = \u0003fi − fi−1 \u0005/\u0003xi − xi−1 \u0005,\nand \u0018ij is the elastic energy kernel [43].\nThe first term in the energy functional Uelastic is now discretized to be consistent with\nthe discretized misfit energy, which makes the total energy functional variational. Another\nmodification in this approach is that the nonlinear misfit potential in the energy functional\nUmisfit is a function of all three components of the nodal misfit f \u0003xi \u0005. Namely, in addition to\nthe misfit along the Burgers vector, lateral and even vertical misfits across the glide plane\nare also included. This allows the treatment of straight dislocations of arbitrary orientation\nin arbitrary glide planes. Furthermore, because the misfit vector f \u0003xi \u0005 is allowed to change\nduring the process of dislocation translation, the energy barrier (referred to as the Peierls\nbarrier) can be significantly lowered compared to the corresponding value taken from a rigid\ntranslation. The response of a dislocation to an applied stress is achieved by minimization\n\u0003l\u0005\nof the energy functional with respect to \u0010i at the given value of the applied stress, \u001bi .\nAn instability is reached when an optimal solution for \u0010i no longer exists, which is manifested\nnumerically by the failure of the minimization procedure to converge. The Peierls stress is\ndefined as the critical value of the applied stress that gives rise to this instability.\nThe SVPN model has been applied to study various interesting material problems related\nto dislocation phenomena [45–47]. One study involved the understanding of hydrogenenhanced local plasticity (HELP) in Al. HELP is regarded as one of three general\nmechanisms responsible for H embrittlement of metals [53]. There was overwhelming experimental evidence in support of HELP, but a theoretical foundation was lacking. To gain an\nunderstanding of the physics behind the HELP mechanism, Lu et al. carried out ab initio\ncalculations for the \u0002-surface of Al with H impurities placed at the interstitial sites [45].\nThe \u0002-surfaces for both pure Al and the Al + H systems are shown in Fig. 3. Comparing\nthe two \u0002-surfaces, one finds an overall reduction in \u0002-energy in the presence of H, which\nis attributed to the change of atomic bonding across the glide plane, from covalent-like to\nionic-like [54].\n(b)\n\n(a)\n\n0.5\n0.4\n0.3\n0.2\n0.1\n0\n\n0.5\n0.4\n0.3\n0.2\n0.1\n0\n\n[110]\n\n[110]\n[112]\n\n[112]\n\nFigure 3. The \u0002-surface (J/m2 ) for displacements along a (111) plane for (a) pure Al and (b) Al + H systems. The\ncorners of the plane and its center correspond to identical equilibrium configurations (i.e., the ideal lattice). The\ntwo surfaces are displayed in exactly the same perspective and on the same energy scale to facilitate comparison of\nimportant features.\n\n8\n\nOverview of Multiscale Simulations of Materials\n\nThe core properties of four different dislocations, screw (0\b ), 30\b , 60\b , and edge (90\b )\nhave been studied using the SVPN model combined with the ab initio–determined \u0002-surface.\nIt was found that the Peierls stress for these dislocations is reduced by more than an order\nof magnitude in the presence of H [45], which is compatible with the experimental findings\nthat support the HELP mechanism [53]. Moreover, to address the experimental observation\nfor H trapping at dislocation cores and H-induced slip planarity, the H-binding energy to\nthe dislocation cores was calculated [45]. These calculations showed that there is strong\nbinding between H and the dislocation cores; that is, H is attracted (trapped) to dislocation\ncores, which lowers the core energies. More important, the binding energy was found to be a\nfunction of dislocation character, with the edge dislocation having the greatest and the screw\ndislocation having the lowest binding energies. For a mixed dislocation, the binding energy\nincreases with the amount of edge component of the Burgers vector. These results indicate\nthat in the presence of H, it costs more energy for an edge dislocation to transform into a\nscrew dislocation to cross-slip, as the edge dislocation has almost twice the binding energy\nof the screw dislocation [45]. In the same vein, it costs more energy for a mixed dislocation\nto transfer its edge component to a screw component for cross-slip. Therefore, the cross-slip\nprocess is suppressed because of the presence of H, and the slip is confined to the primary\nglide plane, exhibiting the experimentally observed slip planarity.\nA similar approach was applied to the study of the vacancy lubrication effect on dislocation\nmotion in Al. From this analysis, it was shown that the role of vacancies is crucial in reconciling the results of Peierls stress measured from different experimental techniques [46].\nVery recently, a multiple-plane P-N model has been developed to study dislocation phenomena involving more than one glide plane, such as dislocation constriction and cross-slip [47].\nFinally, we should point out that the P-N model is just one example of more-general cohesive\nsurface models that are built on the idea of limiting all constitutive nonlinearity to certain\nprivileged interfaces, while the remainder of the material is treated via more conventional\ncontinuum theories [1]. The same strategy can also be applied to the study of fracture and\ndislocation nucleation from a crack tip [55].\nIt is interesting to note that the analysis of \u0002-surface can provide a qualitative understanding of even more complex mechanical properties of materials. For example, Rice and\ncoworkers [56] formulated powerful criteria for the brittle behavior of materials by extending\nthe Peierls analysis to geometries involving cracks. Based on this framework, Waghmare et al.\n[57, 58] were able to predict which alloying elements could improve the ductility of MoSi2\nby analyzing the ab initio–determined \u0002-surface of the alloys and comparing the changes\ninduced by alloying to key features of the \u0002-surface to the induced changes of the surface\nenergy \u0002s . Remarkably, certain predictions of this relatively simple theoretical modeling were\nborne out by subsequent experiments [59].\nWe have devoted some attention to the description of the P-N model and its implementation using ab initio \u0002-surfaces because it is an ideal case of a sequential multiscale\nmodel: It consists of a well-motivated phenomenological framework, within which the set of\natomistically derived quantities is well defined and complete (in this case, the \u0002-surface).\nIn this sense, it fulfills all the requirements for a coherent and complete multiscale model.\nThere are, no doubt, limitations to the model, arising from the range of validity of the phenomenological theory, but within this range there are no other ambiguities in constructing\nthe multiscale model. Perhaps its successes, some of which we presented above, are owed to\nthis complete character of the model.\n\n2.2. Phase-Field Model of Coherent Phase Transformations\nThe structure–properties paradigm is one of the principal pillars in materials science. The\nterm structure here refers to structures at many different scales, including the atomic-scale\ngeometry determined by the crystalline arrangement of atoms, the structure of the defects\nthat exist in a material, and the structure that emerges as a result of the organization of these\ndefects into what is referred to as microstructure. Among these structures, the microstructure\non the scale of micrometers is often directly tied to the mechanical properties of materials,\nand it has therefore attracted great interest in terms of both scientific understanding and\npractical applications [60–64].\n\n9\n\nOverview of Multiscale Simulations of Materials\n\nRecently, a powerful sequential multiscale approach has been put forward for modeling\nthe precipitate microstructure and its evolution in multicomponent alloys [65, 66], materials\nthat appear in many technological applications. The approach is based on the continuum\nphase-field model whose driving forces (free energies) are obtained from combined ab initio\ncalculations and the mixed-space cluster expansion technique. One interesting application of\nthis approach concerned the study of precipitation of the \u001e \u0006 (Al2 Cu) phase in Cu–Al alloys\nduring thermal aging [66].\nIn the phase-field multiscale approach, the nature of phase transformation as well as the\nmicrostructures that are produced are described by a set of continuous order–parameter\nfields [67, 68]. The temporal microstructure evolution is obtained from solving field kinetic\nequations that govern the time-dependence of the spatially inhomogeneous order–parameter\nfields. Within the diffuse-interface description, the thermodynamics of a phase transformation and the accompanying microstructure evolution are modeled by a free energy that is\na function of the order–parameter field, or phase field. For a structural transformation, the\ntotal free energy can be written as\n\u0001tot = \u0001bulk + \u0001inter + \u0001elast\n\n(9)\n\nwhere \u0001bulk is the bulk free energy, \u0001inter is the interfacial free energy, and \u0001elast is the\ncoherency elastic-strain energy arising from the lattice accommodation along the coherent\ninterfaces in a microstructure. For a microstructure described by a composition field c and\na set of structural order–parameters 1 \u0006 \u0001 \u0001 \u0001 \u0006 p , the first two terms of Eq. (9) are given by\n\u0001bulk + \u0001inter =\n\n\u0001\nV\n\n#f \bc\u0003r\u0005\u0006\n\np \u0003r\u0005\n\n+\n\n$\n1\u0002\n& \u0003p\u0005%i p \u0003r\u0005%j\n\u0007%c\u0003r\u0005\u00072 +\n2\n2 p ij\n\np \u0003r\u0005' dV\n\n(10)\n\nwhere f \u0003c\u0006 p \u0005 is the local free-energy density [69] and $ and &ij \u0003p\u0005 are the gradient\nenergy coefficients that control the width of the diffuse interface. The elastic-strain energy\nis obtained from elasticity theory using the homogeneous modulus approximation [70]. With\nthe total free energy of an inhomogeneous system written as a function of order–parameter\nfields, the temporal evolution of microstructures during a phase transformation can be\nobtained by solving the coupled Cahn–Hilliard equation for a conserved field c, and the\ntime-dependent Ginzburg–Landau equation for a nonconserved field p [71, 72].\n\u0007\n\b\n(c\n(f\n(11)\n= M% 2\n− $% 2 c\n(t\n(c\n( p\n+\u0001\n= −Lp tot\n(t\n+ p\n\n(12)\n\nwhere M is related to atom mobility and Lp is the relaxation constant associated with the\norder–parameter p . As the above equations illustrate, the continuum phase-field methodology depends on three input energies: bulk free energies of solid solution and precipitate phases, precipitate–matrix interfacial free energies, and precipitate–matrix lattice elastic\nenergies. Experimental determination of these quantities can be difficult and problematic.\nTherefore, a physically motivated method for accurately determining these quantities is of\ncritical importance for predicting the microstructure evolution of interest. In particular, if\nthe quantities can be determined from ab initio calculations, the goal of an ab initio modeling\nof alloy microstructure evolution would be, to a great extent, achieved [73, 74].\nBecause direct ab initio calculations of free energies are either impractical or impossible with the currently available computational power, a useful method has been developed to extend the ab initio energetics to thermodynamic properties of alloy systems with\nhundreds of thousands of atoms [75], referred to as the mixed-space cluster expansion\n(CE). In this scheme, energetics from ab initio calculations for a number of small–unit cell\n(∼10 atoms) structures are mapped onto a generalized Ising-like model for a particular\nlattice type, involving two-, three-, and four-body interactions plus coherency strain energies [76]. The Hamiltonian can be incorporated into mixed-space Monte Carlo simulations\nof N ∼ 105 atoms, effectively allowing one to explore the complexity of 2N configurational\n\n10\n\nOverview of Multiscale Simulations of Materials\n\nspace. As demonstrated by Vaithyanathan et al. [66] the bulk free energy can be obtained\nfrom Monte Carlo simulations coupled with thermodynamic integration techniques. The\nprecipitate–matrix interfacial free energies can be determined from similar Monte Carlo simulations or from low-temperature expansion techniques. The elastic strain energies are of\nprecisely the same form as the coherency strain energy used to generate the mixed-space CE.\nHence, from a combination of ab initio calculations, a mixed-space CE approach, and Monte\nCarlo simulations, one can obtain all the driving forces needed as input to the continuum\nphase-field model. The incorporation of these energetic properties, obtained from atomistics,\ninto a continuum microstructural model represents a bridge between these two length scales\nand opens the path toward predictive modeling of microstructures and their evolution.\nTo illustrate the use of the method, we mention briefly the work of Vaithyanathan\net al. [66], who studied the problem of precipitation of the \u001e \u0006 (Al2 Cu) phase in Cu–Al\nalloys. The free energy of the \u001e \u0006 phase is obtained from ab initio calculations of the energy\nat T = 0 K, coupled with the calculated vibrational entropy of this phase. The bulk free\nenergies of matrix and precipitate phases are then fit to the local free energy as a function\nof order–parameter fields in the phase-field model. From supercell calculations, T = 0 K\ninterfacial energies are determined, both for the coherent interface and for the incoherent\ninterface. The anisotropy of these interfacial energies is large and has been incorporated in\nthe phase-field model. Elastic energy calculations for the coherent strain of Al/Al2 Cu (\u001e \u0006 )\nand the calculated lattice parameters of each phase determine the elastic driving force in this\nsystem. Having determined all the necessary thermodynamic input, Vaithyanathan et al. [66]\nwere able, for the first time, to clarify the physical contributions responsible for the observed\nmorphology of \u001e \u0006 precipitate microstructure. The agreement between the calculated and the\nexperimentally observed microstructures of \u001e \u0006 in the Al–Cu alloys was excellent, confirming\nthe validity of the approach.\nAlthough the phase-field model is able to predict complex microstructure evolution during\nphase transformations, it requires, as input, phenomenological thermodynamic and kinetic\nparameters. For binary systems, ab initio calculations can provide these parameters for the\nphase-field model, but it is unrealistic to assume that such calculations can be used to determine all the thermodynamic information for systems beyond ternary. Therefore, semiempirical methods, such as CALPHAD (calculated phase-diagram) will remain a useful tool in\nsuch an endeavor [77–79].\n\n2.3. Other Sequential Approaches\nKinetic Monte Carlo (KMC) simulations, coupled with atomistically determined kinetic\nenergy barriers, represent a powerful class of sequential multiscale approaches. For example,\na large body of research has been carried out into surface-growth phenomena with KMC\nsimulations whose kinetic energy barrier parameters for relevant elemental processes are\nsupplied by ab initio calculations [80, 81]. In an altogether different field, Cai et al. [82]\nhave used the KMC method to study dislocation motion in Si based on the well-established\ndouble-kink mechanism. In their approach, the dislocation is represented by a connected\nset of straight-line segments that move as the cumulative effect of a large number of kink\nnucleation and migration processes. The rate of these processes is calculated from transition\nstate theory, with the transition energy barrier having contributions from both atomistically\ndetermined energetics (double-kink formation and migration energy) and elastic interactions\nwith other dislocation segments, as well as from the externally applied stress.\nAn example of a multiscale approach, in which KMC is a key component, employs the\nso-called level-set method [83, 84] for the largest (macroscopic) scale. This approach is particularly well suited for the study of epitaxial growth, a subject of great importance in microelectronics and optoelectronics applications. In the level-set method, growth is described\nby the creation and subsequent motion of island boundaries. The model treats the growing\nfilm as a continuum in the lateral direction but retains atomistic discreteness in the growth\ndirection. In the lateral direction, continuum equations representing the field variables can\nbe coupled to growth through island evolution by solving the appropriate boundary-value\nproblem for the field and using local values of this field to determine the velocity of the\nisland boundaries. The central idea behind the level-set method [85] is that any boundary\n\n11\n\nOverview of Multiscale Simulations of Materials\n\ncurve . , such as a step or the boundary of an island, can be represented as the set of values\n/ = 0 (the level-set) of a smooth function /. For a given boundary velocity v, the equation\nfor / is\n(/\n+ v · %/ = 0\n(13)\n(t\nGrowth is naturally described by the smooth evolution of /, determined by this differential\nequation. In the case of multilayer growth, the boundaries .k \u0003t\u0005 of the islands are defined as\nthe set of spatial points x for which /\u0003x\u0006 t\u0005 = k for k = 0\u0006 1\u0006 2, and so on. The evolution of\nthe level-set function / can be obtained by numerically solving Eq. (13) using nonoscillatory\nmethods [86]. The key parameters entering the model are diffusion constants (the terrace\nand island-edge diffusion constants) that can, in principle, be supplied from atomistic calculations through the following procedure (see Fig. 4): first, the atomistic processes that are\nresponsible for terrace or island-edge diffusion are identified and their energetics analyzed\nusing atomistic (possibly ab initio) calculations; next, the energy barriers for the atomistic\nprocesses are incorporated in a KMC model that provides the means for coarse-graining the\natomistic degrees of freedom to a few mesoscopic degrees of freedom, describing the evolution of surface features (the island step edges); finally, the results of the KMC model are\ncoarse-grained to provide the input to the level-set equations—that is, they define the values\nof the boundary velocity v, which depends on the local surface morphology. The coarsegraining between scales eliminates degrees of freedom that are not essential, making the\npassage to the next scale feasible. For example, in the illustration shown in Fig. 4, the smallest step width in the KMC scale corresponds to a two-atom-wide region at the microscopic\nscale, a situation that is relevant to the Si(100) surface and possibly to other semiconductor\nsurfaces (such as III–V compound surfaces). In these cases, surface atoms tend to be bound\nto dimer pairs, which is the essential unit that determines the step structure, even though the\nunderlying dynamics may be determined by the motion of individual atoms. Thus, the KMC\nsimulation need only take into account structures consisting of dimer units, the dynamics\nof which determine the step-edge motion needed for the level-set simulation. The middle\nterrace in Fig. 4(b) is shown as a grid of squares, each representing a four-atom cluster and\nbeing the minimal unit relevant to step motion at the KMC scale in this example, assuming that only steps of width equal to two atoms in each direction are stable. The level-set\nmethod is a manifestly multiscale approach, combining information from three different\n\n2\n1\n0\n\n(a)\n\n(b)\n\n(c)\n\nFigure 4. Illustration of the three different levels of simulation in the level-set multiscale approach of surface\ngrowth. (a) The macroscopic scale, in which island borders are continuous lines separating heights at different levels\n(the levels along a particular cross section are shown schematically, labeled 0, 1, and 2); this scale is treated with\nthe level-set method. (b) The mesoscopic scale, where the features of the island edges contain some information\nabout the underlying atomic lattice, indicated here as the small straight lines that define step directions consistent\nwith atomic positions; this scale is treated with the kinetic Monte Carlo approach. (c) The microscopic scale, where\nthe individual degrees of freedom are explicitly included. The step is determined by the positions of atoms in two\nterraces, with the ones on the upper terrace shown as white larger circles and the ones on the lower terrace shown\nas shaded smaller circles; this scale is treated by atomistic (possibly ab initio) methods. All views in this schematic\nrepresentation are top views (see text for details).\n\n12\n\nOverview of Multiscale Simulations of Materials\n\nregimes (atomistic, mesoscopic, and continuum) into a neatly integrated scheme. Recently,\nthe level-set method has also been applied to study dislocation dynamics in alloys [87].\nYet another sequential multiscale approach has been successfully applied to the study of\ncrystal plasticity. This is the DD method mentioned earlier, which incorporates dislocation\nmotion at the macroscopic scale—the mechanism ultimately responsible for crystal plasticity. To predict the mechanical properties of materials using DD simulations, a connection\nbetween micro-to-meso scales must be established because dislocation interactions at close\nrange (when the cores intersect, for instance) are totally beyond the reach of continuum\nmodels. Along these lines, Bulatov et al. were able to study dislocation reactions and plasticity in fcc metals [88] that compare well with deformation experiments by integrating the\nlocal rules derived from atomistic simulation of dislocation core interactions into the DD\nsimulations. The same idea has been further explored by Rhee et al. in a study of the stage I\nstress–strain behavior of bcc single crystals [19].\n\n3. CONCURRENT MULTISCALE APPROACHES\nBroadly speaking, a concurrent multiscale approach is more general in scope than its sequential counterpart because the concurrent approach does not rely on any assumptions (in the\nform of a particular coarse-graining model) pertaining to a particular physical problem. As a\nconsequence, a successful concurrent approach can be used to study many different problems. For example, dislocation core properties, grain boundary structure, and crack propagation could all be modeled individually or collectively by the same concurrent approach,\nas long as it incorporates all the relevant features at each level. What is probably most\nappealing, however, is that a concurrent approach does not require a priori knowledge of\nthe physical quantities or processes of interest. Thus, concurrent approaches are particularly useful when exploring problems about which little is known at the atomistic level and\nabout their connection to larger scales, and when discovering new phenomena. We discuss\nbelow three instances of concurrent approaches in some detail and mention some additional\nexamples more briefly.\n\n3.1. Macroscopic Atomistic Ab Initio Dynamics\nFracture dynamics is one of the most challenging problems in materials science and solid\nmechanics. Despite nearly a century of study, several important issues remain unsolved.\nIn particular, there is little fundamental understanding of the brittle-to-ductile transition\nas a function of temperature in materials, there is still no definitive explanation of how\nfracture stress is transmitted through plastic zones at crack tips, and there is no complete\nunderstanding of the disagreement between theory and experiment regarding the limiting\nspeed of crack propagation. These difficulties stem from the fact that fracture phenomena\nare governed by processes occurring over a wide range of length scales that are all connected\nand that all contribute to the total fracture energy [89]. In particular, the physics on different\nlength scales interacts dynamically; therefore, a sequential coupling scheme would not be\nadequate for the study of fracture dynamics.\nTo address these challenges, Abraham, Broughton, Bernstein, and Kaxiras developed a\nconcurrent multiscale modeling approach that dynamically couples different length scales\n[25, 26]. This multiscale methodology aims at linking the length scales ranging from the\natomic scale, treated with a quantum-mechanical tight-binding approximation method;\nthrough the microscale, treated via the classical molecular dynamics method; and finally to\nthe mesoscale/macroscale, treated via the finite element method in the context of continuum elasticity. These authors applied this unified approach, termed macroscopic-atomistic–\nab initio dynamics (MAAD), to the study of the dynamical fracture process in Si, a typical\nbrittle material. In traditional studies of fracture, only the continuum mechanics level\n(employing, for instance, the FE method) is usually invoked to account for the macroscopic\nbehavior. However, as there is no natural small-length cutoff present in the continuum\nmechanics approach, any important aspect of the atomic-scale mechanisms for fracture is\ncompletely missed. This can be remedied by introducing classical MD to the simulations.\n\n13\n\nOverview of Multiscale Simulations of Materials\n\nIn particular, the MAAD approach employed the Stillinger–Weber [90] interatomic empirical potential for Si to perform MD calculations at the atomistic level for a large region\nof the material near a crack tip. However, the treatment of formation and the breaking\nof covalent bonds at the atomic scale is not reliable with any empirical potential, because\nbonds between atoms are an essentially quantum mechanical phenomenon arising from the\nsharing of valence electrons. However, small deviations from ideal bonding arrangements\ncan be captured accurately by empirical potentials because they are, to first approximation,\nharmonic, a feature that is easily incorporated in empirical descriptions of the interaction between atoms. Therefore, it was deemed necessary to include a quantum mechanical\napproach in the simulations of a small region in the immediate neighborhood of the crack\ntip, where bond breaking is prevalent during fracture, whereas further away from this region\nthe empirical potential description is adequate. The particular methodology chosen to model\nthe immediate neighborhood of the crack tip, a semiempirical nonorthogonal TB scheme\n[91], describes well the bulk, amorphous, and surfaces properties of Si. Figure 5 shows the\nspatial decomposition of the computational cell into five different dynamic regions of the\nsimulation: the continuum FE region at the far-field, where the atomic displacements and\nstrain gradients are small; the atomistic MD region around the crack, with large strain gradients but with no bond breaking; the quantum mechanical region (labeled TB because of\nthe use of the tight-binding method) right at the crack tip, where atomic bonds are being\nbroken and formed; the FE/MD handshaking region; and the MD/TB handshaking region.\nThe total Hamiltonian Htot for the entire system was written as\nHtot = HFE \u0003#u\u0006 u̇' ∈ FE\u0005 + HMD \u0003#r\u0006 ṙ' ∈ MD\u0005 + HTB \u0003#r\u0006 ṙ' ∈ TB\u0005\n+ HFE/MD \u0003#u\u0006 u̇\u0006 r\u0006 ṙ' ∈ FE/MD\u0005 + HMD/TB \u0003#r\u0006 ṙ ∈ MD/TB\u0005\nThe degrees of freedom of the Hamiltonian are atomic positions r and velocities ṙ for the\nTB and MD regions and displacements u and their time rates of change u̇ for the FE regions.\nEquations of motion for all the relevant variables in the system are obtained by taking\nappropriate derivatives of this Hamiltonian. All variables can then be updated in lock-step as\n\n(a)\n\nFE\n\nMD\n\n(b)\n\n(c)\nTB\n\nMD\n\nFigure 5. Geometrical decomposition of a Si slab with a small crack into different dynamic regions in a macrosopicatomistic–ab initio dynamics simulation: (a) The system at the macroscopic scale, which is modeled as a continuum\nusing finite elements (FEs), except for the region near the crack, outlined in dashed line. (b) The mesoscopic scale,\ntreated atomistically with interatomic potentials and molecular dynamics (MD), with the atoms indicated by green\ncircles, except for the region in the immediate neighborhood of the crack, which is outlined in a dashed line. (c) The\nmicrocopic scale, treated atomistically with forces derived from quantum mechanical calculations, with the atoms\nindicated by red circles. The handshaking regions between FE and MD and between MD and tight binding (TB)\nare also shown schematically (see text for details).\n\n14\n\nOverview of Multiscale Simulations of Materials\n\na function of time using the same integrator. Thus, the entire time history of the system may\nbe obtained numerically, given an appropriate set of initial conditions. Following trajectories\ndictated by this Hamiltonian leads to evolution of the system with conserved total energy,\nwhich ensures numerical stability.\nThe individual approaches at each level (FE, MD, and TB) are well-established and tested\nmethods. What was much more important in this study was the seamless handshaking of\nthe different methods at the interface of the respective domains; namely, the handshaking\nalgorithms between the FE and MD regions and between the MD and TB regions. We\npresent here the main ideas behind the coupling of the different regions.\n\n3.1.1. FE/MD Coupling\nTo achieve the FE/MD handshaking, the FE mesh spacing is scaled down to atomic dimensions at the interface of the two regions. In Fig. 5, the FE nodes are indicated as small open\ncircles connected by thin lines. Moving away from the FE/MD region and deep into the\ncontinuum, one can expand the mesh size. In this way, the atomistic simulation is embedded in a large continuum solid, indicated by a green-colored region in Fig. 5a. FE cells\ncontributing fully to the overall Hamiltonian (unit weight) are marked with thin solid lines,\nwhereas cells contributing to the handshake Hamiltonian (half weight) are represented by\nthin dashed lines. Interactions between the atoms on the MD side, which are represented\nby an interatomic potential, carry full weight when fully inside the MD region (thick solid\nlines joining neighboring atoms) and half weight (thick dashed lines) when they cross the\nboundary, with one of the neighbors effectively represented by a node in the FE region.\nThe FE/MD interface is chosen to be far from the fracture region. Hence, the atoms of the\nMD region and the displacements of the FE lattice can be unambiguously mapped onto one\nanother. The assignment of weights equal to unity within each region and equal to one-half\nat the interface is arbitrary and can be generalized by the introduction of a smooth step\nfunction.\n\n3.1.2. MD/TB Coupling\nAt this interface, the atoms treated quantum mechanically are shown in red and those\ntreated classically are shown in green. The dangling bonds at the edge of the TB region\nare terminated with pseudo-hydrogen atoms. The Hamiltonian matrix elements of these\npseudo-hydrogen atoms are carefully constructed to tie off a single Si bond and to ensure\nthe absence of any charge transfer when that atom is placed in a position commensurate\nwith the Si lattice. In other words, the TB-terminating atoms are fictitious monovalent atoms\nforming covalent bonds with the strength and length of bulk Si bonds. These fictitious atoms\nare called “silogens”: They behave mechanically just like Si, but chemically like H. The TB\nHamiltonian including silicon–silicon and silicon–silogen matrix elements is then diagonalized to obtain electronic energies and wavefunctions, from which the total energy can be\ncomputed. Thus, at the perimeter of the MD/TB region, there are silogens sitting directly\non top of the atoms of the MD region, which are shown as the smaller red circles on top\nof the green circles in Fig. 5. On one side of the TB/MD interface, the bonds to an atom\nare derived from the TB Hamiltonian, and are shown as shaded regions in Fig. 5, to indicate the electronic distribution responsible for the formation of the covalent bonds. On the\nother side of the interface, the bonds are derived from the interatomic potential of the MD\nsimulation. The MD atoms of the interface have a full complement of neighbors, including\nneighbors whose positions are determined by the dynamics of atoms in the TB region; these\nare shown as small green circles on top of the red circles in Fig. 5. As before, the TB code\nupdates atomic positions in lockstep with its FE and MD counterparts.\nThe MAAD approach was employed to study the brittle fracture of Si in a geometry containing a small crack (notch) within an otherwise perfect solid, with the exposed notch face in\nthe (100) plane and the notch pointed in the 010 direction. The system consisted of 258,048\nmesh points in each FE region, 1,032,192 atoms in the MD region, and approximately 280\nunique atoms in the TB region (for computational reasons, the entire region modeled by the\nTB method was broken into smaller, partially overlapping regions, each assigned to a different processor in a parallel implementation). The lengths of the MD region are 10.9 Å for\n\nOverview of Multiscale Simulations of Materials\n\n15\n\nthe slab thickness along the front of the crack, 3649 Å in the primary direction of propagation, and 521 Å in the direction of pull (before pulling). Periodic boundary conditions were\nimposed at the slab faces normal to the direction of the crack propagation (along the front\nof the crack). The wall-clock time for a TB force update was 1.5 s, that for the MD update\nwas 1.8 s, and that for the FE update was 0.7 s. The TB region was relocated after every\n10 time steps to ensure that it remained at the very tip of the propagating crack. The computational slab was initialized at zero temperature, and a constant strain rate was imposed\non the outermost FE boundaries defining the opposing horizontal faces of the slab. Furthermore, a linear velocity gradient was applied within the slab, which results in an increasing\ninternal strain with time. It was observed that the Si solid failed in a brittle fashion at the\nnotch tip when the material was stretched by ∼1.5%. The limiting speed of crack propagation was found to be 85% of the Rayleigh speed with the chosen computational setup. In\nthe course of the simulation, the straight-ahead brittle cleavage of the Si slab left behind a\nrough surface, with increased roughening as a function of crack distance. On the basis of\nthese results, the authors suggested that the roughening surface is the result of the spawning\nof dislocations with low mobility on the timescale of the crack motion.\nA general problem associated with domain decomposition, as in the MAAD simulations,\nis the spurious reflection of elastic waves (phonons) at the domain boundaries because of the\nchanges in system description across the boundaries. For example, such effects have been\nobserved in the atomistic modeling of dislocation motion [92], crack propagation [93–96],\nand energetic particle–solid collisions [97, 98], all of which involved some domain coupling\nscheme. Because the MAAD method involves domain decomposition into the TB, MD, and\nFE regions, the quality of coupling between different regions needs to be examined. In a\nsubsequent paper, Broughton et al. reported that there was no visible reflection of phonons\nat the FE/MD interface and no obvious discontinuities at the MD/TB interface [26]. Thus,\nin this scheme the coupling between the various domains is indeed performed in a seamless manner, closely mimicking the actual behavior of the physical system under investigation. Overall, the MAAD approach represents state-of-the-art current multiscale simulation\nstrategies. It is a finite-temperature, dynamic, and parallel algorithm that, at least as far as\ngeneral computational aspects are concerned, is applicable to any type of material.\nOngoing efforts are exploring the possibility of applying the MAAD strategy to studying chemical effects on mechanical properties of metallic alloys, such as impurity effects\non dislocation motion, crack nucleation, and propagation in various metals. There is an\nimportant qualitative difference between such systems and the study of the brittle fracture\nof Si mentioned above: The nature of bonds in metallic systems is very different from the\nsimple covalent bonds in Si. This makes necessary the development of a different way of\ncoupling the quantum mechanical to the classical atomistic region, because it is no longer\nfeasible to terminate the bonds at the boundary of the quantum region by simply saturating them with fictitious atoms such as the silogens. In such endeavors, other more efficient\nand versatile quantum mechanical formulations are desirable. One candidate is the linearscaling real space kinetic energy functional method [99]. This method approximates the\nnoninteracting kinetic energy of DFT as a functional of electron density, and electronic\nwave-functions are thus eliminated from calculations; therefore, the method is termed as\norbital-free density-functional theory (OFDFT). As a consequence, no diagonalization of\nthe electronic Hamiltonian and no sampling of reciprocal space are necessary, making the\nmethod computationally efficient [100]. In particular, the explicit real space feature of this\napproach makes it naturally suitable for domain coupling within the MAAD framework.\nAlthough efforts to construct a fully functioning scheme along these lines are continuing, we\nbelieve this is a promising method with great potential for applications in metallic systems,\nwhich are difficult to handle with other techniques.\n\n3.2. Quasicontinuum Model\nOne observation from many large-scale atomistic simulations is that only a small subset of\natomic degrees of freedom do anything interesting. The great majority of the atoms behave\nin a way that could be described by effective continuum models like the elasticity theory.\n\n16\n\nOverview of Multiscale Simulations of Materials\n\nThe computation and storage of the uninteresting degrees of freedom—necessary for a\nfully atomistic calculation—consume a large proportion of computational resources. This\nobservation calls for novel multiscale approaches that can reduce the number of degrees\nof freedom in atomic simulations [101, 102]. One such approach, proposed by Tadmor,\nOrtiz, and Phillips, is particularly promising and has yielded considerable success in many\napplications [103]. This concurrent multiscale approach is called the quasicontinuum method,\nand it seamlessly couples the atomistic and continuum realms. The chief objective of the\napproach is to systematically coarsen the atomistic description by the judicious introduction\nof kinematic constraints. These kinematic constraints are selected and designed so as to\npreserve full atomistic resolution where required—for example, in the vicinity of lattice\ndefects—and to treat collectively large numbers of atoms in regions in which the deformation\nfield varies slowly on the scale of the lattice. Variants of the quasicontinuum model have been\ndeveloped and applied in different situations [103–114]. The essential building blocks of the\nstatic quasicontinuum model are the constrained minimization of the atomistic energy of the\nsolid, the use of summation rules to compute the effective equilibrium equations, and the use\nof adaptation criteria to tailor the computational mesh to the structure of the deformation\nfield. An extension of the method to finite temperature has also been proposed [115].\nThe quasicontinuum model starts from a conventional atomistic description, which computes the energy of the solid as a function of the atomic positions. (A web site with\nuseful information related to the quasicontinuum method can be found at http://www.\nqcmethod.com, where the quasicontinuum codes are also available to download.) The configuration space of the solid is then reduced to a subset of representative atoms. The positions\nof the remaining atoms are obtained by piecewise linear interpolations of the representative atom coordinates, much in the same manner as displacement fields are constructed in\nthe FE method. The effective equilibrium equations are then obtained by minimizing the\npotential energy of the solid over the reduced configuration space. A direct calculation of\nthe total energy in principle requires the evaluation of sums that are extended over the full\ncollection of atoms; namely\nEtot =\n\nN\n\u0002\ni=1\n\nEi\n\n(14)\n\nwhere N is the total number of atoms in the solid. The full sums may be avoided by the\nintroduction of approximate summation rules. For example, the lattice quadrature analog of\nEq. (14) can be written as\nEtot ≈\n\nNr\n\u0002\ni=1\n\n\u000fi\nni E\n\n(15)\n\nwhere ni is the quadrature weight that signifies how many atoms a given representative atom\n\u000fi is the energy of ith representastands for in the description of the total energy and E\ntive atom. Note that in this case the sum is over the Nr representative atoms only. In the\nquasicontinuum approach, the FE method serves as the numerical tool for determining the\ndisplacement fields, whereas an atomistic calculation is used to determine the energy of a\ngiven displacement field. The positions of the coarse-grained atoms are needed because the\nenergy of the representative atoms depends on them. This approach is in contrast to standard FE schemes, in which the constitutive law is introduced through a phenomenological\nmodel. The selection of the representative atoms may be based on the local variation of\nthe deformation field. For example, near dislocation cores and on planes undergoing slip,\nfull atomistic resolution is attained with adapted meshing. Far from defects or other highly\nstressed regions, the density of representative atoms rapidly decreases, and the collective\nmotion of very large numbers of atoms is dictated without appreciable loss of accuracy by a\nsmall number of representative atoms.\nThe quasicontinuum method has been applied to a variety of problems, including dislocation structures [103, 104], interactions of cracks with grain boundaries [105], nanoindentations [110, 112, 114], dislocation junctions [108], atomistic-scale fracture process [106],\n\n17\n\nOverview of Multiscale Simulations of Materials\n\nand so forth. By way of example, Shenoy et al. applied the method to study the interaction of dislocations with grain boundaries (GBs) in Al [105]. In particular, they considered\na reformulation of the quasicontinuum model that allows for the treatment of interfaces,\nand therefore of polycrystalline solids. As the first test of the model, they computed the\nGB energy and atomic structure for various symmetric tilt GBs in Au, Al, and Cu, using\nboth direct atomistic calculations and the model calculations. They found excellent agreement between the two sets of calculations, indicating the reliability of the model for their\npurpose. In the study of Al, they used nanoindentation-induced dislocations to probe the\ninteraction between dislocations and GBs. Specifically, they considered a block oriented so\nthat the (111) planes are positioned to allow for the emergence of dislocations, which then\ntravel to the 5 21(2̄41) GB located at ∼200 Å beneath the surface (see Fig. 6a). First, the\nenergy minimization is performed to obtain the equilibrium configuration of the GB, then a\nmesh is constructed accordingly, as shown in Fig. 6a. The region that is expected to participate in the dislocation–GB interaction is meshed with full atomistic resolution, whereas in\nthe far fields the mesh is coarser. The displacement boundary conditions at the indentation\nsurface are then imposed onto this model structure, and after the critical displacement level\nis reached, dislocations are nucleated at the surface. With the EAM potential [12] supplying\nthe atomistic energies in the quasicontinuum approach, the authors observed closely spaced\n(15 Å) Shockley partials nucleated at the free surface. As seen from Fig. 6b, the partials are\nsubsequently absorbed at the GB with the creation of a step at the GB, and no evidence of\nslip transmission into the adjacent grain is observed. The resultant structure can be understood based on the concept of the displacement shift complete lattice [116] associated with\nthis symmetric-tilt GB. As the load is increased, the second pair of Shockley partials is nucleated. These partials are not immediately absorbed into the GB, but instead form a pile-up\n(Fig. 6b). The dislocations are not absorbed until a much higher load level is reached. Even\nafter the second set of partial dislocations is absorbed at the GB, there is no evidence of\nslip transmission into the adjacent grain, although the GB becomes much less ordered. The\nauthors argued that their results give hints for the general mechanism governing the absorption and transmission of dislocations at GBs. The same work also studied the interaction\nbetween a brittle crack and a GB and observed stress-induced GB motion (the combination\nof GB sliding and migration). In this example, the reduction in the computational effort\nassociated with the quasicontinuum thinning of degrees of freedom is significant. For example, the number of degrees of freedom associated with the mesh of Fig. 6a is about 104 ,\nthree orders of magnitude smaller than what would be required by a full atomistic simulation\n(107 degrees of freedom).\nB\n0\n\nGrain 1\n\nA\n\n–500\n\n–1000\n\nGrain 2\n–1000\n\n–500\n\n(a)\n\n0\n\n(b)\n\nFigure 6. Example of a multiscale simulation using the quasicontinuum method. (a) Finite-element mesh used to\nmodel dislocation-grain boundary interaction. The surface marked AB is rigidly indented to generate dislocations\nat A (distance in Amstroms). (b) Snapshots of atomic positions at different stages in the deformation history.\nAbsorption of the first pair of dislocations at the GB results in a step, while the second pair form a pileup.\n\n18\n\nOverview of Multiscale Simulations of Materials\n\nRecently, the quasicontinuum model has been extended to complex Bravais lattices [117],\nwhereby more complicated materials can be handled [114]. However, because of the expression for the total energy adopted in Eqs. (14) and (15), the actual atomistic methods that\ncan be implemented in the quasicontinuum model are limited to ones that can be easily cast\nin such a form, if one insists on having the ability to resolve the FE nodes all the way to\nthe atomic scale. This limit is often referred to in the literature as the “nonlocal” regime of\nthe quasicontinuum method. In contrast, the “local” limit refers to the case in which each\nFE node represents a very large number of atomistic degrees of freedom, which is modeled\nas corresponding to an infinite solid homogeneously deformed according to the local strain\nat the node. In this limit, it is advantageous to employ effective Hamiltonians to compute\nenergetics for the representative atoms. Such Hamiltonians can be constructed from ab initio\ncalculations and may include physics that atomistic simulations based on classical interatomic\npotentials (such as EAM) are not able to capture. For example, by constructing an effective Hamiltonian parametrized from ab initio calculations, Tadmor et al. were able to study\npolarization switching in piezoelectric material PbTiO3 in the context of the quasicontinuum\nmodel in the local limit [118]. This particular Hamiltonian includes the following terms: the\nelastic energy of the lattice, the coupling between strain and atomic displacement, harmonic\nand anharmonic phonon energy contributions, the interaction of atomic displacement with\nthe applied electric field, and the electrostatic energy. With this effective Hamiltonian, it\nwas shown that the behavior of a large-strain ferroelectric actuator under the application of\ncompeting external stress and electric fields can be modeled successfully, reproducing, for\nexample, all the important features of the experimental strain versus the electric field curve\nfor the actuator. The advantage of these simulations is that they also provide insight into\nthe microscopic mechanisms responsible for the macroscopic behavior, making possible the\nimprovement of design of the technologically useful materials.\nOne pitfall of the quasicontinuum model is the so-called “ghost force” at the interface\nbetween the local region, identified with slow variation of the deformation gradient, and\nthe nonlocal region, identified with rapid variation of the deformation gradient [109]. The\nerror arises from the fact that different energy formulations are used for local and nonlocal\nregions, and Newton’s third law is not satisfied across the local–nonlocal interfaces. Care\nmust be taken to correct these “ghost forces” [109]. Finally, we should point out that the\nquasicontinuum approach also shares certain features with sequential approaches; namely,\nthe constitutive equation for the FE nodes is drawn from atomistic calculations (akin to\nmessage-passing in sequential approaches). The reason we categorize it as a concurrent\nmultiscale approach is that the atomistic and FE calculations are performed concurrently\nrather than in sequence, as the range of deformations encountered in various parts of the\nsystem are not known beforehand. Moreover, some sort of domain partitioning (meshing) is\ninvolved in the quasicontinuum approach.\n\n3.3. Coarse-grained Molecular Dynamics\nMesoscopic elastic systems, and in particular nano-electro-mechanical systems (NEMS),\nrecently have captured a great deal of attention and research interest as nanoscale machines\nand devices. However, there is serious concern regarding their mechanical integrity and stability in applications because these nanoscale devices are so minuscule that structural defects\nand surface effects could have a large effect on their performance. However, the computational study of the mechanical properties of the NEMS has turned out to be extremely\ndifficult because they are too small in size for FE simulations (at the limit at which continuum elasticity theory may be no longer valid), but too large for atomistic simulations.\nTo resolve this problem, a concurrent multiscale simulation strategy called coarse-grained\nmolecular dynamics (CGMD) has been developed by Rudd and Broughton [119, 120]. This\napproach bears some resemblance to the quasicontinuum model, yet there exist important\ndifferences between the two.\nThe CGMD approach is based on a statistical coarse-graining prescription. In particular,\nthe model aims at constructing scale-dependent constitutive equations for different regions in\na material. In general, the material of interest can be partitioned into cells, whose size varies\n\nOverview of Multiscale Simulations of Materials\n\n19\n\nso that in important regions a mesh node is assigned to each equilibrium atomic position,\nwhereas in other regions the cells contain many atoms, and the nodes need not coincide with\natomic sites. The CGMD approach produces equations of motion for a mean displacement\nfield defined at the nodes by defining a conserved energy functional for the coarse-grained\nsystem as a constrained ensemble average of the atomistic energy under fixed thermodynamic\nconditions. The key point of this effective model is that the equations of motion for the nodal\n(mean) fields are not derived from the continuum model but from the underlying atomistic\nmodel. The nodal fields represent the average properties of the corresponding atoms, and\nequations of motion (in this particular case Hamilton’s equations) are constructed to describe\nthe mean behavior of underlying atoms that have been integrated out.\nOne important underlying principle of CGMD is that the classical ensemble must obey the\nconstraint that the position and momenta of atoms are consistent with the mean displacement and momentum fields. To be specific, let the displacement of atom be u = x − x 0 ,\nwhere x 0 is its equilibrium position. The displacement of mesh node j is an average of the\natomic displacements\n\u0002\nfj u\n(16)\nuj =\nwhere fj is a weighting function, a microscopic analog of the FE interpolating functions.\nNote that Latin indices j and k denote mesh nodes and the Greek indices and denote\natoms. A similar relation holds for the momenta p . Because the nodal displacements\nare fewer or equal to the atomic positions in number, fixing the nodal displacements and\nmomenta does not necessarily entirely determine the atomic positions. Therefore, some subspace of phase space remains not sampled, which corresponds to the degrees of freedom\nthat are missing from the mesh points. The coarse-grained energy is defined as the average\nenergy of the canonical ensemble on this constrained phase space\nE\u0003uk \u0006 u̇k \u0005 = HMD uk \u0006 u̇k\n\u0001\n= dx dp HMD e−&HMD \u0012/Z\u0006\n\u0007\n\b \u0007\n\b\n\u0002\n\u0002 p fj\n\u0012 = + uj −\nu fj + u̇j −\nm\nj\n\n(17)\n\nwhere & = 1/\u0003kB T \u0005 is the inverse temperature and Z is the partition function. The threedimensional delta functions +\u0003u\u0005 enforce the mean field constraint [Eq. (16)].\nWhen the mesh nodes and the atomic sites are identical, the CGMD equations of motion\nagree with the atomistic equations of motion. As the mesh size increases, some shortwavelength degrees of freedom are not supported by the coarse mesh, but these degrees of\nfreedom are not neglected entirely, because their thermodynamic average effect has been\nretained. This approximation is expected to be good if the system is initially in thermal equilibrium and the missing degrees of freedom only produce adiabatic changes to the system.\nThe Hamiltonian was derived originally for a monoatomic harmonic solid but can be easily generalized to polyatomic solids [119]. After deriving the equations of motion from the\nassumed Hamiltonian for a particular system, one can perform the CGMD for the nodal\npoints.\nAs proof of principle, the method was applied to one-dimensional chains of atoms with\nperiodic boundary conditions, where it was shown that the CGMD gives better results for\nthe phonon spectrum of the model system compared to two different FE methods [119].\nA variety of other calculations have also been performed with the CGMD to validate its\neffectiveness [120, 121].\nAlthough the CGMD has proven to be reliable in the description of lattice statics and\ndynamics, the implementation of the model varies from system to system. This is because\ndifferent approximations have to be made to the Hamiltonian that represents a particular system. However, such approximations can be estimated and controlled in the CGMD method.\nThis advantage makes the CGMD method a good candidate for replacing the FE method\n\n20\n\nOverview of Multiscale Simulations of Materials\n\nin the MAAD approach when a high quality of FE/MD coupling is required. As we alluded\nearlier, the CGMD approach resembles the quasicontinuum model in the sense that both\napproaches adopt an effective field model, an idea rooted in the renormalization group theory for critical phenomena. In both approaches, less important (long-wavelength) degrees of\nfreedom are removed while the effective Hamiltonian is derived from the underlying finescale (atomistic) model. Although both approaches are developed to couple FE and atomistic\nmodels, the quasicontinuum method is mainly applicable to zero-temperature calculations,\nwhereas the CGMD is designed for finite-temperature dynamics. The quasicontinuum model\nhas shown its success in many applications, but the CGMD approach has yet to show its\nwider applicability and versatility.\n\n3.4. Other Works\nRecently, a more general model for the dynamics of coarse-grained multiscale systems was\nproposed by Curtarolo and Ceder [122]. The model is similar to the Migdal–Kadanoff\napproach in the renormalization group theory [123], in which the system is coarse-grained\nthrough a bond-moving process. The new potentials are constructed to ensure that the partial partition function of the system remains unchanged. The information removed from the\ncoarse-graining process can be quantified by the entropy contribution of each step. Although\nthe model is shown to produce excellent results for mechanical and thermodynamical properties compared to the non-coarse-grained system, so far it is limited to two-dimensional\nsystems, and its generalization to three dimensions is yet to be achieved and tested.\nAnother interesting approach has been developed by Shilkrot, Miller, and Curtin, aimed at\nlinking an atomistic region to a “defected” dislocation dynamics region [124]. In this coupled\natomistic and discrete dislocation (CADD) method, the fully atomistic region is directly\ncoupled to a linear elastic continuum region containing dislocations that are modeled as\ncontinuum elastic line defects. The dislocations at the continuum region are treated with\nthe standard discrete dislocation method [125], and the atomistic region may have any kind\nof atomic scale defects. The key aspect of the CADD method is that the dislocations can\npass between the atomistic and continuum regions smoothly. Two developments have been\nmade to achieve this goal: first, the detection of the dislocation near the atomic–continuum\ninterface, and second, a procedure for moving the “right” dislocations across the interface.\nSo far, this approach has only been implemented in two-dimensional systems, but it has been\nshown to agree quite well with the two-dimensional atomistic calculations for Al.\nSome other concurrent approaches are similar to the MAAD method but concentrate on\nlinking two different length scales rather than three. For example, Bernstein and Hess [126]\nhave simulated brittle fracture of Si by dynamically coupling empirical-potential MD and\nsemiclassical TB approaches. In a similar vein, Lidorikis et al. have studied stress distribution in Si/Si3 N4 , using a hybrid MD and FE approach [127]. More recently, a first-principles\nGreen’s function boundary condition method has been developed to self-consistently couple the strain field produced by a line defect to the long-range elastic field of the host\nlattice [128].\nConcurrent multiscale ideas have also been applied to the modeling of polymers [129]\nand biomolecules. In particular, the hybrid quantum mechanical and molecular mechanical\n(QM/MM) methods have been gaining ground in the study of proteins and enzymes in which\nthe small part of a molecule (active site) is modeled by ab initio methods while the rest of\nthe molecule can be dealt with by a more approximate classical force field theory [130]. One\nparticular implementation [131] of the QM/MM strategy is to combine the quantum mechanical self-consistent-charge density-functional-based TB method [132] with the CHARMM\nmolecular force fields [133]. This approach has been used to study the reactions catalyzed\nby triosephosphate isomerase and the dynamics of small peptide helices in water [131].\nFinally, we wish to comment that many concurrent models such as the ones discussed\nabove are designed for covalently bonded systems. These methods take advantage of the\nlocalized electron bonding across the domain interface (between TB/MD and between\nQM/MM) and partition the bonding energy approximately, with a certain degree of empiricism. For metallic systems, however, the bonds are not localized or associated with a distinct pair of atoms; therefore, the concept of “bonding energy partition” across the domain\n\nOverview of Multiscale Simulations of Materials\n\n21\n\ninterface becomes invalid, and new concepts are needed. Recently, several groups have\nexploited the idea of “embedding potential” in simulations in which a region (I) with a\nmore accurate description of the physics is embedded into another region (II) with a less\naccurate description. The influence of region II on region I is described by the “embedding potential,” which corresponds to a local one-electron operator in the framework of the\nDFT [134–137]. For example, in an effort to improve the LDA/DFT description of molecular adsorption on surfaces, a coupling method was developed in which a more accurate\n(quantum chemical) region (I) was embedded in a less accurate LDA/DFT region (II) [134,\n135, 137]. The “embedding potential” is defined as the functional derivative of the coupling\nenergy with respect to the electron density \u0010I \u0003r\u0005 in region I. The total electron density\n\u0010tot = \u0010I + \u0010II , where \u0010II is the electron density in the LDA/DFT region, can be obtained\nby just LDA/DFT calculations for the entire system because the electron density is usually\nwell represented by LDA/DFT. \u0010tot is then held fixed during the subsequent calculations. By\nemploying the OFDFT method [100] for the coupling energy, the “embedding potential” can\nbe explicitly evaluated for any given \u0010I \u0003r\u0005. The “embedding potential” as an effective local\none-electron operator can in turn be added to the Hamiltonian of region I, and the new\nelectron density \u0010I \u0003r\u0005 is thus determined. In this way, \u0010I \u0003r\u0005 can be updated self-consistently\nfor the given \u0010tot . The same “embedding potential” idea can be applied to the coupling\nbetween two different DFT regions, or between two regions, where one is treated with DFT,\nand the other is treated classically, for instance, with EAM.\nThis last approach, currently under development in our group, deserves some elaboration.\nThis approach strives to combine quantum mechanics via OFDFT, classical mechanics via\nEAM, and continuum mechanics via the quasicontinuum method in a unified description for\nmetallic systems. Because the electron density defined in the EAM potential along with the\nEAM nuclei could generate an “embedded potential” that the OFDFT electrons experience,\nthe coupling energy between OFDFT and EAM regions can be explicitly calculated. Furthermore, the EAM atomistic region can be easily coupled to the continuum region based\non the nonlocal description of the quasicontinuum framework.\n\n4. EXTENDING TIMESCALES\n4.1. Accelerated Dynamics\nAs we have seen, MD plays a critical role in the modeling of materials problems because\nMD simulations can follow the actual dynamical evolution of the system without assuming\nany mechanism or pathway for the dynamics, in contrast to, say, Monte Carlo or molecular\nstatics simulations. However, MD is typically limited to a timescale of nanoseconds because\nstandard MD simulations follow the individual vibrations of all the atoms, whose vibration\nfrequencies are on the order of 1014 s−1 . This is particularly troublesome for the complex systems whose dynamics are characterized by the occurrence of rare but important events, such\nas chemical reactions, diffusion processes, and conformational changes. In these systems, the\nexistence of energetic barriers much larger than kB T that separate the initial from the final\nstate leads to reaction times far greater than those that can be currently accessed computationally. The other reason for extending timescales is that time is a sequential object, and\nthe current progress in parallel computing has little effect on solving the problem. Therefore, algorithms that could address the timescale problem could revolutionize the field of\ncomputational materials science and engineering.\nIn the past few years, significant progress has been made in accelerating MD simulations. A class of accelerated dynamics methods, including hyperdynamics, parallel replica\ndynamics, and temperature-accelerated dynamics, has been developed by Voter and coworkers [138–140]. Although each method accomplishes this acceleration in a different way,\ntransition-state theory (TST) provides the common theoretical foundation. TST is an elegant\ntheory with extensive applications in materials science [141–146]. In TST theory, a state-tostate transition rate constant (K T ST ) is approximated as the flux through a dividing surface in\nthe phase space separating the initial and final states. A common and useful approximation\nto TST is the harmonic TST, in which one assumes that the potential energy surface (PES)\n\n22\n\nOverview of Multiscale Simulations of Materials\n\nnear the minimum can be expanded with the harmonic approximation. Thus, the TST rate\nconstant (the flux through the saddle plane) becomes\nK HT ST =\n\n0 exp\u0003−E/kB T \u0005\n\n(18)\n\nwhere\n0 =\n\n3N\ni\ni\n3N −1 \u0006\ni\ni\n\n(19)\n\nHere E is the activation energy (energy difference between the minimum and the saddle\npoint), i is the ith normal mode frequency at the minimum, and i\u0006 is the nonimaginary normal model frequency at the saddle point [146]. The analytic integration over the whole phase\nspace yields the well-known Arrhenius temperature dependence. It is worthwhile pointing\nout that although the exponent depends only on the barrier height, there is no assumption\nthat the trajectory passes exactly through the saddle point. For systems in which there is\nno recrossing of the dividing surface and the modes are truly harmonic, the rate [Eq. (18)]\nis exact. The underlying concept in the accelerated dynamics methods is that the system\ntrajectory is simulated to find an appropriate pathway for escape from an energy well by a\nprocess that takes place much faster in the simulation than it would with direct MD. We\nprovide below an elementary description of this concept.\nThe general formulation of TST rests on two assumptions to treat infrequent events: first,\nit is known in advance what the different equilibrium states of the system will be, and second,\nit is possible to construct a reasonable dividing surface along the boundaries between initial\nand final states (or, equivalently, all the saddle points can be identified). Unfortunately, the\nknowledge of states through which a system may evolve in most cases (especially in complex\nsystems) is incomplete. The hyperdynamics method [139, 140] is designed to accelerate MD\nsimulations without any advance knowledge of either the location of the dividing surface or\nthe states through which the system may evolve. Based on TST, Voter has shown that it is\npossible to modify the PES of the system in such a way that a simulation on this modified\nsurface exhibits the correct relative probabilities of transitions, but with enhanced overall\ntransition rates for the system escaping from one equilibrium state to the various nearby\nequilibrium states. The key of this approach is to construct a bias potential to raise the\nenergy of the system in regions other than at the dividing surfaces. Dynamical evolution with\nthe biased potential leads to accelerated transition from one equilibrium state to another\nequilibrium state, whereas the elapsed time is related to statistical properties of the system.\nMore precisely, the total time advance for a hyperdynamics simulation after n integration\nsteps is\nn\n\u0002\nthyper =\n\u0012tMD e\u0012V \u0003r\u0003tj \u0005\u0005/kB T\n(20)\nj=1\n\nwhere \u0012tMD is the time advance for a regular MD trajectory, \u0012V \u0003r\u0005 is the bias potential,\nand T is the temperature. The overall computational speed-up is given by the average boost\nfactor (thyper /tMD ) divided by the extra computational cost of calculating the bias potential\nand its derivatives. The evolution of hyperdynamics from state to state is correct because the\nbias potential does not change the relative TST rates for different escape paths from a given\nstate. The long-time dynamics of the simulations are exact to the extent that the dynamical\ncorrections to the TST are negligible. Recently, Voter has shown that the bias potential and\nits derivatives can be computed in O(N) fashion without ever constructing the Hessian [140].\nThus, the implementation of the hyperdynamics method requires only first derivatives of the\ninteratomic potential, as for normal MD simulations.\nTo demonstrate the effectiveness of the method, Voter has studied the diffusion of an\nAg adatom on the Ag (100) surface at 400 K using an EAM potential for the energetics.\nHe found that a 3\u00017 × 106 steps of hyperdynamics run gave an average boost of 1356, for a\ntotal time of 9\u000189 ± 0\u00015 s. Each hyperdynamics step required ∼30 times the computational\ntime of a direct MD step; therefore, the net computational boost was a factor of 45. The\nrate constants obtained from the calculations are in agreement with the full harmonic rate.\n\nOverview of Multiscale Simulations of Materials\n\n23\n\nFor a more complex system with a 10-atom Ag cluster on the Ag (111) surface at 300 K,\nhe achieved an average boost of 8310 with a hyperdynamics run for 221.2 s. With this\napproach, one should be able to observe novel diffusion mechanisms that can not be accessed\nby normal MD simulations.\nTo take advantage of recent advances in parallel computation, Voter proposed the socalled parallel replica dynamics method [147] to treat infrequent events. For a system in\nwhich successive transitions are uncorrelated, running a number of independent MD trajectories in parallel gives the exact dynamical evolution between the states. For a system with\ncorrelated crossing events, the state-to-state transition sequence is still correct, but care must\nbe taken to eliminate or reduce the error associated with the simulation time. The parallel\nreplica method represents the simplest and most accurate of the accelerated dynamics techniques, with the only assumption being that of infrequent events obeying first-order kinetics.\nTo be more specific, the probability distribution for the waiting time before the next escape\nis assumed to be\np\u0003t\u0005 = K exp\u0003−Kt\u0005\n\n(21)\n\nwhere K is the rate constant for finding the next escape path from the current state. In\na system that exhibits no correlated crossing events, K is exactly the TST rate constant\n(K TST ). In a more general case, in which correlated crossings occur, K < K TST . For an\nN -atom system in a particular equilibrium state (potential energy basin), the entire system is\nreplicated on each of M available parallel or distributed processors. After a short dephasing\nstage, during which momenta are periodically randomized to eliminate correlations between\nreplicas, each processor carries out an independent constant-temperature MD trajectory for\nthe entire N -atom system, thus exploring the phase space within the particular basin M times\nfaster than a single trajectory would. Whenever a transition is detected on any processor,\nall processors are alerted to stop. The simulation clock is advanced by the accumulated\ntrajectory time summed over all replicas (i.e., the total time spent exploring phase space\nwithin the basin before the escape pathway is found). The parallel replica method also\ncorrectly accounts for correlated dynamical events in which TST is no longer valid. This is\naccomplished by allowing the trajectory that made the transition to continue on its processor\nfor a further amount of time \u0012tcorr , during which recrossings or follow-on events may occur.\nThe simulation clock is then advanced by \u0012tcorr , the final state is replicated on all processors,\nand the whole process is restarted. This overall procedure then gives exact state-to-state\ndynamical evolution because the escape times obey the correct probability distribution [138].\nWith this approach, significant extensions of MD timescales can be achieved. For example, in\nMD simulations of vacancy diffusion on the Cu(100) surface at 500 K, a 15-processor parallel\ncomputer can give a 14-fold increase in simulation time per wall-clock time. Moreover, the\nparallel replica method can be combined with other accelerated dynamics methods, such as\nhyperdynamics, to give a multiplicative effect in the MD timescale gain [147].\nIn the temperature-accelerated dynamics (TAD) method, the transition from state to state\nis accelerated by the increasing temperature [148]. The transitions that should not have\noccurred at the original temperature are then filtered out. The TAD method is more approximate than the previous two methods because it relies on the harmonic TST approximation,\nbut it often gives substantially bigger boost than the hyperdynamics or the parallel replica\ndynamics in systems in which the approximation is justified. Consistent with the accelerated dynamics concept, the trajectory in TAD is allowed to wander on its own to find each\nescape path, so that no prior information is required about the nature of the reaction mechanisms [138]. Like hyperdynamics, TAD can also be combined with the parallel replica method\nto achieve an even higher acceleration on parallel computers.\n\n4.2. Finding Transition Pathways\nAs stated earlier, the problem of finding transition pathways for infrequent events between\ntwo known equilibrium (stable or metastable) states is of considerable interest. The accelerated dynamics methods are designed to find the real dynamic pathways via effective MD\nsimulations. Other methods requiring no preconceived mechanism or transition state have\n\n24\n\nOverview of Multiscale Simulations of Materials\n\nalso been developed to locate transition pathways. For example, Elber and Karplus [149]\ndeveloped a method to find the transition pathway by minimizing the average value of the\npotential energy along the path rather than trying to find the path with the lowest barrier.\nA more popular approach, similar in spirit to the Elber–Karplus method, is the so-called\nnudged elastic band (NEB) approach [150, 151], which focuses on the global character of\nthe path rather than on local properties of the PES.\nThe NEB method is based on the “chain-of-states” idea, where a number of images (or\nreplicas or “states”) of the system are connected together between the endpoint configurations to trace out a transition pathway [150]. If the images are connected with springs of\nzero natural length, one can define the object function for the so-called plain elastic band\n(PEB) method in the following\nS PEB \u0003R\u0013 1 \u0006 \u0001 \u0001 \u0001 \u0006 R\u0013 P −1 \u0005 =\n\nP\n\u0002\ni=0\n\n\u0002 \u0003R\u0013 i \u0005 +\n\nP\n\u0002\nPk\ni=1\n\n2\n\n\u0003R\u0013 i − R\u0013 i−1 \u00052\n\n(22)\n\nwhere vector R\u0013 represents the coordinate of the system, \u0002 is the potential energy of the\nsystem, and k is the spring constant. The spring is introduced to ensure that the images\nare evenly spaced along the path. One would envision finding the transition pathway by\nminimizing the object function in Eq. (22) with respect to the intermediate images while\nkeeping the endpoint images R\u0013 0 and R\u0013 P fixed. The force acting on the image i is\nF\u0013i = −% \u0002 \u0003R\u0013 i \u0005 + F\u0013is\n\n(23)\n\nF\u0013is = ki+1 \u0003R\u0013 i+1 − R\u0013 i \u0005 − ki \u0003R\u0013 i − R\u0013 i−1 \u0005\n\n(24)\n\nwhere\n\nHowever, as demonstrated by Jónsson et al., the PEB method fails to provide the transition\npathway in most situations [150]. For example, if ki is too large, the elastic band becomes\ntoo stiff, and the transition path would then “cut the corner” and thus miss the saddle\npoint region. In contrast, if ki is small, the elastic band comes closer to the saddle point,\nbut the images slide down from the energy barrier (and avoid the saddle point), therefore\nreducing the resolution of the path in the most critical region. Furthermore, by noticing the\nanalogy between the object function in the continuum limit and the action of a classical\nparticle of unit mass moving on the inverted PES, Jónsson et al. argued that the particle\nwould move through the saddle point region with a finite velocity affected by the force\ncomponent perpendicular to the curved path. In other words, the images would deviate\nfrom the minimum energy path (MEP). The problem with “corner cutting” is caused by the\ncomponent of the spring force that is perpendicular to the path, which tends to pull images\noff the MEP. The problem with sliding down results from the component of the potential\nforce or of the true force, % \u0002 \u0003R\u0013 i \u0005 that is parallel to the path. The distance between images\nbecomes uneven, so that the net spring force can balance the parallel component of the true\npotential force. To cure these problems, the NEB method projects out the perpendicular\ncomponent of the spring force and the parallel component of the potential force relative to\nthe path. The force on image i becomes\nF\u0013i0 = −% \u0002 \u0003R\u0013 i \u0005\u0007⊥ + F\u0013is · \u001bˆ\u0016 \u001bˆ\u0016\n\n(25)\n\nwhere \u001bˆ\u0016 is the unit tangent to the transition path and % \u0002 \u0003R\u0013 i \u0005\u0007⊥ = % \u0002 \u0003R\u0013 i \u0005 − % \u0002 \u0003R\u0013 i \u0005 · \u001bˆ\u0016 \u001bˆ\u0016 .\nThese force projections (“nudging”) decouple the dynamics of the path itself from the discrete representation of the path. The spring force thus does not interfere with the relaxation\nof the images perpendicular to the path, and the relaxed configuration of the images satisfies\n% \u0002 \u0003R\u0013 i \u0005\u0007⊥ = 0 (i.e., they lie on the MEP).\nThe implementation of the NEB in a MD program is quite simple. First, the energy and\nits gradient are evaluated for each image in the elastic band, using some description of the\nenergetics (ab initio or empirical force fields). Then, for each image, the local tangent to the\npath is estimated and the force defined in Eq. (25) is evaluated for an initial guess of the path.\n\nOverview of Multiscale Simulations of Materials\n\n25\n\nThe subsequent minimization for the magnitude of the forces with respect to the coordinates\nof the intermediate images can be carried out with the velocity Verlet algorithm [152].\nRecently, several improvements of the original NEB have been proposed [151, 153, 154].\nThe NEB method has found a wide range of applications in materials problems, including\na cross-slip of screw dislocations in metals [155], diffusion and atomic exchange processes\nat metal and semiconductor surfaces [156, 157], dissociative adsorption of molecules on\nsurfaces [158], and contact formation of metal tips on surface [159]. The NEB method has\nbeen implemented in many empirical potential and ab initio atomistic approaches [150, 151].\nOne drawback of the NEB method is the difficulty in choosing appropriate spring constants.\nA large spring constant requires a small time step in the evolution of states (i.e., more images\nalong the path). A small spring constant, however, may fail to achieve the desired uniformity\nof the images along the path and, hence, may reduce the accuracy for the energy barrier.\nFurthermore, like other methods in this category, the NEB method becomes less efficient\nor even inapplicable to systems with very rough energy landscapes.\nRealizing the importance of real dynamical pathways, Chandler and collaborators have\nrecently proposed methods for statistically sampling dynamical paths (MC sampling of MD\ntrajectories) that do not require the assumption of TST or the existence of a single, welldefined transition state or transition path [160, 161]. In particular, no reaction coordinate\nis needed to study the dynamics or kinetics of rare transitions [162] with these methods.\nIn a sense, the transition path-sampling methods are metaphorically akin to throwing ropes\nover rough mountain passes in the dark: “throwing ropes” corresponds to shooting short\nreal dynamical trajectories, and “in the dark” implies that the high-dimensional systems are\nso complex that it is generally impossible to visualize the topography of relevant energy\nsurfaces. Although these methods are extremely powerful for treating complex systems with\nrough energy landscapes, they are usually computationally demanding. In particular, their\nefficiency usually hinges on the ability to produce new accepted paths from old ones; thus,\nthey have found limited application so far.\nRecently, an alternative finite temperature string method was proposed that represents\ntransition paths by their intrinsic parameterization to efficiently evolve and sample paths in\nthe path space [163]. The string method performs a constrained sampling of the equilibrium\ndistribution of the system in hyperplanes normal to the transition pathways of a coarsegrained potential that need not be determined beforehand. The collection of the hyperplanes\nis parametrized by a string that is updated self-consistently until it approximates locally the\ncorrect coordinate associated with the reaction event. The region in these planes in which\nthe equilibrium distribution is concentrated determines a transition tube in the configuration\nspace in which a transition takes place with high probability. The string method naturally\novercomes the spring constant problem in the NEB method because of the intrinsic parameterization of the string, and the distribution of the replicas along the chain is automatically\nuniform. The method, however, rests on the assumption that the equilibrium distribution\nmust be localized on the iso-surfaces of the reaction coordinate and that these iso-surfaces\ncan be locally approximated by the hyperplanes. If the effective transition tube is highly\ncurved in configuration space, this approach may have to be modified.\nA method for efficiently generating classical trajectories with fixed initial and final boundary conditions has recently attracted attention because of its conceptual and computational\nsimplicity [164]. The approach developed by Passerone and Parrinello addresses a very general problem: Given an initial and a final configuration, what are the dynamical paths that\nconnect them? Given a classical dynamical system described by a set of coordinates q, its\ntrajectory q\u0003t\u0005 with boundary conditions q\u00030\u0005 = qA and q\u0003\u001b\u0005 = qB is determined by locating\nthe stationary point of the action \u0003\n\u0003 =\n\n\u0001\u001b\n0\n\n\u0004\u0003q\u0003t\u0005\u0006 q̇\u0003t\u0005\u0005 dt\u0006\n\n(26)\n\nwhere \u0004 is the Lagrangian \u0004 = \u0005 − \u0002 and \u0005 and \u0002 are the kinetic and potential\nenergy, respectively. Following the work of Gillilan and Wilson [165], the action \u0003 can be\n\n26\n\nOverview of Multiscale Simulations of Materials\n\ndiscretized as\n\u0003 =\n\nN\n−1\n\u0002\nj=0\n\n\u0012\n\n\u0007\n\b\n1 qj − qj+1 2\n− \u0002 \u0003qj \u0005\n2\n\u0012\n\n(27)\n\nwhere q0 = qA , qN = qB ; \u0012 = \u001b/N is the time interval and the mass is taken as unitary [164].\nThe stationary solution of this action is the discretized Euler–Lagrangian equation, and the\ncorresponding trajectory is identical to the well-known Verlet trajectory. The novel part of\nthis method is supplementing the action with a penalty function that favors the energyconserving trajectories\nA\u0003qj \u0006 E\u0005 = \u0003 +\n\nN\n−1\n\u0002\nj=0\n\n\u0003Ej − E\u00052\n\n(28)\n\nHere determines the strength with which the energy conservation is enforced, Ej is the\ninstantaneous energy given by\nEj = \u0003qj − qj+1 \u00052 /\u00032\u00122 \u0005 + \u0002 \u0003qj \u0005\nand E is its target value. This is motivated by the fact that the physical trajectories have to\nconserve total energy. In all the systems studied, it was found that there exists a rather large\ninterval of values such that A has a minimum close to the Verlet trajectories. To minimize\nthe A function more efficiently, Passerone et al. make the transformation\nqj = qA +\n\nN\n\u0002\nj\u0012\nai sin\n\u0003qB − qA \u0005 +\n\u001b\ni=1\n\n\u0007\ni\n\nj\u0012\n\u001b\n\n\b\n(29)\n\nthus automatically satisfying the boundary conditions. The advantage of using ai over qj is\nthat ai has a global character. In practice, A is first optimized with respect to a relatively\nsmall number of ai , thus capturing the global features of the trajectory, and then higher\nfrequency terms are added. Each time, a standard conjugate gradient algorithm is used to\nminimize A with only the evaluation of the forces. The computational scaling is therefore\nlinear in the number of degrees of freedom, rather than quadratic, as in other approaches\ninvolving the Hessian matrix.\nTo illustrate the performance of the method, Passerone et al. studied a few simple systems. For a one-dimensional double-well potential, they found that their solutions agree very\nwell with the Verlet trajectory, but without the calculation of the Hessian matrix. The second example was a minimization of a trajectory in a two-dimensional configurational space;\nnamely, in the Mueller potential [166]. Again, the authors found a satisfactory result; namely,\nthat the trajectories pass exactly through the saddle point and that the overall behavior of the\ntrajectories is physical. The last example was to look at a process in which the central atom\nof a seven-atom, two-dimensional Lennard–Jones cluster migrates to the surface. In this\ncase, Passerone et al. claim that their calculations reproduce the results from the more elaborate method, which involves transition path-sampling procedure [167]. Finally, the authors\npointed out that their method can be easily implemented within the Car–Parrinello MD\napproach [168], offering a powerful tool for the study of problems in chemistry and materials\nscience. The main advantages of this method are the fact that it requires only the calculation\nof the forces, its numerical stability, and the quality of the trajectories. Furthermore, the\nmethod lends itself to very efficient parallelization, and it can include naturally the multiple\ntimescale approaches [169].\n\n4.3. Escaping Free-Energy Minima\nFor many systems, the free-energy surface (FES) may have multiple local minima separated\nby large barriers; therefore, the timescale that typical MD and MC simulations can reach is\nseverely limited. Examples of such systems include conformational changes in solution, protein folding, and many chemical reactions. A large number of methods have been developed\nto overcome the problem, some of which were already mentioned in Sections 4.1 and 4.2\n\n27\n\nOverview of Multiscale Simulations of Materials\n\n(see, e.g., the accelerated dynamics approach [138] or the dynamical transition path sampling\nmethod [160]).\nRecently, a novel and powerful method for exploring the properties of multi-dimensional\nFES of complex systems was proposed by Laio and Parrinello [170]. This method combines\nthe ideas of coarse-grained dynamics on the FES [171, 172] with those of adaptive bias\npotential methods [173, 174]. The method allows the system to escape from local minima\nin the FES and at the same time achieves a quantitative determination of the FES through\nthe integrated process. This method assumes that there exist a finite number of relevant\ncollective coordinates si , i = 1\u0006 n, where n is a small number, and that the free energy \u0001 \u0003s\u0005\ndepends on these parameters. The exploration of the FES is guided by the generalized\nforces Fit = −(\u0001 /(sit . To estimate the forces more efficiently, an ensemble of P replicas of\nthe system is introduced, each obeying the constraint that the collective coordinates have\na preassigned value si = sit . The coarse-grained dynamics of the collective coordinates is\ndefined as follows:\nBt\n(30)\nit+1 = \u001cit + +\u001c it\n\u0007B \u0007\nwhere \u001cit = sit /\u0012si and Bti = Fit \u0012si are the scaled collective coordinates and forces, respectively. The variable \u0012si is the estimated size of the FES well in the direction si , \u0007Bt \u0007 is the\nmodulus of the nth dimensional vector Bti , and +\u001c is a dimensionless stepping parameter.\nAfter the collective coordinates are updated using Eq. (30), a new ensemble of replicas of\nthe system with values \u001cit+1 is prepared, and new forces Fit+1 are calculated for the next iteration. At the same time, the driving forces are evaluated from the microscopic Hamiltonian\nin short, standard microscopic MD runs. To explore the FES more efficiently, the forces in\nEq. (30) are replaced by a history-dependent term\n\u0006\n\n\u0007\u001c −\u001c t \u00072\n\u0002\n(\n− i i2\nBi → Bi −\nW\ne 2\u0003+\u001c\u0005\n(\u001ci t\u0006 ≤t i\n\n(31)\n\nwhere the height and the width of the Gaussian, W and +\u001c, are chosen to provide a reasonable balance between accuracy and efficiency in exploring the FES. The component of\nthe forces coming from the Gaussian will discourage the system from revisiting the same\nspot and will encourage an efficient exploration of the FES. As the system diffuses though\nthe FES, the Gaussian potentials accumulate and fill the FES well, allowing the system to\nmigrate from well to well. After a while, the sum of the Gaussian terms will almost exactly\ncompensate the underlying FES well [170].\nA typical example of this behavior can be seen in Fig. 7, in which the dynamics in Eq. (30)\nare used to explore a one-dimensional PES \u0002 \u0003s\u0005 with three wells. The dynamics start from\na local minimum that is filled by the Gaussians in ∼20 steps. Then the dynamic escapes\nfrom the well from the lowest-energy saddle point, filling the second well in ∼80 steps. The\nsecond-highest saddle point is reached in ∼160 steps, and the full PES is filled in a total of\n∼320 steps. Hence, in the case of this example, because the form of the potential is known,\nit can be verified that for large t and small +\n−\n\n\u0002\n\n\u0006 2\n\nWe\n\n− \u0007\u001c−\u001ct 2\u0007\n2\u0003+\u001c\u0005\n\n→ \u0002 \u0003s\u0005\n\n(32)\n\nt \u0006 ≤t\n\nmodulo an additive constant. Laio and Parrinello also suggest that Eq. (32) holds for a FES,\nand the free energy can be estimated from Eq. (32) for large t [170]. The efficiency of the\nmethod in filling a well in the PES or the FES can be estimated by the number of Gaussians\nthat are needed to fill the well. This number is proportional to \u00031/+\u001c\u0005n , where n is the\ndimensionality of the problem. Hence, the efficiency of the method scales exponentially with\nthe number of dimensions involved. A judicious choice of \u0012si , W , and +\u001c will ensure the\nright balance between accuracy and sampling efficiency, and the optimal height and width\nof the Gaussians can be determined by the typical variations of the FES.\nThe method has been applied to the study of dissociation of a NaCl molecule in water and\nof the isomerization of alanine dipeptide in water [170]. Overall, the method is very efficient\n\n28\n\nOverview of Multiscale Simulations of Materials\n2\n\n0\n\nV(x)\n\n–2\n\n320\n\n160\n\n20\n\n80\n\n10\n\n–4\n40\n–6\n\n–8\n\n–10\n–6\n\n–4\n\n–2\n\n0\n\nx\n\n2\n\n4\n\n6\n\nFigure 7. Time evolution of the sum of a one-dimensional model potential V \u0003\u001c) and the accumulating Gaussian\nterms of Eq. (31). The dynamic evolution (thin lines) is labeled by the number of dynamical iterations in Eq. (30).\nThe starting potential (thick line) has three minima, and the dynamics are initiated in the second minimum.\n\nin exploring the FES of complex systems if the collective coordinates are chosen judiciously.\nIn particular, the topology of a FES can usually be determined by a few coarse-grained\ndynamics steps using “large” Gaussians. Subsequently, the qualitative knowledge of the FES\ncan be improved using “smaller” Gaussians, effectively reducing the dimensionality of the\nproblem by exploiting the topological information obtained with “large” Gaussians. As we\nalluded earlier, the current method assumes that the free energy \u0001 \u0003si \u0005 depends on a small\nnumber of collective coordinates si . However, it is not always obvious or possible to identify\nsuch collective coordinates for complex systems a priori. In the example of isomerization of\nalanine dipeptide in water, Laio et al. chose the dihedral angles D and E as the collective\ncoordinates to explore the FES. These authors recognized that the dihedral angles alone do\nnot provide the complete description of the dialanine isomerization reaction and that the real\nreaction coordinates should include the solvent degrees of freedom. However, their results\nseemed to reproduce the essential features of the FES; therefore, the authors concluded\nthat the neglected degrees of freedom, although relevant for determining the reaction coordinates, are associated with small free-energy barriers and are sampled efficiently during the\nmicroscopic dynamics of the dihedral angles D and E . Despite the success of this particular\nexample, identifying a small number of collective coordinates a priori remains challenging\nwithin this approach. Moreover, the exploration of the FES would be more efficient if an\nadaptive way of determining the parameters of Gaussians could be developed.\n\n4.4. Other Methods\nFor systems with a natural disparity in inherent timescales, various multiple-time-step integration algorithms have been developed to deal with them more efficiently [175–177]. One\nwell-known example of such strategy is the Born–Oppenheimer approximation, in which the\nelectron motion is separated from that of the nuclei because of the large disparity between\ntheir masses. In general, the separation of timescales occurs when some subset of forces\npresent in the system is much stronger compared to the rest of the forces, while the masses\nof the constituents are about the same. For example, in the simulations of the polyatomic\nliquids with flexible bonds, the bond vibrations usually occur at a much faster rate than\nbond translation and rotations. In such systems, the configuration space can be divided into\nfast and slow degrees of freedom, with the force also being separated into fast and slow\ncomponents. This separation yields a set of coupled equations of motion for the evolution\nof the fast and slow degrees of freedom. Instead of solving this set of equations simultaneously, multiple-time-step integration uses a small time step +t to advance the fast degrees\n\nOverview of Multiscale Simulations of Materials\n\n29\n\nof freedom n steps holding the slow variables fixed. The slow degrees of freedom are then\nupdated using a time step n+t. The variable n can be chosen typically between 5 and 10 steps\nin MD simulations of molecules that can be described in this way. Furthermore, if an analytic solution of high-frequency motion can be found, this solution can be incorporated into\nan integration scheme for the whole system, such that a time-step characteristic of the slow\ndegrees of freedom can be used and the system simulated effectively with a much smaller\nnumber of cycles [177].\nRecently, a method based on optimization of the action functional was proposed to extend\nthe timescale of MD simulations by several orders of magnitude [178]. In this method,\ninstead of parameterizing the trajectory as a function of time, the trajectory is parametrized\nas a function of length. Instead of solving the Newton equations in MD simulations, an\naction term (stochastic difference equation with respect to time) is optimized. For activated\nprocesses, the method eliminates the “incubation time,” and has proven to be very efficient\nin the simulations of biomolecules. It remains to be seen, however, whether the method can\nbe applied to problems in materials science.\n\n5. CONCLUSIONS\nIn this chapter we have attempted to provide a comprehensive, if not exhaustive, overview\nof the current status of multiscale simulations methods and their applications in materials\nscience. We divided the methods that address multiscale problems in the spatial regime into\nsequential and concurrent methods.\nThe sequential multiscale modeling techniques are, in general, more efficient computationally, but they depend on a priori knowledge of physical quantities of interest, such as the\n\u0002-surface in the P-N model, the free energies in the phase–field model, and atomistic local\nlaws for mesoscopic DD simulations. The relevance of these quantities to the coarse-grained\nmodels needs to be carefully examined before the application of the methods. Furthermore, these approaches should only be pursued when phenomenological theories (such as\nthe P-N model or the phase–field model) are well established; therefore, the methods are\nrestricted in their range of application. In particular, these phenomenological models are\noften associated with the assumption of locality (both in space and time). The example of\na local approximation in the phase–field model is embodied in Eq. (10), which assumes\nthat part of the energetics of an inhomogeneous system can be written in terms of quantities obtained for homogeneous systems [1]. Similarly, in the P-N model, the \u0002-energy is\nassumed to be constant within \u0012x distance [see Eq. (7)] to evaluate the total misfit energy.\nThe static approximation (locality in time) for dynamic properties is also widely used in\nphenomenological models. The coupling between different scales in a sequential approach\nis usually implicit. A successful sequential simulation depends equally on the reliability of\nthe phenomenological model and on the accuracy of the relevant parameters entering the\nmodel.\nThe concurrent multiscale approaches are much more complicated and computationally\ndemanding, but they do not require a priori knowledge of physical quantities supplied from\ndistinct, lower-scale simulations. Furthermore, concurrent approaches do not depend on any\nphenomenological models; therefore, they are of more general applicability. Although concurrent approaches are more desirable and appealing, the actual problem to be attacked\nmust be carefully posed to make the method practical. The problems that may arise in a\nconcurrent approach are usually associated with the partition of domains in the system.\nFor example, one needs to dynamically track the domain boundaries in the MAAD simulations and to adapt the FE meshes in the quasicontinuum simulations, both of which require\nadditional care and computational resources. More important, in contrast to a sequential\nmethod, a “good” handshaking in a concurrent approach between different domains is both\nchallenging and critical. Although some interesting ideas have been proposed to remedy the\nproblems of coupling between different domains, such as the reflection of phonons at the\ndomain interface [179–181], there is no general consensus on what a proper coupling of\ndomains is. A general criterion that measures the quality of handshaking between domains\nwould therefore be desirable. There is plenty of room for innovative research on the issue\n\n30\n\nOverview of Multiscale Simulations of Materials\n\nof domain coupling. General mathematical formulations of multiscale problems, including\nerror estimation, may turn out to be very useful for practical simulations [172, 182]. In\nour view, a successful concurrent approach usually has to satisfy three conditions. First,\nsolve the coupled problem (Hamiltonian) accurately and efficiently by using ideas such as\ncoarse-graining, “bonding energy partition,” or “embedding potential.” Second, the separate models employed in different domains of the system ought to be compatible (i.e., the\nphysical description of the system resulting from the distinct models should be as close as\npossible). Third, at each level, the individual model should provide a good description of its\nassigned domain. We wish to emphasize the importance of the second condition that is not\nin general well recognized. The first condition usually guarantees a “smooth” handshaking\nacross two domains (e.g., the electron density distribution or the displacement field varies\nsmoothly across the interface), but nonphysical charge transfer or atomic relaxation at the\ninterface could occur if the second condition is not satisfied. Therefore, a “smooth” handshaking does not constitute a “good” handshaking, and a successful concurrent approach\nrelies on handshakings that are both mathematically accurate and physically consistent.\nIn this overview, we have also described a number of approaches that strive to extend the\ntemporal scale in the modeling and simulation of material properties. We categorized these\napproaches to methods for accelerating the dynamics, methods for finding transition paths\nbetween equilibrium structures, and methods for escaping free-energy minima. Although\nthese approaches represent very significant developments in the field, the problem of linking\nthe timescale of atomic motion and vibrations (on the order of order femtoseconds) to scales\nat which interesting physical phenomena are typically studied (microseconds and beyond) is\nstill wide open in many respects.\nBecause of the tremendous and continuing progress in multiscale strategies, this review is\nby no means exhaustive. We hope that we have conveyed the message that multiscale modeling is a truly vibrant enterprise of multidisciplinary nature. It combines the skills of physicists,\nmaterials scientists, chemists, mechanical and chemical engineers, applied mathematicians,\nand computer scientists. The marriage of disciplines and the concomitant dissolution of traditional barriers between them represent the true power and embody the great promise\nof multiscale approaches for enhancing our understanding of, and our ability to control,\ncomplex physical phenomena.\n\nACKNOWLEDGMENTS\nWe acknowledge support from grant F49620-99-1-0272 through U.S. Air Force Office for\nScientific Research (Brown University MURI) and from the Harvard Materials Research\nScience and Engineering Center, which is funded by the National Science Foundation. We\nthank V. B. Shenoy and A. Laio for providing Figs. 6 and 7. We are grateful to Nick Choly,\nWeinan E, Paul Maragakis, Ellad Tadmor, and Sidney Yip for useful comments and a critical\nreading of the manuscript.\n\nREFERENCES\n1. R. Phillips, “Crystals, Defects and Microstructures—Modeling Across Scales.” Cambridge University Press,\nCambridge, 2001.\n2. E. Kaxiras and S. Yip (Guest Editors), Curr. Opin. Solid State Mater. Sci. 3, 523 (1998) and accompanying\narticles.\n3. T. Diaz de la Rubia and V. V. Bulatov (Guest Editors), MRS Bull. 26, 169 (2001) and accompanying articles.\n4. S. Yip, Nature Mater. 2, 3 (2003).\n5. W. M. C. Foulkes, L. Mitas, R. J. Needs, and G. Rajagopal, Rev. Mod. Phys. 73, 33 (2001).\n6. A. Szabo, N. S. Ostlund, “Modern Quantum Chemistry.” McGraw-Hill, New York, 1989.\n7. P. Hohenberg and W. Kohn, Phys. Rev. 136, B864 (1964); W. Kohn and L. Sham, ibid. 140, A1133 (1965).\n8. M. C. Payne, M. P. Teter, D. C. Allan, T. A. Arias, and J. D. Joannopoulos, Rev. Mod. Phys. 64, 1045 (1992).\n9. S. Goedecker, Rev. Mod. Phys. 71, 1085 (1999).\n10. L. Colombo, Comput. Mater. Sci. 12, 278 (1998).\n11. M. Z. Bazant and E. Kaxiras, Phys. Rev. Lett. 77, 4370 (1996).\n12. F. Ercolessi and J.B. Adams, Europhys. Lett. 26, 583 (1994).\n13. F. F. Abraham, R. Walkup, H. Gao, M. Duchaineau, T. de la Rubia, and M. Seager, Proc. Natl. Acad. Sci. 99,\n5777 (2002).\n\nOverview of Multiscale Simulations of Materials\n\n31\n\n14. L. P. Kubin and G. R. Canova, Scripta Metall. Mater. 27, 957 (1992).\n15. J. P. Hirth, M. Rhee, and H. M. Zbib, J. Comput. Aided Mater. Des. 3, 164 (1996).\n16. K. W. Schwarz, Phys. Rev. Lett. 78, 4785 (1997).\n17. A. Needleman, Acta Mater. 48, 105 (2000).\n18. V. V. Bulatov, M. Tang, and H. M. Zbib, MRS Bull. 26, 191 (2001).\n19. M. Rhee, H. M. Zbib, J. P. Hirth, H. Huang, and T. de la Rubia, Model. Simul. Mater. Sci. Eng. 6, 467 (1998).\n20. T. J. R. Hughes, “The Finite Element Method.” Prentice-Hall, Englewood Cliffs, NJ, 1987.\n21. P. R. Dawson and E. B. Marin, Adv. Appl. Mech. 34, 77 (1998).\n22. T. Ohashi, Philo. Mag. Lett. 75, 51 (1997).\n23. D. G. Pettifor and I. I. Oleinik, Phys. Rev. Lett. 84, 4124 (2000).\n24. D. G. Pettifor, Phys. Rev. Lett. 63, 2480 (1989).\n25. F. Abraham, J. Broughton, N. Bernstein, and E. Kaxiras, Comput. Phys. 12, 538 (1998).\n26. J. Broughton, F. Abraham, N. Bernstein, and E. Kaxiras, Phys. Rev. B 60, 2391 (1999).\n27. E. Clementi, Philos. Trans. R. Soc. London A 326, 445 (1988).\n28. “Computational and Mathematical Models of Microstructural Evolution” (J. W. Bullard, L. Q. Chen,\nR. K. Kalia, and A. M. Stoneham, Eds.). Mater. Res. Soc. Proc. 529, Warrendale, PA, 1998.\n29. “Multiscale Modeling of Materials” (V. V. Bulatov, T. Diaz de la Rubia, R. Phillips, E. Kaxiras, and\nN. Ghoniem, Eds.). Mater. Res. Soc. Proc. 538, Warrendale, PA, 1999.\n30. “Multiscale Phenomena in Materials—Experiments and Modeling” (I. M. Robertson, D. H. Lassila,\nB. Devincre, and R. Phillips, Eds.). Mater. Res. Soc. Proc. 578, Warrendale, PA, 2000.\n31. “Multiscale Modeling of Materials—2000” (L. P. Kubin, J. L. Bassani, K. Cho, H. Gao, and R. L. B. Selinger,\nEds.). Mater. Res. Soc. Proc. 653, Warrendale, PA, 2001.\n32. G. H. Campbell, S. M. Foiles, H. Huang, D. A. Hughes, W. E. King, D. H. Lassila, D. J. Nikkel, T. Diaaz de\nla Rubia, J. Y. Shu, and V. P. Smyshlyaev, Mater. Sci. Eng. A 251, 1 (1998).\n33. W. E and B. Engquist, Notices of the AMS, 50, 1062 (2003).\n34. M. S. Duesbery and G. Y. Richardson, CRC Crit. Rev. Solid State Mater. Sci. 17, 1 (1991).\n35. V. Vitek, Prog. Mater. Sci. 36, 1 (1992).\n36. B. Joós, Q. Ren, and M. S. Duesbery, Phys. Rev. B 50, 5890 (1994).\n37. B. Joós and M. S. Duesbery, Phys. Rev. Lett. 78, 266 (1997).\n38. Y. Juan and E. Kaxiras, Philos. Mag. A 74, 1367 (1996).\n39. J. Hartford, B. von Sydow, G. Wahnström, and B. I. Lundqvist, Phys. Rev. B 58, 2487 (1998).\n40. B. von Sydow, J. Hartford, and G. Washnström, Comput. Mater. Sci. 15, 367 (1999).\n41. N. I. Medvedeva, O. N. Mryasov, Y. N. Gornostyrev, D. L. Novikov and A. J. Freeman, Phys. Rev. B 54, 13506\n(1996).\n42. O. N. Mryasov, Y. N. Gornostyrev, and A. J. Freeman, Phys. Rev. B 58, 11927 (1998).\n43. V. V. Bulatov and E. Kaxiras, Phys. Rev. Lett. 78, 4221 (1997).\n44. G. Lu, N. Kioussis, V. V. Bulatov, and E. Kaxiras, Phys. Rev. B 62, 3099 (2000); Philos. Mag. Lett. 80, 675\n(2000).\n45. G. Lu, Q. Zhang, N. Kioussis, and E. Kaxiras, Phys. Rev. Lett. 87, 095501 (2001).\n46. G. Lu and E. Kaxiras, Phys. Rev. Lett. 89, 105501 (2002).\n47. G. Lu, V. V. Bulatov, and N. Kioussis, Phys. Rev. B 66, 144103 (2002).\n48. R. Peierls, Proc. Phys. Soc. London 52, 34 (1940).\n49. F. R. N. Nabarro, Proc. Phys. Soc. London 59, 256 (1947).\n50. V. Vitek, Philos. Mag. 18, 773 (1968).\n51. J. D. Eshelby, Philos. Mag. 40, 903 (1949).\n52. J. P. Hirth and J. Lothe, “Theory of Dislocations,” 2nd ed. Wiley, New York, 1992.\n53. S. M. Myers et al., Rev. Mod. Phys. 64, 559 (1992), and references therein.\n54. G. Lu, D. Orlikowski, I. Park, O. Politano, and E. Kaxiras, Phys. Rev. B 65, 064102 (2002).\n55. G. Xu, A. S. Argon, and M. Ortiz, Philos. Mag. A 75, 341 (1997).\n56. J. R. Rice, J. Mech. Phys. Solids 40, 239 (1992); J. R. Rice, G. E. Beltz, and Y. Sun, in “Topics in Fracture\nand Fatigue” (A. S. Argon, Ed.). Springer, Berlin, 1992.\n57. U. V. Waghmare, V. Bulatov, E. Kaxiras, and M. S. Duesbery, Mater. Sci. Eng. A 261, 147 (1999).\n58. U. V. Waghmare, E. Kaxiras, V. Bulatov, and M. S. Duesbery, Model. Simul. Mater. Sci. Eng. 6, 483 (1998).\n59. P. Peralta, S. A. Maloy, F. Chu, J. J. Petrovic, and T. E. Mitchell, Scripta Mater. 37, 1599 (1997).\n60. Z. Suo, Adv. Appl. Mech. 33, 193 (1997).\n61. A. Cocks and S. Gill, Adv. Appl. Mech. 36, 81 (1999).\n62. M. Gurtin, Physica D 92, 178 (1996).\n63. J. Bullard, E. Garboczi, and W. Carter, J. Appl. Phys. 83, 4477 (1998).\n64. D. Fan and L. Q. Chen, Philos. Mag. Lett. 75, 187 (1997).\n65. L. Q. Chen, C. Wolverton, V. Vaithyanathan, and Z. K. Liu, MRS Bull. 26, 197 (2001).\n66. V. Vaithyanathan, C. Wolverton, and L. Q. Chen, Phys. Rev. Lett. 88, 125503 (2002).\n67. Y. Z. Wang, L. Q. Chen, and A. G. Khachaturyan, in “Computer Simulation in Materials Science—\nNano/Meso/Macroscopic Space and Time Scales” (H. Kirchner, L. Kubin, and V. Pontikis, Eds.). NATO ASI\nSeries, Ile d’Oleron, France, 1995.\n68. L. Q. Chen and Y. Z. Wang, JOM 48, 13 (1996).\n69. D. Y. Li and L. Q. Chen, Acta Mater. 46, 2573 (1998).\n70. A. G. Khachaturyan, “Theory of Structural Transformations in Solids.” John Wiley, New York, 1983.\n\n32\n\nOverview of Multiscale Simulations of Materials\n\n71. J. W. Cahn, Acta Metall. 9, 795 (1961).\n72. P. C. Hohenberg and B. I. Halperin, Rev. Mod. Phys. 49, 435 (1977).\n73. A. Zunger, in “Statics and Dynamics of Alloy Phase Transformations” (P. E. A. Turchi and A. Gonis, Eds.),\np. 361. NATO ASI Series, Plenum, New York, 1994.\n74. D. de Fontaine, Solid State Phys. 47, 33 (1994).\n75. C. Wolverton, Philos. Mag. Lett. 79, 683 (1999); Model. Simul. Mater. Sci. Eng. 8, 323 (2000).\n76. D. B. Laks, L. G. Ferreira, S. Froyen, and A. Zunger, Phys. Rev. B 46, 12587 (1992).\n77. L. Kaufman and H. Bernstein, “Computer Calculation of Phase Diagrams with Special Reference to Refractory\nMetals.” Academic Press, New York, 1970.\n78. N. Saunders and A. P. Miodownik, “CALPHAD: A Comprehensive Guide.” Pergamon, Oxford, 1998.\n79. P. J. Spencer, MRS Bull. 24, 18 (1999).\n80. D. Kandel and E. Kaxiras, Solid State Phys. 54, 219 (2000).\n81. P. Kratzer and M. Scheffler, Comput. Sci. Eng. 3, 16 (2001).\n82. W. Cai, V. V. Bulatov, J. F. Justo, S. Yip, and A. S. Argon, Phys. Rev. Lett. 84, 3346 (2000).\n83. C. Ratsch, M. F. Gyure, R. E. Caflisch, M. Petersen, M. Kang, J. Garcia, and D. D. Vvedensky, Phys. Rev. B\n65, 195403 (2002).\n84. M. F. Gyure, C. Ratsch, B. Merriman, R. E. Caflisch, S. Osher, J. Zinck, and D. D. Vvedensky, Phys. Rev. E\n58, 6927 (1998).\n85. S. Osher and J. A. Sethian, J. Comput. Phys. 79, 12 (1988).\n86. C. W. Shu and S. Osher, J. Comput. Phys. 83, 32 (1989).\n87. C. S. Deo, D. J. Srolovitz, W. Cai and V. V. Bulatov, to be published.\n88. V. Bulatov, F. F. Abraham, L. Kubin, B. Devincre and S. Yip, Nature 391, 669 (1998).\n89. A. Needleman and E. Van der Giessen, MRS Bull. 26, 211 (2001).\n90. F. Stillinger and T. A. Weber, Phys. Rev. B 31, 5262 (1985).\n91. N. Bernstein and E. Kaxiras, Phys. Rev. B 56, 10488 (1997).\n92. K. Ohsawa and E. Kuramoto, J. Appl. Phys. 86, 179 (1999).\n93. F. F. Abraham and H. Gao, Phys. Rev. Lett. 84, 3113 (2000).\n94. S. J. Zhou, P. S. Lomdahl, R. Thomson, and B. L. Holian, Phys. Rev. Lett. 76, 2318 (1996).\n95. B. L. Holian and R. Ravelo, Phys. Rev. B 51, 11275 (1995).\n96. P. Gumbsch, S. J. Zhou, and B. L. Holian, Phys. Rev. B 55, 3445 (1997).\n97. S. J. Carroll, P. D. Nellist, R. E. Palmer, S. Hobday, and R. Smith, Phys. Rev. Lett. 84, 2654 (2000).\n98. M. Moseler, J. Nordiek, and H. Haberland, Phys. Rev. B 56, 15439 (1997).\n99. N. Choly and E. Kaxiras, Solid State Comm. 121, 281 (2002).\n100. S. Watson, and E. Carter, Comput. Phys. Comm. 128, 67 (2000).\n101. S. Kohlhoff, P. Gumbsch, and H. F. Fischmeister, Philos. Mag. A 64, 851 (1991).\n102. P. Gumbsch, J. Mater. Res. 10, 2897 (1995).\n103. E. B. Tadmor, M. Ortiz, and R. Phillips, Philos. Mag. A 73, 1529 (1996).\n104. E. B. Tadmor, R. Phillips, and M. Ortiz, Langmuir 12, 4529 (1996).\n105. V. B. Shenoy, R. Miller, E. B. Tadmor, R. Phillips, and M. Ortiz, Phys. Rev. Lett. 80, 742 (1998).\n106. R. Miller, E. B. Tadmor, R. Phillips, and M. Ortiz, Model. Simul. Mater. Sci. Eng. 6, 607 (1998).\n107. R. Miller, M. Ortiz, R. Phillips, V. Shenoy, and E. B. Tadmor, Eng. Fracture Mech. 61, 427 (1998).\n108. D. Rodney and R. Phillips, Phys. Rev. Lett. 82, 1704 (1999).\n109. V. B. Shenoy, R. Miller, E. B. Tadmor, D. Rodney, R. Phillips, and M. Ortiz, J. Mech. Phys. Solid 47, 611\n(1999).\n110. E. B. Tadmor, R. Miller, R. Phillips, and M. Ortiz, J. Mater. Res. 14, 2233 (1999).\n111. V. B. Shenoy, R. Phillips, and E. B. Tadmor, J. Mech. Phys. Solid 48, 649 (2000).\n112. G. S. Smith, E. B. Tadmor, and E. Kaxiras, Phys. Rev. Lett. 84, 1260 (2000).\n113. J. Knap and M. Ortiz, J. Mech. Phys. Solid 49, 1899 (2001).\n114. G. S. Smith, E. B. Tadmor, N. Bernstein, and E. Kaxiras, Acta Mater. 49, 4089 (2001).\n115. V. Shenoy, V. Shenoy, and R. Phillips, in “Multiscale Modeling of Materials,” (V. V. Bulatov, T. Diaz de la\nRubia, R. Phillips, E. Kaxiras, and N. Ghoniem, Eds.), p. 465. Mater. Res. Soc. Symp. Proc. 538, Warrendale,\nPA, 1999.\n116. A. H. King and D. A. Smith, Acta Crystallogr. A 36, 335 (1980).\n117. E. B. Tadmor, G. S. Smith, N. Bernstein, and E. Kaxiras, Phys. Rev. B 59, 235 (1999).\n118. E. B. Tadmor, U. V. Waghmare, G. S. Smith, and E. Kaxiras, Acta Mater. 50, 2989 (2002).\n119. R. E. Rudd and J. Q. Broughton, Phys. Rev. B 58, R5893 (1998).\n120. R. E. Rudd and J. Q. Broughton, Phys. Stat. Sol. 217, 251 (2000).\n121. R. E. Rudd and J. Q. Broughton (unpublished).\n122. S. Curtarolo and G. Ceder. Phys. Rev. Lett. 88, 255504 (2002).\n123. A. A. Migdal, Zh. Eksp. Teor. Fiz. 69, 1457 (1975); L. P. Kadanoff, Ann. Phys. (N.Y.) 100, 259 (1968).\n124. L. E. Shilkrot, R. E. Miller, and W. A. Curtin, Phys. Rev. Lett. 89, 025501 (2002).\n125. E. van der Giessen and A. Needleman, Model. Simul. Mater. Sci. Eng. 3, 689 (1995).\n126. N. Bernstein and D. Hess, Mat. Res. Soc. Symp. Proc. 653, Z2.7.1 (2001).\n127. E. Lidorikis, M. Bachlechner, R. K. Kalia, A. Nakano, P. Vashishta, and G. Z. Voyiadjis, Phys. Rev. Lett. 87,\n086104 (2001).\n128. C. Woodward and S. I. Rao, Phys. Rev. Lett. 88, 216402 (2002).\n129. K. Kremer and F. Müller-Plathe, MRS Bull. 26, 205 (2001).\n\nOverview of Multiscale Simulations of Materials\n\n33\n\n130. J. Gao, Rev. Comput. Chem. 7, 119 (1996).\n131. Q. Cui, M. Elstner, E. Kaxiras, T. Frauenheim, and M. Karplus, J. Phys. Chem. B 105, 569 (2001).\n132. M. Elstner, D. Porezag, G. Jungnickel, J. Elsner, M. Haugk, T. Frauenheim, S. Suhai, and D. Seifert, Phys.\nRev. B 58, 7260 (1998).\n133. B. R. Brooks, R. E. Burccoleri, B. D. Olafson, D. J. States, S. Swaminathan, and M. Karplus, J. Compt. Chem.\n4, 187 (1983).\n134. N. Govind, Y. A. Wang, A. J. R. da Silva, and E. A. Carter, Chem. Phys. Lett. 295, 129 (1998).\n135. N. Govind, Y. A. Wang, and E. A. Carter, J. Chem. Phys. 110, 7677 (1999).\n136. T. A. Wesolowski and A. Warshel, J. Phys. Chem. 97, 8050 (1993).\n137. T. Kluner, N. Govind, Y. A. Wang, and E. A. Carter, Phys. Rev. Lett. 86, 5694 (2001).\n138. A. F. Voter, F. Montalenti, and T. C. Germann, Annu. Rev. Mater. Res. 32, 321 (2002).\n139. A. F. Voter, J. Chem. Phys. 106, 4665 (1997).\n140. A. F. Voter, Phys. Rev. Lett. 78, 3908 (1997).\n141. R. Marcelin, Ann. Phys. 3, 120 (1915).\n142. E. Wigner, Z. Phys. Chem. B 19, 203 (1932).\n143. H. Eyring, J. Chem. Phys. 3, 107 (1935).\n144. P. Hanggi, P. Talkner, and M. Borkovec, Rev. Mod. Phys. 62, 251 (1990).\n145. J. B. Anderson, Adv. Chem. Phys. 91, 381 (1995).\n146. G. H. Vineyard, J. Phys. Chem. Solid 3, 121 (1957).\n147. A. F. Voter, Phys. Rev. B 57, R13985 (1998).\n148. M. Sørensen and A. F. Voter, J. Chem. Phys. 112, 9599 (2000).\n149. R. Elber and M. Karplus, Chem. Phys. Lett. 139, 375 (1987).\n150. H. Jonsson, G. Mills, and K. W. Jacobsen, in “Computer Simulation of Rare Events and Dynamics of Classical\nand Quantum Condensed-Phase Systems” (B. J. Berne, G. Ciccotti, and D. Coker, Eds.). World Scientific,\nSingapore, 1998.\n151. G. Henkelman, G. Johannesson, and H. Jonsson, in “Progress on Theoretical Chemistry and Physics,” (S. D.\nSchwartz, Ed.). Kluwer Academic Publishers, 2000.\n152. H. C. Anderson, J. Chem. Phys. 72, 2384 (1980).\n153. G. Henkelman, B. Uberuaga, and H. Jonsson, J. Chem. Phys. 113, 9901 (2000).\n154. P. Maragakis, S. Andreev, Y. Brumer, D. Reichman, and E. Kaxiras, J. Chem. Phys. 117, 4651 (2002).\n155. T. Rasmussen, K. W. Jacobsen, T. Leffers, O. B. Petersen, S. G. Srinivasan, and H. Jonsson, Phys. Rev. Lett.\n79, 3676 (1997).\n156. M. Villarba and H. Jonsson, Surf. Sci. 317, 35 (1994).\n157. B. P. Uberuaga, M. Leskovar, A. P. Smith, H. Jonsson, and M. Olmstead, Phys. Rev. Lett. 84, 2441 (2000).\n158. G. Mills and H. Jonsson, Phys. Rev. Lett. 72, 1124 (1994).\n159. M. R. Sorensen, K. W. Jacobsen, and H. Josson, Phys. Rev. Lett. 77, 5067 (1996).\n160. C. Dellago, P. G. Bolhuis, F. S. Csajka, and D. Chandler, J. Chem. Phys. 108, 1964 (1998).\n161. P. G. Bolhuis, C. Dellago, and D. Chandler, Faraday Discuss. Chem. Soc. 110, 421 (1998).\n162. P. G. Bolhuis, D. Chandler, C. Dellago, and P. L. Geissler, Annu. Rev. Phys. Chem. 53, 291 (2002).\n163. W. E, W. Ren and E. Vanden-Eijnden, to be published.\n164. D. Passerone and M. Parrinello, Phys. Rev. Lett. 87, 108302 (2001).\n165. R. E. Gillilan and K. R. Wilson, J. Chem. Phys. 97, 1757 (1992).\n166. K. Mueller, Angew. Chem. 19, 1 (1980).\n167. C. Dellago, P. G. Bolhuis, and D. Chandler, J. Chem. Phys. 108, 9326 (1998).\n168. R. Car and M. Parrinello, Phys. Rev. Lett. 55, 2471 (1985).\n169. V. Zaloj and R. Elber, Comput. Phys. Commun. 128, 118 (2000).\n170. A. Laio and M. Parrinello, Proc. Natl. Acad. Sci. 99, 12562 (2002).\n171. I. G. Kevrekidis, C. Theodoropoulos, and C. W. Gear, Computers and Chemical Engineering (to be published).\n172. W. E and B. Engquist, Comm. Math Sci. 1, 87 (2003).\n173. T. Huber, A. E. Torda, and W. F. van Gunsteren, J. Comput. Aided Mol. Design 8, 695 (1994).\n174. F. Wang and D. P. Landau, Phys. Rev. Lett. 86, 2050 (2001).\n175. R. D. Swindoll and J. M. Haile, J. Comput. Phys. 53, 289 (1984).\n176. O. Teleman and B. Jonsson, J. Comput. Chem. 7, 58 (1986).\n177. M. E. Tuckerman, G. J. Martyna, and B. J. Berne, J. Chem. Phys. 93, 1287 (1990).\n178. R. Elber, A. Ghosh, and A. Cardenas, Acc. Chem. Res. 35, 396 (2002).\n179. W. Cai, M. de Koning, V. V. Bulatov, and S. Yip, Phys. Rev. Lett. 85, 3213 (2000).\n180. W. E and Z. Huang, Phys. Rev. Lett. 87, 135501 (2001).\n181. W. E and Z. Huang, J. Comput. Phys. 182, 234 (2002).\n182. W. E, B. Engquist, and Z. Huang, Phys. Rev. B 67, 092101 (2003).\n\n","pages":{"startPosition":[0,5000,9997,14991,19998,24991,30000,34998,39992,44995,50000,54997,59998,65000,69994,75001,79999,84996,89998,95000,99996,104997,109996,115001,119999,124996,130001,134995]}},"html":{"comparison":{"identical":{"groupId":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,6,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9],"source":{"chars":{"starts":[3776017,3776034,3776042,3776059,3776067,3776084,3776092,3776109,3776117,3776134,3776142,3776159,3776167,3776184,3776192,3776209,3776217,3776234,3776242,3794672,3794689,3794697,3794714,3794722,3794739,3794747,3794764,3794772,3794789,3794797,3794814,3794822,3794839,3794847,3794864,3794872,3794889,3794897,3794914,3794922,3794939,3794947,3794964,3794972,3794989,3794997,3839244,3839261,3839269,3839286,3839294,3839311,3839319,3839336,3839344,3839361,3839369,3839386,3839394,3839411,3839419,3839436,3839444,3839461,3839469,3839486,3839494,3839511,3839519,3839536,3839544,3909967,3909984,3909992,3910009,3910017,3910034,3910042,3910059,3910067,3910084,3910092,3910109,3910117,3910134,3910142,3910159,3910167,3910184,3910192,3910209,3910217,3910234,3910242,4025419,4025436,4025444,4025461,4025469,4025486,4025494,4025511,4025519,4025536,4025544,4025561,4025569,4025586,4025594,4025611,4025619,4025636,4025644,4025661,4025669,4027458,4027475,4027483,4027500,4027508,4027525,4027533,4027550,4027558,4027575,4027583,4027600,4027608,4027625,4027633,4027650,4027658,4027675,4027683,4027700,4027708,4027725,4027733,4064367,4064384,4064392,4064409,4064417,4064434,4064442,4064459,4064467,4064484,4064492,4064509,4064517,4064534,4064542,4064559,4064567,4064584,4064592,4064609,4064617,4064634,4064642,4074420,4074437,4074445,4074462,4074470,4074487,4074495,4074512,4074520,4074537,4074545,4074562,4074570,4074587,4074595,4074612,4074620,4074637,4074645,4074662,4074670,4074687,4074695,4074712,4074720,4074737,4074745,4074762,4074770,4074787,4074795,4078912,4078929,4078937,4078954,4078962,4078979,4078987,4079004,4079012,4079029,4079037,4079054,4079062,4079079,4079087,4079104,4079112,4079129,4079137,4079154,4079162,4081529,4081546,4081554,4081571,4081579,4081596,4081604,4081621,4081629,4081646,4081654,4081671,4081679,4081696,4081704,4081721,4081729,4081746,4081754,4081771,4081779,4081796,4081804,4081821,4081829,4081846,4081854,4081871,4081879,4081896,4081904],"lengths":[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]},"words":{"starts":[8314,8314,8314,8314,8314,8314,8314,8314,8314,8314,8314,8314,8314,8314,8314,8314,8314,8314,8314,8511,8511,8511,8511,8511,8511,8511,8511,8511,8511,8511,8511,8511,8511,8511,8511,8511,8511,8511,8511,8511,8511,8511,8511,8511,8511,8511,9545,9545,9545,9545,9545,9545,9545,9545,9545,9545,9545,9545,9545,9545,9545,9545,9545,9545,9545,9545,9545,9545,9545,9545,9545,11035,11035,11035,11035,11035,11035,11035,11035,11035,11035,11035,11035,11035,11035,11035,11035,11035,11035,11035,11035,11035,11035,11035,13660,13660,13660,13660,13660,13660,13660,13660,13660,13660,13660,13660,13660,13660,13660,13660,13660,13660,13660,13660,13660,13735,13735,13735,13735,13735,13735,13735,13735,13735,13735,13735,13735,13735,13735,13735,13735,13735,13735,13735,13735,13735,13735,13735,14573,14573,14573,14573,14573,14573,14573,14573,14573,14573,14573,14573,14573,14573,14573,14573,14573,14573,14573,14573,14573,14573,14573,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,14914,15073,15073,15073,15073,15073,15073,15073,15073,15073,15073,15073,15073,15073,15073,15073,15073,15073,15073,15073,15073,15073,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144,15144],"lengths":[9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15]}},"suspected":{"chars":{"starts":[380,380,380,380,380,380,380,380,380,380,380,380,380,380,380,380,380,380,380,261,261,261,261,261,261,261,261,261,261,261,261,261,261,261,261,261,261,261,261,261,261,261,261,261,261,261,530,530,530,530,530,530,530,530,530,530,530,530,530,530,530,530,530,530,530,530,530,530,530,530,530,857,857,857,857,857,857,857,857,857,857,857,857,857,857,857,857,857,857,857,857,857,857,857,1057,1057,1057,1057,1057,1057,1057,1057,1057,1057,1057,1057,1057,1057,1057,1057,1057,1057,1057,1057,1057,1081,1081,1081,1081,1081,1081,1081,1081,1081,1081,1081,1081,1081,1081,1081,1081,1081,1081,1081,1081,1081,1081,1081,1166,1166,1166,1166,1166,1166,1166,1166,1166,1166,1166,1166,1166,1166,1166,1166,1166,1166,1166,1166,1166,1166,1166,1228,1228,1228,1228,1228,1228,1228,1228,1228,1228,1228,1228,1228,1228,1228,1228,1228,1228,1228,1228,1228,1228,1228,1228,1228,1228,1228,1228,1228,1228,1228,1304,1304,1304,1304,1304,1304,1304,1304,1304,1304,1304,1304,1304,1304,1304,1304,1304,1304,1304,1304,1304,1366,1366,1366,1366,1366,1366,1366,1366,1366,1366,1366,1366,1366,1366,1366,1366,1366,1366,1366,1366,1366,1366,1366,1366,1366,1366,1366,1366,1366,1366,1366],"lengths":[19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,19,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,27,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,25,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,23,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,21,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31,31]},"words":{"starts":[86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,86,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,40,123,123,123,123,123,123,123,123,123,123,123,123,123,123,123,123,123,123,123,123,123,123,123,123,123,232,232,232,232,232,232,232,232,232,232,232,232,232,232,232,232,232,232,232,232,232,232,232,301,301,301,301,301,301,301,301,301,301,301,301,301,301,301,301,301,301,301,301,301,313,313,313,313,313,313,313,313,313,313,313,313,313,313,313,313,313,313,313,313,313,313,313,345,345,345,345,345,345,345,345,345,345,345,345,345,345,345,345,345,345,345,345,345,345,345,363,363,363,363,363,363,363,363,363,363,363,363,363,363,363,363,363,363,363,363,363,363,363,363,363,363,363,363,363,363,363,388,388,388,388,388,388,388,388,388,388,388,388,388,388,388,388,388,388,388,388,388,412,412,412,412,412,412,412,412,412,412,412,412,412,412,412,412,412,412,412,412,412,412,412,412,412,412,412,412,412,412,412],"lengths":[9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,13,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,12,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,11,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,10,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15,15]}}},"minorChanges":{"groupId":[],"source":{"chars":{"starts":[],"lengths":[]},"words":{"starts":[],"lengths":[]}},"suspected":{"chars":{"starts":[],"lengths":[]},"words":{"starts":[],"lengths":[]}}},"relatedMeaning":{"groupId":[],"source":{"chars":{"starts":[],"lengths":[]},"words":{"starts":[],"lengths":[]}},"suspected":{"chars":{"starts":[],"lengths":[]},"words":{"starts":[],"lengths":[]}}}}},"version":3}